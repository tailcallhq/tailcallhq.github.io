"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[8749],{91895:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"what-is-grpc","metadata":{"permalink":"/blog/what-is-grpc","source":"@site/blog/what-is-grpc-2024-07-13.mdx","title":"gRPC Decoded: The API Protocol That\'s Changing Everything","description":"Demystify gRPC and its impact on modern software architecture. Explore how this powerful tool is reshaping the landscape of API communication.","date":"2024-07-13T00:00:00.000Z","tags":[],"readingTime":13.89,"hasTruncateMarker":true,"authors":[{"name":"Hunain Ahmed","title":"A freelance software developer, always working on something new and fascinating.","url":"https://github.com/hunxjunedo","image_url":"https://avatars.githubusercontent.com/u/89797440?v=4","imageURL":"https://avatars.githubusercontent.com/u/89797440?v=4"}],"frontMatter":{"title":"gRPC Decoded: The API Protocol That\'s Changing Everything","sidebar_label":"What is gRPC","description":"Demystify gRPC and its impact on modern software architecture. Explore how this powerful tool is reshaping the landscape of API communication.","image":"/images/docs/grpc_logo.png","authors":[{"name":"Hunain Ahmed","title":"A freelance software developer, always working on something new and fascinating.","url":"https://github.com/hunxjunedo","image_url":"https://avatars.githubusercontent.com/u/89797440?v=4","imageURL":"https://avatars.githubusercontent.com/u/89797440?v=4"}],"hide_table_of_contents":true,"slug":"what-is-grpc"},"unlisted":false,"nextItem":{"title":"Are Hackers Using Your Own GraphQL API Against You?","permalink":"/blog/graphql-introspection-security"}},"content":"![gRPC Logo](/images/docs/grpc_logo.png)\\n\\ngRPC is an open-source RPC (Remote Procedure Call) framework initially developed by Google. It enables efficient communication between services across different environments, utilizing a binary serialization format called Protocol Buffers (Protobuf) over HTTP/2.\\n\\n\x3c!-- truncate --\x3e\\n\\ngRPC plays a crucial role in modernizing software architectures by providing efficient, high-performance communication channels. Due to it\'s low-latency, it is used by many well-known software like Kubernetes, CockroachDB and Netflix etc.\\n\\n[An Example Snippet from Kubernetes](https://github.com/kubernetes/kubernetes/blob/0c8b3e5f305bf2bf56d47019199b81330d90c2c3/staging/src/k8s.io/kms/apis/v1beta1/api.proto#L29)\\n\\n_sample code for gRPC:_\\n\\n```protobuf\\n\\nsyntax = \\"proto3\\";\\n\\npackage greeting;\\n\\nservice GreetingService {\\n  rpc SayHello (HelloRequest) returns (HelloResponse);\\n}\\n\\nmessage HelloRequest {\\n  string name = 1;\\n}\\n\\nmessage HelloResponse {\\n  string message = 1;\\n}\\n\\n```\\n\\n## The Evolution of API Communication\\n\\n![evolution](/images/docs/timeline.png)\\n\\nRequest\u2013response protocols date back to early distributed computing in the late 1960s. Theoretical proposals of remote procedure calls as the model of network operations date to the 1970s, with practical implementations emerging in the early 1980s. Traditional RPC mechanisms had limitations in terms of performance, language independence, and flexibility. gRPC addresses these issues by leveraging modern protocols and technologies.\\n\\ngRPC was initially created by Google, which used a single general-purpose RPC infrastructure called Stubby to connect its numerous microservices. In 2015, Google decided to build the next version of Stubby and make it open source.\\n\\n## Understanding gRPC\\n\\ngRPC is a high-performance, language-neutral RPC framework. It uses Protobuf for serialization and HTTP/2 for transport, offering features like streaming, multiplexing, and bidirectional communication. It uses HTTP/2 for transport, Protocol Buffers as the interface description language, and provides features such as authentication, bidirectional streaming and flow control, blocking or nonblocking bindings, and cancellation and timeouts.\\n\\n### Key components of gRPC\\n\\n- **Protocol Buffers (Protobuf):** A language-neutral, platform-neutral, extensible mechanism for serializing structured data. It is used to define the structure of messages (request and response payloads) that gRPC services exchange.\\n\\n- **HTTP/2:** Provides additional capabilities such as multiplexing, header compression, and server push, which are not as efficient and reliable in HTTP/1.1\\n\\n### How gRPC works (step-by-step process)\\n\\n![step by step process](/images/docs/steps.png)\\n\\ngRPC (Remote Procedure Call) works using a straightforward yet powerful mechanism that facilitates communication between clients and servers in a distributed system.\\n\\n### 1. Service Definition\\n\\n- **Protocol Buffers (Protobuf)**: The starting point for using gRPC is defining a service and its methods using Protocol Buffers (Protobuf). Protobuf is a language-neutral, platform-neutral, extensible mechanism for serializing structured data. The structure of data and services is defined in a `.proto` file.\\n\\n[An Example Snippet From Linkerd](https://github.com/linkerd/linkerd2/blob/ad0546b488fad76879e654ad91ceed1e9e53d630/proto/common/net.proto#L4)\\n\\n_Example of a simple `.proto` file :_\\n\\n```protobuf\\nsyntax = \\"proto3\\";\\n\\npackage calculator;\\n\\nservice CalculatorService {\\n  rpc Add (AddRequest) returns (AddResponse);\\n}\\n\\nmessage AddRequest {\\n  double number1 = 1;\\n  double number2 = 2;\\n}\\n\\nmessage AddResponse {\\n  double result = 1;\\n}\\n\\n```\\n\\n### 2. Code Generation\\n\\nOnce a service is defined in a .proto file, the Protocol Buffer compiler (protoc) is used to generate client and server code in your chosen programming languages. This step is crucial as it automates the creation of the boilerplate code needed for the gRPC service and client to communicate effectively. The generated code includes:\\n\\n- **Service Stubs:** These are classes with methods that correspond to the service methods defined in the .proto file. They handle the marshalling and unmarshalling of request and response messages, abstracting away the complexities of network communication.\\n\\n- **Client-Side Stubs:** These are used by the client application to make remote procedure calls to the server. The client stubs handle the creation and sending of requests, as well as receiving and processing responses.\\n\\nFor Example if the calculator example is converted to python, it would look something like this:\\n\\n```python\\n# -*- coding: utf-8 -*-\\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\\n# source: calculator\\n\\"\\"\\"Generated protocol buffer code.\\"\\"\\"\\nfrom google.protobuf import descriptor as _descriptor\\nfrom google.protobuf import descriptor_pool as _descriptor_pool\\nfrom google.protobuf import message as _message\\nfrom google.protobuf import reflection as _reflection\\nfrom google.protobuf import symbol_database as _symbol_database\\n# @@protoc_insertion_point(imports)\\n\\n_sym_db = _symbol_database.Default()\\n\\n\\n\\n\\nDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b\'\\\\n\\\\ncalculator\\\\x12\\\\ncalculator\\\\\\".\\\\n\\\\nAddRequest\\\\x12\\\\x0f\\\\n\\\\x07number1\\\\x18\\\\x01 \\\\x01(\\\\x01\\\\x12\\\\x0f\\\\n\\\\x07number2\\\\x18\\\\x02 \\\\x01(\\\\x01\\\\\\"\\\\x1d\\\\n\\\\x0b\\\\x41\\\\x64\\\\x64Response\\\\x12\\\\x0e\\\\n\\\\x06result\\\\x18\\\\x01 \\\\x01(\\\\x01\\\\x32K\\\\n\\\\x11\\\\x43\\\\x61lculatorService\\\\x12\\\\x36\\\\n\\\\x03\\\\x41\\\\x64\\\\x64\\\\x12\\\\x16.calculator.AddRequest\\\\x1a\\\\x17.calculator.AddResponseb\\\\x06proto3\')\\n\\n\\n\\n_ADDREQUEST = DESCRIPTOR.message_types_by_name[\'AddRequest\']\\n_ADDRESPONSE = DESCRIPTOR.message_types_by_name[\'AddResponse\']\\nAddRequest = _reflection.GeneratedProtocolMessageType(\'AddRequest\', (_message.Message,), {\\n\'DESCRIPTOR\' : _ADDREQUEST,\\n\'__module__\' : \'calculator_pb2\'\\n# @@protoc_insertion_point(class_scope:calculator.AddRequest)\\n})\\n_sym_db.RegisterMessage(AddRequest)\\n\\nAddResponse = _reflection.GeneratedProtocolMessageType(\'AddResponse\', (_message.Message,), {\\n\'DESCRIPTOR\' : _ADDRESPONSE,\\n\'__module__\' : \'calculator_pb2\'\\n# @@protoc_insertion_point(class_scope:calculator.AddResponse)\\n})\\n_sym_db.RegisterMessage(AddResponse)\\n\\n_CALCULATORSERVICE = DESCRIPTOR.services_by_name[\'CalculatorService\']\\nif _descriptor._USE_C_DESCRIPTORS == False:\\n\\nDESCRIPTOR._options = None\\n_ADDREQUEST._serialized_start=26\\n_ADDREQUEST._serialized_end=72\\n_ADDRESPONSE._serialized_start=74\\n_ADDRESPONSE._serialized_end=103\\n_CALCULATORSERVICE._serialized_start=105\\n_CALCULATORSERVICE._serialized_end=180\\n# @@protoc_insertion_point(module_scope)\\n\\n```\\n\\n### 3. Client-Server Communication\\n\\n- **Transmission**:\\n  When a gRPC client initiates a request to a gRPC server, it sends an HTTP/2 request containing the service name, specific method, and serialized parameters using Protobuf. HTTP/2\'s advantages include multiplexing, enabling concurrent handling of multiple streams over a single connection, binary framing that minimizes overhead and accelerates data exchange, efficient header compression via HPACK, and integrated flow control mechanisms.\\n\\n### 4. Serialization and Deserialization\\n\\n- **Protobuf Serialization**: Data exchanged between gRPC clients and servers is serialized and deserialized using Protobuf.\\n\\n## gRPC Service Methods\\n\\n![gRPC Methods](/images/docs/methods.png)\\n\\n- **Unary RPC**: This is the simplest form where the client sends a single request to the server and receives a single response:\\n\\n  ```protobuf\\n  service MyService { rpc UnaryExample(MyRequest) returns (MyResponse); }\\n  ```\\n\\n- **Server Streaming RPC**: The client sends a request to the server and receives a stream of responses:\\n\\n  ```protobuf\\n  service MyService { rpc UnaryExample(MyRequest) returns (stream MyResponse); }\\n  ```\\n\\n- **Client Streaming RPC**: The client sends a stream of requests to the server and receives a single response:\\n\\n  ```protobuf\\n  service MyService { rpc UnaryExample(stream MyRequest) returns (MyResponse); }\\n  ```\\n\\n- **Bidirectional Streaming RPC**: Both the client and server send a stream of messages to each other, establishing a persistent connection:\\n  ```protobuf\\n  service MyService { rpc UnaryExample(stream MyRequest) returns (stream MyResponse); }\\n  ```\\n\\n## gRPC vs. REST: Basic Comparison\\n\\n![payload size comparison](/images/docs/size-compare.png)\\n\\n_A comparison of payload sizes: REST JSON vs gRPC binary [checkout full comparison ](https://nilsmagnus.github.io/post/proto-json-sizes/)_\\n\\n### Communication model\\n\\n- **gRPC:** RPC-based, strong typing, and allows unary and bi-directional streaming, making it feasible for modern-day applications and use-cases.\\n- **REST:** Stateless, used for CRUD-based operations over HTTP, follows a simple unary request/response cycle.\\n\\n### Data format and serialization\\n\\n- **gRPC:** Uses Protobuf for efficient binary serialization.\\n- **REST:** Uses a plain-text format like JSON and XML, which requires more processing in order to parse.\\n\\n### Use cases for each\\n\\n- **gRPC:** Suitable for internal microservices, real-time applications, and situations needing high-performance and time-sensitive communication.\\n- **REST:** Better for public APIs, browser-based applications, and situations requiring stateless operations where ease of use is a priority.\\n\\n## Advantages of gRPC\\n\\n### Efficiency and performance\\n\\n![gRPC performance](/images/docs/grpc_performance.webp)\\n\\nProtobuf efficiently serializes messages on both the server and client sides, ensuring that data is transmitted in a compact binary format. This results in smaller message payloads, which are quicker to transmit over the network compared to the verbose JSON format used in REST APIs.\\n\\nIn addition, HTTP/2 uses features like header-compression, multiplexing and server-push which significantly reduce the payload size, as well as make response faster.\\n\\nThese features collectively contribute to significant performance gains, making gRPC [7-10 times](https://medium.com/@EmperorRXF/evaluating-performance-of-rest-vs-grpc-1b8bdf0b22da) faster than traditional REST APIs using JSON.\\n\\n### Language-agnostic nature\\n\\n![gRPC Language Agnostic](/images/docs/language_agnostic.png)\\n\\ngRPC uses Protocol Buffers (Protobuf) as its (IDL) for describing both the structure and the semantics of the messages sent between clients and servers. Protobuf is independent of programming languages, meaning you can define your API once using Protobuf and then generate code in various languages to interact with it. This allows seamless integration of sub-systems API specification, while also enhancing the DX.\\n\\n### Strong typing and code generation\\n\\nProtocol Buffers (Protobuf) defines both the structure and the types of messages exchanged between clients and servers within a .proto file, thereby establishing a clear and standardized API contract. This contract specifies the fields and their data types for each message, ensuring consistency and predictability in communication. By enforcing strong typing, Protobuf enhances code reliability by detecting type-related errors during compilation rather than at runtime. This approach not only prevents type mismatches and potential bugs but also saves developers time that would otherwise be spent implementing manual type-checking. Additionally, Protobuf\'s built-in type safety simplifies the development process, allowing developers to focus more on business logic and less on handling data integrity issues, thus improving the developer experience.\\n\\n### Bidirectional streaming capabilities\\n\\nUnlike traditional RPC methods that are unidirectional (either client-to-server or server-to-client), gRPC\'s bidirectional streaming allows both parties to establish a persistent connection and send a sequence of messages asynchronously.\\n\\nBidirectional streaming is particularly beneficial for applications requiring interactive and responsive communication, such as chat systems, collaborative tools, multiplayer games, and real-time data feeds.\\n\\n### Extensibility and backward compatibility\\n\\ngRPC using Protobuf as the IDL opens support for extensibility by allowing new fields, messages, and services to be added to the `.proto` file definitions. As services evolve, these changes can be propagated through automated code generation using the `protoc` compiler, which produces language-specific stubs and serializers/deserializers.\\n\\nMoreover, explicit versioning and API contracts defined in the `.proto` files help manage compatibility between different versions of services. During the RPC connection handshake, gRPC allows clients and servers to negotiate capabilities, ensuring that both parties can communicate effectively even if they support different versions or extensions.\\n\\n**_Example:_**\\n\\n```protobuf\\nsyntax = \\"proto3\\";\\n\\npackage greet.v1;\\n\\nservice Greeter {\\n  rpc SayHello (HelloRequest) returns (HelloReply);\\n}\\n\\nmessage HelloRequest {\\n  string name = 1;\\n}\\n\\nmessage HelloReply {\\n  string message = 1;\\n}\\n\\n```\\n\\n## Challenges and Considerations\\n\\n### Learning curve\\n\\ngRPC has a much steeper learning curve compared to the traditional REST, mainly due to some new concepts like HTTP/2 and Protobuf which require significant practice and experience.\\n\\n### Debugging complexity\\n\\nDebugging gRPC applications can be really challenging compared to traditional REST APIs. The binary nature of Protobuf messages makes it difficult to inspect and manipulate payloads directly. Tools for debugging and tracing gRPC calls are available, but they often require additional setup and expertise.\\n\\n### Ecosystem maturity\\n\\nWhile gRPC has gained significant traction and support, its ecosystem is still maturing compared to REST. Some languages and frameworks may have limited or incomplete support for gRPC features. Additionally, there is less developer support on the internet, less browser-support and very few articles published which makes it challenging to learn especially for beginners.\\n\\n### Browser support limitations\\n\\ngRPC\'s reliance on HTTP/2 poses challenges for browser-based applications. [Traditional browsers do not natively support gRPC](https://grpc.io/blog/state-of-grpc-web/), requiring workarounds such as gRPC-Web , which translates gRPC calls to HTTP/1.1 requests as no modern browser supports HTTP/2. Therefore the performance of gRPC on browsers may not be as good as it should be.\\n\\ngRPC is powerful for service to service communication, but it may not be the best choice for public APIs or browser-based applications where REST/GraphQL is more prevalent.\\n\\n:::tip\\nTo seamlessly integrate the benefits of both gRPC and GraphQL, you can easily generate GraphQL from gRPC using Tailcall. Check out the documentation here:\\n\\n- [gRPC to GraphQL](https://tailcall.run/docs/graphql-grpc-tailcall/) .\\n- [Automated gRPC to GraphQL](https://tailcall.run/docs/graphql-configuration-generation-with-tailcall/#effortless-grpc-integration)\\n  :::\\n\\n## Implementing gRPC: Best Practices\\n\\n### Designing Effective Protobuf Schemas\\n\\nCreating efficient and maintainable Protobuf schemas is crucial. Use meaningful field names and provide clear comments for each field, otherwise you may end up in a nested jargon of types! Versioning schemas properly ensures backward and forward compatibility makes it easier to evolve your API without breaking existing clients.\\n\\n### Error Handling and Status Codes\\n\\nDefine and document all possible error codes your service can return. Consistent and informative error messages aid in debugging and provide a better experience for developers integrating with your API, if the API is not verbose about the error, the developer trying to integrate the API on the other side may get frustrated:\\n\\n:::info\\n**_A bad API is like a traffic jam - frustrating, confusing, and costly._**\\n[ - Joshua Bloch](https://www.twitter.com/joshbloch)\\n:::\\n\\n### Security Considerations (Authentication, Encryption)\\n\\nSecure your gRPC services by implementing authentication and encryption. Use Transport Layer Security (TLS) to encrypt communication between clients and servers. Leverage gRPC\'s support for various authentication mechanisms, such as OAuth, JWT, or custom tokens, to ensure that only authorized clients can access your services.\\n\\n### Performance Optimization Techniques\\n\\ngRPC API performance can be boosted in many ways. The channels are expensive to make, and reusing them instead of remaking has a significant impact.\\n\\n**_Example:_**\\n\\n```javascript\\nconst grpc = require(\\"grpc\\")\\n\\n// Singleton instance for the gRPC channel\\nlet channel = null\\n\\nfunction getGrpcChannel() {\\n  if (!channel) {\\n    // Create a new channel if it doesn\'t exist\\n    channel = new grpc.Client(\\"localhost:50051\\", grpc.credentials.createInsecure())\\n  }\\n  return channel\\n}\\n\\n// Example usage:\\nconst myChannel = getGrpcChannel()\\n// Use `myChannel` to make gRPC calls\\n```\\n\\nAlongside with reusing channels, many other ways can improve performance like implementing [load-balancers](https://grpc.io/blog/grpc-load-balancing/) and using streaming instead of unary where needed.\\n\\n## gRPC Use Cases and Real-World Examples\\n\\n### Microservices Architecture\\n\\ngRPC is well-suited for microservices architectures, enabling efficient communication between services. Companies like Netflix and Google use gRPC to connect their microservices, benefiting from its performance and strong typing. It ensures reliable, low-latency communication, which is crucial for maintaining responsive and scalable microservices.\\n\\n### Real-Time Communication Systems\\n\\n![enter image description here](/images/docs/realtime.png)\\n\\ngRPC is ideal for real-time communication systems such as chat applications, online gaming, and live streaming services. Its support for bidirectional streaming allows for seamless and efficient data exchange between clients and servers, enabling real-time interactions and reducing latency.\\n\\n[A snippet from Open-Match, a gaming framework:](https://github.com/googleforgames/open-match/blob/d781be1a3ce1b6b7fce495345b23256089f55de9/api/backend.proto#L132)\\n\\n```protobuf\\n\\n  // Tickets in matches returned by FetchMatches are moved from active to\\n  // pending, and will not be returned by query.\\n  rpc FetchMatches(FetchMatchesRequest) returns (stream FetchMatchesResponse) {\\n    option (google.api.http) = {\\n      post: \\"/v1/backendservice/matches:fetch\\"\\n      body: \\"*\\"\\n    };\\n  }\\n\\n```\\n\\n### IoT and Edge Computing\\n\\nIn IoT and edge computing scenarios, gRPC\'s low overhead and efficient communication make it suitable for resource-constrained devices. It enables reliable communication between edge devices and central servers, facilitating data collection, processing, and command execution in real time.\\n\\n### Mobile and Web Applications\\n\\ngRPC is increasingly used in mobile and web applications to improve performance and reduce bandwidth usage. For example, companies like Lyft use gRPC to enhance the efficiency of their mobile apps, ensuring faster response times and a smoother user experience.\\n\\n## Tools and Frameworks for gRPC Development\\n\\n### Popular gRPC Libraries for Different Languages\\n\\ngRPC has libraries and tooling support for various programming languages:\\n\\n- [gRPC Core](https://github.com/grpc/grpc) - C, C++, Ruby, Node.js, Python, PHP, C#, Objective-C\\n- [gRPC Java](https://github.com/grpc/grpc-java) - The Java gRPC implementation. HTTP/2 based RPC\\n- [gRPC Node.js](https://github.com/grpc/grpc-node) - gRPC for Node.js\\n- [gRPC Go](https://github.com/grpc/grpc-go) - The Go language implementation of gRPC. HTTP/2 based RPC\\n- [gRPC C#](https://github.com/grpc/grpc-dotnet) - The C# language implementation of gRPC\\n- [gRPC Web](https://github.com/grpc/grpc-web) - gRPC for Web Clients\\n\\n### Testing and Debugging Tools\\n\\n- [ghz](https://github.com/bojand/ghz)\\n- [gatling-grpc](https://github.com/phiSgr/gatling-grpc)\\n\\n### API Management Platforms\\n\\n- [Postman](https://postman.com/)\\n- [letmegrpc](https://github.com/gogo/letmegrpc)\\n\\n## Future of gRPC and API Communication\\n\\n### Emerging Trends in API Design\\n\\nThe future of API design is moving towards more efficient and flexible communication protocols like gRPC. With the rise of microservices, IoT, and real-time applications, gRPC\'s performance advantages make it a compelling choice. Trends like GraphQL and RESTful JSON APIs will continue to coexist, but gRPC will gain traction for specific use cases requiring high efficiency and low latency.\\n\\n### gRPC\'s Role in Cloud-Native Applications\\n\\ngRPC is becoming a cornerstone of cloud-native applications, facilitating communication in containerized environments orchestrated by platforms like Kubernetes. Its ability to handle high-performance, low-latency communication is essential for the scalability and reliability of cloud-native architectures.\\n\\n### Potential Improvements and Extensions\\n\\nThe gRPC ecosystem is continuously evolving, with potential improvements and extensions on the horizon. Enhancements in tooling, support for more languages, better integration with existing frameworks, and increased adoption of gRPC-Web are some areas of expected growth. The community\'s efforts to address current limitations will make gRPC more accessible and robust for a wider range of applications.\\n\\n## Conclusion\\n\\n#### Recap of gRPC\'s key features and benefits\\n\\nIn summary, gRPC offers efficient, low-latency communication, strong typing through Protobuf, and support for multiple languages. Its bidirectional streaming and multiplexing capabilities make it ideal for real-time and microservices-based applications. The performance and reliability of gRPC provide significant advantages over traditional REST APIs in many scenarios, mainly because of the new HTTP/2 and its binary nature.\\n\\n#### Considerations for Adopting gRPC in Projects\\n\\nWhen considering gRPC for your projects, ensure that your team is prepared to handle the challenges and leverage the best practices discussed to design, implement, and maintain robust gRPC services. Make sure you have enough support resources and officials, as gRPC doesn\'t have a community as large as REST.\\n\\n### Further Resources\\n\\n#### Official documentation and tutorials\\n\\n- [gRPC Official Documentation](https://grpc.io/)\\n\\n#### Community forums and support\\n\\n- [gRPC Twitter handle](https://twitter.com/grpcio)\\n- [gRPC StackOverflow tag](https://stackoverflow.com/questions/tagged/grpc)\\n- [gRPC Gitter room](https://app.gitter.im/#/room/#grpc_grpc:gitter.im)\\n- [gRPC Google Group](https://groups.google.com/g/grpc-io)\\n\\n#### Books for in-depth learning\\n\\n- [gRPC: Up and Running](https://www.oreilly.com/library/view/grpc-up-and/9781492058328/)\\n- [gRPC Microservices in Go](https://www.manning.com/books/grpc-microservices-in-go)"},{"id":"graphql-introspection-security","metadata":{"permalink":"/blog/graphql-introspection-security","source":"@site/blog/graphql-introspection-security-2024-7-12.md","title":"Are Hackers Using Your Own GraphQL API Against You?","description":"Learn how attackers exploit GraphQL introspection and the battle-tested strategies to keep your data safe.","date":"2024-07-12T00:00:00.000Z","tags":[{"inline":true,"label":"GraphQL","permalink":"/blog/tags/graph-ql"},{"inline":true,"label":"Schema","permalink":"/blog/tags/schema"},{"inline":true,"label":"Security","permalink":"/blog/tags/security"},{"inline":true,"label":"Introspection","permalink":"/blog/tags/introspection"}],"readingTime":6.44,"hasTruncateMarker":true,"authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"frontMatter":{"title":"Are Hackers Using Your Own GraphQL API Against You?","authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"tags":["GraphQL","Schema","Security","Introspection"],"description":"Learn how attackers exploit GraphQL introspection and the battle-tested strategies to keep your data safe.","hide_table_of_contents":true,"slug":"graphql-introspection-security"},"unlisted":false,"prevItem":{"title":"gRPC Decoded: The API Protocol That\'s Changing Everything","permalink":"/blog/what-is-grpc"},"nextItem":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry","permalink":"/blog/graphql-schema"}},"content":"![GraphQL Introspection Security Issues](../static/images/blog/introspection-issues.png)\\nGraphQL has taken the API world by storm, offering developers a flexible and powerful way to interact with backend systems. But with great power comes great responsibility\u2014especially when it comes to security.\\n\\n\x3c!-- truncate --\x3e\\n\\nLet\'s dive into one of GraphQL\'s most fascinating features: introspection. It\'s a double-edged sword that can be both a developer\'s best friend and a security expert\'s nightmare.\\n\\n## Understanding GraphQL Introspection\\n\\nImagine having a magical lens that lets you peek into the very structure of a GraphQL server. That\'s essentially what introspection does! It\'s like having a detailed map of a treasure trove, showing you every nook and cranny of the API\'s capabilities. This self-documenting capability is incredibly useful for developers, enabling tools like GraphiQL and GraphQL Playground to provide rich, interactive documentation and auto-completion features.\\n\\nA basic introspection query might look like this:\\n\\n```graphql\\n{\\n  __schema {\\n    types {\\n      name\\n      fields {\\n        name\\n        type {\\n          name\\n        }\\n      }\\n    }\\n  }\\n}\\n```\\n\\nThis query asks the server to return information about all the types in the schema, including their fields and field types. The server\'s response provides a comprehensive map of its structure, which can be invaluable during development.\\n\\n## The Security Implications of Introspection\\n\\nWhile introspection is a goldmine for developers, it can also be a treasure map for attackers. Let\'s put on our black hat for a moment and see how a malicious actor might exploit this feature.\\n\\n### Schema Reconnaissance\\n\\nOne of the primary risks of introspection is schema reconnaissance. An attacker who gains access to a GraphQL endpoint can use introspection to explore the schema and identify potential targets for further attacks. This includes discovering sensitive types and fields, as well as understanding the relationships between different parts of the schema. Armed with this knowledge, an attacker can craft more effective queries to exploit vulnerabilities in the system.\\n\\nFor instance, an attacker might discover a \'User\' type with fields like \'email\', \'password\', and \'isAdmin\'. They could then craft a query to exploit this:\\n\\n```graphql\\nquery {\\n  allUsers {\\n    email\\n    password\\n    isAdmin\\n  }\\n}\\n```\\n\\nIf not properly secured, this query could potentially expose sensitive user data. The attacker might also notice an \'updateUser\' mutation, which could be a target for privilege escalation attempts.\\n\\n### Information Disclosure\\n\\nAnother significant risk is information disclosure. The introspection feature can inadvertently reveal implementation details that should remain hidden. This includes internal types, deprecated fields, and administrative functionalities. Such exposure can give attackers clues about the underlying system architecture and any potential weaknesses.\\n\\n### Attack Surface Expansion\\n\\nBy using introspection, attackers can significantly expand their attack surface. They can identify entry points for various attacks, including SQL injection, cross-site scripting (XSS), and denial of service (DoS) attacks. For instance, if introspection reveals that certain fields accept user input, an attacker might probe these fields for injection vulnerabilities.\\n\\n## Mitigating Introspection Risks\\n\\nNow, let\'s switch gears and become the defenders of our GraphQL realm. Here are some battle-tested strategies to keep your API safe from prying eyes:\\n\\n### Disable Introspection in Production\\n\\nDisabling introspection in production is crucial because it significantly reduces the information available to potential attackers. Without introspection, they can\'t easily map out your API\'s structure or discover hidden fields and types. This forces attackers to rely on guesswork or prior knowledge, making their job much more difficult. However, it\'s important to note that this is not a silver bullet\u2014determined attackers may still attempt to reverse-engineer your API through trial and error.\\n\\nIn many GraphQL implementations, disabling introspection is straightforward. For example, in [Tailcall](https://tailcall.run/docs/tailcall-dsl-graphql-custom-directives/#introspection), you can disable introspection by setting the `introspection` option to `false`:\\n\\n```graphql\\nschema\\n  # highlight-next-line\\n  @server(introspection: false) {\\n  query: Query\\n  mutation: Mutation\\n}\\n```\\n\\nThis configuration ensures that introspection is disabled.\\n\\n### Implement Authentication and Authorization\\n\\nAnother critical measure is to implement robust authentication and authorization mechanisms. By ensuring that only authenticated and authorized users can access your GraphQL endpoint, you can reduce the risk of unauthorized introspection queries. Use industry-standard authentication protocols such as OAuth2 or JWT to secure your endpoints.\\n\\nImagine a GraphQL API for a banking application. You might implement role-based access control where only users with an \'ADMIN\' role can access certain fields or mutations.\\n\\nIn [Tailcall](https://tailcall.run/docs/field-level-access-control-graphql-authentication/), you can achieve this by using the `@protected` directive.\\n\\nTailcall supports a variety of authentication and authorization mechanisms, including JWT, OAuth2, and custom authentication strategies.\\n\\nThis ensures that even if an attacker gains access to a regular user account, they can\'t use it to access sensitive admin-only data or operations.\\n\\n### Rate Limiting and Throttling\\n\\nRate limiting and throttling can also help mitigate the risks of introspection. By limiting the number of queries a client can execute within a given timeframe, you can reduce the likelihood of an attacker using introspection to gather information about your schema. Implementing these controls can also help protect your server from DoS attacks.\\n\\n### Query Allow Lists\\n\\nQuery allow lists work by pre-registering all valid queries that your application needs. This is typically done during the build process of your frontend application. Each query is hashed, and these hashes are stored on the server. When a query comes in, its hash is checked against the allow list.\\n\\nFor example, you might have a client-side query like this:\\n\\n```graphql\\nquery GetUserProfile($id: ID!) {\\n  user(id: $id) {\\n    name\\n    email\\n  }\\n}\\n```\\n\\nThis query would be hashed and stored on the server. When executed, the server checks if the incoming query\'s hash matches any in its allow list. If not, it\'s rejected.\\n\\nThis approach is powerful because it completely prevents arbitrary queries, including introspection queries, from being executed. It does require more setup and maintenance, especially in applications where queries change frequently, but it provides a very high level of security.\\n\\n### Monitor and Log Introspection Queries\\n\\nMonitoring and logging introspection queries can provide valuable insights into potential security threats. By tracking when and how introspection queries are executed, you can identify suspicious activity and respond accordingly. Implement logging at both the application and network levels to capture detailed information about each query.\\n\\n### Use a Web Application Firewall (WAF)\\n\\nA WAF can be particularly effective for GraphQL APIs because it can be configured to understand GraphQL-specific threats. For instance, you can set up rules to:\\n\\n1. Limit query depth: Prevent deeply nested queries that could overload your server.\\n2. Restrict field counts: Avoid overly broad queries that request too many fields at once.\\n3. Block known malicious patterns: Such as attempts to inject malicious code into queries.\\n\\nFor example, a WAF rule might look like this:\\n\\n```\\nSecRule ARGS_POST:query \\"@contains __schema\\" \\\\\\n    \\"id:1000,\\\\\\n    phase:2,\\\\\\n    t:none,\\\\\\n    block,\\\\\\n    msg:\'GraphQL introspection query detected\'\\"\\n```\\n\\nThis rule would block any POST request containing \'\\\\_\\\\_schema\' in the query parameter, which is typically indicative of an introspection query.\\n\\nBy implementing these kinds of rules, a WAF adds an extra layer of protection, catching many potential attacks before they even reach your GraphQL server.\\n\\n## Conclusion\\n\\nSecuring GraphQL is like playing a high-stakes game of chess. You need to think several moves ahead, anticipating potential threats while leveraging the strengths of your position. By implementing these strategies, you\'re not just protecting your API\u2014you\'re ensuring that GraphQL\'s power remains in the right hands. Stay vigilant, keep learning, and may your queries be ever secure!\\n\\nBy prioritizing security in your GraphQL implementation, you can harness the power of this modern query language while safeguarding your data and maintaining the trust of your users. Securing GraphQL is an ongoing process that requires vigilance and a proactive approach. Stay informed about the latest security developments, regularly review and update your security measures, and ensure that your development and security teams are aligned in their efforts to protect your applications."},{"id":"graphql-schema","metadata":{"permalink":"/blog/graphql-schema","source":"@site/blog/graphql-schema-2024-07-11.md","title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry","description":"Learn how to design a robust, scalable GraphQL schema. Best practices and considerations to build a schema that can evolve with your application\'s needs.","date":"2024-07-11T00:00:00.000Z","tags":[{"inline":true,"label":"GraphQL","permalink":"/blog/tags/graph-ql"},{"inline":true,"label":"API","permalink":"/blog/tags/api"},{"inline":true,"label":"Schema","permalink":"/blog/tags/schema"},{"inline":true,"label":"Design","permalink":"/blog/tags/design"},{"inline":true,"label":"Best Practices","permalink":"/blog/tags/best-practices"}],"readingTime":8.855,"hasTruncateMarker":true,"authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"frontMatter":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry","authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"tags":["GraphQL","API","Schema","Design","Best Practices"],"description":"Learn how to design a robust, scalable GraphQL schema. Best practices and considerations to build a schema that can evolve with your application\'s needs.","image":"/images/graphql/graphql-schema-structure.png","hide_table_of_contents":true,"slug":"graphql-schema"},"unlisted":false,"prevItem":{"title":"Are Hackers Using Your Own GraphQL API Against You?","permalink":"/blog/graphql-introspection-security"},"nextItem":{"title":"Writing a GraphQL Backend by Hand is Long Gone","permalink":"/blog/writing-a-graphql-backend-by-hand-is-long-gone"}},"content":"![GraphQL Schema Structure](../static/images/graphql/graphql-schema-structure.png)\\n\\nDesigning a robust, scalable GraphQL schema is critical for building production-ready APIs that can evolve with your application\'s needs. In this comprehensive guide, we\'ll walk through the process of crafting a GraphQL schema for a real-world application, highlighting best practices and considerations along the way.\\n\\n\x3c!-- truncate --\x3e\\n\\nIf you\'re new to GraphQL Schema, check out our [GraphQL Schema Tutorial](https://tailcall.run/graphql/schemas-and-types/) to get up to speed with the basics.\\n\\n## The Power of GraphQL Schemas\\n\\nA well-designed GraphQL schema serves as the blueprint for your entire API. It defines:\\n\\n- The types of data available\\n- The relationships between those types\\n- The operations clients can perform (queries, mutations, subscriptions)\\n- The structure of requests and responses\\n\\nYour schema acts as a contract between your backend and frontend teams. Once published, clients can rely on its structure, enabling them to build UIs with confidence. A thoughtful schema design upfront can save significant refactoring down the road.\\n\\n## Our Example Application: TechTalent\\n\\nTo illustrate schema design principles, let\'s imagine we\'re building TechTalent - a platform connecting tech companies with job seekers. Our application will allow:\\n\\n- Companies to post job listings\\n- Candidates to create profiles and apply to jobs\\n- Recruiters to search candidates and manage applications\\n\\nWe\'ll design our schema step-by-step to support these core features.\\n\\n## Step 1: Identify Core Types\\n\\nThe first step is to identify the main entities in our domain. For TechTalent, our core types might include:\\n\\n- Company\\n- JobListing\\n- Candidate\\n- Application\\n- Recruiter\\n\\nLet\'s start by defining these as object types in our schema:\\n\\n```graphql\\ntype Company {\\n  id: ID!\\n  name: String!\\n  description: String\\n  # More fields to come\\n}\\n\\ntype JobListing {\\n  id: ID!\\n  title: String!\\n  description: String!\\n  # More fields to come\\n}\\n\\ntype Candidate {\\n  id: ID!\\n  name: String!\\n  email: String!\\n  # More fields to come\\n}\\n\\ntype Application {\\n  id: ID!\\n  # More fields to come\\n}\\n\\ntype Recruiter {\\n  id: ID!\\n  name: String!\\n  email: String!\\n  # More fields to come\\n}\\n```\\n\\nNotice we\'ve only included a few basic fields at this stage. We\'ll flesh these out as we progress.\\n\\n## Step 2: Model Relationships\\n\\nNext, we need to consider how these types relate to each other. In GraphQL, we model relationships by adding fields that reference other types. Let\'s update our types:\\n\\n```graphql\\ntype Company {\\n  id: ID!\\n  name: String!\\n  description: String\\n  jobListings: [JobListing!]!\\n  recruiters: [Recruiter!]!\\n}\\n\\ntype JobListing {\\n  id: ID!\\n  title: String!\\n  description: String!\\n  company: Company!\\n  applications: [Application!]!\\n}\\n\\ntype Candidate {\\n  id: ID!\\n  name: String!\\n  email: String!\\n  applications: [Application!]!\\n}\\n\\ntype Application {\\n  id: ID!\\n  jobListing: JobListing!\\n  candidate: Candidate!\\n  status: ApplicationStatus!\\n}\\n\\ntype Recruiter {\\n  id: ID!\\n  name: String!\\n  email: String!\\n  company: Company!\\n}\\n\\nenum ApplicationStatus {\\n  PENDING\\n  REVIEWED\\n  REJECTED\\n  ACCEPTED\\n}\\n```\\n\\nWe\'ve now established the core relationships:\\n\\n- Companies have job listings and recruiters\\n- Job listings belong to a company and have applications\\n- Candidates have applications\\n- Applications link a candidate to a job listing\\n- Recruiters belong to a company\\n\\nNote the use of the `ApplicationStatus` enum to represent the fixed set of possible statuses.\\n\\n## Step 3: Plan Query Operations\\n\\nWith our core types defined, let\'s consider what query operations our clients will need. We\'ll start with some basic CRUD (Create, Read, Update, Delete) operations:\\n\\n```graphql\\ntype Query {\\n  company(id: ID!): Company\\n  jobListing(id: ID!): JobListing\\n  candidate(id: ID!): Candidate\\n\\n  # List operations\\n  companies: [Company!]!\\n  jobListings(filters: JobListingFilters): [JobListing!]!\\n  candidates(filters: CandidateFilters): [Candidate!]!\\n}\\n\\ninput JobListingFilters {\\n  companyId: ID\\n  title: String\\n  # Add more filter options\\n}\\n\\ninput CandidateFilters {\\n  skills: [String!]\\n  experienceYears: Int\\n  # Add more filter options\\n}\\n```\\n\\nWe\'ve added basic queries to fetch individual entities by ID, as well as list queries for our main types. Notice the use of `input` types for filters - this allows for more flexible and extensible querying.\\n\\n## Step 4: Plan Mutation Operations\\n\\nNext, let\'s define some mutation operations to allow clients to modify data:\\n\\n```graphql\\ntype Mutation {\\n  # Company mutations\\n  createCompany(\\n    input: CreateCompanyInput!\\n  ): CreateCompanyPayload!\\n  updateCompany(\\n    id: ID!\\n    input: UpdateCompanyInput!\\n  ): UpdateCompanyPayload!\\n\\n  # Job Listing mutations\\n  createJobListing(\\n    input: CreateJobListingInput!\\n  ): CreateJobListingPayload!\\n  updateJobListing(\\n    id: ID!\\n    input: UpdateJobListingInput!\\n  ): UpdateJobListingPayload!\\n\\n  # Candidate mutations\\n  createCandidate(\\n    input: CreateCandidateInput!\\n  ): CreateCandidatePayload!\\n  updateCandidate(\\n    id: ID!\\n    input: UpdateCandidateInput!\\n  ): UpdateCandidatePayload!\\n\\n  # Application mutations\\n  submitApplication(\\n    input: SubmitApplicationInput!\\n  ): SubmitApplicationPayload!\\n  updateApplicationStatus(\\n    id: ID!\\n    status: ApplicationStatus!\\n  ): UpdateApplicationStatusPayload!\\n}\\n\\n# Input and Payload types for each mutation...\\n```\\n\\nNotice the pattern we\'re using for mutations:\\n\\n1. Each mutation has a corresponding input type\\n2. Each mutation returns a payload type\\n\\nThis structure offers several benefits:\\n\\n- Input types allow for easy addition of new fields in the future\\n- Payload types can include both the modified entity and any errors or metadata\\n- It provides a consistent structure across all mutations\\n\\nLet\'s look at an example input and payload type:\\n\\n```graphql\\ninput CreateJobListingInput {\\n  companyId: ID!\\n  title: String!\\n  description: String!\\n  requirements: [String!]!\\n  salary: SalaryInput\\n}\\n\\ninput SalaryInput {\\n  min: Int!\\n  max: Int!\\n  currency: String!\\n}\\n\\ntype CreateJobListingPayload {\\n  jobListing: JobListing\\n  errors: [Error!]\\n}\\n\\ntype Error {\\n  message: String!\\n  path: [String!]\\n}\\n```\\n\\nThis structure allows for detailed error reporting and future extensibility.\\n\\n## Step 5: Consider Authentication and Authorization\\n\\nIn a production application, we need to consider authentication and authorization. Let\'s add some operations for user management:\\n\\n```graphql\\ntype Mutation {\\n  # ... previous mutations\\n\\n  signup(input: SignupInput!): AuthPayload!\\n  login(input: LoginInput!): AuthPayload!\\n  logout: Boolean!\\n}\\n\\ninput SignupInput {\\n  email: String!\\n  password: String!\\n  name: String!\\n  role: UserRole!\\n}\\n\\ninput LoginInput {\\n  email: String!\\n  password: String!\\n}\\n\\ntype AuthPayload {\\n  token: String!\\n  user: User!\\n}\\n\\ntype User {\\n  id: ID!\\n  email: String!\\n  name: String!\\n  role: UserRole!\\n}\\n\\nenum UserRole {\\n  CANDIDATE\\n  RECRUITER\\n  ADMIN\\n}\\n```\\n\\nWe\'ve added basic authentication operations and a `User` type to represent authenticated users. In a real-world scenario, you\'d likely want to implement more robust authentication and authorization mechanisms.\\n\\n## Step 6: Implement Pagination\\n\\nAs our application grows, we\'ll need to implement pagination for our list queries. Let\'s update our `jobListings` query to use cursor-based pagination:\\n\\n```graphql\\ntype Query {\\n  # ... other queries\\n\\n  jobListings(\\n    first: Int\\n    after: String\\n    filters: JobListingFilters\\n  ): JobListingConnection!\\n}\\n\\ntype JobListingConnection {\\n  edges: [JobListingEdge!]!\\n  pageInfo: PageInfo!\\n}\\n\\ntype JobListingEdge {\\n  node: JobListing!\\n  cursor: String!\\n}\\n\\ntype PageInfo {\\n  hasNextPage: Boolean!\\n  endCursor: String\\n}\\n```\\n\\nThis implementation follows the Relay connection specification, which provides a standardized way to handle pagination in GraphQL.\\n\\n## Step 7: Plan for Real-time Updates\\n\\nFor certain features, we might want to provide real-time updates. Let\'s add a subscription to notify when new job listings are posted:\\n\\n```graphql\\ntype Subscription {\\n  newJobListing: JobListing!\\n}\\n```\\n\\nClients can subscribe to this operation to receive updates whenever a new job listing is created.\\n\\n## Step 8: Implement Custom Scalars\\n\\nOur schema might benefit from some custom scalar types for specific data formats. For example, let\'s add a `DateTime` scalar:\\n\\n```graphql\\nscalar DateTime\\n\\ntype JobListing {\\n  # ... other fields\\n  postedAt: DateTime!\\n  applicationDeadline: DateTime\\n}\\n```\\n\\nWe\'ll need to implement the serialization/deserialization logic for this scalar in our resolvers.\\n\\n## Step 9: Use Interfaces for Shared Fields\\n\\nAs our schema grows, we might notice some types sharing common fields. We can use interfaces to model this shared structure:\\n\\n```graphql\\ninterface Node {\\n  id: ID!\\n}\\n\\ninterface Timestamped {\\n  createdAt: DateTime!\\n  updatedAt: DateTime!\\n}\\n\\ntype Company implements Node & Timestamped {\\n  id: ID!\\n  createdAt: DateTime!\\n  updatedAt: DateTime!\\n  # ... other fields\\n}\\n\\ntype JobListing implements Node & Timestamped {\\n  id: ID!\\n  createdAt: DateTime!\\n  updatedAt: DateTime!\\n  # ... other fields\\n}\\n```\\n\\nThis approach promotes consistency and can make it easier to implement features that work across multiple types.\\n\\n## Step 10: Document Your Schema\\n\\nFinally, it\'s crucial to document your schema thoroughly. GraphQL allows for built-in documentation:\\n\\n```graphql\\n\\"\\"\\"\\nRepresents a company on the TechTalent platform.\\n\\"\\"\\"\\ntype Company implements Node & Timestamped {\\n  \\"\\"\\"\\n  Unique identifier for the company.\\n  \\"\\"\\"\\n  id: ID!\\n\\n  \\"\\"\\"\\n  The name of the company.\\n  \\"\\"\\"\\n  name: String!\\n\\n  # ... other fields\\n}\\n```\\n\\nGood documentation helps both your team and API consumers understand the purpose and usage of each type and field.\\n\\n## Visualizing the Schema\\n\\nTo better understand the relationships in our schema, let\'s visualize the core types:\\n\\n![Diagram Illustrating Relationships between various types ](../static/images/blog/entity-relationships.png)\\n\\nThis diagram illustrates the key relationships between our main entities, helping us ensure our schema accurately represents our domain.\\n\\nTo visualize your schema, you can use tools like [GraphQL Voyager](https://graphql-kit.com/graphql-voyager/).\\n\\n## Best Practices and Considerations\\n\\nAs we\'ve designed our schema, we\'ve touched on several best practices. Let\'s recap some key points and add a few more considerations:\\n\\n1. **Start with the UI in mind**: Design your schema based on how the data will be used in your UI, not just how it\'s stored in your database.\\n\\n2. **Use clear, consistent naming**: Adopt a naming convention (e.g., PascalCase for types, camelCase for fields) and stick to it.\\n\\n3. **Leverage GraphQL features**: Make use of enums, interfaces, and unions to create a rich, expressive schema.\\n\\n4. **Plan for change**: Use input types for mutations and consider versioning strategies for evolving your schema over time.\\n\\n5. **Optimize for performance**: Be mindful of N+1 query problems and consider implementing DataLoader or similar batching mechanisms.\\n\\n6. **Secure your schema**: Implement proper authentication and authorization. Consider using directives for field-level permissions.\\n\\n7. **Validate input**: Use non-nullable fields and custom scalars to enforce data integrity at the schema level.\\n\\n8. **Provide meaningful errors**: Return detailed error information in your mutation payloads to help clients handle failures gracefully.\\n\\n9. **Monitor and analyze**: Implement logging and monitoring to understand how your schema is being used and where optimizations can be made.\\n\\n10. **Keep it DRY**: Use interfaces and abstract types to reduce duplication in your schema.\\n\\n## Conclusion\\n\\nDesigning a production-grade GraphQL schema is an iterative process that requires careful thought and planning. By starting with core types and relationships, then gradually adding queries, mutations, and advanced features, we can build a schema that\'s both powerful and maintainable.\\n\\nRemember, your schema is a living document. As your application evolves, so too will your schema. By following these principles and best practices, you\'ll be well-equipped to design and maintain a GraphQL schema that can grow with your needs.\\n\\nThe TechTalent example we\'ve explored here demonstrates many real-world considerations, but every application will have its unique requirements. Always design with your specific use cases in mind, and don\'t be afraid to iterate as you learn more about how your API is used in practice.\\n\\nBy investing time in thoughtful schema design upfront, you\'ll create a solid foundation for your GraphQL API, enabling efficient development and a great experience for your API consumers."},{"id":"writing-a-graphql-backend-by-hand-is-long-gone","metadata":{"permalink":"/blog/writing-a-graphql-backend-by-hand-is-long-gone","source":"@site/blog/no-code-graphql-2024-05-30.md","title":"Writing a GraphQL Backend by Hand is Long Gone","description":"Writing a GraphQL backend by hand doesn\'t scale beyond a point.","date":"2024-05-30T00:00:00.000Z","tags":[{"inline":true,"label":"GraphQL","permalink":"/blog/tags/graph-ql"},{"inline":true,"label":"Node.js","permalink":"/blog/tags/node-js"},{"inline":true,"label":"JavaScript","permalink":"/blog/tags/java-script"}],"readingTime":6.265,"hasTruncateMarker":true,"authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=5","imageURL":"https://avatars.githubusercontent.com/u/194482?v=5"}],"frontMatter":{"title":"Writing a GraphQL Backend by Hand is Long Gone","subtitle":"Writing a GraphQL backend by hand doesn\'t scale beyond a point.","authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=5","imageURL":"https://avatars.githubusercontent.com/u/194482?v=5"}],"tags":["GraphQL","Node.js","JavaScript"],"description":"Writing a GraphQL backend by hand doesn\'t scale beyond a point.","image":"/images/blog/no-code-cover.png","hide_table_of_contents":true,"slug":"writing-a-graphql-backend-by-hand-is-long-gone","canonical_url":"https://tailcall.hashnode.dev/writing-a-graphql-backend-by-hand-is-long-gone"},"unlisted":false,"prevItem":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry","permalink":"/blog/graphql-schema"},"nextItem":{"title":"GraphQL vs REST vs gRPC - an unfair comparison","permalink":"/blog/graphql-vs-rest-vs-grpc"}},"content":"![Cover Image for Writing a GraphQL Backend by Hand is Long Gone](../static/images/blog/no-code-cover.png)\\nBuilding a GraphQL backend by hand might seem like a noble pursuit, but the landscape of API development is evolving rapidly, and so are the challenges that come with it. Today, the process is often fraught with complexity, performance bottlenecks, security vulnerabilities, and reliability issues. Yet again, we had a developer expressing [frustration](https://bessey.dev/blog/2024/05/24/why-im-over-graphql/) about the issues with GraphQL and the reasons for leaving our mighty ship. I wish to dive deeper into these challenges and explore why the future points towards automated, high-performance solutions.\\n\\n\x3c!-- truncate --\x3e\\n\\n<head>\\n<link rel=\\"canonical\\" href=\\"https://tailcall.hashnode.dev/writing-a-graphql-backend-by-hand-is-long-gone\\"/>\\n<title>Writing a GraphQL Backend by Hand is Long Gone</title>\\n</head>\\n\\n## Complexity with GraphQL\\n\\nIf you see, most of the concerns with GraphQL are around building a robust GraphQL backend. It\'s rarely about consuming GraphQL, because if you look closely at the GraphQL spec, you will find that it\'s focused on how to elegantly consume data. As long as the output of your backend matches what\'s expected in the query, the specification doesn\'t care about how the backend is implemented.\\n\\nHence, the main complexity with GraphQL comes with how GraphQL is built. One of the major hurdles in hand-coding a GraphQL backend is managing performance. Issues like batching, incorrect usage of data loaders, caching, and the notorious N+1 problem can cripple your application.\\n\\nManually implementing batching mechanisms and data loaders can be incredibly tedious. While libraries like [DataLoader](https://github.com/graphql/dataloader) can assist, integrating them seamlessly into your system requires a deep understanding of both your data and the GraphQL query patterns. Overuse of data loaders is so common with most GraphQL implementations that ultimately it becomes the main culprit for high latency.\\n\\nSecondly, traditional caching doesn\'t work with GraphQL, so you have to resort to all sorts of solutions, using persisted queries or some vendor-specific implementation of caching. Implementing effective caching strategies is essential for performance but it\'s tricky. Developers must decide what to cache, when to invalidate the cache, and how to manage cache consistency, which adds another layer of complexity.\\n\\nThe N+1 issue, boy, that\'s perhaps everyone\'s favorite issue with GraphQL. It arises when executing multiple upstream requests that could have been combined into one, leading to massive performance degradation. Detecting and solving this requires meticulous analysis of query patterns and database access, which requires developers to have the context of the whole query at once, generate a query plan, translate it to appropriate upstream calls, and then execute! That\'s a lot of complex engineering effort; building a general-purpose query engine is not for the faint-hearted, and in the midst of all this complex yet interesting work, I need to ship features!\\n\\n> [Grafast](https://grafast.org/grafast) is an upcoming generalized query planner that could make query-planning in JS a bit more tamed.\\n\\nGraphQL\u2019s flexibility can be a double-edged sword when it comes to security, necessitating robust mechanisms for authentication and authorization. Like caching, traditional route-based API access doesn\'t work with GraphQL. Implementing these security layers correctly involves ensuring that only authenticated users can access the GraphQL entity and that they can only access data or fields that they are authorized to see. This requires fine-grained control and often custom logic and the invention of a new standard that works just for you.\\n\\nLastly, but most importantly, ensuring your GraphQL API is reliable means tackling error handling, propagation, and telemetry. Proper error handling in GraphQL is crucial for providing meaningful feedback to clients and maintaining the integrity of your application. The GraphQL team recently started working on a [standard](https://graphql-http.com/) for serving GraphQL over HTTP, which won\'t be easy to integrate if you already have a GraphQL API running in production. Moreover, integrating telemetry within a GraphQL backend isn\'t easy either; it is a very involved process to integrate spans to trace GraphQL resolvers. And, if you have written your GraphQL layer by hand in JavaScript, be ready for some [significant performance degradation](https://github.com/DataDog/dd-trace-js/issues/1095).\\n\\n## GraphQL is more like SQL and less like REST\\n\\nWe talked about it in our [previous](graphql-vs-rest-vs-grpc-2024-03-30.md) blog why GraphQL isn\'t like REST or gRPC. I would argue that SQL is a closer elder sibling of GraphQL than REST or gRPC. Writing a GraphQL backend can be likened to building an SQL engine manually. Imagine if every time you wanted to interact with a database, you had to write the SQL engine from scratch. Every time you made a database change, you would need to rewrite your engine so that it can work with the new schema or indexes. It\u2019s inefficient and impractical; no one does that. Fortunately, modern databases come with embedded, high-performance SQL engines such as [Apache Calcite](https://calcite.apache.org/) that adhere to the SQL specification but abstract away the complexities around building it. These databases allow developers to focus on writing queries and managing data without worrying about the underlying mechanics, thanks to their sophisticated query engines.\\n\\nGraphQL, much like SQL, is a query language designed to allow clients to request exactly the data they need. Unlike REST, which relies on fixed endpoints, or gRPC, which focuses on remote procedure calls, GraphQL provides a flexible, hierarchical way to fetch and manipulate data, making it a closer analog to SQL in terms of expressiveness and precision. And I believe the future of GraphQL is going to be like the journey of this elder sibling.\\n\\n## The future of GraphQL\\n\\nThe future of GraphQL development is moving towards generalized automated solutions built on modern, low-level system stacks like Rust and Zig, and moving away from the prevalent hand-written Node.js-based solutions of today.\\n\\n[![Most common GraphQL implementations](../static/images/blog/graphql-stack.png)](https://hygraph.com/graphql-survey-2024#how-developers-build-graphql-apis)\\n\\n- These engines will connect to data sources of any type and build a GraphQL endpoint on top of them. They will find connections between other data sources, sometimes completely automatically and sometimes using hints given by the developer, creating a unified GraphQL experience.\\n\\n- Similar to SQL engines, which use JIT techniques to identify performance optimizations at runtime, GraphQL engines will become extremely smart about performance. My hope is that GraphQL will eventually move away from its dependency on the JSON protocol, into something more efficient such as protobuf.\\n\\n- There is definitely going to be a lot of work put into the standardization of the loose ends. GraphQL engines will eventually converge on error handling and error propagation strategies. GraphQL on HTTP is the first step in that direction. Authentication and Authorization too will very quickly become standard features of GraphQL, so you won\'t need to worry about inventing a new way of authentication. This will all be packed into a GraphQL standard. This might be a stretch, but if the standards team gets together, I think even GraphQL caching will be consistent across all GraphQL engines, and you will be able to switch from one caching solution to another without locking into a vendor-specific implementation.\\n\\nYou might have already seen a wave of open-source solutions that build GraphQL on top of existing data sources. One such solution paving the way is [Tailcall](https://tailcall.run). Tailcall\u2019s platform is designed to automate the creation, validation, and optimization of GraphQL backends. Sticking to standards and ensuring developers don\'t ever have to pay the heavy tax of using GraphQL that they do today, do check it out!\\n\\nLastly, if you are reading this today and thinking of writing a GraphQL server by hand, I urge you to reconsider and use something that does this for you. Before you know it, your handwritten solution will be deprecated in favor of something faster, easier, and more secure: an automatic GraphQL solution."},{"id":"graphql-vs-rest-vs-grpc","metadata":{"permalink":"/blog/graphql-vs-rest-vs-grpc","source":"@site/blog/graphql-vs-rest-vs-grpc-2024-03-30.md","title":"GraphQL vs REST vs gRPC - an unfair comparison","description":"Understand what makes GraphQL different from REST and gRPC.","date":"2024-03-30T00:00:00.000Z","tags":[],"readingTime":3.875,"hasTruncateMarker":true,"authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=5","imageURL":"https://avatars.githubusercontent.com/u/194482?v=5"}],"frontMatter":{"title":"GraphQL vs REST vs gRPC - an unfair comparison","authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=5","imageURL":"https://avatars.githubusercontent.com/u/194482?v=5"}],"description":"Understand what makes GraphQL different from REST and gRPC.","image":"/images/blog/gql-vs-rest-vs-grpc-cover.png","hide_table_of_contents":true,"slug":"graphql-vs-rest-vs-grpc","canonical_url":"https://tailcall.hashnode.dev/graphql-vs-rest-vs-grpc"},"unlisted":false,"prevItem":{"title":"Writing a GraphQL Backend by Hand is Long Gone","permalink":"/blog/writing-a-graphql-backend-by-hand-is-long-gone"},"nextItem":{"title":"GraphQL Conf 2023","permalink":"/blog/graphql-conf-2023"}},"content":"![Cover Image for GraphQL vs REST vs gRPC - an unfair comparison](../static/images/blog/gql-vs-rest-vs-grpc-cover.png)\\n\\n\x3c!-- truncate --\x3e\\n\\n<head>\\n<link rel=\\"canonical\\" href=\\"https://tailcall.hashnode.dev/graphql-vs-rest-vs-grpc\\"/>\\n<title>GraphQL vs REST vs gRPC - an unfair comparison</title>\\n</head>\\n\\nSince its inception, GraphQL has steadily gained popularity, often finding itself at the center of comparisons with other data query and manipulation languages such as REST and gRPC. The internet is replete with articles debating the merits and demerits of each, with some even questioning the viability of GraphQL. However, this discourse misses a crucial point: the unique strengths of GraphQL. This article aims to illuminate the distinct advantages GraphQL offers, particularly in addressing a common but complex challenge known as impedance mismatch.\\n\\nImpedance mismatch refers to the discordance between the capabilities of an existing API and the ideal features required for a specific use case. From the perspective of a platform engineer, the goal is to develop APIs that cater to a broad range of needs. Yet, crafting a unique API for every conceivable requirement is neither practical nor efficient. Consequently, engineers often end up creating generalized APIs. However, as a consumer, you might find these APIs lacking in some respects while being superfluous in others. Furthermore, as your needs evolve, so does your notion of the ideal API, exacerbating this mismatch. Herein lies the brilliance of GraphQL: it offers a framework for structuring data exposure and queries that significantly mitigates this issue.\\n\\nThe GraphQL specification introduces the concept of viewing data as a graph composed of nodes, which represent domain entities for a business, interconnected by relationships that define their interactions. For instance, in the development of a social network, a user entity might have the ability to create a post, which in turn could receive comments, illustrating the interconnected nature of data entities.\\n![Image Demonstrating a graph of entities](../static/images/blog/entity-graph.png)\\n\\nWith the data conceptualized as a graph, GraphQL advocates for a method of querying that allows for precise data retrieval. This selective querying capability enables developers to request exactly the data they need, distinguishing GraphQL from REST and gRPC which aren\'t truly a \\"queryable\\". The precision of GraphQL extends to the granularity of specifying individual fields within entities, facilitating extremely efficient and targeted queries.\\n![Image Demonstrating a relations between entities](../static/images/blog/entity-relation.png)\\n\\nNotably, the GraphQL specification does not prescribe any specific data storage methodologies but focuses on the manner in which data is queried, hence the designation \\"Graph Query Language.\\" This approach allows for queries tailored to specific requirements, such as obtaining posts by the current user along with comments on those posts. By enabling precise data queries, GraphQL helps in avoiding the inefficiencies associated with over-fetching or under-fetching data, thereby enhancing overall system performance.\\n\\nThe impedance mismatch is not solely a technical issue pertaining to the differences in API schemas. It extends into the realm of development processes as well. GraphQL significantly ameliorates this aspect by allowing the consumers of an API to begin their work even before the actual API is fully implemented. This is made possible through the agreement on a schema upfront. By decoupling the dependency between the consumer and the provider of the API, GraphQL facilitates a more efficient and flexible development process.\\n\\nComparing GraphQL with REST or gRPC on this front might not do justice to their distinct objectives. REST and gRPC are primarily designed as lightweight RPC protocols, not specifically to address impedance mismatch for which a full fledged query language is more suitable. A more apt comparison would be with OpenAPI, which also allows for API composition. However, OpenAPI\'s capabilities in fine-tuning what an API delivers are somewhat [constrained](https://swagger.io/specification/#composition-and-inheritance-polymorphism) compared to GraphQL\'s flexible querying capabilities.\\n\\nBeyond the technical resolution of impedance mismatch, GraphQL addresses a critical business problem: the inefficiency in software development that arises from this gap between actual and ideal APIs. This inefficiency leads to developers spending excessive time on API orchestration\u2014time that could be better spent on core application development. They find themselves constantly writing, revising, and optimizing APIs and their orchestration, as well as managing the fallout from breaking changes. By leveraging GraphQL, developers can significantly reduce these frictions, streamlining the development process and enhancing productivity. In essence, GraphQL not only solves a technical problem but also delivers substantial business value by enabling more efficient and flexible software development practices.\\n\\nGraphQL offers an excellent developer experience for API consumption with its intuitive query language that allows for retrieving deeply nested data independently of the upstream source. However, it does have some limitations. At [Tailcall](https://tailcall.run), we are dedicated to making GraphQL more accessible and easier to work with.\\n\\nIf you like what you just read, please do subscribe and share on twitter and linkedin \ud83d\ude4f"},{"id":"graphql-conf-2023","metadata":{"permalink":"/blog/graphql-conf-2023","source":"@site/blog/2023-graphql-conf-2023-09-29.md","title":"GraphQL Conf 2023","description":"A glimpse into the future of GraphQL! \ud83d\ude80.","date":"2023-09-29T00:00:00.000Z","tags":[],"readingTime":2.655,"hasTruncateMarker":true,"authors":[{"name":"Sujeet Sreenivasan","image_url":"https://avatars.githubusercontent.com/u/113442?v=5","imageURL":"https://avatars.githubusercontent.com/u/113442?v=5"}],"frontMatter":{"title":"GraphQL Conf 2023","authors":[{"name":"Sujeet Sreenivasan","image_url":"https://avatars.githubusercontent.com/u/113442?v=5","imageURL":"https://avatars.githubusercontent.com/u/113442?v=5"}],"description":"A glimpse into the future of GraphQL! \ud83d\ude80.","image":"/images/blog/graphql-conf-2023.png","hide_table_of_contents":true,"slug":"graphql-conf-2023","canonical_url":"https://tailcall.hashnode.dev/graphql-conf-2023"},"unlisted":false,"prevItem":{"title":"GraphQL vs REST vs gRPC - an unfair comparison","permalink":"/blog/graphql-vs-rest-vs-grpc"},"nextItem":{"title":"The truth about scaling Automatic Persisted Queries","permalink":"/blog/the-truth-about-scaling-automatic-persisted-queries"}},"content":"![A Photo from GraphQL Conf 2023](../static/images/blog/graphql-conf-2023.png)\\nGraphQLConf 2023 wasn\'t just another tech conference; it was a groundbreaking event hosted by the GraphQL Foundation. Bursting with riveting workshops, enlightening talks, and interactive sponsor booths, this conference was a deep dive into the ever-evolving world of GraphQL.\\n\\n\x3c!-- truncate --\x3e\\n<head>\\n<link rel=\\"canonical\\" href=\\"https://tailcall.hashnode.dev/graphql-conf-2023\\"/>\\n<title>GraphQL Conf 2023</title>\\n</head>\\nGone are the days when GraphQL was just for UI developers. This year\'s theme revolved around the long-term vision of GraphQL and its seamless integration into backend architecture. It was all about the bigger picture!\\n\\n### **Workshops & Talks Highlights**\\n\\n- **Is GraphQL BFF Necessary:** An electrifying discussion led by Tanmay from Hasura, as he unravels the significance of the BFF layer in the era after ReactJS. One profound takeaway?\\n\\n  > _GraphQL isn\'t just a fleeting tactic for instant gains\u2014it\'s a visionary strategy that propels businesses toward unparalleled success!_\\n\\n- **Interactive GraphQL with Envoy & Kubernetes**: The team from solo.io showcased the magic of adding GraphQL to an envoy gateway. It\'s all about giving clients more power while retaining essential gateway features.\\n\\n- **The Future of Efficiency**: Benjie Gillam\'s talk was a rollercoaster! He introduced grafast, a new GraphQL execution engine that optimizes data loading through query planning. One to watch!\\n\\n- **Rethinking Rate Limiting**: Meenakshi Dhanani from Postman took us on a journey through the intricacies of rate-limiting GraphQL queries. Traditional methods? Not so effective. Enter query cost analysis!\\n\\n- **GraphQL Fusion Unveiled**: Michael Staib from ChilliCream introduced GraphQL Fusion, a revolutionary approach to building distributed GraphQL APIs. The future of federating GraphQL APIs is looking bright!\\n\\n- **The Null Saga**: Stephen Spalding from Netflix delved into the history of \'null\' and introduced the Client Controlled Nullability proposal. A game-changer for GraphQL clients, we are definitely looking forward to this one!\\n\\n- **The Right Size for GraphQL**: Theo Browne\'s presentation was an eye-opener. He introduced us to scenarios where tRPC might be a better fit than GraphQL.\\n\\n- **Data Load 3.0:** Jens from Wundergraph talked about the massive performance gains one could potentially get by using a BFS algorithm in data loaders.\\n\\n### **Unconference Session: Where Everyone\'s a Speaker!**\\n\\nThis was our first time to such a thing. The conference kicked off with a dynamic unconference session. Everyone in attendance brainstormed discussion topics grouped them, and then dove deep into discussions. Our table delved into the multifaceted world of \\"Federation\\" - merging multiple GraphQL graphs into a supergraph. The consensus? The journey towards a supergraph is filled with challenges, but with tools like the Open Federation spec and GraphQL Fusion, the future looks promising!\\n\\n### **Networking & Global Connections**\\n\\nOne of the highlights of GraphQLConf 23 was the global representation. Meeting tech enthusiasts from the Netherlands, New Zealand, Poland, Romania, and more was truly inspiring. Special shoutout to Gerard Klijs from AxonIQ for his unique take on CQRS and GraphQL!\\n\\n### **Conclusion**\\n\\nDid you miss out on some sessions? No worries! All the talks are available on the GraphQL Foundation\'s [YouTube](https://www.youtube.com/playlist?list=PLP1igyLx8foE9SlDLI1Vtlshcon5r1jMJ) channel. Dive in and get inspired!\\n\\nGraphQLConf 2023 was more than just a conference for us; it was an experience. Here\'s to the future of GraphQL and the endless possibilities it holds! \ud83c\udf89"},{"id":"the-truth-about-scaling-automatic-persisted-queries","metadata":{"permalink":"/blog/the-truth-about-scaling-automatic-persisted-queries","source":"@site/blog/automatic-persisted-queries-2023-08-11.md","title":"The truth about scaling Automatic Persisted Queries","description":"Learn about the limitations and potential scaling issues that accompany Automatic Persisted Queries (APQ).","date":"2023-08-11T00:00:00.000Z","tags":[],"readingTime":6.075,"hasTruncateMarker":true,"authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=5","imageURL":"https://avatars.githubusercontent.com/u/194482?v=5"}],"frontMatter":{"title":"The truth about scaling Automatic Persisted Queries","authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=5","imageURL":"https://avatars.githubusercontent.com/u/194482?v=5"}],"description":"Learn about the limitations and potential scaling issues that accompany Automatic Persisted Queries (APQ).","image":"/images/blog/apq-cover.png","hide_table_of_contents":true,"slug":"the-truth-about-scaling-automatic-persisted-queries","canonical_url":"https://tailcall.hashnode.dev/the-truth-about-scaling-automatic-persisted-queries"},"unlisted":false,"prevItem":{"title":"GraphQL Conf 2023","permalink":"/blog/graphql-conf-2023"},"nextItem":{"title":"Unraveling the Challenges of BFF Federation","permalink":"/blog/unraveling-the-challenges-of-bff-federation"}},"content":"![Cover Image for The truth about scaling Automatic Persisted Queries](../static/images/blog/apq-cover.png)\\n\\nPersisted queries are often hailed as a solution to several challenges in GraphQL related to network performance, caching, and maintenance. However, they may not always be the silver bullet they appear to be. This post delves into the concept of persisted queries (PQ) and automatic persisted queries (APQ), highlighting the limitations and potential scaling issues that accompany these technologies.\\n\\n\x3c!-- truncate --\x3e\\n<head>\\n<link rel=\\"canonical\\" href=\\"https://tailcall.hashnode.dev/the-truth-about-scaling-automatic-persisted-queries\\"/>\\n<title>The truth about scaling Automatic Persisted Queries</title>\\n</head>\\n### The Problem\\n\\n#### Large Queries\\n\\nClients send queries to a GraphQL server as HTTP requests that include the query as the body. When these queries become large, they can lead to increased latency and network usage, degrading client performance.\\n\\nFor example, a normal GraphQL query might look like this:\\n\\n```bash\\ncurl -X POST -H \\"Content-Type: application/json\\" \\\\\\n  --data \'{\\"query\\": \\"{ largeQuery { field1 field2 ... } }\\"}\' \\\\\\n  http://your-graphql-server.com/graphql\\n```\\n\\nEach GraphQL query is parsed every time the server receives it. If it\'s large, the parsing can take a significant amount of time, increasing latency even further.\\n\\n#### Legacy Infrastructure\\n\\nExisting CDN infrastructure is designed to cache only GET calls. To make a GraphQL request, one must make a POST call. This limits the usage of CDNs for caching purposes.\\n\\n### Solution: Persisted Queries (PQ)\\n\\n#### Definition and Benefits\\n\\nTo enhance network performance for large query strings, GraphQL server supports Persisted Queries (PQ). A PQ is a GraphQL query cached server-side, identified by its SHA-256 hash. Clients send this identifier instead of the query, dramatically reducing request sizes (without affecting response), saving parsing time, and enabling GET calls instead of POST.\\n\\nA PQ request might look like this:\\n\\n```bash\\ncurl -X GET -H \\"Content-Type: application/json\\" \\\\\\n  --data-urlencode \'extensions={\\"persistedQuery\\":{\\"version\\":1,\\"sha256Hash\\":\\"<SHA 256>\\"}}\' \\\\\\n  http://your-graphql-server.com/graphql\\n```\\n\\n#### Application with CDNs\\n\\nUsing the PQ link automatically sends short hashed queries as GET requests, enabling CDNs to serve them.\\n\\n##### **Latency Reduction**\\n\\n- **No Parsing Overhead**: Since the query isn\'t sent to the server, the parsing stage, which can be computationally expensive, is eliminated. This saves valuable server processing time, directly reducing client latency.\\n\\n- **Network Efficiency**: By transmitting only the hash instead of the full query, the request size is dramatically reduced, leading to faster network transmission and lower latency.\\n\\n##### **Security Enhancements**\\n\\n- **Control Over Allowed Queries**: The server can start with a finite set of \\"allowed\\" queries, ensuring that unauthorized or unoptimized GraphQL requests cannot be made. This control is a significant safeguard for production environments, preventing potential abuse or inefficiencies.\\n\\n- **Reduction in Attack Surface**: By limiting the queries to a pre-defined set, the risk of malicious queries is reduced, enhancing the security profile of the application.\\n\\n#### Problem\\n\\nWhile PQs provide remarkable benefits, they are not without challenges:\\n\\n- **Schema Rigidity**: If you aim to keep the schema open and queries dynamic, supporting any possible query becomes complex.\\n\\n- **Maintenance of Cached Queries**: Managing the cache of allowed queries and keeping them in sync with evolving client needs can become a maintenance burden, especially in a fast-changing environment.\\n\\n### Automatic Persisted Queries (APQs)\\n\\n#### APQs vs PQs\\n\\nAPQs are a supposed improvement over PQs. In a PQ setup, the server runs with a known set of queries, meaning client changes require server updates. This has implications for maintenance costs, particularly in supporting multiple versions of queries and making a server deployment for every change in the client query. APQs were introduced to overcome these challenges.\\n\\n#### How APQs Work\\n\\nThe APQ process is a two-step approach:\\n\\n1. **Hash Request**: The client sends a request with the hash of the query. If the server recognizes the hash, it returns the corresponding response:\\n\\n   ```bash\\n   curl -X GET -H \\"Content-Type: application/json\\" \\\\\\n     --data-urlencode \'extensions={\\"persistedQuery\\":{\\"version\\":1,\\"sha256Hash\\":\\"<SHA 256>\\"}}\' \\\\\\n     http://your-graphql-server.com/graphql\\n   ```\\n\\n2. **Full Query Request**: If the server does not recognize the hash, it returns an error. The client then sends a new request that includes both the hash and the full query string:\\n\\n   ```bash\\n   curl --get http://localhost:4000/graphql \\\\\\n     --header \'content-type: application/json\' \\\\\\n     --data-urlencode \'{\\"query\\": \\"{ largeQuery { field1 field2 ... } }\\"}\' \\\\\\n     --data-urlencode \'extensions={\\"persistedQuery\\":{\\"version\\":1,\\"sha256Hash\\":\\"<HASH>\\"}}\'\\n   ```\\n\\n   The server parses the full query, caches it for future use, and returns the GraphQL response. Subsequent requests use the hash.\\n\\nThis process optimizes network performance while allowing flexibility in the queries that can be run. You can read more about APQ [here](https://www.apollographql.com/docs/apollo-server/performance/apq/)\\n\\n### Problems with APQs\\n\\n#### Thundering Herd Problem\\n\\nConsider a situation where a server has just been deployed or restarted, and the cache is empty. Now, multiple clients send hash requests for queries that are not yet cached.\\n\\n1. **Massive Error Responses**: Since the cache is empty, the server returns errors for all hash requests, signaling the clients to send the full query strings.\\n\\n2. **Simultaneous Full Query Requests**: All clients now simultaneously send full query requests, causing a sudden surge in demand.\\n\\n3. **Server Strain**: The server must parse and cache each unique query, placing significant strain on its resources. This can lead to increased latency and even server failure if the demand is too high.\\n\\n4. **Repeated Pattern**: If the server struggles to cache the queries quickly enough, the clients may continue to receive errors and retry the full query requests, perpetuating the problem.\\n\\nIn an environment with many clients and dynamically changing queries, the system can become vulnerable to sudden surges in demand. This vulnerability can undermine the performance benefits APQs are designed to provide, leading to potential system instability.\\n\\n#### Cache Limitations\\n\\nQueries are typically cached in memory, requiring cache warmup on each instance, hindering deployment on server-less solutions. An alternative could be using a centralized cache, but it typically nullifies performance gains due to serialization, deserialization, and IO call overhead.\\n\\n#### Security Concerns\\n\\nAutomatically persisting queries can cause memory leaks, as clients can send varying query combinations, exhausting server memory. Mitigation through cache size limits and eviction mechanisms may lead to frequent cache misses, leading to doubling request numbers.\\n\\n### Possible Solution\\n\\nPersistent queries are a great improvement over regular queries. They clearly improve performance and are more secure. APQs on the other hand though try to give more flexibility they can become quite messy to deal with as you scale. One alternative that is significantly more effective, is to run GraphQL on Edge itself. Essentially write your own CDN layer that is smart enough to understand that it\'s a graphQL and deploy it on edge with caching and whatnot! This is hard, and that\'s exactly what [Tailcall](https://tailcall.run) helps solve.\\n\\n### Conclusion\\n\\nAutomatic persisted queries, while offering some advantages in network performance, reveal significant challenges when it comes to scaling. The complexities of caching, potential security risks, and the inherent problems with automatic persistence highlight that persisted queries may not be the one-size-fits-all solution they are often portrayed as.\\n\\nThe question of whether to implement PQ or APQ must be approached with caution, taking into account the specific requirements and potential scalability issues of your system. While they may serve as a useful tool in certain scenarios, understanding the limitations and conducting thorough analysis is vital to avoid falling into the trap of a solution that doesn\'t truly scale. This blog post has aimed to shed light on these complexities, encouraging a more nuanced perspective on a topic that is often oversimplified."},{"id":"unraveling-the-challenges-of-bff-federation","metadata":{"permalink":"/blog/unraveling-the-challenges-of-bff-federation","source":"@site/blog/bff-challenges-2023-06-19.md","title":"Unraveling the Challenges of BFF Federation","description":"A different take on GraphQL Federation.","date":"2023-06-19T00:00:00.000Z","tags":[],"readingTime":10.425,"hasTruncateMarker":true,"authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=5","imageURL":"https://avatars.githubusercontent.com/u/194482?v=5"}],"frontMatter":{"title":"Unraveling the Challenges of BFF Federation","subtitle":"A different take on GraphQL Federation.","authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=5","imageURL":"https://avatars.githubusercontent.com/u/194482?v=5"}],"description":"A different take on GraphQL Federation.","image":"/images/blog/bff-cover.png","hide_table_of_contents":true,"slug":"unraveling-the-challenges-of-bff-federation","canonical_url":"https://tailcall.hashnode.dev/unraveling-the-challenges-of-bff-federation"},"unlisted":false,"prevItem":{"title":"The truth about scaling Automatic Persisted Queries","permalink":"/blog/the-truth-about-scaling-automatic-persisted-queries"},"nextItem":{"title":"No one talks about API Orchestration","permalink":"/blog/no-one-talks-about-api-orchestration"}},"content":"![Cover Image for Unraveling the Challenges of BFF Federation](../static/images/blog/bff-cover.png)\\nIn our [previous](https://blog.tailcall.run/no-one-talks-about-api-orchestration) blog post, we discussed the challenges of API Orchestration and its often overlooked role in a microservices architecture. We explored how, while it serves as an abstraction for frontend apps and websites, this abstraction\'s performance is very sensitive to network latency and device performance thus directly impacting end-user experience. One proposed solution was to create a Backend for Frontend (BFF) layer, essentially moving the frontend abstraction to powerful servers within your VPC. Although this approach effectively addresses the user experience problem and simplifies the work of front-end engineers, it introduces a new set of challenges for the backend, leading to difficulties in scaling the monolithic solution. Here\'s what the BFF architecture looked like:\\n\\n\x3c!-- truncate --\x3e\\n\\n<head>\\n<link rel=\\"canonical\\" href=\\"https://tailcall.hashnode.dev/unraveling-the-challenges-of-bff-federation\\"/>\\n<title>Unraveling the Challenges of BFF Federation</title>\\n</head>\\n\\n![Architecture Diagram for BFF](../static/images/blog/bff-architecture.png)\\n\\n## Using a BFF Federation\\n\\nFederation, as a concept, is not exclusive to GraphQL. In essence, it\'s about abstracting multiple data sources or services into a unified, single API interface that can be consumed by clients. This approach is not unique to any particular technology or framework and can be implemented with various tools and languages.\\n\\nHowever, GraphQL has played a significant role in popularizing the concept of federation. With its strong typing, introspective capabilities, and its natural fit for defining schemas across distributed services, it has provided an elegant solution to the challenge of federating APIs.\\n\\nWhile this blog discusses federation in the context of GraphQL, it\'s essential to understand that the core principles and challenges of the federation can be applied beyond GraphQL. Remember, the implementation of federation is not about a specific technology, but about the architectural approach to create a unified interface from multiple data sources.\\n\\nWith this in mind, let\'s delve into the pros and cons of the federation, using GraphQL as our main context for the discussion. As you\'ll see, the benefits and pitfalls of federation are relevant, whether you\'re using GraphQL or not.\\n\\nFederation is a concept that originates from the philosophy of microservices. This approach promotes the partitioning of large monolithic systems into smaller, more manageable components. In a federated architecture, instead of having a monolithic Backend-for-Frontend (BFF) handling all requests, you have multiple smaller BFFs that handle different aspects of the request.\\n\\nImagine a client makes a request to your system. This request still goes through an API gateway, which serves as the entry point to your system. However, instead of hitting a monolithic BFF, it now meets a BFF Router, specifically designed to understand and route requests to the appropriate BFFs.\\n\\nThe Router is smart. It understands the client\'s request and can break it down into smaller parts. It then delegates these smaller tasks to the appropriate services, each responsible for a specific aspect of the request. These services work in parallel, handling their part of the request, which often involves calling downstream microservices and orchestrating their responses.\\n\\nOnce the BFFs have finished their tasks, they send their responses back to the Router. The Router, in turn, takes these individual responses, combines them into a single response that fulfils the original request, and sends it back to the client.\\n\\nThis system, where individual services handle specific parts of a request in a coordinated manner, is often referred to as a Federation. The term \\"Apollo Federation\\" or \\"Super Graph\\" is commonly used to describe this setup when it\'s implemented with Apollo, a popular GraphQL implementation, but the concept is not limited to any specific technology or tool.\\n\\n![BFF Federation Architecture](../static/images/blog/bff-federation.png)\\n\\n## Federation Benefits\\n\\nMany large organizations using GraphQL in production have transitioned to this architecture to accommodate their scaling needs. The primary selling points of this architecture are:\\n\\n1. **Enhanced Team Ownership**: GraphQL Federation fosters a sense of ownership among teams by allowing each team to own and maintain its GraphQL service. With Federation, teams can operate independently, focusing on their specific domain without worrying about the overall schema. This separation of concerns leads to more maintainable code, faster development cycles, and increased productivity. It empowers teams to work in parallel, each owning a piece of the larger schema while ensuring that the entire system operates as a cohesive whole. This significantly enhances team efficiency and collaboration, particularly in larger organizations with multiple teams working on different services. This alone is by far the most significant aspect of using GraphQL Federation.\\n\\n2. **Incremental Adoption**: A major advantage of GraphQL Federation is its ability to support incremental adoption. This means teams can gradually wrap their domain-specific microservices with a GraphQL layer, one at a time, and integrate it into the federated schema without disrupting the entire system. This flexible approach minimizes the impact on existing workflows and reduces the risks associated with large-scale changes.  \\n   From the frontend perspective, GraphQL Federation offers a unified interface for querying the data. This simplifies the frontend code and enables the development of rich, interactive UIs with less effort. As soon as the first services are federated, frontend developers can begin transitioning their queries to the federated schema, reducing disruption and allowing for a smoother adoption process.  \\n   This incremental approach also allows teams to evaluate and demonstrate the value of federation at each step, building confidence and promoting buy-in across the organization. It ensures teams are not overwhelmed by the complexity of new technology or architecture and can adjust their practices as they learn.\\n\\n## Federation vs BFF\\n\\n![BFF vs Federation](../static/images/blog/bff-vs-federation.png)\\n\\nIt\'s not hard to see that GraphQL Federation carries some serious muscle over its monolithic adversary, the BFF. But before we declare a champion, let\'s take a few rounds to scrutinize the [limitations](https://blog.tailcall.run/no-one-talks-about-api-orchestration#heading-highly-specialized) we\'ve come across in our BFF solution, and see how the GraphQL Federation stands up under pressure. It\'s time for a head-to-head comparison!\\n\\n1. **Specialization**: Both BFF and GraphQL Federation require a certain amount of manual intervention. In the BFF approach, the entire layer is custom-built, meaning there\'s no ready-to-use solution, which necessitates significant manual management. On the other hand, GraphQL Federation provides an open-source, ready-to-use Apollo Router. However, it\'s not an all-inclusive solution, as the individual GraphQL services still need to be manually maintained and written by hand for specific use cases. While it\'s still a tough fight, the federation manages to land a jab here and gets a few extra points in this round.\\n\\n2. **Fragility**: Federation offers an enhanced strategy. In a federated architecture, when a GraphQL service malfunction, only its segment of the graph becomes inaccessible to the user. This results in a more resilient system, less prone to total failure, demonstrating the ability to continue the fight even after taking a hit. In this round, Federation steps up and delivers a solid punch.\\n\\n3. **Performance**: When it comes to Performance, the Federation architecture introduces an extra journey for each packet. The request has to travel through the router, then to the individual GraphQL services, before finally reaching the domain service. This journey can add a few milliseconds of latency, a difference that may not be perceptible to the end user. However, this seemingly small delay has a broader impact on the performance of the entire architecture. The addition of the router introduces a requirement for more infrastructure and increases the frequency of data serialization and deserialization. This increased complexity affects both the system\'s throughput and infrastructure costs. In this round, the Federation architecture might not be the clear knockout winner we were hoping for.\\n\\n4. **Monolith Tendency**: It\'s a clear knockout in this round for the Federation! It elegantly sidesteps the monolith tendency, keeping the architecture agile and modular. BFF, in contrast, takes a heavy fall with its tendency to become a monolithic layer over time.\\n\\n5. **Canary Release:** Federation, unlike BFF, reveals graph dependencies and compatibility issues at runtime, not compile time. This amps up the need for first-class canary releases. However, when it comes to canary support, it\'s a draw. Both fighters are still in the ring, each showing resilience in their own way. No knockout here, folks!\\n\\n6. **Coupled Release**: In the Federation architecture, each GraphQL service operates independently, significantly reducing the coupling between services and the router. This independence allows each team to manage its own release cycles, putting an end to the wide-scale halts that were commonplace with the BFF layer. However, it\'s important to note that each GraphQL service still maintains a tight connection with its corresponding downstream domain service. While this is a form of coupling, it\'s considerably less invasive than the BFF approach, where the entire layer was intertwined. Despite this necessary connection to the domain services, the Federation architecture proves to be more agile. In this round, GraphQL Federation edges out the BFF approach.\\n\\n7. **Organizational Friction:** With Federation, the responsibility for managing the architecture often falls squarely on the shoulders of backend engineers. The reason is simple: the complexity of the architecture and its intimate ties with downstream domain services necessitate a deep level of technical understanding. This is a departure from the BFF paradigm, where frontend teams could claim ownership of this part of the infrastructure. The intricate nature of the Federation, however, makes this almost untenable. When put head-to-head with BFFs, the Federation seems to take a step back in this regard. The power to control abstraction slips away from the consumer. In this round, BFFs manage to hold their ground.\\n\\n8. **Legacy Gateway:** Just as in the BFF model, the API gateway maintains its place in the Federation architecture, and rightfully so. However, we find ourselves reestablishing a substantial amount of resiliency and caching logic within these new layers, duplicating efforts previously expended on a traditional gateway. This redundancy marks a lack of efficiency in the Federation approach, signaling a tie in this round.\\n\\nOverall, this round favors GraphQL Federation. It proves to be a significantly more robust architecture when evaluated based on the aforementioned criteria. Let\'s explore further and assess how it performs in isolation and as the company expands.\\n\\n## Pitfalls of GraphQL Federation\\n\\nWhile GraphQL Federation has numerous benefits, it is not without its downsides. Here are some points of caution that should be considered when deciding to use this architecture:\\n\\n1. **Cost and Complexity:** GraphQL Federation introduces significant complexity into the architecture. Setting up, maintaining, and testing a federated graph can be a challenge as it requires a deep understanding of both GraphQL and distributed systems. Additionally, this architecture demands more infrastructure and a larger team for maintenance. As such, the adoption and migration process can be complex and costly. Typically, only large organizations with platform teams, robust budgets, and a governing body to maintain the schema\'s sanctity and system reliability, tend to consider adopting this approach. The inherent complexity and cost implications make the Federation a less likely choice for small to medium-sized organizations.\\n\\n2. **Ownership Challenges:** It is often argued that domain service owners maintain their individual GraphQL layers. However, this doesn\'t always reflect the reality. Services can frequently be divided or merged, leading to uncertainty about how to modify the GraphQL layer. This results in a complex web of requests from GraphQL services to domain services outside the team\'s control.\\n\\n3. **Infrastructure Scaling:** Each subgraph in a federated architecture operates on a separate piece of infrastructure, scaling independently. This brings its own set of challenges. For instance, when a subgraph is divided or merged, computing and scaling requirements need to be re-evaluated. Moreover, a deployment in another subgraph can trigger a substantial increase in load from the router on your subgraph, potentially causing unexpected stress on your infrastructure. This underscores the need for robust scaling and load-balancing strategies within a federated architecture.\\n\\nWhile GraphQL Federation has the potential to solve some issues of traditional BFF architecture, it brings in its own set of challenges. Therefore, it\'s important to evaluate these considerations based on the specific requirements and constraints of your project before deciding to implement this architecture.\\n\\n## We are onto something\\n\\nWhen examining the underlying issue, the debate essentially revolves around microservices and monoliths. Undoubtedly, the federated solution offers better scalability compared to a monolithic architecture; however, it also introduces a myriad of distinct challenges related to maintenance and costs that warrant careful consideration. This is not the end of the discussion, as client requests pass through CDNs and the Gateway before reaching the router, and we have yet to explore those components of the infrastructure. In the following sections, we will delve into these components and further investigate how they interact, as well as delve deeper into GraphQL."},{"id":"no-one-talks-about-api-orchestration","metadata":{"permalink":"/blog/no-one-talks-about-api-orchestration","source":"@site/blog/api-orchestration-2023-06-12.md","title":"No one talks about API Orchestration","description":"A Forsaken Piece Of Every Microservice Architecture","date":"2023-06-12T00:00:00.000Z","tags":[],"readingTime":10.235,"hasTruncateMarker":true,"authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=5","imageURL":"https://avatars.githubusercontent.com/u/194482?v=5"}],"frontMatter":{"title":"No one talks about API Orchestration","subtitle":"A Forsaken Piece Of Every Microservice Architecture.","authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=5","imageURL":"https://avatars.githubusercontent.com/u/194482?v=5"}],"description":"A Forsaken Piece Of Every Microservice Architecture","image":"/images/blog/bff-architecture.png","hide_table_of_contents":true,"slug":"no-one-talks-about-api-orchestration","canonical_url":"https://tailcall.hashnode.dev/no-one-talks-about-api-orchestration"},"unlisted":false,"prevItem":{"title":"Unraveling the Challenges of BFF Federation","permalink":"/blog/unraveling-the-challenges-of-bff-federation"}},"content":"![bff-architecture.png](../static/images/blog/bff-architecture.png)\\n\\n\x3c!-- truncate --\x3e\\n\\n<head>\\n<link rel=\\"canonical\\" href=\\"https://tailcall.hashnode.dev/no-one-talks-about-api-orchestration\\"/>\\n<title>No one talks about API Orchestration</title>\\n</head>\\n\\nBeing in the industry for many years, building and consuming microservices, I have realized that there is one problem that no one really talks about when it comes to microservices ie. API Orchestration. As engineers, we love our microservices, small independent components that are responsible for doing just one thing. The promise that was sold when I was a kid was you can build these small independent services and compose them together to build an app, very fast and reliably. It took me years to realize that the necessary tooling for \\"composing\\" just doesn\'t exist! There are tools for distributed tracing, observability, caching, discovery, etc. But to compose services to build a product is completely offloaded to front-end engineers! There were two things that were happening in the tech ecosystem:\\n\\n1. **Rich User Interfaces:** Responsive websites that worked on desktop and mobile are dead. To build a successful B2C business, you need to build for all three platforms viz. Android, iOS, and Web (Desktop/PWA). The applications need to look slick, rich in information, and have snappy response times. Development on multiple platforms requires a nuanced understanding of the stack and a lot of duplication of code.\\n\\n2. **Microservice Proliferation:** Companies these days bootstrap themselves on microservices instead of monoliths. This is because the tooling to build microservices has gotten a lot better, and reusable components are available either in open-source or as a SAAS solution. This allows developers to focus on their core business logic and move fast.\\n\\n## Microservice\\n\\nMicroservices architecture is a design pattern in which a large application is built as a suite of modular services, each of which runs its process and communicates with other services through well-defined interfaces, typically using a lightweight messaging protocol. This approach has several benefits over a monolithic architecture, including improved scalability, resilience, and maintainability. In a microservices architecture, each service has a specific role and is independently deployable, so developers can work on different services in parallel and deploy them independently of each other. This can make the development process more agile and allow for faster deployment of new features.\\n\\n![Microservices Architecture](../static/images/blog/microservices-architecture.png)\\n\\nAn API gateway is a server that acts as a single point of entry for certain types of requests. It can receive requests from the client, route them to the appropriate backend service, and then return the response from the backend service to the client. An API gateway can also perform tasks such as authentication, rate limiting, and caching. This makes it a useful component in a microservices architecture, where each service has its API and the API gateway acts as the \\"front door\\" for clients to access the services.\\n\\n## API Composition\\n\\nAPI composition refers to the process of combining multiple APIs to create a new API or a new functionality. This can be done by sending requests to multiple APIs and combining the results, or by creating a new API that acts as a fa\xe7ade for the underlying APIs.\\n\\n> \ud83d\udca1 API Composition is also known as API Orchestration. This is however vastly different from Microservice Orchestration.\\n\\nFor example, consider a scenario where a client application wants to display a user\'s profile information and recent posts on a social media platform. In this case, the client can send two separate requests to two different APIs: one to retrieve the user\'s profile information, and another to retrieve their recent posts. The client can then combine the results from these two APIs to create a single response that contains all the required information. This new response can be considered as the output of the composed API.\\n\\nTo build a rich user interface, API composition is necessary on the client side. One of the main challenges with API composition on the client side is that it can lead to increased complexity in the client application. This is because the client needs to handle the process of sending requests to multiple APIs and combining the results, which can add to the overall size and complexity of the client code.\\n\\nAnother challenge with API composition on the client side is that it can result in reduced performance and increased latency. This is because the client needs to make multiple separate requests to different APIs, which can take more time and result in a slower response from the composed API.\\n\\nIn addition, API composition on the client side can also lead to increased security risks. This is because the client needs to handle sensitive information, such as API keys and authentication credentials, which can be vulnerable to attacks if not properly secured. The client doesn\'t have access to powerful CPUs or a reliable network either. This makes the composition problem even more challenging to implement and manage. It is therefore often more efficient and effective to perform API composition on the server side instead.\\n\\n## Backend For Frontend\\n\\nA BFF layer can help to solve the challenges of API composition by providing a separate backend service that is optimized for each specific frontend client. This can enable the BFF to perform API composition on behalf of the client, which can help to improve the performance and reliability of the composed API. The BFF layer typically sits as a separate component in the overall architecture, between the frontend client and the microservices. It can communicate with both the frontend client and the microservices using well-defined interfaces and protocols, such as REST or gRPC.\\n\\nThe BFF can take advantage of a powerful CPU and access to a fast network to improve the performance and reliability of the composed API. It can also provide added flexibility and control over the composition process. This can make it a useful tool for developers who want to create new APIs by combining the functionality of multiple underlying APIs.\\n\\n![BFF Architecture](../static/images/blog/bff-architecture.png)\\n\\nBFFs truly solve the problems mentioned above to a great extent, however they introduce new set of challenges viz.\\n\\n### Highly Specialized\\n\\nOne of the challenges with using a BFF layer is that it is a highly specialized solution that requires a significant amount of hand-written code. Unlike an API gateway, there is no standard BFF solution that can be deployed out-of-the-box, and each BFF implementation must be custom-tailored to the specific requirements of the frontend client. This lack of standardization and reusability can make the BFF solution more complex and difficult to maintain.\\n\\n### Fragile\\n\\nAnother challenge with using a BFF layer is that it can be fragile and susceptible to failure. The BFF solution is dependent on the developers to follow best practices and handle all error scenarios, and if these steps are not taken, the solution can be prone to bugs and performance issues. Additionally, the BFF solution must be thoroughly tested, including performance testing, unit testing, and integration testing, to ensure that it is reliable and performs well in production. This can require significant effort and expertise, and if these steps are not properly followed, the BFF solution can be fragile and prone to failure. Also, it\'s worth mentioning that a BFF layer is an entry point to all your backend, it going down basically means nothing is accessible for the user so this layer needs to be robust and resilient to exceptions.\\n\\n### Performance\\n\\nBecause BFF layers are typically custom-written for each use case, it can be difficult to predict the performance impact of a small code change. Issues such as unoptimized algorithms, inefficient caching, and unnecessary downstream requests can go unnoticed and only be discovered very late in the development cycle. Typically companies perform thorough benchmarking and load testing before anything goes live. This results in a very high time to market even for minor changes.\\n\\n### Monolith\\n\\nEventually, this layer turns out to be a big monolith touching every service in your backend. The layer contains a lot of handwritten spaghetti code that\'s hard to maintain. Onboarding new engineers also becomes harder and upgrading libraries or architecture gets costlier. Any tiny change requires a full-fledged deployment on your infrastructure.\\n\\n### Canary Support (or lack thereof)\\n\\nEvery change that happens in the backend requires the deployment of the BFF layer. In fact, any feature that is built on the client also requires changes on the BFF layer. Such frequent changes can not be exposed to 100% of users because the reliability and performance of this system are unknown. A common way to solve this problem is to use [blue-green](https://www.redhat.com/en/topics/devops/what-is-blue-green-deployment) deployments. This requires additional infrastructure and complex routing mechanisms. First-class support to do canary releases is very important and should be part of a modern BFF layer, however, most companies rely on DevOps for its support.\\n\\n### Coupled Release\\n\\nBFF layers can\'t be deployed independently since they act as a bridge between the clients and the services. Generally, the services need to go live first, and they need to make sure that the change is compatible with the current version of the BFF layer running in production. The interesting problem is in case there is a bug in the microservice and it needs to be reverted, even the BFF layer needs to be reverted. This kind of coupling makes it operationally very expensive to manage.\\n\\n### Organizational Friction\\n\\nThe Backends for Frontends (BFF) pattern is designed to create a tailor-made backend service for each user interface (e.g., desktop, mobile, etc.), with the aim of simplifying the client-side and improving the user experience.\\n\\nHowever, in practice, this architecture sometimes creates friction within the organization, particularly when BFFs are developed and maintained by the backend team. Here are a few reasons why:\\n\\n1. **Communication and Responsiveness:** As the backend team is typically in charge of the BFF, front-end teams often have to wait for them to make necessary changes. This slows down the development process, especially when backlogs are high or priorities differ.\\n\\n2. **Different Skillsets:** Backend and frontend developers often specialize in different programming languages and paradigms. If the backend team is in charge of the BFF, they might not be as comfortable or efficient at dealing with issues that are more closely related to the frontend.\\n\\n3. **Lack of Ownership:** Frontend teams often feel that they lack ownership and control over the part of the system that directly impacts their work. This leads to decreased motivation and productivity.\\n\\nOne potential solution to these issues is to shift the ownership of the BFFs to the front-end teams. Since these teams are the primary consumers of the BFFs, they could be better placed to design, implement, and maintain them. This would not only empower the front-end teams but also free up backend teams to focus on their core responsibilities.\\n\\nHowever, this solution is not without its own challenges. For one, front-end teams would need to upskill to handle their new responsibilities. Also, the organization would need to ensure that there are clear lines of communication between the front-end and backend teams, so that any changes to shared resources can be coordinated effectively.\\n\\n### Legacy Gateway\\n\\nBFF layers often end up implementing some of the cross-cutting concerns of an API gateway such as rate limiting, authentication, throttling, etc. This makes its purpose quite confusing in the sense that do we need an API gateway if we are using a BFF layer. Moreover, it\'s not very clear if we use an API gateway with a BFF layer, where should we place it? Should we place it between the clients and the BFF layer or the BFF layer and the service mesh? These are subjective decisions that each company ends up making as there is no standard way of doing this. However, it\'s worth mentioning that legacy gateways do introduce a gap that\'s being attempted to be filled by a BFF layer.\\n\\n> BFF, Presentation Layer, Facade, Middleware, UI Layer, Orchestration Layer, API Adapter \u2014 Are all different nomenclatures used for the same thing.\\n\\nTo summarize, BFFs do indeed address the issues of API orchestration to a significant extent; however, they also present a new set of challenges for organizations to tackle. Clearly, there is more to the story. In our [next blog post](https://blog.tailcall.run/unraveling-the-challenges-of-bff-federation), we will discuss some of the solutions that large organizations with unlimited budgets have implemented to overcome this problem. So, please subscribe if you haven\'t already."}]}}')}}]);