"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[8749],{91895:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"graphql-vs-grpc","metadata":{"permalink":"/blog/graphql-vs-grpc","source":"@site/blog/grpc-vs-graphql-2024-07-26.mdx","title":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","description":"Discover the differences between GraphQL and gRPC. Learn which is better for your needs in this comprehensive guide. Find out now!","date":"2024-07-26T00:00:00.000Z","tags":[],"readingTime":8.02,"hasTruncateMarker":true,"authors":[{"name":"Hunain Ahmed","title":"A freelance software developer, always working on something new and fascinating.","url":"https://github.com/hunxjunedo","image_url":"https://avatars.githubusercontent.com/u/89797440?v=4","imageURL":"https://avatars.githubusercontent.com/u/89797440?v=4"}],"frontMatter":{"title":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","sidebar_label":"gRPC vs graphQL","description":"Discover the differences between GraphQL and gRPC. Learn which is better for your needs in this comprehensive guide. Find out now!","image":"/images/graphql/graphql-vs-grpc.png","authors":[{"name":"Hunain Ahmed","title":"A freelance software developer, always working on something new and fascinating.","url":"https://github.com/hunxjunedo","image_url":"https://avatars.githubusercontent.com/u/89797440?v=4","imageURL":"https://avatars.githubusercontent.com/u/89797440?v=4"}],"hide_table_of_contents":true,"slug":"graphql-vs-grpc"},"unlisted":false,"nextItem":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 4","permalink":"/blog/graphql-schema-part-2-3"}},"content":"![banner](/images/graphql/graphql-vs-grpc.png)\\n\\nWhile REST has been the go-to for API development, gRPC and GraphQL are stepping in as game-changing contenders.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Introduction\\n\\nWhen it comes to choosing the tech stack for your application, it\'s never a straightforward task, especially when choosing between gRPC and graphQL - both backed by tech giants. Follow us as we discuss real world scenarios and perform a detailed feature-comparison on both, concluding exactly where each should be used.\\n\\n## The Problem\\n\\nLet\u2019s say you are building a social app like Reddit, and you have screens like home and popular. You implement a simple REST API on the backend and everything looks fine:\\n\\n- it wasn\u2019t so challenging to setup\\n- has tons of resources if anything goes wrong\\n- seems like a perfect solution.\\n\\nUntil the user base grows and there\u2019s thousands of users - and disaster strikes: the loading times increase and the costs skyrocket, you begin to lose engagement of the users.\\n\\nDeep down, the root cause of this problem is the slow nature of REST and over-fetching. What happens is that when a user opens the app, goes to the home screen, and the app fetches tons of unnecessary data from the backend: all pictures of a post, all comments and even related posts! Which is even worsened by the fact that the client has to call multiple endpoints to finally show the feed to the user. You are stuck in performance jargon, let\u2019s rewind it. You use graphQL instead of REST, which has many advantages over the REST:\\n\\n- thanks to its predefined schemas you don\u2019t have to spend hours writing simple validation tests to check that a parameter is a number and not a string.\\n- graphQL only serves what the client asks for, which means there\u2019s no chance of over-fetching\\n- not to mention that one endpoint of graphQL is more useful and comprehensive than 5 REST API routes.\\n\\n## Knowing gRPC\\n\\nSo what is behind the magic of gRPC ? Since Google open-sourced it in 2015, gRPC has been revolutionizing service-to-service communication with its robust, schema-driven framework. By harnessing the power of HTTP/2 and Protocol Buffers (Protobuf), gRPC unleashes high-performance, real-time data streaming and rock-solid typing - a winning combo that\'s made it a go-to tool for developers building scalable, efficient systems. No wonder tech titans like [Tesla, Netflix, Coinbase and Dropbox](https://theirstack.com/en/technology/grpc) are all on board!\\n\\nRead more about [What is gRPC](/blog/what-is-grpc/).\\n\\n![companies using grpc](/images/docs/stack-grpc.png)\\n\\n## Unleashing GraphQL Magic!\\n\\nGraphQL, born at Facebook in 2012 and unleashed to the world in 2015, revolutionizes API queries. It\u2019s a powerful and flexible alternative to REST APIs, featuring declarative data fetching that ensures you get just the data you need\u2014no more, no less. With a single endpoint, GraphQL simplifies API structures, eliminating the hassle of managing multiple endpoints. This efficiency and flexibility have made it the darling of tech giants like [Github, Meta, Shopify and Microsoft ](https://landscape.graphql.org/borderless-mode?grouping=category). With GraphQL, you can build more efficient and intuitive APIs that make data fetching a breeze!\\n\\nRead more about [What is GraphQL and How it works?](/graphql/what-is-graphql).\\n\\n![companies using graphql](/images/docs/stack-graphql.png)\\n\\n## Feature Comparison\\n\\n| Feature                           | gRPC                                                    | GraphQL                                                                                        |\\n| --------------------------------- | ------------------------------------------------------- | ---------------------------------------------------------------------------------------------- |\\n| **Message Format**                | Binary                                                  | JSON                                                                                           |\\n| **Data Fetching**                 | Fixed endpoints and methods                             | Flexible queries, specified by clients                                                         |\\n| **Real-Time**                     | Supports streaming via server-side push                 | Supports real-time updates via subscriptions                                                   |\\n| **Type Safety**                   | Strongly typed with Protocol Buffers                    | Strongly typed with schema definition                                                          |\\n| **Introspection**                 | No built-in introspection                               | Built-in schema introspection                                                                  |\\n| **Code Generation**               | Automatic code generation from .proto files             | Code generation tools available, but not automatic                                             |\\n| **Tooling and Browser Support**   | Limited browser support, requires proxies for web use   | Strong tooling support, works natively in browsers                                             |\\n| **Community**                     | currently nascent                                       | Growing rapidly, strong in web and mobile development                                          |\\n| **Adoption**                      | widely in microservices                                 | mostly in mobile app development and [PWA](https://en.wikipedia.org/wiki/Progressive_web_app)s |\\n| **Performance**                   | High performance with low latency                       | Generally efficient, schemas defined correctly                                                 |\\n| **Debugging and Troubleshooting** | non-human-readable format, require tools for debugging. | JSON response is easier to read and debug                                                      |\\n\\n## Scenarios for Using gRPC\\n\\nThe ideal scenario for gRPC? When microservices need to communicate at lightning speed and with top-notch efficiency! Think of gRPC as the ultimate express lane for data\u2014perfect when you need swift, reliable interactions and don\u2019t need to be super flexible. It\u2019s like having a fast track for your information, keeping everything running smoothly and quickly!\\n\\n### Scenario 1: A social media app backend\\n\\n![sm app example](/images/docs/services.png)\\n\\nImagine a social media app where everything works like clockwork. Here\u2019s how gRPC fits in:\\nThe Cast:\\n\\n- Media-Scanner: Analyzes media files with precision.\\n- Media-Tagger: Tags content accurately.\\n- Jobs-Manager: Handles tasks efficiently.\\n- Followers-Notifier: Sends timely updates to users.\\n\\nIn this setup, gRPC\u2019s Protocol Buffers ensure fast, efficient communication, cutting down on overhead and latency. Each service gets exactly what it needs, there\'s no risk of overfetching. It\u2019s a perfect match for microservices, where speed and efficiency are key.\\n\\n### Scenario 2: A movie streaming backend\\n\\n![movie app example](/images/docs/services2.png)\\n\\nImagine the backend of a movie-streaming app, where Content-Age-Rater, Relations-Builder, Subtitles-Generator, and Subtitles-Translator each have their own star roles. They rate movies, connect related content, create subtitles, and translate them with precision. With gRPC, these services chat efficiently, making sure data zips around quickly and smoothly. No extra baggage\u2014just a slick, high-performance team working seamlessly together. It\u2019s like having a top-notch crew behind the scenes, making sure everything runs smooth! \ud83c\udfac\ud83c\udf7f\\n\\n## Scenarios for Using GraphQL\\n\\nGraphQL shines when you need to tailor data fetching to match your frontend\'s needs precisely. It allows for fetching exactly the data you need, nothing more, nothing less, which can be a game-changer for optimizing performance and reducing over-fetching. This flexibility can really streamline interactions between the frontend and backend, especially in complex applications, as we discuss below:\\n\\n### Scenario 1: Fetching Multiple Items\\n\\nGitHub uses GraphQL to make fetching PR details a breeze. With gRPC, you\'d have to set up different RPC methods for each data type\u2014comments, commits, changed files\u2014potentially resulting in several requests. Often, you just need the first and last comments right off the bat. GraphQL swoops in, pulling exactly those details with one neat query, cutting down on network strain and speeding things up.\\n\\n```graphql\\nquery {\\n  repository(owner: \\"username\\", name: \\"repository-name\\") {\\n    pullRequest(number: 123) {\\n      title\\n      createdAt\\n      updatedAt\\n      author {\\n        login\\n        avatarUrl\\n      }\\n      comments(first: 2, orderBy: {field: CREATED_AT, direction: ASC}) {\\n        nodes {\\n          author {\\n            login\\n          }\\n          body\\n          createdAt\\n        }\\n      }\\n    }\\n  }\\n}\\n```\\n\\nInstagram uses a smart approach to fetch just a handful of comments on a reel\u2014those that show up right under the title without diving into the full comments section. It\u2019d be a hassle to pull 10 or 20 comments when only 5 are needed. This is where GraphQL shines, perfectly tuned for getting just the right data without any extra fluff.\\n\\n### Scenario 2: Ecommerce App\\n\\n![graphql fetch](/images/docs/fetch-graphql.png)\\n\\nThink about an ecommerce app with loads of products. On the explore page, users just want a quick snapshot\u2014picture, name, and a brief description. But when they dive into a product page, they\u2019re looking for more details like weight and extra images. With gRPC, you\u2019d need separate calls for each view, which can be a bit clunky and might pull in extra data. GraphQL, on the other hand, lets you customize your queries to get just what you need for each page, cutting down on excess data and making everything run smoother:\\n\\n```graphql\\nquery {\\n  products {\\n    id\\n    name\\n    shortDescription\\n    imageUrl\\n  }\\n}\\n```\\n\\nFor the product details page:\\n\\n```graphql\\nquery {\\n  product(id: \\"product-id\\") {\\n    id\\n    name\\n    description\\n    weight\\n    images {\\n      url\\n    }\\n  }\\n}\\n```\\n\\nThis approach makes data retrieval a breeze and keeps performance top-notch, highlighting why GraphQL shines in dynamic content and ecommerce apps over gRPC. It\u2019s all about getting exactly what you need, when you need it, and keeping things running smoothly!\\n\\n## Integrating gRPC and GraphQL\\n\\n![integrating both](/images/docs/integration.png)\\n\\nPicture a social media app where the backend whips up user feeds based on activity. The frontend needs different data for various screens\u2014blogs or videos\u2014so grabbing everything at once would be overkill. GraphQL steps in to save the day by letting the frontend fetch just what it needs, keeping things snappy and efficient.\\n\\nMeanwhile, backend services like feed-generator and logs-handler are busy creating and analyzing feeds. They require steady input and don\u2019t need much tweaking once live. For this, gRPC is perfect with its lightning-fast performance and low latency.\\n\\nBy mixing GraphQL on the frontend with gRPC on the backend, you get a dynamic, high-performance setup. GraphQL fine-tunes data requests while gRPC keeps backend communication smooth.\\n\\nRead this guide explaining the challenges and details associated with integrating gRPC and graphQL: [Building GraphQL over gRPC](/docs/graphql-grpc-tailcall) .\\n\\n## Conclusion\\n\\nIn summary, both gRPC and graphQL have numerous advantages over each other, where gRPC has:\\n\\n- more boosted performance\\n- Low payload sizes\\n- Simple and intuitive API design\\n\\nOn the other hand GraphQL takes the lead in:\\n\\n- API flexibility\\n- Friendly nature for web and mobile apps\\n- Easier debugging\\n\\nIt doesn\u2019t matter which one is better, what truly matters is how good it is implemented, and how well it suits the use case. Remember - as Doug LInder likes to say -\\n\\n**_\u201cA good programmer is someone who always looks both ways before crossing a one-way street\u201d_**\\n\\nthis simple concept can elevate you to the top tier of programmers."},{"id":"graphql-schema-part-2-3","metadata":{"permalink":"/blog/graphql-schema-part-2-3","source":"@site/blog/graphql-schema-part-2-3-2024-07-23.mdx","title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 4","description":"Learn how to remove schema elements without causing disruptions. Strategies to handle breaking changes and maintain backward compatibility.","date":"2024-07-23T00:00:00.000Z","tags":[{"inline":true,"label":"GraphQL","permalink":"/blog/tags/graph-ql"},{"inline":true,"label":"API","permalink":"/blog/tags/api"},{"inline":true,"label":"Schema","permalink":"/blog/tags/schema"},{"inline":true,"label":"Design","permalink":"/blog/tags/design"},{"inline":true,"label":"Best Practices","permalink":"/blog/tags/best-practices"}],"readingTime":6.665,"hasTruncateMarker":true,"authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"frontMatter":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 4","authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"tags":["GraphQL","API","Schema","Design","Best Practices"],"description":"Learn how to remove schema elements without causing disruptions. Strategies to handle breaking changes and maintain backward compatibility.","image":"/images/blog/quiz-part4.png","hide_table_of_contents":true,"slug":"graphql-schema-part-2-3"},"unlisted":false,"prevItem":{"title":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","permalink":"/blog/graphql-vs-grpc"},"nextItem":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 3","permalink":"/blog/graphql-schema-part-2-2"}},"content":"import Quiz from \\"../src/components/quiz/quiz.tsx\\"\\n\\n## What Do You Already Know? \ud83e\udde0\ud83d\udcab\\n\\n<Quiz\\n  title=\\"GraphQL Schema Change\\"\\n  questions={[\\n    {\\n      id: 1,\\n      text: \\"What is a critical consideration before removing a field from a GraphQL schema?\\",\\n      options: [\\n        \\"Ensuring the field is no longer in use by any clients\\",\\n        \\"Providing a detailed explanation in the schema documentation\\",\\n        \\"Immediately notifying all clients via email\\",\\n        \\"Replacing the field with a temporary placeholder\\",\\n      ],\\n      correctAnswer: 0,\\n    },\\n    {\\n      id: 2,\\n      text: \\"Why is it recommended to deprecate a field before removing it?\\",\\n      options: [\\n        \\"To avoid immediate schema validation errors\\",\\n        \\"To provide clients with time to migrate to the new schema\\",\\n        \\"To enhance schema performance temporarily\\",\\n        \\"To test the removal process in a staging environment\\",\\n      ],\\n      correctAnswer: 1,\\n    },\\n    {\\n      id: 3,\\n      text: \\"What is the best practice for handling arguments that cannot be deprecated directly in GraphQL?\\",\\n      options: [\\n        \\"Removing the argument immediately and updating the resolver\\",\\n        \\"Indicating the deprecation through the argument\'s description\\",\\n        \\"Notifying clients to ignore the argument\\",\\n        \\"Using schema validation to enforce the change\\",\\n      ],\\n      correctAnswer: 1,\\n    },\\n    {\\n      id: 4,\\n      text: \\"What is a key risk when removing a type that is part of a union or implements an interface?\\",\\n      options: [\\n        \\"It will cause performance degradation\\",\\n        \\"It cannot be documented properly\\",\\n        \\"It may break queries that rely on the type\\",\\n        \\"It requires changing the schema version\\",\\n      ],\\n      correctAnswer: 2,\\n    },\\n    {\\n      id: 5,\\n      text: \\"How can you minimize disruption when removing an argument from a GraphQL query?\\",\\n      options: [\\n        \\"Immediately notify all clients\\",\\n        \\"Provide a new query or field that does not use the argument\\",\\n        \\"Deprecate the entire query\\",\\n        \\"Change the schema version\\",\\n      ],\\n      correctAnswer: 1,\\n    },\\n    {\\n      id: 8,\\n      text: \\"What is the primary goal of providing a deprecation period before removing a schema element?\\",\\n      options: [\\n        \\"To test the impact of the removal on server performance\\",\\n        \\"To allow clients sufficient time to adjust their queries\\",\\n        \\"To prepare the documentation for the change\\",\\n        \\"To gradually phase out old schema versions\\",\\n      ],\\n      correctAnswer: 1,\\n    },\\n  ]}\\n/>\\n\x3c!-- truncate --\x3e\\n\\n## Removing Without Breaking: The Subtraction Subterfuge\\n\\nIn our [previous post](/blog/graphql-schema-part-2-2), we explored how to modify existing schema elements without causing disruptions. Now, we\'ll tackle the most challenging part: removing schema elements and handling breaking changes.\\n\\n## Recap of Additive Changes and Modifications\\n\\nIn [Part 2](/blog/graphql-schema-part-2-1), we focused on additive changes, emphasizing the importance of expanding your schema\'s capabilities without disrupting existing clients. By adding new fields, types, and arguments, you can enhance your API while maintaining backward compatibility.\\n\\nIn [Part 3](/blog/graphql-schema-part-2-2), we delved into modifying existing schema elements, discussing how to handle changes such as updating default values, transforming non-null fields to nullable, and changing field types. We highlighted the need for clear communication, providing transition paths, and leveraging schema design tools to minimize client disruptions.\\n\\n### Safe, Dangerous, and Breaking Changes\\n\\n1. **Safe Changes:** Additive changes such as adding new fields or types that do not affect existing queries or functionality.\\n2. **Dangerous Changes:** Modifications that might not break the schema immediately but can cause subtle issues, such as changing default values or making non-nullable fields nullable.\\n3. **Breaking Changes:** Changes that will definitely break existing queries and require clients to update their code, such as removing fields or changing field types.\\n\\n## The Subtraction Subterfuge\\n\\nRemoving things from your schema is almost always a breaking change. If you remove a field, type, or argument, clients that depend on it will break. You can\'t just take things away without consequences.\\n\\nBut sometimes, it\'s necessary. Here\'s how to do it without causing a riot.\\n\\n### The Field Farewell\\n\\nLet\'s say we want to remove a field because it\'s causing performance issues. Here\'s the smart way to do it:\\n\\n1. Introduce a replacement\\n2. Deprecate the old field\\n3. Wait (patiently!)\\n4. Remove when usage has died down\\n\\n```diff\\ntype Query {\\n-  products(first: Int!): [Product!]!\\n+  products(first: Int!): [Product!]! @deprecated(reason: \u201cproducts is deprecated and is getting replaced by the field `topProducts`.\u201d)\\n+  topProducts(first: Int!): [Product!]!\\n}\\n```\\n\\nBy introducing `topProducts` and deprecating `products`, we give our clients time to adapt. And hey, we\'ve even improved our API in the process!\\n\\nThe old field may be removed after a certain period and if the usage for it has gone down. Keep in mind you don\u2019t necessarily have to make the change unless absolutely needed. Additive changes and deprecations are sometimes enough to keep evolving the API.\\n\\n### The Argument Abandonment\\n\\nRemoving an argument is similar to removing a field. You can deprecate it and\\n\\nintroduce a new field with the desired behavior. Clients will have time to migrate to the new field before the old one is removed.\\n\\n```diff\\ntype Query {\\n-  products(first: Int!, featured: Boolean): String!\\n+  products(first: Int!, featured: Boolean): String! @deprecated(reason: \u201cproducts is deprecated, use `allProducts` for products and `featuredProducts` to get products that are featured\u201d)\\n+  allProducts(first: Int!): String!\\n+  featuredProducts(first: Int!): String!\\n}\\n```\\n\\nIf you need to make a change to an existing field, because arguments can\u2019t be deprecated just yet, you should indicate that the argument is deprecated through its description.\\n\\n```diff\\ntype Query {\\n- products(first: Int!, featured: Boolean): String!\\n+  products(first: Int!,\\n+  # DEPRECATED: This argument will be removed. Use query `featuredProducts`.\\n+  featured: Boolean\\n+   ): String!\\n}\\n```\\n\\n### The Type Deletion Dilemma\\n\\nSometimes, you need to remove an entire type from your schema. This is a major operation and requires careful planning.\\n\\n1. First, deprecate all fields that return this type:\\n\\n```graphql\\ntype Query {\\n  oldUser(id: ID!): OldUser @deprecated(reason: \\"Use `user` query with new User type instead\\")\\n  user(id: ID!): User\\n}\\n```\\n\\n2. If the type is part of a union or implements an interface, you\'ll need to be extra cautious. These can\'t be easily deprecated, so clear communication is key.\\n3. Finally, after a long deprecation period and when usage has dropped to zero, you can remove the type entirely.\\n\\nNote that you might want to deprecate using that type within your codebase to avoid developers to use that User type for new fields. Removing a type is even trickier when it\u2019s part of union types or implements interfaces. Once again, union members and interface implementations cannot be marked as deprecated. This means that fields like node may stop working correctly if the type you\u2019re removing was reachable through that field.\\n\\nYour best bet in these cases are to either keep this type as part of unions and through interfaces or to communicate that change very carefully through descriptions and out of band communication like documentation and emails.\\n\\n## Conclusion\\n\\nRemoving schema elements is a delicate process that requires strategic planning and clear communication to avoid breaking changes. By following the principles and strategies outlined in this article, you can confidently remove fields, arguments, and types while minimizing disruption to your clients.\\n\\nRemember these key takeaways:\\n\\n1. **Deprecate Cautiously**: Use deprecation notices, schema descriptions, and out-of-band communication to keep your clients informed about upcoming changes.\\n2. **Provide Transition Paths**: When breaking changes are necessary, offer clear migration paths. This might involve introducing new fields alongside deprecated ones or providing new query structures that achieve the same results.\\n3. **Monitor Usage**: Keep an eye on usage metrics to determine when it\'s safe to remove deprecated elements. Don\'t rush the process \u2013 give your clients time to adapt.\\n   :::note\\n   Tailcall supports a variety of integrations with monitoring tools to help you track usage metrics and make informed decisions about schema changes. you can check out our [documentation](/docs/graphql-data-dog-telemetry-tailcall/) for more information.\\n   :::\\n\\nBy treating your GraphQL schema as a product with its own lifecycle and evolution strategy, you can build APIs that are both powerful and adaptable. This approach allows you to innovate rapidly while providing a stable and reliable service to your clients.\\n\\nRemember, a great GraphQL schema is never truly finished \u2013 it\'s a living, breathing entity that grows and evolves with your application\'s needs. Embrace this continuous evolution, and you\'ll create APIs that stand the test of time."},{"id":"graphql-schema-part-2-2","metadata":{"permalink":"/blog/graphql-schema-part-2-2","source":"@site/blog/graphql-schema-part-2-2-2024-07-22.mdx","title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 3","description":"Learn how to modify existing schema elements in GraphQL without causing disruptions.","date":"2024-07-22T00:00:00.000Z","tags":[{"inline":true,"label":"GraphQL","permalink":"/blog/tags/graph-ql"},{"inline":true,"label":"API","permalink":"/blog/tags/api"},{"inline":true,"label":"Schema","permalink":"/blog/tags/schema"},{"inline":true,"label":"Design","permalink":"/blog/tags/design"},{"inline":true,"label":"Best Practices","permalink":"/blog/tags/best-practices"}],"readingTime":4.625,"hasTruncateMarker":true,"authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"frontMatter":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 3","authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"tags":["GraphQL","API","Schema","Design","Best Practices"],"description":"Learn how to modify existing schema elements in GraphQL without causing disruptions.","image":"/images/graphql/graphql-schema-structure.png","hide_table_of_contents":true,"slug":"graphql-schema-part-2-2"},"unlisted":false,"prevItem":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 4","permalink":"/blog/graphql-schema-part-2-3"},"nextItem":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 2","permalink":"/blog/graphql-schema-part-2-1"}},"content":"import Quiz from \\"../src/components/quiz/quiz.tsx\\"\\n\\n## What Do You Already Know? \ud83e\udde0\ud83d\udcab\\n\\n<Quiz\\n  title=\\"GraphQL Schema Change\\"\\n  questions={[\\n    {\\n      id: 1,\\n      text: \\"Changing the default value of an argument is considered a:\\",\\n      options: [\\"Safe change\\", \\"Dangerous change\\", \\"Breaking change\\", \\"Non-issue\\"],\\n      correctAnswer: 1,\\n    },\\n    {\\n      id: 2,\\n      text: \\"When changing a field type from non-nullable to nullable, what should be considered to prevent client-side errors?\\",\\n      options: [\\n        \\"Updating the field\'s description\\",\\n        \\"Implementing a fallback value in resolvers\\",\\n        \\"Notifying clients via email\\",\\n        \\"Adding a deprecation notice\\",\\n      ],\\n      correctAnswer: 1,\\n    },\\n    {\\n      id: 3,\\n      text: \\"Which of the following changes is likely to cause the most disruption?\\",\\n      options: [\\n        \\"Changing a field\'s default value\\",\\n        \\"Deprecating a field\\",\\n        \\"Changing a field\'s type from String to ID\\",\\n        \\"Adding a new optional argument\\",\\n      ],\\n      correctAnswer: 2,\\n    },\\n    {\\n      id: 4,\\n      text: \\"Modifying an existing field to be non-null is generally considered a:\\",\\n      options: [\\"Safe change\\", \\"Dangerous change\\", \\"Breaking change\\", \\"Improvement\\"],\\n      correctAnswer: 2,\\n    },\\n    {\\n      id: 5,\\n      text: \\"When changing a field\'s return type, what is the best approach to minimize client impact?\\",\\n      options: [\\n        \\"Immediately update the schema\\",\\n        \\"Provide a new field with the updated type and deprecate the old one\\",\\n        \\"Change the field type and notify clients afterward\\",\\n        \\"Modify the resolver logic to handle both types\\",\\n      ],\\n      correctAnswer: 1,\\n    },\\n  ]}\\n/>\\n\\n\x3c!-- truncate --\x3e\\n\\n## Modifying Without Breaking: Navigating the Modification Minefield\\n\\nIn our [previous post](/blog/graphql-schema-part-2-1), we explored how to make additive changes to your GraphQL schema without causing disruptions. Now, we\'ll dive into the tricky territory of modifying existing schema elements.\\n\\n## Recap of Additive Changes\\n\\nIn [Part 2](/blog/graphql-schema-part-2-1), we discussed the importance of making additive changes to your GraphQL schema to expand its capabilities while maintaining backward compatibility. By adding new fields, types, and arguments, you can enhance your API without causing disruptions to existing clients. We also emphasized the importance of providing transition paths to ensure a smooth adoption process.\\n\\n### Safe, Dangerous, and Breaking Changes\\n\\n1. **Safe Changes:** Additive changes such as adding new fields or types that do not affect existing queries or functionality.\\n2. **Dangerous Changes:** Modifications that might not break the schema immediately but can cause subtle issues, such as changing default values or making non-nullable fields nullable.\\n3. **Breaking Changes:** Changes that will definitely break existing queries and require clients to update their code, such as removing fields or changing field types.\\n\\n## The Modification Minefield\\n\\nNow, let\'s talk about modifying existing parts of your schema. This is where things can get really hairy. For example, changing a field\u2019s type or changing the name of a type is a big-breaking change.\\n\\n### The Default Value Dilemma\\n\\nChanging default values might seem innocent, but it can cause some serious headaches. Consider this:\\n\\n```diff\\ntype Query {\\n-  products(category: String, showOutOfStock: Boolean = False): [Product!]!\\n+  products(category: String, showOutOfStock: Boolean = True): [Product!]!\\n}\\n```\\n\\nChanging the default value of an argument or input field is unlikely to be a breaking change in terms of the schema itself, but is very likely to cause issues at runtime if the default value affects the runtime behavior of the field.\\n\\nAvoid this change in general, but it may be possible to achieve if the behavior of the field does not change.\\n\\n### The Non-Null to Null Transformation\\n\\nThis is one of the trickiest changes to make. You thought making a field non-null was a good idea, but now you need to change it back. Here\'s how to handle it:\\n\\nFor scalar fields, you might be able to save your users from errors by returning the `default value` instead of null.\\n\\nFor object types, sometimes it\u2019s possible to use a `Default Object` when the result is null.\\n\\nThis approach can help prevent null pointer exceptions on the client side.\\n\\n### Changing a Field Type\\n\\nChanging a field\u2019s type is not a change we can make easily. Once again, approaching the change in an additive is often your best bet.\\n\\n```diff\\ntype User {\\n  bestFriend: String! @deprecated(reason: \u201cUse `bestFriendObject` instead.\u201d)\\n+ bestFriendObject: User!\\n}\\n```\\n\\nAs you might have noticed, the downside of additive changes is that often the best names are already taken. If wanted, you may remove the original field and reintroduce it under the new object at that point.\\n\\n```diff\\ntype User {\\n- bestFriend: String! @deprecated(reason: \u201cUse `bestFriendObject` instead.\u201d)\\n  bestFriendObject: User!\\n+ bestFriend: User!\\n}\\n```\\n\\n### Changing Description or Deprecation\\n\\nChanging the description of fields, types and any member is unlikely to cause any harm to clients. Clients should not depend on schema descriptions for runtime logic!\\n\\n## Conclusion\\n\\nModifying existing schema elements requires careful planning and execution to avoid breaking changes. By following the principles and strategies outlined in this article, you can confidently make necessary modifications while minimizing disruption to your clients.\\n\\nRemember these key takeaways:\\n\\n1. **Deprecate Cautiously**: Use deprecation notices, schema descriptions, and out-of-band communication to keep your clients informed about upcoming changes.\\n2. **Provide Transition Paths**: When breaking changes are necessary, offer clear migration paths. This might involve introducing new fields alongside deprecated ones or providing new query structures that achieve the same results.\\n3. **Leverage Schema Design Tools**: Use schema comparison tools like [GraphQL Editor](https://github.com/graphql-editor/graphql-editor).\\n\\nBy treating your GraphQL schema as a product with its own lifecycle and evolution strategy, you can build APIs that are both powerful and adaptable. This approach allows you to innovate rapidly while providing a stable and reliable service to your clients.\\n\\nStay tuned for the [next part](/blog/graphql-schema-part-2-3) of this series, where we will dive into removing schema elements and handling breaking changes!"},{"id":"graphql-schema-part-2-1","metadata":{"permalink":"/blog/graphql-schema-part-2-1","source":"@site/blog/graphql-schema-part-2-1-2024-07-21.mdx","title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 2","description":"Learn how to make additive changes to your GraphQL schema without causing disruptions.","date":"2024-07-21T00:00:00.000Z","tags":[{"inline":true,"label":"GraphQL","permalink":"/blog/tags/graph-ql"},{"inline":true,"label":"API","permalink":"/blog/tags/api"},{"inline":true,"label":"Schema","permalink":"/blog/tags/schema"},{"inline":true,"label":"Design","permalink":"/blog/tags/design"},{"inline":true,"label":"Best Practices","permalink":"/blog/tags/best-practices"}],"readingTime":8.15,"hasTruncateMarker":true,"authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"frontMatter":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 2","authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"tags":["GraphQL","API","Schema","Design","Best Practices"],"description":"Learn how to make additive changes to your GraphQL schema without causing disruptions.","image":"/images/graphql/graphql-schema-structure.png","hide_table_of_contents":true,"slug":"graphql-schema-part-2-1"},"unlisted":false,"prevItem":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 3","permalink":"/blog/graphql-schema-part-2-2"},"nextItem":{"title":"Apollo vs Urql vs Fetch: The Ultimate Showdown","permalink":"/blog/graphql-angular-client"}},"content":"import Quiz from \\"../src/components/quiz/quiz.tsx\\"\\n\\n## What Do You Already Know? \ud83e\udde0\ud83d\udcab\\n\\n<Quiz\\n  title=\\"GraphQL Schema Change\\"\\n  questions={[\\n    {\\n      id: 1,\\n      text: \\"Adding a new field to a GraphQL schema is generally a:\\",\\n      options: [\\"Safe change\\", \\"Dangerous change\\", \\"Breaking change\\", \\"Requires deprecation\\"],\\n      correctAnswer: 0,\\n    },\\n    {\\n      id: 2,\\n      text: \\"What is a potential issue when adding a new optional argument to a resolver?\\",\\n      options: [\\n        \\"It requires clients to update their queries\\",\\n        \\"It can change the default behavior if not handled properly\\",\\n        \\"It always breaks existing queries\\",\\n        \\"It is not allowed in GraphQL\\",\\n      ],\\n      correctAnswer: 1,\\n    },\\n    {\\n      id: 3,\\n      text: \\"Which strategy can make adding a required argument safe?\\",\\n      options: [\\n        \\"Introducing a new field\\",\\n        \\"Providing a default value\\",\\n        \\"Deprecating the old argument\\",\\n        \\"Using introspection queries\\",\\n      ],\\n      correctAnswer: 1,\\n    },\\n    {\\n      id: 4,\\n      text: \\"What is a common risk when adding a new type to an existing interface?\\",\\n      options: [\\n        \\"Clients will receive runtime errors if not properly type-checked\\",\\n        \\"The schema becomes invalid\\",\\n        \\"Existing types get overridden\\",\\n        \\"It forces all clients to update immediately\\",\\n      ],\\n      correctAnswer: 0,\\n    },\\n    {\\n      id: 5,\\n      text: \\"What should clients implement to handle new union members?\\",\\n      options: [\\n        \\"Fallback UI components for unknown types\\",\\n        \\"Always use non-null fields\\",\\n        \\"Deprecation notices\\",\\n        \\"Schema descriptions\\",\\n      ],\\n      correctAnswer: 0,\\n    },\\n  ]}\\n/>\\n\\nIn our [previous post](/blog/graphql-schema), we learned scalable GraphQL schema is critical for building production-ready APIs that can evolve with your application\'s needs.\\n\\n\x3c!-- truncate --\x3e\\n\\nIn this post, we will dive deeper into how to **continuously** evolve your schema to meet your application\'s changing requirements without hard-coded versioning.\\n\\n## Adding Without Breaking: The Art of Additive Changes\\n\\nYou know that feeling when you\'re working on a project, and suddenly you realize your schema needs to change? Maybe you need to add a new field, modify an existing one, or even remove something entirely. It\'s enough to make any developer break out in a cold sweat, right?\\n\\nBut fear not! I\'m here to show you **how to evolve your schema like a pro**, keeping your API fresh and exciting without causing your clients to tear their hair out.\\n\\n## The Good, The Bad, and The Ugly of Schema Changes\\n\\nNot all changes are created equal. In this section, we\u2019ll analyze a few different types of changes and what makes them safe or unsafe.\\n\\nFirst things first, let\'s break down the types of changes we might make to our schema:\\n\\n1. **Safe Changes:** These are the golden children of schema evolution. You can make these changes anytime, and your clients won\'t even bat an eyelash.\\n2. **Dangerous Changes:** These are the sneaky ones. They might not break anything outright, but they can cause subtle issues that\'ll have your clients scratching their heads. We\'ll need to proceed carefully here.\\n3. **Breaking Changes:** The name says it all. These changes will send your clients\' applications crashing down faster than you can say \\"**GraphQL**\\". We want to avoid these like the plague, but sometimes they\'re necessary. Don\'t worry, I\'ll show you how to handle them like a pro.\\n\\n## Additive Changes\\n\\nMost of the time, these are safe as houses.\\n\\nFor example, adding fields & adding types is unlikely to cause issues for clients. But, there are a few tricky scenarios to watch out for.\\n\\n### The Optional Argument Conundrum\\n\\nAdding optional arguments is generally safe - it\'s like offering your clients a shiny new toy without forcing them to play with it.\\n\\nHowever, there\'s a catch. Check this out:\\n\\n```diff\\n  type Query {\\n-   products(category: String): [Product!]!\\n+   products(category: String, inStock: Boolean): [Product!]!\\n  }\\n```\\n\\nSee what we did there? We added an optional `inStock` argument. Seems harmless, right?\\n\\nLet\'s dive deeper into why changing the behavior of a resolver when an optional argument isn\'t provided can be problematic:\\n\\n```graphql\\ntype Query {\\n  products(category: String, inStock: Boolean): [Product!]!\\n}\\n```\\n\\nImagine you have clients that have been using this query:\\n\\n```graphql\\nquery {\\n  products(category: \\"Electronics\\") {\\n    name\\n    price\\n  }\\n}\\n```\\n\\nIf your resolver suddenly starts filtering out out-of-stock products when `inStock` isn\'t provided, these clients will unexpectedly receive fewer results. This could break their UI or data processing logic.\\n\\nTo avoid this issue, you can implement a strategy to handle the absence of the `inStock` argument gracefully in your resolver, so that the behavior remains consistent for clients.\\n\\n### The Required Argument Trap\\n\\nNow, this is where things get spicy \ud83c\udf36\ufe0f.\\n\\nAdding a required argument is almost always a **breaking change**.\\n\\nBut, fear not! There\'s a way out:\\n\\n```diff\\n  type Query {\\n-   products(category: String): [Product!]!\\n+   products(category: String, sortBy: SortOption!): [Product!]!\\n  }\\n```\\n\\nThis change is **breaking**, but it doesn\'t have to be.\\n\\nYou can provide a **default value** for the new argument to keep your existing clients happy.\\n\\n```diff\\ntype Query {\\n-    products(category: String): [Product!]!\\n+    products(category: String, sortBy: SortOption! = POPULARITY): [Product!]!\\n}\\n```\\n\\nSee that `= POPULARITY`? That\'s your get-out-of-jail-free card. By providing a default value, you\'ve made this addition safe.\\n\\nExisting clients will use the default, and new clients can take advantage of the sorting option.\\n\\n### The Interface and Union Twist\\n\\nNow, let\'s talk about some trickier additive changes that can catch you off guard if you\'re not careful.\\n\\n### Adding New Interface Implementations\\n\\nAdding a new type that implements an existing interface might seem harmless, but it can cause some unexpected behavior. Check this out:\\n\\n```graphql\\ninterface Node {\\n  id: ID!\\n}\\n\\ntype User implements Node {\\n  id: ID!\\n  name: String!\\n}\\n\\ntype Team implements Node {\\n  id: ID!\\n  name: String!\\n}\\n\\n# highlight-start\\ntype Organization implements Node {\\n  id: ID!\\n  name: String!\\n  employees: [User!]!\\n}\\n# highlight-end\\n```\\n\\nBy adding the `Organization` type, we\'ve expanded what could be returned by queries selecting for `Node`. This could break clients that aren\'t prepared to handle new types. Always encourage clients to use proper type checking.\\n\\n```graphql\\nquery {\\n  node(id: \\"1\\") {\\n    ... on User {\\n      name\\n    }\\n    ... on Team {\\n      name\\n    }\\n    ... on Organization {\\n      name\\n      employees {\\n        name\\n      }\\n    }\\n  }\\n}\\n```\\n\\nWithout proper type checking, clients might encounter these issues:\\n\\n1. **Runtime Errors:** If a client assumes all Node types have only a name field, they might try to access `employees` on a `User` or `Team`, causing errors.\\n2. **Missing Data:** Clients might not display Organization-specific data if they\'re not prepared to handle it.\\n3. **Incorrect Data Processing:** Business logic that assumes only `User` and `Team` types exist might produce incorrect results.\\n\\nTo mitigate these issues:\\n\\n1. Use TypeScript or Flow on the client-side to catch type errors at compile-time.\\n2. Implement exhaustive type checking in your client code:\\n\\n```typescript\\nfunction handleNode(node: Node) {\\n  switch (node.__typename) {\\n    case \\"User\\":\\n      return handleUser(node)\\n    case \\"Team\\":\\n      return handleTeam(node)\\n    case \\"Organization\\":\\n      return handleOrganization(node)\\n    default:\\n      const _exhaustiveCheck: never = node\\n      throw new Error(`Unhandled node type: ${(_exhaustiveCheck as any).__typename}`)\\n  }\\n}\\n```\\n\\nThis approach ensures that if a new type is added in the future, TypeScript will raise a compile-time error, prompting developers to update their code.\\n\\n### The Union Expansion Conundrum\\n\\nSimilar to interfaces, adding new members to a union can cause runtime surprises. Consider this:\\n\\n```diff\\n-  union SearchResult = User | Post\\n+  union SearchResult = User | Post | Comment\\n```\\n\\nSurprise! Your clients might suddenly receive a type they weren\'t expecting. It\'s like opening a box of chocolates and finding a pickle - not necessarily bad, but definitely unexpected. Make sure to document how clients should handle these surprise types.\\n\\nLet\'s delve into why union expansions can be tricky and how to handle them gracefully:\\n\\nWhen you add `Comment` to the `SearchResult` union, existing clients might break in subtle ways:\\n\\n1. **Incomplete UI:** If the client only has UI components for `User` and `Post`, `Comment` results won\'t be displayed.\\n2. **Runtime Errors:** Code that assumes only `User` and `Post` types exist might throw errors when encountering a `Comment`.\\n\\nTo handle this gracefully:\\n\\n1. Implement a fallback UI component for unknown types:\\n\\n   ```tsx\\n   function SearchResultItem({result}) {\\n     switch (result.__typename) {\\n       case \\"User\\":\\n         return <UserResult user={result} />\\n       case \\"Post\\":\\n         return <PostResult post={result} />\\n       case \\"Comment\\":\\n         return <CommentResult comment={result} />\\n       default:\\n         return <UnknownResultType type={result.__typename} />\\n     }\\n   }\\n   ```\\n\\n2. Encourage clients to use introspection queries to stay updated on schema changes:\\n\\n   ```graphql\\n   query {\\n     __type(name: \\"SearchResult\\") {\\n       kinds\\n       possibleTypes {\\n         name\\n       }\\n     }\\n   }\\n   ```\\n\\nBy implementing these strategies, clients can gracefully handle new union members without breaking existing functionality.\\n\\n### The Enum Evolution\\n\\nAdding new enum values seems innocent enough, but it can impact client-side logic. Let\'s look at an example:\\n\\n```diff\\n  enum OrderStatus {\\n   PENDING\\n   COMPLETED\\n+  CANCELED\\n+  REFUNDED\\n}\\n```\\n\\nClients that were using exhaustive switches might now have incomplete logic. Encourage clients to use default cases to handle new enum values.\\n\\n```typescript\\nswitch (order.status) {\\n  case \\"PENDING\\":\\n    return \\"Order is pending\\"\\n  case \\"COMPLETED\\":\\n    return \\"Order is completed\\"\\n  default:\\n    return \\"Order status unknown\\"\\n}\\n```\\n\\n## Conclusion\\n\\nEvolving a GraphQL schema through additive changes allows you to expand your API\'s capabilities while maintaining backward compatibility. By following the principles and strategies outlined in this article, you can confidently add new fields, types, and arguments without causing disruptions to your clients.\\n\\nRemember these key takeaways:\\n\\n1. **Favor Additive Changes**: Whenever possible, add new fields, types, or arguments instead of modifying existing ones. This approach maintains backward compatibility while allowing your schema to grow.\\n\\n2. **Provide Transition Paths**: Introduce new features alongside existing ones to allow gradual client adoption.\\n\\nBy treating your GraphQL schema as a product with its own lifecycle and evolution strategy, you can build APIs that are both powerful and adaptable. This approach allows you to innovate rapidly while providing a stable and reliable service to your clients.\\n\\nStay tuned for the [next part](/blog/graphql-schema-part-2-2) of this series, where we will dive into removing schema elements and handling breaking changes!"},{"id":"graphql-angular-client","metadata":{"permalink":"/blog/graphql-angular-client","source":"@site/blog/graphql-angular-clients-2024-07-20.md","title":"Apollo vs Urql vs Fetch: The Ultimate Showdown","description":"We pushed each method to its limits. Here\'s what we discovered.","date":"2024-07-20T00:00:00.000Z","tags":[{"inline":true,"label":"GraphQL","permalink":"/blog/tags/graph-ql"},{"inline":true,"label":"Angular","permalink":"/blog/tags/angular"},{"inline":true,"label":"Apollo client","permalink":"/blog/tags/apollo-client"}],"readingTime":28.2,"hasTruncateMarker":true,"authors":[{"name":"David Onyedikachi","title":"NodeJs-Golang Backend Developer, with experience in Python, Rust, and Solidity","url":"https://github.com/onyedikachi-david","image_url":"https://avatars.githubusercontent.com/u/51977119?v=4","imageURL":"https://avatars.githubusercontent.com/u/51977119?v=4"}],"frontMatter":{"authors":[{"name":"David Onyedikachi","title":"NodeJs-Golang Backend Developer, with experience in Python, Rust, and Solidity","url":"https://github.com/onyedikachi-david","image_url":"https://avatars.githubusercontent.com/u/51977119?v=4","imageURL":"https://avatars.githubusercontent.com/u/51977119?v=4"}],"tags":["GraphQL","Angular","Apollo client"],"hide_table_of_contents":true,"title":"Apollo vs Urql vs Fetch: The Ultimate Showdown","description":"We pushed each method to its limits. Here\'s what we discovered.","sidebar_label":"GraphQL with Angular","slug":"graphql-angular-client","image":"/images/blog/angular-with-graphql.png"},"unlisted":false,"prevItem":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 2","permalink":"/blog/graphql-schema-part-2-1"},"nextItem":{"title":"gRPC Decoded: The API Protocol That\'s Changing Everything","permalink":"/blog/what-is-grpc"}},"content":"![Cover Image for Angular with GraphQL](../static/images/blog/angular-with-graphql.png)\\n\\nAngular developers often face the challenge of efficiently fetching and managing data from GraphQL APIs. This comprehensive guide dives into five powerful approaches for integrating GraphQL into your Angular applications. We\'ll explore everything from full-featured client libraries to lightweight solutions, using a practical example of fetching post data to demonstrate each method\'s strengths and nuances.\\n\\n\x3c!-- truncate --\x3e\\n\\nOur journey will take us through Apollo Angular, Urql, GraphQL-Request, Axios, and the native Fetch API, each offering unique advantages for different project needs. Whether you\'re building a small-scale application or a complex enterprise system, this guide will equip you with the knowledge to choose the best GraphQL integration method for your Angular project.\\n\\nWe\'ll not only cover the implementation details but also delve into error handling strategies, providing you with robust solutions to gracefully manage various API-related issues. By the end of this guide, you\'ll have a clear understanding of how to leverage GraphQL in Angular, complete with code snippets, real-world analogies, and a detailed comparison table to aid your decision-making process.\\n\\nSo, buckle up and get ready to supercharge your Angular applications with the power of GraphQL!\\n\\n:::note\\n_**NB**: We are not using the traditional NgModule-based Angular applications instead we will be using the newer standalone component approach; below is the version of angular cli version used throughout the guide._\\n:::\\n\\n```shell\\nng version\\n\\n    _                      _                 ____ _     ___\\n   / \\\\   _ __   __ _ _   _| | __ _ _ __     / ___| |   |_ _|\\n  / \u25b3 \\\\ | \'_ \\\\ / _` | | | | |/ _` | \'__|   | |   | |    | |\\n / ___ \\\\| | | | (_| | |_| | | (_| | |      | |___| |___ | |\\n/_/   \\\\_\\\\_| |_|\\\\__, |\\\\__,_|_|\\\\__,_|_|       \\\\____|_____|___|\\n\\n\\n\\nAngular CLI: 18.0.7\\nNode: 20.12.2\\nPackage Manager: npm 10.5.0\\nOS: linux x64\\n\\nAngular: 18.0.6\\n... animations, common, compiler, compiler-cli, core, forms\\n... platform-browser, platform-browser-dynamic, platform-server\\n... router\\n\\nPackage                         Version\\n---------------------------------------------------------\\n@angular-devkit/architect       0.1800.7\\n@angular-devkit/build-angular   18.0.7\\n@angular-devkit/core            18.0.7\\n@angular-devkit/schematics      18.0.7\\n@angular/cli                    18.0.7\\n@angular/ssr                    18.0.7\\n@schematics/angular             18.0.7\\nrxjs                            7.8.1\\ntypescript                      5.4.5\\nzone.js                         0.14.7\\n```\\n\\nWe\'ll be using a Tailcall backend that wraps the JSONPlaceholder API, providing a GraphQL interface to RESTful data.\\n\\n### \ud83d\udee0\ufe0f Project Setup\\n\\nFirst, let\'s set up our Angular project:\\n\\n```bash\\nng new angular-graphql-tailcall-showcase\\ncd angular-graphql-tailcall-showcase\\n```\\n\\n### \ud83d\udd27 Tailcall Backend Configuration\\n\\nCreate a tailcall directory in the project root and add a jsonplaceholder.graphql file:\\n\\n```graphql\\n# File: tailcall/jsonplaceholder.graphql\\n\\nschema\\n  @server(port: 8000, hostname: \\"0.0.0.0\\")\\n  @upstream(\\n    baseURL: \\"http://jsonplaceholder.typicode.com\\"\\n    httpCache: 42\\n  ) {\\n  query: Query\\n}\\n\\ntype Query {\\n  posts: [Post] @http(path: \\"/posts\\")\\n  user(id: Int!): User @http(path: \\"/users/{{.args.id}}\\")\\n}\\n\\ntype User {\\n  id: Int!\\n  name: String!\\n  username: String!\\n  email: String!\\n  phone: String\\n  website: String\\n}\\n\\ntype Post {\\n  id: Int!\\n  userId: Int!\\n  title: String!\\n  body: String!\\n  user: User @http(path: \\"/users/{{.value.userId}}\\")\\n}\\n```\\n\\nTo start the Tailcall server, run:\\n\\n```sh\\ntailcall start ./tailcall/jsonplaceholder.graphql\\n```\\n\\n### 1. Apollo Angular - The Luxury Sports Car of GraphQL Clients\\n\\nFirst up on our list is Apollo Angular. If GraphQL clients were cars, Apollo would be the Tesla of the bunch - sleek, powerful, and packed with features you didn\'t even know you needed. Let\'s pop the hood and see what makes this beauty purr!\\n\\n#### Installation and Integration Steps\\n\\nBefore we can take Apollo for a spin, we need to get it set up in our garage (I mean, project). Here\'s how:\\n\\n1. **Install the necessary packages:**:\\n\\n   ```sh\\n   npm install apollo-angular @apollo/client graphql\\n   ```\\n\\n2. **Configure Apollo in your `app.config.ts`**:\\n\\n   ```jsx\\n    import { APOLLO_OPTIONS, ApolloModule } from \'apollo-angular\';\\n    import { HttpLink } from \'apollo-angular/http\';\\n    import { InMemoryCache } from \'@apollo/client/core\';\\n\\n    // In your ApplicationConfig\\n    {\\n    providers: [\\n        importProvidersFrom(ApolloModule),\\n        {\\n        provide: APOLLO_OPTIONS,\\n        useFactory: (httpLink: HttpLink) => ({\\n            cache: new InMemoryCache(),\\n            link: httpLink.create({\\n            uri: \'/graphql\',\\n            }),\\n        }),\\n        deps: [HttpLink],\\n        },\\n    ],\\n    }\\n   ```\\n\\n3. **Code Snippets**\\n   Now that we\'ve got our Apollo rocket fueled up, let\'s see it in action! Here\'s a component that fetches a list of posts using Apollo in `src/app/apollo-angular/post-list.component.ts`:\\n\\n```typescript\\nimport {Component, OnDestroy} from \\"@angular/core\\"\\nimport {CommonModule} from \\"@angular/common\\"\\nimport {Apollo, gql} from \\"apollo-angular\\"\\nimport {ChangeDetectorRef} from \\"@angular/core\\"\\nimport {\\n  catchError,\\n  takeUntil,\\n  mergeMap,\\n} from \\"rxjs/operators\\"\\nimport {Subject, of, throwError} from \\"rxjs\\"\\n\\n@Component({\\n  selector: \\"app-apollo-post-list\\",\\n  standalone: true,\\n  imports: [CommonModule],\\n  template: `\\n    <h2>Posts (Apollo Angular)</h2>\\n    <button (click)=\\"fetchPosts()\\" [disabled]=\\"loading\\">\\n      {{ loading ? \\"Loading...\\" : \\"Load Posts\\" }}\\n    </button>\\n    <button (click)=\\"triggerNetworkError()\\">\\n      Trigger Network Error\\n    </button>\\n    <button (click)=\\"triggerGraphQLError()\\">\\n      Trigger GraphQL Error\\n    </button>\\n    <button (click)=\\"triggerUnexpectedError()\\">\\n      Trigger Unexpected Error\\n    </button>\\n    <ul *ngIf=\\"!error\\">\\n      <li *ngFor=\\"let post of posts\\">{{ post.title }}</li>\\n    </ul>\\n    <div *ngIf=\\"error\\" class=\\"error-message\\">\\n      {{ error }}\\n    </div>\\n  `,\\n  styles: [\\n    `\\n      .error-message {\\n        color: red;\\n        margin-top: 10px;\\n      }\\n    `,\\n  ],\\n})\\nexport class ApolloPostListComponent implements OnDestroy {\\n  // ... (component properties and constructor)\\n\\n  fetchPosts() {\\n    this.loading = true\\n    this.error = null\\n    this.posts = []\\n\\n    let query = gql`\\n        query GetPosts($limit: Int) {\\n            posts(limit: $limit) {\\n            id\\n            title\\n            ${this.simulateGraphQLError ? \\"nonExistentField\\" : \\"\\"}\\n            }\\n        }\\n        `\\n\\n    this.apollo\\n      .watchQuery({\\n        query: query,\\n        variables: {\\n          limit: 10,\\n        },\\n      })\\n      .valueChanges.pipe(\\n        takeUntil(this.unsubscribe$),\\n        mergeMap((result) => {\\n          if (this.simulateNetworkError) {\\n            return throwError(\\n              () => new Error(\\"Simulated network error\\"),\\n            )\\n          }\\n          if (this.simulateUnexpectedError) {\\n            throw new Error(\\"Simulated unexpected error\\")\\n          }\\n          return of(result)\\n        }),\\n        catchError((error) => {\\n          this.handleError(error)\\n          return of(null)\\n        }),\\n      )\\n      .subscribe({\\n        next: (result: any) => {\\n          if (result) {\\n            this.posts = result.data?.posts || []\\n          }\\n          this.loading = false\\n          this.cdr.detectChanges()\\n        },\\n        error: (error) => this.handleError(error),\\n        complete: () => {\\n          this.loading = false\\n          this.cdr.detectChanges()\\n        },\\n      })\\n  }\\n\\n  // ... (error handling and simulation methods)\\n}\\n```\\n\\nWow, would you look at that beauty? \ud83d\ude0d This component is like a finely tuned engine, ready to fetch your posts with the precision of a Swiss watch. Let\'s break down what\'s happening here:\\n\\n1. We\'re using Apollo\'s watchQuery method to fetch our posts. It\'s like having a personal assistant who\'s always on the lookout for the latest data.\\n2. We\'ve got some nifty error simulation methods. It\'s like having a crash test dummy for your data fetching - you can deliberately cause errors to see how your app handles them. Safety first, right?\\n3. The mergeMap operator is our traffic controller, deciding whether to let the data through or throw an error based on our simulation flags.\\n4. We\'re using takeUntil with a Subject to ensure we clean up our subscriptions when the component is destroyed. It\'s like having an eco-friendly car that doesn\'t leave any pollution (memory leaks) behind!\\n5. The template gives us a simple UI to fetch posts and trigger various error scenarios. It\'s like having a dashboard with different buttons to test your car\'s performance.\\n\\n#### Error Handling\\n\\nSpeaking of errors, Apollo doesn\'t just fetch data - it\'s got your back when things go wrong. Check out this error handling logic:\\n\\n```typescript\\n    private handleError(error: any) {\\n    this.loading = false;\\n    if (error.networkError) {\\n        this.error = \'Network error. Please check your internet connection.\';\\n    } else if (error.graphQLErrors) {\\n        this.error = `GraphQL error: ${error.graphQLErrors\\n        .map((e: { message: any }) => e.message)\\n        .join(\', \')}`;\\n    } else {\\n        this.error = \'An unexpected error occurred. Please try again later.\';\\n    }\\n    console.error(\'Error fetching posts\', error);\\n    this.cdr.detectChanges();\\n    }\\n```\\n\\nThis error handler is like having a built-in mechanic. Whether it\'s a network issue (like running out of gas) or a GraphQL error (engine trouble), it\'s got you covered with user-friendly messages.\\n\\n#### Wrapping Up Apollo Angular\\n\\nAnd there you have it, folks! Apollo Angular - the smooth-riding, feature-packed, error-handling marvel of the GraphQL world. It\'s like driving a luxury car with a supercomputer onboard.\\n\\n### 2. Axios - The Versatile Muscle Car of HTTP Clients\\n\\nIf Apollo Angular is the luxury sports car of GraphQL clients, then Axios is like a classic muscle car - powerful, versatile, and ready to handle anything you throw at it. It might not have all the GraphQL-specific bells and whistles, but boy, can it perform!\\n\\n#### 1. Installation and Integration Steps\\n\\nBefore we hit the gas, let\'s get our Axios engine installed and tuned up:\\n\\n1. **Installations**.\\n\\nFirst, rev up your terminal and run:\\n\\n```bash\\nnpm install axios\\n```\\n\\nUnlike Apollo, Axios doesn\'t need any special configuration in your app.config.ts. It\'s more of a plug-and-play solution. Just import it where you need it, and you\'re good to go!\\n\\n1. **Code Snippets**\\n\\nNow, below we implement data fetching using axios in `src/app/axios-angular/post-list.component.ts`:\\n\\n```typescript\\nimport {\\n  Component,\\n  OnInit,\\n  ChangeDetectorRef,\\n} from \\"@angular/core\\"\\nimport {CommonModule} from \\"@angular/common\\"\\nimport axios, {AxiosInstance, AxiosError} from \\"axios\\"\\n\\n@Component({\\n  selector: \\"app-axios-post-list\\",\\n  standalone: true,\\n  imports: [CommonModule],\\n  template: `\\n    <h2>Posts (Axios Angular)</h2>\\n    <button (click)=\\"fetchPosts()\\" [disabled]=\\"loading\\">\\n      {{ loading ? \\"Loading...\\" : \\"Load Posts\\" }}\\n    </button>\\n    <button (click)=\\"triggerNetworkError()\\">\\n      Trigger Network Error\\n    </button>\\n    <button (click)=\\"triggerGraphQLError()\\">\\n      Trigger GraphQL Error\\n    </button>\\n    <button (click)=\\"triggerUnexpectedError()\\">\\n      Trigger Unexpected Error\\n    </button>\\n    <ul *ngIf=\\"!error\\">\\n      <li *ngFor=\\"let post of posts\\">{{ post.title }}</li>\\n    </ul>\\n    <div *ngIf=\\"error\\" class=\\"error-message\\">\\n      {{ error }}\\n    </div>\\n  `,\\n  // ... (styles omitted for brevity)\\n})\\nexport class AxiosPostsListsComponent implements OnInit {\\n  private client: AxiosInstance\\n  posts: any[] = []\\n  loading = false\\n  error: string | null = null\\n\\n  // Error simulation flags\\n  private simulateNetworkError = false\\n  private simulateGraphQLError = false\\n  private simulateUnexpectedError = false\\n\\n  constructor(private cdr: ChangeDetectorRef) {\\n    this.client = axios.create({\\n      baseURL: \\"/graphql\\",\\n      headers: {\\n        \\"Content-Type\\": \\"application/json\\",\\n      },\\n    })\\n  }\\n\\n  ngOnInit() {\\n    // Add a request interceptor\\n    this.client.interceptors.request.use(\\n      (config) => {\\n        if (this.simulateNetworkError) {\\n          return Promise.reject(\\n            new Error(\\"Simulated network error\\"),\\n          )\\n        }\\n        return config\\n      },\\n      (error) => Promise.reject(error),\\n    )\\n  }\\n\\n  private GET_DATA = `\\n        query GetPosts($limit: Int) {\\n        posts(limit: $limit) {\\n            id\\n            title\\n            ${this.simulateGraphQLError ? \\"nonExistentField\\" : \\"\\"}\\n        }\\n        }\\n    `\\n\\n  async query(queryString: string, variables: any = {}) {\\n    try {\\n      if (this.simulateUnexpectedError) {\\n        throw new Error(\\"Simulated unexpected error\\")\\n      }\\n      const response = await this.client.post(\\"\\", {\\n        query: queryString,\\n        variables,\\n      })\\n      return response.data\\n    } catch (error) {\\n      this.handleError(error)\\n      throw error\\n    }\\n  }\\n\\n  async fetchPosts() {\\n    this.loading = true\\n    this.error = null\\n    this.posts = []\\n    this.cdr.detectChanges()\\n\\n    try {\\n      const result = await this.query(this.GET_DATA, {\\n        limit: 10,\\n      })\\n      this.posts = result.data.posts\\n      this.loading = false\\n      this.cdr.detectChanges()\\n    } catch (error) {\\n      // Error is already handled in query method\\n      this.loading = false\\n      this.cdr.detectChanges()\\n    }\\n  }\\n\\n  // ... (error handling and simulation methods omitted for brevity)\\n}\\n```\\n\\nThis Axios-powered component is revving up to fetch those posts faster than you can say \\"GraphQL\\"! Let\'s break down what\'s happening in this high-octane code:\\n\\n1. We\'re creating an Axios instance in the constructor. It\'s like customizing your car with a specific paint job (baseURL) and some cool decals (headers).\\n2. The ngOnInit method adds a request interceptor. Think of it as a nitrous oxide system - it can give your requests an extra boost or, in this case, simulate a network error if you want to test your error handling.\\n3. Our query method is like the engine of this muscle car. It takes a GraphQL query string and variables, then fires off the request. If something goes wrong, it calls our trusty mechanic (the handleError method).\\n4. The fetchPosts method is where the rubber meets the road. It calls our query method with the posts query, then updates our component state with the results.\\n5. We\'ve got our error simulation methods, just like in the Apollo example. It\'s like having different test tracks for your muscle car - you can simulate various error conditions to make sure your code can handle any bumps in the road.\\n\\n#### 2. Error Handling\\n\\nNow, let\'s talk about handling of errors:\\n\\n```typescript\\n    private handleError(error: any) {\\n    if (axios.isAxiosError(error)) {\\n        const axiosError = error as AxiosError;\\n        if (axiosError.response) {\\n        // The request was made and the server responded with a status code\\n        // that falls out of the range of 2xx\\n        this.error = `Server error: ${axiosError.response.status} ${axiosError.response.statusText}`;\\n        } else if (axiosError.request) {\\n        // The request was made but no response was received\\n        this.error = \'Network error. Please check your internet connection.\';\\n        } else {\\n        // Something happened in setting up the request that triggered an Error\\n        this.error = \'An unexpected error occurred. Please try again later.\';\\n        }\\n    } else if (error.graphQLErrors) {\\n        this.error = `GraphQL error: ${error.graphQLErrors\\n        .map((e: any) => e.message)\\n        .join(\', \')}`;\\n    } else {\\n        this.error = \'An unexpected error occurred. Please try again later.\';\\n    }\\n    console.error(\'Error fetching posts:\', error);\\n    }\\n```\\n\\nThis error handler is like the world\'s best shock absorber system. Whether you hit a pothole (network error), take a wrong turn (server error), or your engine misfires (unexpected error), it\'s got you covered with user-friendly messages. It even handles those tricky GraphQL-specific errors!\\n\\n#### Wrapping Up Axios\\n\\nAnd there you have it, Axios - the muscle car of HTTP clients, now tuned up to handle GraphQL queries with style. It might not have all the GraphQL-specific features of Apollo, but it\'s a powerhouse that can handle just about anything you throw at it.\\nAxios shines when you need a lightweight, versatile solution that can handle both REST and GraphQL APIs. It\'s like having a car that\'s equally at home on the racetrack and the city streets. Plus, if you\'re already familiar with Axios from REST API work, the learning curve here is as smooth as a freshly paved highway.\\n\\n### 3. Fetch API - The Lean, Mean, JavaScript Machine\\n\\nIf Apollo was our luxury sports car and Axios our muscle car, then the Fetch API is like a nimble, lightweight motorcycle. It\'s built right into modern browsers, requires no external libraries, and can zip through traffic with ease. Let\'s see how this speed demon handles our GraphQL queries!\\n\\n#### 1. Installation and Integration Steps\\n\\nHere\'s the beauty of the Fetch API - there\'s nothing to install! \ud83c\udf89 It\'s like finding out your new apartment comes with a free motorcycle in the garage. Just hop on and ride!\\n\\n#### 2. Code Snippets\\n\\n```typescript\\nimport {Component, ChangeDetectorRef} from \\"@angular/core\\"\\nimport {CommonModule} from \\"@angular/common\\"\\n\\n@Component({\\n  selector: \\"app-fetch-post-list\\",\\n  standalone: true,\\n  imports: [CommonModule],\\n  template: `\\n    <h2>Posts (Fetch Angular)</h2>\\n    <button (click)=\\"fetchPosts()\\" [disabled]=\\"loading\\">\\n      {{ loading ? \\"Loading...\\" : \\"Load Posts\\" }}\\n    </button>\\n    <button (click)=\\"triggerNetworkError()\\">\\n      Trigger Network Error\\n    </button>\\n    <button (click)=\\"triggerGraphQLError()\\">\\n      Trigger GraphQL Error\\n    </button>\\n    <button (click)=\\"triggerUnexpectedError()\\">\\n      Trigger Unexpected Error\\n    </button>\\n    <ul *ngIf=\\"!error\\">\\n      <li *ngFor=\\"let post of posts\\">{{ post.title }}</li>\\n    </ul>\\n    <div *ngIf=\\"error\\" class=\\"error-message\\">\\n      {{ error }}\\n    </div>\\n  `,\\n  // ... (styles omitted for brevity)\\n})\\nexport class FetchPostListComponent {\\n  private endpoint = \\"/graphql\\"\\n  posts: any[] = []\\n  loading = false\\n  error: string | null = null\\n\\n  // Error simulation flags\\n  private simulateNetworkError = false\\n  private simulateGraphQLError = false\\n  private simulateUnexpectedError = false\\n\\n  constructor(private cdr: ChangeDetectorRef) {}\\n\\n  private GET_DATA = `\\n        query GetPosts($limit: Int) {\\n        posts(limit: $limit) {\\n            id\\n            title\\n            ${this.simulateGraphQLError ? \\"nonExistentField\\" : \\"\\"}\\n        }\\n        }\\n    `\\n\\n  async query(queryString: string, variables: any = {}) {\\n    if (this.simulateNetworkError) {\\n      throw new Error(\\"Simulated network error\\")\\n    }\\n\\n    if (this.simulateUnexpectedError) {\\n      throw new Error(\\"Simulated unexpected error\\")\\n    }\\n\\n    try {\\n      const response = await fetch(this.endpoint, {\\n        method: \\"POST\\",\\n        headers: {\\n          \\"Content-Type\\": \\"application/json\\",\\n        },\\n        body: JSON.stringify({\\n          query: queryString,\\n          variables,\\n        }),\\n      })\\n\\n      if (!response.ok) {\\n        throw new Error(\\n          `HTTP error! status: ${response.status}`,\\n        )\\n      }\\n\\n      const result = await response.json()\\n\\n      if (result.errors) {\\n        throw new Error(\\n          result.errors\\n            .map((e: any) => e.message)\\n            .join(\\", \\"),\\n        )\\n      }\\n\\n      return result\\n    } catch (error) {\\n      this.handleError(error)\\n      throw error\\n    }\\n  }\\n\\n  async fetchPosts() {\\n    this.loading = true\\n    this.error = null\\n    this.posts = []\\n    this.cdr.detectChanges()\\n\\n    try {\\n      const result = await this.query(this.GET_DATA, {\\n        limit: 10,\\n      })\\n      this.posts = result.data.posts\\n      this.loading = false\\n      this.cdr.detectChanges()\\n    } catch (error) {\\n      // Error is already handled in query method\\n      this.loading = false\\n      this.cdr.detectChanges()\\n    }\\n  }\\n\\n  // ... (error handling and simulation methods omitted for brevity)\\n}\\n```\\n\\nThis Fetch-powered component is leaner than a greyhound and faster than a caffeinated cheetah! Let\'s break down what\'s happening in this high-speed code:\\n\\n1. No imports needed for Fetch - it\'s built right into the browser. It\'s like having a motorcycle that doesn\'t need gas!\\n2. Our query method is the engine of this speed machine. It takes a GraphQL query string and variables, then zooms off to fetch the data.\\n3. We\'re using async/await syntax, which makes our asynchronous code read like a smooth ride down the highway.\\n4. The fetchPosts method is where we kick into high gear. It calls our query method with the posts query, then updates our component state with the results.\\n5. We\'ve still got our error simulation methods. It\'s like having different obstacle courses for our motorcycle - we can test how it handles in various tricky situations.\\n\\n#### Error Handling\\n\\nNow, let\'s talk about the suspension system of our Fetch motorcycle - the error handling:\\n\\n```typescript\\n    private handleError(error: any) {\\n    if (error instanceof TypeError && error.message === \'Failed to fetch\') {\\n        this.error = \'Network error. Please check your internet connection.\';\\n    } else if (error instanceof Error) {\\n        if (error.message.includes(\'GraphQL error\')) {\\n        this.error = `GraphQL error: ${error.message}`;\\n        } else if (error.message.startsWith(\'HTTP error!\')) {\\n        this.error = `Server error: ${error.message}`;\\n        } else {\\n        this.error = \'An unexpected error occurred. Please try again later.\';\\n        }\\n    } else {\\n        this.error = \'An unexpected error occurred. Please try again later.\';\\n    }\\n    console.error(\'Error fetching posts:\', error);\\n    }\\n```\\n\\nThis error handler efficiently manages various error types. It provides user-friendly messages for network issues, server errors, unexpected problems, and GraphQL-specific errors, ensuring a smooth user experience even when things go wrong.\\n\\n#### Wrapping Up Fetch API\\n\\nAnd there you have it, The Fetch API - the nimble, lightweight motorcycle of HTTP clients, now revved up to handle GraphQL queries with style. It might not have all the bells and whistles of Apollo or the versatility of Axios, but it\'s fast, it\'s built-in, and it gets the job done with minimal fuss.\\n\\nFetch shines when you need a lightweight, no-dependency solution that can handle both REST and GraphQL APIs. It\'s like having a motorcycle that\'s equally at home zipping through city traffic or cruising on the open highway. Plus, if you\'re looking to keep your project dependencies to a minimum, Fetch is your go-to ride.\\n\\n### 4. GraphQL Request - The Precision-Engineered Sports Car\\n\\nIf Apollo was our luxury sedan, Axios our muscle car, and Fetch our nimble motorcycle, then GraphQL Request is like a finely-tuned sports car. It\'s designed specifically for GraphQL, offering a perfect balance of simplicity and power. Let\'s see how this beauty handles our data-fetching curves!\\n\\n1. **Installation and Integration Steps**\\n   Before we hit the track, let\'s get our GraphQL Request engine installed:\\n\\n```bash\\nnpm install graphql-request graphql\\n```\\n\\nNo special configuration needed in your app.config.ts. Just import it in your component, and you\'re ready to race!\\n\\n2. **Code Snippets**\\n\\nNow, let\'s pop the hood and examine our GraphQL Request-powered component:\\n\\n```typescript\\nimport {Component, ChangeDetectorRef} from \\"@angular/core\\"\\nimport {CommonModule} from \\"@angular/common\\"\\nimport {\\n  GraphQLClient,\\n  gql,\\n  ClientError,\\n} from \\"graphql-request\\"\\n\\n@Component({\\n  selector: \\"app-graphql-request-post-list\\",\\n  standalone: true,\\n  imports: [CommonModule],\\n  template: `\\n    <h2>Posts (Graphql Request Angular)</h2>\\n    <button (click)=\\"fetchPosts()\\" [disabled]=\\"loading\\">\\n      {{ loading ? \\"Loading...\\" : \\"Load Posts\\" }}\\n    </button>\\n    <button (click)=\\"triggerNetworkError()\\">\\n      Trigger Network Error\\n    </button>\\n    <button (click)=\\"triggerGraphQLError()\\">\\n      Trigger GraphQL Error\\n    </button>\\n    <button (click)=\\"triggerUnexpectedError()\\">\\n      Trigger Unexpected Error\\n    </button>\\n    <ul *ngIf=\\"!error\\">\\n      <li *ngFor=\\"let post of posts\\">{{ post.title }}</li>\\n    </ul>\\n    <div *ngIf=\\"error\\" class=\\"error-message\\">\\n      {{ error }}\\n    </div>\\n  `,\\n  // ... (styles omitted for brevity)\\n})\\nexport class GraphqlRequestPostListComponent {\\n  private client: GraphQLClient\\n  posts: any[] = []\\n  loading = false\\n  error: string | null = null\\n\\n  // Error simulation flags\\n  private simulateNetworkError = false\\n  private simulateGraphQLError = false\\n  private simulateUnexpectedError = false\\n\\n  constructor(private cdr: ChangeDetectorRef) {\\n    this.client = new GraphQLClient(\\n      \\"http://localhost:4200/graphql\\",\\n    )\\n  }\\n\\n  private GET_DATA = gql`\\n        query GetPosts($limit: Int) {\\n        posts(limit: $limit) {\\n            id\\n            title\\n            ${this.simulateGraphQLError ? \\"nonExistentField\\" : \\"\\"}\\n        }\\n        }\\n    `\\n\\n  async fetchPosts() {\\n    this.loading = true\\n    this.error = null\\n    this.posts = []\\n    this.cdr.detectChanges()\\n\\n    try {\\n      if (this.simulateNetworkError) {\\n        throw new Error(\\"Simulated network error\\")\\n      }\\n\\n      if (this.simulateUnexpectedError) {\\n        throw new Error(\\"Simulated unexpected error\\")\\n      }\\n\\n      const result: any = await this.client.request(\\n        this.GET_DATA,\\n        {\\n          limit: 10,\\n        },\\n      )\\n      this.posts = result.posts\\n      this.loading = false\\n      this.cdr.detectChanges()\\n    } catch (error) {\\n      this.handleError(error)\\n      this.loading = false\\n      this.cdr.detectChanges()\\n    }\\n  }\\n\\n  // ... (error handling and simulation methods omitted for brevity)\\n}\\n```\\n\\nLet\'s break down what\'s happening in this high-performance code:\\n\\n1. We\'re importing GraphQLClient and gql from graphql-request. It\'s like having a custom-built engine and transmission, specifically designed for GraphQL roads.\\n2. In the constructor, we\'re initializing our GraphQLClient. It\'s like setting up the onboard computer of our sports car, telling it exactly where to go for our data.\\n3. Our GET_DATA query is defined using the gql tag. It\'s like programming the GPS with the exact route we want to take.\\n4. The fetchPosts method is where we put the pedal to the metal. We\'re using the client.request method, which is like engaging the launch control on our sports car - it handles everything for us, from acceleration to gear shifts.\\n5. We\'ve still got our error simulation methods. It\'s like having different road conditions we can simulate - wet roads, oil slicks, you name it!\\n\\n#### Error Handling\\n\\nNow, let\'s talk about the advanced traction control system of our GraphQL Request sports car - the error handling:\\n\\n```typescript\\n    private handleError(error: any) {\\n    if (error instanceof ClientError) {\\n        if (error.response.errors) {\\n        // GraphQL errors\\n        this.error = `GraphQL error: ${error.response.errors\\n            .map((e) => e.message)\\n            .join(\', \')}`;\\n        } else {\\n        // Network errors or other HTTP errors\\n        this.error = `Network error: ${error.response.status} ${error.response[\'statusText\']}`;\\n        }\\n    } else if (error instanceof Error) {\\n        if (error.message === \'Simulated network error\') {\\n        this.error = \'Network error. Please check your internet connection.\';\\n        } else {\\n        this.error = \'An unexpected error occurred. Please try again later.\';\\n        }\\n    } else {\\n        this.error = \'An unexpected error occurred. Please try again later.\';\\n    }\\n    console.error(\'Error fetching posts:\', error);\\n    }\\n```\\n\\nThis error handler is like having the world\'s best traction control and stability management system. Whether you hit a patch of black ice (network error), take a corner too fast (GraphQL error), or encounter an unexpected obstacle (other errors), it\'s got you covered with user-friendly messages. It even distinguishes between different types of errors, giving you precise control over how to handle each situation.\\n\\n#### Wrapping Up GraphQL Request\\n\\nAnd there you have it, folks! GraphQL Request - the precision-engineered sports car of GraphQL clients. It\'s streamlined, efficient, and designed specifically for the twists and turns of GraphQL queries.\\nGraphQL Request shines when you need a lightweight, GraphQL-specific solution that offers more than Fetch but doesn\'t require the full ecosystem of Apollo. It\'s like having a sports car that\'s perfect for both daily commutes and weekend track days. Plus, its simplicity makes it a joy to work with, especially for smaller to medium-sized projects.\\n\\n### 5. Urql in Angular\\n\\n#### Installation and Integration Steps\\n\\nFirst things first, let\'s get our hands dirty with some installation magic. To bring Urql into your Angular project, you\'ll need to wave your command line wand and chant:\\n\\n```bash\\nnpm install @urql/core graphql\\n```\\n\\nWe need to set up our Urql client.\\n\\n#### Code Snippets and Explanation\\n\\nLet\'s break down our UrqlPostListComponent which you\'ll create following the same format above and solder structure:\\n\\n```typescript\\nimport {\\n  createClient,\\n  fetchExchange,\\n  cacheExchange,\\n  Client,\\n} from \\"@urql/core\\"\\n\\n// ... other imports\\n\\nexport class UrqlPostListComponent {\\n  client: Client\\n\\n  constructor(private cdr: ChangeDetectorRef) {\\n    this.client = createClient({\\n      url: \\"http://localhost:4200/graphql\\",\\n      exchanges: [cacheExchange, fetchExchange],\\n    })\\n  }\\n\\n  // ... rest of the component\\n}\\n```\\n\\nHere, we\'re setting up our Urql client faster than you can say \\"GraphQL\\". We\'re telling it where to find our GraphQL endpoint and which exchanges to use. Think of exchanges as middleware for your GraphQL requests - they\'re like bouncers at a club, deciding how to handle incoming and outgoing traffic.\\n\\nNow, let\'s look at how we\'re fetching posts:\\n\\n```typescript\\n    getPostsQuery = gql`\\n    query GetPosts($limit: Int) {\\n        posts(limit: $limit) {\\n        id\\n        title\\n        }\\n    }\\n    `;\\n\\n    fetchPosts() {\\n    this.loading = true;\\n    this.error = null;\\n    this.posts = [];\\n    this.cdr.detectChanges();\\n\\n    this.client\\n        .query(this.getPostsQuery, { limit: 10 })\\n        .toPromise()\\n        .then((result) => {\\n        if (result.error) {\\n            this.handleError(result.error);\\n        } else {\\n            this.posts = result.data?.posts || [];\\n            this.loading = false;\\n            this.cdr.detectChanges();\\n        }\\n        })\\n        .catch((error) => this.handleError(error))\\n        .finally(() => {\\n        this.loading = false;\\n        this.cdr.detectChanges();\\n        });\\n    }\\n```\\n\\nThis fetchPosts method is where the magic happens. We\'re using Urql\'s query method to fetch our posts, handling the result like a pro juggler. If there\'s an error, we toss it to our error handler. If it\'s successful, we update our posts faster than you can say \\"data fetched\\"!\\n\\n#### Error Handling\\n\\nNow, let\'s talk about error handling. In the world of APIs, errors are like unexpected plot twists in a movie - they keep things interesting, but you need to know how to handle them:\\n\\n```typescript\\n    private handleError(error: any) {\\n    this.loading = false;\\n    if (error instanceof CombinedError) {\\n        if (error.networkError) {\\n        this.error = \'Network error. Please check your internet connection.\';\\n        } else if (error.graphQLErrors.length > 0) {\\n        this.error = `GraphQL error: ${error.graphQLErrors\\n            .map((e) => e.message)\\n            .join(\', \')}`;\\n        }\\n    } else if (error instanceof Error) {\\n        this.error = `An unexpected error occurred: ${error.message}`;\\n    } else {\\n        this.error = \'An unexpected error occurred. Please try again later.\';\\n    }\\n    console.error(\'Error fetching posts:\', error);\\n    this.cdr.detectChanges();\\n    }\\n```\\n\\nThis error handler is like a Swiss Army knife for API errors. Network error? We\'ve got you covered. GraphQL error? No problem. Unexpected error that makes you question the nature of reality? We handle that too!\\nWhy Choose Urql?\\nYou might be wondering, \\"Why should I choose Urql over other options?\\" Well, let me tell you, Urql is like that cool, efficient friend who always knows the best way to get things done:\\n\\n1. **Lightweight**: Urql is as light as a feather, which means your app won\'t feel like it\'s carrying extra baggage.\\n2. **Flexible**: It\'s adaptable to various use cases, like a chameleon in the coding world.\\n3. **Great Developer Experience**: With Urql, you\'ll feel like you\'re coding with a tailwind, not against a headwind.\\n\\n:::tip\\nWant to see all this in action?\\nCheck out our GitHub repo!\\n\\nWe\'ve put together a complete set of working examples for everything we\'ve covered in this article. It\'s the perfect companion to help you dive deeper into Angular and GraphQL.\\n\\n[Explore the code on GitHub](https://github.com/onyedikachi-david/angular-graphql-multiapproach)\\n:::\\n\\n## Detailed Comparison Table\\n\\n| Method          | Bundle Size (minified + gzip)\\\\* | Learning Curve | Caching Capabilities                    | Community Support | Additional Features                        |\\n| --------------- | ------------------------------- | -------------- | --------------------------------------- | ----------------- | ------------------------------------------ |\\n| Apollo Angular  | ~2kB                            | Moderate       | Extensive (InMemoryCache, customizable) | High              | State management, optimistic UI updates    |\\n| Urql            | ~10.2 KB                        | Low            | Moderate (Document caching)             | Moderate          | Extensible architecture, lightweight       |\\n| GraphQL-Request | Unknown                         | Low            | None (Minimal client)                   | Moderate          | Simplicity, works in Node and browsers     |\\n| Axios           | ~13.2 KB                        | Low            | None (HTTP client only)                 | High              | Familiar HTTP handling, interceptors       |\\n| Fetch API       | 0 KB (Browser built-in)         | Low            | None (Native API)                       | High              | No additional dependency, widely supported |\\n\\n(\\\\*) Bundle sizes are approximate and may vary based on version and configuration. Values are culled from bundlephobia.com where available.\\n\\n### Notes:\\n\\n- **Apollo Angular**: Offers the most comprehensive feature set but comes with a larger bundle size and steeper learning curve.\\n- **Urql**: Provides a good balance between features and bundle size, with a focus on simplicity.\\n- **GraphQL-Request**: Minimal client ideal for simple use cases where advanced features aren\'t needed.\\n- **Axios**: Not a GraphQL-specific solution, but familiar to many developers and versatile for various HTTP requests.\\n- **Fetch API**: Native browser API, no additional bundle size, but requires more manual work for GraphQL operations.\\n\\nThis table should help developers choose the right method based on their specific project needs, considering factors like bundle size, learning curve, caching capabilities, community support, and additional features.\\n\\n### Caching Capabilities\\n\\n1. **Apollo Angular**\\n\\n   - Extensive caching capabilities through InMemoryCache\\n   - Normalization of data for efficient storage and retrieval\\n   - Customizable cache policies (cache-first, network-only, etc.)\\n   - Automatic cache updates on mutations\\n   - Support for pagination and optimistic UI updates\\n   - Ability to manually update and read from the cache\\n\\n2. **Urql**\\n\\n   - Document caching by default\\n   - Customizable caching through exchangeable cache implementations\\n   - Supports normalized caching with additional setup\\n   - Cache invalidation and updates through GraphQL mutations\\n   - Simpler caching model compared to Apollo, focusing on ease of use\\n\\n3. **GraphQL-Request**\\n\\n   - No built-in caching mechanism\\n   - Requires manual implementation of caching if needed\\n   - Can be combined with external caching solutions or state management libraries\\n\\n4. **Axios**\\n\\n   - No built-in GraphQL-specific caching\\n   - Can implement HTTP-level caching (e.g., using headers)\\n   - Requires manual implementation of application-level caching\\n   - Can be combined with state management libraries for more sophisticated caching\\n\\n5. **Fetch API**\\n   - No built-in GraphQL-specific caching\\n   - Supports basic HTTP caching through cache-control headers\\n   - Requires manual implementation of application-level caching\\n   - Can be combined with other libraries or custom solutions for more advanced caching\\n\\nIn summary, Apollo Angular offers the most robust out-of-the-box caching solution, followed by Urql with its flexible caching system. GraphQL-Request, Axios, and Fetch API do not provide GraphQL-specific caching, requiring developers to implement their own caching strategies or integrate with other libraries for advanced caching needs.\\n\\nWhen choosing an approach, consider your application\'s complexity, performance requirements, and willingness to manage caching manually versus leveraging built-in solutions.\\n\\n## Common Issues and Resolutions\\n\\n1. **Apollo Angular**\\n\\n   Issue: Cache inconsistencies after mutations\\n   Resolution:\\n\\n   - Ensure proper cache updates in mutation\'s `update` function\\n   - Use `refetchQueries` option to refresh related queries\\n   - Implement `optimisticResponse` for immediate UI updates\\n\\n   Issue: Over-fetching data\\n   Resolution:\\n\\n   - Utilize fragments for reusable field selections\\n   - Implement proper query splitting for components\\n   - Use `@connection` directive for pagination to avoid refetching all data\\n\\n2. **Urql**\\n\\n   Issue: Stale data after mutations\\n   Resolution:\\n\\n   - Use the `cache-and-network` request policy\\n   - Implement cache updates in mutation\'s `updates` option\\n   - Utilize the `refocusExchange` for automatic refetching on window focus\\n\\n   Issue: Complex state management\\n   Resolution:\\n\\n   - Combine Urql with external state management libraries like NgRx if needed\\n   - Leverage Urql\'s `useQuery` and `useMutation` hooks for simpler state handling\\n\\n3. **GraphQL-Request**\\n\\n   Issue: Lack of automatic caching\\n   Resolution:\\n\\n   - Implement manual caching using services or state management libraries\\n   - Use HTTP caching headers for basic caching needs\\n   - Consider switching to Apollo or Urql for more complex applications\\n\\n   Issue: Error handling complexities\\n   Resolution:\\n\\n   - Implement a centralized error handling service\\n   - Use TypeScript for better type checking and error prevention\\n   - Wrap GraphQL-Request calls in try-catch blocks for granular error handling\\n\\n4. **Axios**\\n\\n   Issue: Constructing complex GraphQL queries\\n   Resolution:\\n\\n   - Use template literals for dynamic query construction\\n   - Implement a query builder utility for complex queries\\n   - Consider using a GraphQL-specific library for very complex schemas\\n\\n   Issue: Handling GraphQL errors\\n   Resolution:\\n\\n   - Check for `errors` array in the response body\\n   - Implement custom error classes for different GraphQL error types\\n   - Use interceptors for global error handling\\n\\n5. **Fetch API**\\n\\n   Issue: Verbose syntax for GraphQL operations\\n   Resolution:\\n\\n   - Create utility functions to abstract common GraphQL operations\\n   - Use TypeScript interfaces for better type safety and autocompletion\\n   - Consider using a lightweight wrapper around Fetch for GraphQL specifics\\n\\n   Issue: Limited built-in features\\n   Resolution:\\n\\n   - Implement custom middleware for features like retries and caching\\n   - Use external libraries for advanced features (e.g., Observable support)\\n   - Create a custom Angular service to encapsulate Fetch API logic\\n\\nGeneral Resolutions:\\n\\n- Implement proper error boundaries in your Angular components\\n- Use TypeScript for better type checking and IDE support\\n- Leverage Angular\'s HttpInterceptors for global request/response handling\\n- Implement proper loading states to improve user experience during data fetching\\n- Use environment variables for GraphQL endpoint configuration\\n\\nBy addressing these common issues, developers can create more robust and efficient GraphQL implementations in their Angular applications, regardless of the chosen approach.\\n\\n## Conclusion\\n\\nAs we\'ve journeyed through the landscape of GraphQL integration in Angular, we\'ve explored five distinct approaches, each with its own strengths and considerations. Let\'s recap and draw some final insights:\\n\\n1. **Apollo Angular** emerges as the powerhouse solution, offering a comprehensive feature set including robust caching, state management, and optimistic UI updates. It\'s ideal for large-scale applications with complex data requirements, though it comes with a steeper learning curve and larger bundle size.\\n\\n2. **Urql** strikes a balance between functionality and simplicity. Its lightweight nature and extensible architecture make it an excellent choice for projects that need flexibility without the full weight of Apollo. It\'s particularly suitable for medium-sized applications or teams that prefer a more customizable approach.\\n\\n3. **GraphQL-Request** shines in its simplicity. For small projects or microservices where basic GraphQL operations are all that\'s needed, it provides a no-frills solution with minimal overhead. However, it lacks built-in caching and advanced features, which may become limitations as your project grows.\\n\\n4. **Axios**, while not GraphQL-specific, leverages its widespread adoption and familiarity among developers. It\'s a solid choice for teams already using Axios in their stack or for projects that mix RESTful and GraphQL APIs. However, it requires more manual work for GraphQL-specific features.\\n\\n5. **Fetch API** represents the most lightweight approach, with zero additional bundle size. It\'s ideal for projects prioritizing minimal dependencies and maximum browser compatibility. However, it necessitates more boilerplate code and manual implementation of GraphQL-specific features.\\n\\nThe choice between these approaches ultimately depends on your project\'s specific needs, your team\'s expertise, and your application\'s scalability requirements. Here are some final recommendations:\\n\\n- For large, data-intensive applications with complex requirements, Apollo Angular is likely your best bet.\\n- If you\'re looking for a lightweight yet capable solution, Urql offers an excellent middle ground.\\n- For smaller projects or microservices, GraphQL-Request or Fetch API might be sufficient.\\n- If your project involves a mix of REST and GraphQL APIs, consider Axios for its versatility.\\n\\nRemember, there\'s no one-size-fits-all solution. The best approach is the one that aligns with your project\'s needs and your team\'s capabilities. As your application evolves, don\'t hesitate to reassess and switch approaches if necessary.\\n\\nWhichever path you choose, GraphQL\'s power in providing flexible, efficient data fetching can significantly enhance your Angular applications. By understanding these different approaches, you\'re now equipped to make an informed decision and leverage GraphQL to its full potential in your Angular projects.\\n\\nHappy coding, and may your GraphQL queries be ever efficient!"},{"id":"what-is-grpc","metadata":{"permalink":"/blog/what-is-grpc","source":"@site/blog/what-is-grpc-2024-07-13.mdx","title":"gRPC Decoded: The API Protocol That\'s Changing Everything","description":"Demystify gRPC and its impact on modern software architecture. Explore how this powerful tool is reshaping the landscape of API communication.","date":"2024-07-13T00:00:00.000Z","tags":[],"readingTime":14.375,"hasTruncateMarker":true,"authors":[{"name":"Hunain Ahmed","title":"A freelance software developer, always working on something new and fascinating.","url":"https://github.com/hunxjunedo","image_url":"https://avatars.githubusercontent.com/u/89797440?v=4","imageURL":"https://avatars.githubusercontent.com/u/89797440?v=4"}],"frontMatter":{"title":"gRPC Decoded: The API Protocol That\'s Changing Everything","sidebar_label":"What is gRPC","description":"Demystify gRPC and its impact on modern software architecture. Explore how this powerful tool is reshaping the landscape of API communication.","image":"/images/docs/grpc_logo.png","authors":[{"name":"Hunain Ahmed","title":"A freelance software developer, always working on something new and fascinating.","url":"https://github.com/hunxjunedo","image_url":"https://avatars.githubusercontent.com/u/89797440?v=4","imageURL":"https://avatars.githubusercontent.com/u/89797440?v=4"}],"hide_table_of_contents":true,"slug":"what-is-grpc"},"unlisted":false,"prevItem":{"title":"Apollo vs Urql vs Fetch: The Ultimate Showdown","permalink":"/blog/graphql-angular-client"},"nextItem":{"title":"Are Hackers Using Your Own GraphQL API Against You?","permalink":"/blog/graphql-introspection-security"}},"content":"![gRPC Logo](/images/docs/grpc_logo.png)\\n\\ngRPC is an open-source RPC (Remote Procedure Call) framework initially developed by Google. It enables efficient communication between services across different environments, utilizing a binary serialization format called Protocol Buffers (Protobuf) over HTTP/2.\\n\\n\x3c!-- truncate --\x3e\\n\\ngRPC plays a crucial role in modernizing software architectures by providing efficient, high-performance communication channels. Due to it\'s low-latency, it is used by many well-known software like Kubernetes, CockroachDB and Netflix etc.\\n\\n[An Example Snippet from Kubernetes](https://github.com/kubernetes/kubernetes/blob/0c8b3e5f305bf2bf56d47019199b81330d90c2c3/staging/src/k8s.io/kms/apis/v1beta1/api.proto#L29)\\n\\n_sample code for gRPC:_\\n\\n```protobuf\\n\\nsyntax = \\"proto3\\";\\n\\npackage greeting;\\n\\nservice GreetingService {\\n  rpc SayHello (HelloRequest) returns (HelloResponse);\\n}\\n\\nmessage HelloRequest {\\n  string name = 1;\\n}\\n\\nmessage HelloResponse {\\n  string message = 1;\\n}\\n\\n```\\n\\n## The Evolution of API Communication\\n\\n![evolution](/images/docs/timeline.png)\\n\\nRequest\u2013response protocols date back to early distributed computing in the late 1960s. Theoretical proposals of remote procedure calls as the model of network operations date to the 1970s, with practical implementations emerging in the early 1980s. Traditional RPC mechanisms had limitations in terms of performance, language independence, and flexibility. gRPC addresses these issues by leveraging modern protocols and technologies.\\n\\ngRPC was initially created by Google, which used a single general-purpose RPC infrastructure called Stubby to connect its numerous microservices. In 2015, Google decided to build the next version of Stubby and make it open source.\\n\\n## Understanding gRPC\\n\\ngRPC is a high-performance, language-neutral RPC framework. It uses Protobuf for serialization and HTTP/2 for transport, offering features like streaming, multiplexing, and bidirectional communication. It uses HTTP/2 for transport, Protocol Buffers as the interface description language, and provides features such as authentication, bidirectional streaming and flow control, blocking or nonblocking bindings, and cancellation and timeouts.\\n\\n### Key components of gRPC\\n\\n- **Protocol Buffers (Protobuf):** A language-neutral, platform-neutral, extensible mechanism for serializing structured data. It is used to define the structure of messages (request and response payloads) that gRPC services exchange.\\n\\n- **HTTP/2:** Provides additional capabilities such as multiplexing, header compression, and server push, which are not as efficient and reliable in HTTP/1.1\\n\\n### How gRPC works (step-by-step process)\\n\\n![step by step process](/images/docs/steps.png)\\n\\ngRPC (Remote Procedure Call) works using a straightforward yet powerful mechanism that facilitates communication between clients and servers in a distributed system.\\n\\n### 1. Service Definition\\n\\n- **Protocol Buffers (Protobuf)**: The starting point for using gRPC is defining a service and its methods using Protocol Buffers (Protobuf). Protobuf is a language-neutral, platform-neutral, extensible mechanism for serializing structured data. The structure of data and services is defined in a `.proto` file.\\n\\n[An Example Snippet From Linkerd](https://github.com/linkerd/linkerd2/blob/ad0546b488fad76879e654ad91ceed1e9e53d630/proto/common/net.proto#L4)\\n\\n_Example of a simple `.proto` file :_\\n\\n```protobuf\\nsyntax = \\"proto3\\";\\n\\npackage calculator;\\n\\nservice CalculatorService {\\n  rpc Add (AddRequest) returns (AddResponse);\\n}\\n\\nmessage AddRequest {\\n  double number1 = 1;\\n  double number2 = 2;\\n}\\n\\nmessage AddResponse {\\n  double result = 1;\\n}\\n\\n```\\n\\n### 2. Code Generation\\n\\nOnce a service is defined in a .proto file, the Protocol Buffer compiler (protoc) is used to generate client and server code in your chosen programming languages. This step is crucial as it automates the creation of the boilerplate code needed for the gRPC service and client to communicate effectively. The generated code includes:\\n\\n- **Service Stubs:** These are classes with methods that correspond to the service methods defined in the .proto file. They handle the marshalling and unmarshalling of request and response messages, abstracting away the complexities of network communication.\\n\\n- **Client-Side Stubs:** These are used by the client application to make remote procedure calls to the server. The client stubs handle the creation and sending of requests, as well as receiving and processing responses.\\n\\nFor Example if the calculator example is converted to python, it would look something like this:\\n\\n```python\\n# -*- coding: utf-8 -*-\\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\\n# source: calculator\\n\\"\\"\\"Generated protocol buffer code.\\"\\"\\"\\nfrom google.protobuf import descriptor as _descriptor\\nfrom google.protobuf import descriptor_pool as _descriptor_pool\\nfrom google.protobuf import message as _message\\nfrom google.protobuf import reflection as _reflection\\nfrom google.protobuf import symbol_database as _symbol_database\\n# @@protoc_insertion_point(imports)\\n\\n_sym_db = _symbol_database.Default()\\n\\n\\n\\n\\nDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b\'\\\\n\\\\ncalculator\\\\x12\\\\ncalculator\\\\\\".\\\\n\\\\nAddRequest\\\\x12\\\\x0f\\\\n\\\\x07number1\\\\x18\\\\x01 \\\\x01(\\\\x01\\\\x12\\\\x0f\\\\n\\\\x07number2\\\\x18\\\\x02 \\\\x01(\\\\x01\\\\\\"\\\\x1d\\\\n\\\\x0b\\\\x41\\\\x64\\\\x64Response\\\\x12\\\\x0e\\\\n\\\\x06result\\\\x18\\\\x01 \\\\x01(\\\\x01\\\\x32K\\\\n\\\\x11\\\\x43\\\\x61lculatorService\\\\x12\\\\x36\\\\n\\\\x03\\\\x41\\\\x64\\\\x64\\\\x12\\\\x16.calculator.AddRequest\\\\x1a\\\\x17.calculator.AddResponseb\\\\x06proto3\')\\n\\n\\n\\n_ADDREQUEST = DESCRIPTOR.message_types_by_name[\'AddRequest\']\\n_ADDRESPONSE = DESCRIPTOR.message_types_by_name[\'AddResponse\']\\nAddRequest = _reflection.GeneratedProtocolMessageType(\'AddRequest\', (_message.Message,), {\\n\'DESCRIPTOR\' : _ADDREQUEST,\\n\'__module__\' : \'calculator_pb2\'\\n# @@protoc_insertion_point(class_scope:calculator.AddRequest)\\n})\\n_sym_db.RegisterMessage(AddRequest)\\n\\nAddResponse = _reflection.GeneratedProtocolMessageType(\'AddResponse\', (_message.Message,), {\\n\'DESCRIPTOR\' : _ADDRESPONSE,\\n\'__module__\' : \'calculator_pb2\'\\n# @@protoc_insertion_point(class_scope:calculator.AddResponse)\\n})\\n_sym_db.RegisterMessage(AddResponse)\\n\\n_CALCULATORSERVICE = DESCRIPTOR.services_by_name[\'CalculatorService\']\\nif _descriptor._USE_C_DESCRIPTORS == False:\\n\\nDESCRIPTOR._options = None\\n_ADDREQUEST._serialized_start=26\\n_ADDREQUEST._serialized_end=72\\n_ADDRESPONSE._serialized_start=74\\n_ADDRESPONSE._serialized_end=103\\n_CALCULATORSERVICE._serialized_start=105\\n_CALCULATORSERVICE._serialized_end=180\\n# @@protoc_insertion_point(module_scope)\\n\\n```\\n\\n### 3. Client-Server Communication\\n\\n- **Transmission**:\\n  When a gRPC client initiates a request to a gRPC server, it sends an HTTP/2 request containing the service name, specific method, and serialized parameters using Protobuf. HTTP/2\'s advantages include multiplexing, enabling concurrent handling of multiple streams over a single connection, binary framing that minimizes overhead and accelerates data exchange, efficient header compression via HPACK, and integrated flow control mechanisms.\\n\\n### 4. Serialization and Deserialization\\n\\n- **Protobuf Serialization**: Data exchanged between gRPC clients and servers is serialized and deserialized using Protobuf.\\n\\n## gRPC Service Methods\\n\\n![gRPC Methods](/images/docs/methods.png)\\n\\n- **Unary RPC**: This is the simplest form where the client sends a single request to the server and receives a single response:\\n\\n  ```protobuf\\n  service MyService { rpc UnaryExample(MyRequest) returns (MyResponse); }\\n  ```\\n\\n- **Server Streaming RPC**: The client sends a request to the server and receives a stream of responses:\\n\\n  ```protobuf\\n  service MyService { rpc UnaryExample(MyRequest) returns (stream MyResponse); }\\n  ```\\n\\n- **Client Streaming RPC**: The client sends a stream of requests to the server and receives a single response:\\n\\n  ```protobuf\\n  service MyService { rpc UnaryExample(stream MyRequest) returns (MyResponse); }\\n  ```\\n\\n- **Bidirectional Streaming RPC**: Both the client and server send a stream of messages to each other, establishing a persistent connection:\\n  ```protobuf\\n  service MyService { rpc UnaryExample(stream MyRequest) returns (stream MyResponse); }\\n  ```\\n\\n## gRPC vs. REST: Basic Comparison\\n\\n![payload size comparison](/images/docs/size-compare.png)\\n\\n_A comparison of payload sizes: REST JSON vs gRPC binary [checkout full comparison ](https://nilsmagnus.github.io/post/proto-json-sizes/)_\\n\\n### Communication model\\n\\n- **gRPC:** RPC-based, strong typing, and allows unary and bi-directional streaming, making it feasible for modern-day applications and use-cases.\\n- **REST:** Stateless, used for CRUD-based operations over HTTP, follows a simple unary request/response cycle.\\n\\n### Data format and serialization\\n\\n- **gRPC:** Uses Protobuf for efficient binary serialization.\\n- **REST:** Uses a plain-text format like JSON and XML, which requires more processing in order to parse.\\n\\n### Use cases for each\\n\\n- **gRPC:** Suitable for internal microservices, real-time applications, and situations needing high-performance and time-sensitive communication.\\n- **REST:** Better for public APIs, browser-based applications, and situations requiring stateless operations where ease of use is a priority.\\n\\n## Advantages of gRPC\\n\\n### Efficiency and performance\\n\\n![gRPC performance](/images/docs/grpc_performance.webp)\\n\\nProtobuf efficiently serializes messages on both the server and client sides, ensuring that data is transmitted in a compact binary format. This results in smaller message payloads, which are quicker to transmit over the network compared to the verbose JSON format used in REST APIs.\\n\\nIn addition, HTTP/2 uses features like header-compression, multiplexing and server-push which significantly reduce the payload size, as well as make response faster.\\n\\nThese features collectively contribute to significant performance gains, making gRPC [7-10 times](https://medium.com/@EmperorRXF/evaluating-performance-of-rest-vs-grpc-1b8bdf0b22da) faster than traditional REST APIs using JSON.\\n\\n### Language-agnostic nature\\n\\n![gRPC Language Agnostic](/images/docs/language_agnostic.png)\\n\\ngRPC uses Protocol Buffers (Protobuf) as its (IDL) for describing both the structure and the semantics of the messages sent between clients and servers. Protobuf is independent of programming languages, meaning you can define your API once using Protobuf and then generate code in various languages to interact with it. This allows seamless integration of sub-systems API specification, while also enhancing the DX.\\n\\n### Strong typing and code generation\\n\\nProtocol Buffers (Protobuf) defines both the structure and the types of messages exchanged between clients and servers within a .proto file, thereby establishing a clear and standardized API contract. This contract specifies the fields and their data types for each message, ensuring consistency and predictability in communication. By enforcing strong typing, Protobuf enhances code reliability by detecting type-related errors during compilation rather than at runtime. This approach not only prevents type mismatches and potential bugs but also saves developers time that would otherwise be spent implementing manual type-checking. Additionally, Protobuf\'s built-in type safety simplifies the development process, allowing developers to focus more on business logic and less on handling data integrity issues, thus improving the developer experience.\\n\\n### Bidirectional streaming capabilities\\n\\nUnlike traditional RPC methods that are unidirectional (either client-to-server or server-to-client), gRPC\'s bidirectional streaming allows both parties to establish a persistent connection and send a sequence of messages asynchronously.\\n\\nBidirectional streaming is particularly beneficial for applications requiring interactive and responsive communication, such as chat systems, collaborative tools, multiplayer games, and real-time data feeds.\\n\\n### Extensibility and backward compatibility\\n\\ngRPC using Protobuf as the IDL opens support for extensibility by allowing new fields, messages, and services to be added to the `.proto` file definitions. As services evolve, these changes can be propagated through automated code generation using the `protoc` compiler, which produces language-specific stubs and serializers/deserializers.\\n\\nMoreover, explicit versioning and API contracts defined in the `.proto` files help manage compatibility between different versions of services. During the RPC connection handshake, gRPC allows clients and servers to negotiate capabilities, ensuring that both parties can communicate effectively even if they support different versions or extensions.\\n\\n**_Example:_**\\n\\n```protobuf\\nsyntax = \\"proto3\\";\\n\\npackage greet.v1;\\n\\nservice Greeter {\\n  rpc SayHello (HelloRequest) returns (HelloReply);\\n}\\n\\nmessage HelloRequest {\\n  string name = 1;\\n}\\n\\nmessage HelloReply {\\n  string message = 1;\\n}\\n\\n```\\n\\n## Challenges and Considerations\\n\\n### Learning curve\\n\\ngRPC has a much steeper learning curve compared to the traditional REST, mainly due to some new concepts like HTTP/2 and Protobuf which require significant practice and experience.\\n\\n### Debugging complexity\\n\\nDebugging gRPC applications can be really challenging compared to traditional REST APIs. The binary nature of Protobuf messages makes it difficult to inspect and manipulate payloads directly. Tools for debugging and tracing gRPC calls are available, but they often require additional setup and expertise.\\n\\n### Ecosystem maturity\\n\\nWhile gRPC has gained significant traction and support, its ecosystem is still maturing compared to REST. Some languages and frameworks may have limited or incomplete support for gRPC features. Additionally, there is less developer support on the internet, less browser-support and very few articles published which makes it challenging to learn especially for beginners.\\n\\n### Browser support limitations\\n\\nCurrent browser limitations prevent direct implementation of the HTTP/2 gRPC specification. Browsers lack the necessary APIs to provide fine-grained control over requests. For instance:\\n\\n1. There\'s no way to enforce the use of HTTP/2.\\n2. Even if HTTP/2 could be enforced, browsers can\'t access raw HTTP/2 frames.\\n\\nTo address these limitations, the gRPC-Web specification was developed. It builds upon the HTTP/2 spec but introduces key differences:\\n\\n1. Support for both HTTP/1.1 and HTTP/2 protocols.\\n2. A new method for handling gRPC trailers:\\n   - Trailers are sent at the very end of request/response bodies.\\n   - A new bit in the gRPC message header indicates the presence of trailers.\\n3. Requirement of a proxy server:\\n   - This proxy translates between gRPC-Web requests and standard gRPC HTTP/2 responses.\\n   - It\'s a mandatory component in the gRPC-Web architecture.\\n\\nThese adaptations allow gRPC-like functionality in web browsers while working within current browser constraints.\\n\\ngRPC is powerful for service to service communication, but it may not be the best choice for public APIs or browser-based applications where REST/GraphQL is more prevalent.\\n\\n:::tip\\nTo seamlessly integrate the benefits of both gRPC and GraphQL, you can easily generate GraphQL from gRPC using Tailcall. Check out the documentation here:\\n\\n- [gRPC to GraphQL](https://tailcall.run/docs/graphql-grpc-tailcall/) .\\n- [Automated gRPC to GraphQL](https://tailcall.run/docs/graphql-configuration-generation-with-tailcall/#effortless-grpc-integration)\\n  :::\\n\\n## Implementing gRPC: Best Practices\\n\\n### Designing Effective Protobuf Schemas\\n\\nCreating efficient and maintainable Protobuf schemas is crucial. Use meaningful field names and provide clear comments for each field, otherwise you may end up in a nested jargon of types! Versioning schemas properly ensures backward and forward compatibility makes it easier to evolve your API without breaking existing clients.\\n\\n### Error Handling and Status Codes\\n\\nDefine and document all possible error codes your service can return. Consistent and informative error messages aid in debugging and provide a better experience for developers integrating with your API, if the API is not verbose about the error, the developer trying to integrate the API on the other side may get frustrated:\\n\\n:::info\\n**_A bad API is like a traffic jam - frustrating, confusing, and costly._**\\n[ - Joshua Bloch](https://www.twitter.com/joshbloch)\\n:::\\n\\n### Security Considerations (Authentication, Encryption)\\n\\nSecure your gRPC services by implementing authentication and encryption. Use Transport Layer Security (TLS) to encrypt communication between clients and servers. Leverage gRPC\'s support for various authentication mechanisms, such as OAuth, JWT, or custom tokens, to ensure that only authorized clients can access your services.\\n\\n### Performance Optimization Techniques\\n\\ngRPC API performance can be boosted in many ways. The channels are expensive to make, and reusing them instead of remaking has a significant impact.\\n\\n**_Example:_**\\n\\n```javascript\\nconst grpc = require(\\"grpc\\")\\n\\n// Singleton instance for the gRPC channel\\nlet channel = null\\n\\nfunction getGrpcChannel() {\\n  if (!channel) {\\n    // Create a new channel if it doesn\'t exist\\n    channel = new grpc.Client(\\"localhost:50051\\", grpc.credentials.createInsecure())\\n  }\\n  return channel\\n}\\n\\n// Example usage:\\nconst myChannel = getGrpcChannel()\\n// Use `myChannel` to make gRPC calls\\n```\\n\\nAlongside with reusing channels, many other ways can improve performance like implementing [load-balancers](https://grpc.io/blog/grpc-load-balancing/) and using streaming instead of unary where needed.\\n\\n## gRPC Use Cases and Real-World Examples\\n\\n### Microservices Architecture\\n\\ngRPC is well-suited for microservices architectures, enabling efficient communication between services. Companies like Netflix and Google use gRPC to connect their microservices, benefiting from its performance and strong typing. It ensures reliable, low-latency communication, which is crucial for maintaining responsive and scalable microservices.\\n\\n### Real-Time Communication Systems\\n\\n![enter image description here](/images/docs/realtime.png)\\n\\ngRPC is ideal for real-time communication systems such as chat applications, online gaming, and live streaming services. Its support for bidirectional streaming allows for seamless and efficient data exchange between clients and servers, enabling real-time interactions and reducing latency.\\n\\n[A snippet from Open-Match, a gaming framework:](https://github.com/googleforgames/open-match/blob/d781be1a3ce1b6b7fce495345b23256089f55de9/api/backend.proto#L132)\\n\\n```protobuf\\n\\n  // Tickets in matches returned by FetchMatches are moved from active to\\n  // pending, and will not be returned by query.\\n  rpc FetchMatches(FetchMatchesRequest) returns (stream FetchMatchesResponse) {\\n    option (google.api.http) = {\\n      post: \\"/v1/backendservice/matches:fetch\\"\\n      body: \\"*\\"\\n    };\\n  }\\n\\n```\\n\\n### IoT and Edge Computing\\n\\nIn IoT and edge computing scenarios, gRPC\'s low overhead and efficient communication make it suitable for resource-constrained devices. It enables reliable communication between edge devices and central servers, facilitating data collection, processing, and command execution in real time.\\n\\n### Mobile and Web Applications\\n\\ngRPC is increasingly used in mobile and web applications to improve performance and reduce bandwidth usage. For example, companies like Lyft use gRPC to enhance the efficiency of their mobile apps, ensuring faster response times and a smoother user experience.\\n\\n## Tools and Frameworks for gRPC Development\\n\\n### Popular gRPC Libraries for Different Languages\\n\\ngRPC has libraries and tooling support for various programming languages:\\n\\n- [gRPC Core](https://github.com/grpc/grpc) - C, C++, Ruby, Node.js, Python, PHP, C#, Objective-C\\n- [gRPC Java](https://github.com/grpc/grpc-java) - The Java gRPC implementation. HTTP/2 based RPC\\n- [gRPC Node.js](https://github.com/grpc/grpc-node) - gRPC for Node.js\\n- [gRPC Go](https://github.com/grpc/grpc-go) - The Go language implementation of gRPC. HTTP/2 based RPC\\n- [gRPC C#](https://github.com/grpc/grpc-dotnet) - The C# language implementation of gRPC\\n- [gRPC Web](https://github.com/grpc/grpc-web) - gRPC for Web Clients\\n\\n### Testing and Debugging Tools\\n\\n- [ghz](https://github.com/bojand/ghz)\\n- [gatling-grpc](https://github.com/phiSgr/gatling-grpc)\\n\\n### API Management Platforms\\n\\n- [Postman](https://postman.com/)\\n- [letmegrpc](https://github.com/gogo/letmegrpc)\\n\\n## Future of gRPC and API Communication\\n\\n### Emerging Trends in API Design\\n\\nThe future of API design is moving towards more efficient and flexible communication protocols like gRPC. With the rise of microservices, IoT, and real-time applications, gRPC\'s performance advantages make it a compelling choice. Trends like GraphQL and RESTful JSON APIs will continue to coexist, but gRPC will gain traction for specific use cases requiring high efficiency and low latency.\\n\\n### gRPC\'s Role in Cloud-Native Applications\\n\\ngRPC is becoming a cornerstone of cloud-native applications, facilitating communication in containerized environments orchestrated by platforms like Kubernetes. Its ability to handle high-performance, low-latency communication is essential for the scalability and reliability of cloud-native architectures.\\n\\n### Potential Improvements and Extensions\\n\\nThe gRPC ecosystem is continuously evolving, with potential improvements and extensions on the horizon. Enhancements in tooling, support for more languages, better integration with existing frameworks, and increased adoption of gRPC-Web are some areas of expected growth. The community\'s efforts to address current limitations will make gRPC more accessible and robust for a wider range of applications.\\n\\n## Conclusion\\n\\n#### Recap of gRPC\'s key features and benefits\\n\\nIn summary, gRPC offers efficient, low-latency communication, strong typing through Protobuf, and support for multiple languages. Its bidirectional streaming and multiplexing capabilities make it ideal for real-time and microservices-based applications. The performance and reliability of gRPC provide significant advantages over traditional REST APIs in many scenarios, mainly because of the new HTTP/2 and its binary nature.\\n\\n#### Considerations for Adopting gRPC in Projects\\n\\nWhen considering gRPC for your projects, ensure that your team is prepared to handle the challenges and leverage the best practices discussed to design, implement, and maintain robust gRPC services. Make sure you have enough support resources and officials, as gRPC doesn\'t have a community as large as REST.\\n\\n### Further Resources\\n\\n#### Official documentation and tutorials\\n\\n- [gRPC Official Documentation](https://grpc.io/)\\n\\n#### Community forums and support\\n\\n- [gRPC Twitter handle](https://twitter.com/grpcio)\\n- [gRPC StackOverflow tag](https://stackoverflow.com/questions/tagged/grpc)\\n- [gRPC Gitter room](https://app.gitter.im/#/room/#grpc_grpc:gitter.im)\\n- [gRPC Google Group](https://groups.google.com/g/grpc-io)\\n\\n#### Books for in-depth learning\\n\\n- [gRPC: Up and Running](https://www.oreilly.com/library/view/grpc-up-and/9781492058328/)\\n- [gRPC Microservices in Go](https://www.manning.com/books/grpc-microservices-in-go)"},{"id":"graphql-introspection-security","metadata":{"permalink":"/blog/graphql-introspection-security","source":"@site/blog/graphql-introspection-security-2024-7-12.md","title":"Are Hackers Using Your Own GraphQL API Against You?","description":"Learn how attackers exploit GraphQL introspection and the battle-tested strategies to keep your data safe.","date":"2024-07-12T00:00:00.000Z","tags":[{"inline":true,"label":"GraphQL","permalink":"/blog/tags/graph-ql"},{"inline":true,"label":"Schema","permalink":"/blog/tags/schema"},{"inline":true,"label":"Security","permalink":"/blog/tags/security"},{"inline":true,"label":"Introspection","permalink":"/blog/tags/introspection"}],"readingTime":6.44,"hasTruncateMarker":true,"authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"frontMatter":{"title":"Are Hackers Using Your Own GraphQL API Against You?","authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"tags":["GraphQL","Schema","Security","Introspection"],"description":"Learn how attackers exploit GraphQL introspection and the battle-tested strategies to keep your data safe.","hide_table_of_contents":true,"slug":"graphql-introspection-security"},"unlisted":false,"prevItem":{"title":"gRPC Decoded: The API Protocol That\'s Changing Everything","permalink":"/blog/what-is-grpc"},"nextItem":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 1","permalink":"/blog/graphql-schema"}},"content":"![GraphQL Introspection Security Issues](../static/images/blog/introspection-issues.png)\\nGraphQL has taken the API world by storm, offering developers a flexible and powerful way to interact with backend systems. But with great power comes great responsibility\u2014especially when it comes to security.\\n\\n\x3c!-- truncate --\x3e\\n\\nLet\'s dive into one of GraphQL\'s most fascinating features: introspection. It\'s a double-edged sword that can be both a developer\'s best friend and a security expert\'s nightmare.\\n\\n## Understanding GraphQL Introspection\\n\\nImagine having a magical lens that lets you peek into the very structure of a GraphQL server. That\'s essentially what introspection does! It\'s like having a detailed map of a treasure trove, showing you every nook and cranny of the API\'s capabilities. This self-documenting capability is incredibly useful for developers, enabling tools like GraphiQL and GraphQL Playground to provide rich, interactive documentation and auto-completion features.\\n\\nA basic introspection query might look like this:\\n\\n```graphql\\n{\\n  __schema {\\n    types {\\n      name\\n      fields {\\n        name\\n        type {\\n          name\\n        }\\n      }\\n    }\\n  }\\n}\\n```\\n\\nThis query asks the server to return information about all the types in the schema, including their fields and field types. The server\'s response provides a comprehensive map of its structure, which can be invaluable during development.\\n\\n## The Security Implications of Introspection\\n\\nWhile introspection is a goldmine for developers, it can also be a treasure map for attackers. Let\'s put on our black hat for a moment and see how a malicious actor might exploit this feature.\\n\\n### Schema Reconnaissance\\n\\nOne of the primary risks of introspection is schema reconnaissance. An attacker who gains access to a GraphQL endpoint can use introspection to explore the schema and identify potential targets for further attacks. This includes discovering sensitive types and fields, as well as understanding the relationships between different parts of the schema. Armed with this knowledge, an attacker can craft more effective queries to exploit vulnerabilities in the system.\\n\\nFor instance, an attacker might discover a \'User\' type with fields like \'email\', \'password\', and \'isAdmin\'. They could then craft a query to exploit this:\\n\\n```graphql\\nquery {\\n  allUsers {\\n    email\\n    password\\n    isAdmin\\n  }\\n}\\n```\\n\\nIf not properly secured, this query could potentially expose sensitive user data. The attacker might also notice an \'updateUser\' mutation, which could be a target for privilege escalation attempts.\\n\\n### Information Disclosure\\n\\nAnother significant risk is information disclosure. The introspection feature can inadvertently reveal implementation details that should remain hidden. This includes internal types, deprecated fields, and administrative functionalities. Such exposure can give attackers clues about the underlying system architecture and any potential weaknesses.\\n\\n### Attack Surface Expansion\\n\\nBy using introspection, attackers can significantly expand their attack surface. They can identify entry points for various attacks, including SQL injection, cross-site scripting (XSS), and denial of service (DoS) attacks. For instance, if introspection reveals that certain fields accept user input, an attacker might probe these fields for injection vulnerabilities.\\n\\n## Mitigating Introspection Risks\\n\\nNow, let\'s switch gears and become the defenders of our GraphQL realm. Here are some battle-tested strategies to keep your API safe from prying eyes:\\n\\n### Disable Introspection in Production\\n\\nDisabling introspection in production is crucial because it significantly reduces the information available to potential attackers. Without introspection, they can\'t easily map out your API\'s structure or discover hidden fields and types. This forces attackers to rely on guesswork or prior knowledge, making their job much more difficult. However, it\'s important to note that this is not a silver bullet\u2014determined attackers may still attempt to reverse-engineer your API through trial and error.\\n\\nIn many GraphQL implementations, disabling introspection is straightforward. For example, in [Tailcall](https://tailcall.run/docs/tailcall-dsl-graphql-custom-directives/#introspection), you can disable introspection by setting the `introspection` option to `false`:\\n\\n```graphql\\nschema\\n  # highlight-next-line\\n  @server(introspection: false) {\\n  query: Query\\n  mutation: Mutation\\n}\\n```\\n\\nThis configuration ensures that introspection is disabled.\\n\\n### Implement Authentication and Authorization\\n\\nAnother critical measure is to implement robust authentication and authorization mechanisms. By ensuring that only authenticated and authorized users can access your GraphQL endpoint, you can reduce the risk of unauthorized introspection queries. Use industry-standard authentication protocols such as OAuth2 or JWT to secure your endpoints.\\n\\nImagine a GraphQL API for a banking application. You might implement role-based access control where only users with an \'ADMIN\' role can access certain fields or mutations.\\n\\nIn [Tailcall](https://tailcall.run/docs/field-level-access-control-graphql-authentication/), you can achieve this by using the `@protected` directive.\\n\\nTailcall supports a variety of authentication and authorization mechanisms, including JWT, OAuth2, and custom authentication strategies.\\n\\nThis ensures that even if an attacker gains access to a regular user account, they can\'t use it to access sensitive admin-only data or operations.\\n\\n### Rate Limiting and Throttling\\n\\nRate limiting and throttling can also help mitigate the risks of introspection. By limiting the number of queries a client can execute within a given timeframe, you can reduce the likelihood of an attacker using introspection to gather information about your schema. Implementing these controls can also help protect your server from DoS attacks.\\n\\n### Query Allow Lists\\n\\nQuery allow lists work by pre-registering all valid queries that your application needs. This is typically done during the build process of your frontend application. Each query is hashed, and these hashes are stored on the server. When a query comes in, its hash is checked against the allow list.\\n\\nFor example, you might have a client-side query like this:\\n\\n```graphql\\nquery GetUserProfile($id: ID!) {\\n  user(id: $id) {\\n    name\\n    email\\n  }\\n}\\n```\\n\\nThis query would be hashed and stored on the server. When executed, the server checks if the incoming query\'s hash matches any in its allow list. If not, it\'s rejected.\\n\\nThis approach is powerful because it completely prevents arbitrary queries, including introspection queries, from being executed. It does require more setup and maintenance, especially in applications where queries change frequently, but it provides a very high level of security.\\n\\n### Monitor and Log Introspection Queries\\n\\nMonitoring and logging introspection queries can provide valuable insights into potential security threats. By tracking when and how introspection queries are executed, you can identify suspicious activity and respond accordingly. Implement logging at both the application and network levels to capture detailed information about each query.\\n\\n### Use a Web Application Firewall (WAF)\\n\\nA WAF can be particularly effective for GraphQL APIs because it can be configured to understand GraphQL-specific threats. For instance, you can set up rules to:\\n\\n1. Limit query depth: Prevent deeply nested queries that could overload your server.\\n2. Restrict field counts: Avoid overly broad queries that request too many fields at once.\\n3. Block known malicious patterns: Such as attempts to inject malicious code into queries.\\n\\nFor example, a WAF rule might look like this:\\n\\n```\\nSecRule ARGS_POST:query \\"@contains __schema\\" \\\\\\n    \\"id:1000,\\\\\\n    phase:2,\\\\\\n    t:none,\\\\\\n    block,\\\\\\n    msg:\'GraphQL introspection query detected\'\\"\\n```\\n\\nThis rule would block any POST request containing \'\\\\_\\\\_schema\' in the query parameter, which is typically indicative of an introspection query.\\n\\nBy implementing these kinds of rules, a WAF adds an extra layer of protection, catching many potential attacks before they even reach your GraphQL server.\\n\\n## Conclusion\\n\\nSecuring GraphQL is like playing a high-stakes game of chess. You need to think several moves ahead, anticipating potential threats while leveraging the strengths of your position. By implementing these strategies, you\'re not just protecting your API\u2014you\'re ensuring that GraphQL\'s power remains in the right hands. Stay vigilant, keep learning, and may your queries be ever secure!\\n\\nBy prioritizing security in your GraphQL implementation, you can harness the power of this modern query language while safeguarding your data and maintaining the trust of your users. Securing GraphQL is an ongoing process that requires vigilance and a proactive approach. Stay informed about the latest security developments, regularly review and update your security measures, and ensure that your development and security teams are aligned in their efforts to protect your applications."},{"id":"graphql-schema","metadata":{"permalink":"/blog/graphql-schema","source":"@site/blog/graphql-schema-2024-07-11.md","title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 1","description":"Learn how to design a robust, scalable GraphQL schema. Best practices and considerations to build a schema that can evolve with your application\'s needs.","date":"2024-07-11T00:00:00.000Z","tags":[{"inline":true,"label":"GraphQL","permalink":"/blog/tags/graph-ql"},{"inline":true,"label":"API","permalink":"/blog/tags/api"},{"inline":true,"label":"Schema","permalink":"/blog/tags/schema"},{"inline":true,"label":"Design","permalink":"/blog/tags/design"},{"inline":true,"label":"Best Practices","permalink":"/blog/tags/best-practices"}],"readingTime":9.485,"hasTruncateMarker":true,"authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"frontMatter":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 1","authors":[{"name":"Amit Singh","title":"Head of Growth and Strategy @ Tailcall","url":"https://github.com/amitksingh1490","image_url":"https://avatars.githubusercontent.com/u/23661702?v=5","imageURL":"https://avatars.githubusercontent.com/u/23661702?v=5"}],"tags":["GraphQL","API","Schema","Design","Best Practices"],"description":"Learn how to design a robust, scalable GraphQL schema. Best practices and considerations to build a schema that can evolve with your application\'s needs.","image":"/images/graphql/graphql-schema-structure.png","hide_table_of_contents":true,"slug":"graphql-schema"},"unlisted":false,"prevItem":{"title":"Are Hackers Using Your Own GraphQL API Against You?","permalink":"/blog/graphql-introspection-security"},"nextItem":{"title":"Writing a GraphQL Backend by Hand is Long Gone","permalink":"/blog/writing-a-graphql-backend-by-hand-is-long-gone"}},"content":"![GraphQL Schema Structure](../static/images/graphql/graphql-schema-structure.png)\\n\\nDesigning a robust, scalable GraphQL schema is critical for building production-ready APIs that can evolve with your application\'s needs. In this comprehensive guide, we\'ll walk through the process of crafting a GraphQL schema for a real-world application, highlighting best practices and considerations along the way.\\n\\nIf you are thinking how we could possibly cover all of the lovely intricacies associated with this topic in one go, you are right, we can\'t and so we are not! We have created an amazing series to take you through the nuances of working with GraphQL schemas.\\n\\nLet\'s break our job into puzzle pieces. Let\'s start by simply creating designing a brand new schema!\\n\\n\x3c!-- truncate --\x3e\\n\\n<div style={{textAlign: \'center\', margin:\'16px\'}}>\\n\\n<img src=\\"/images/blog/puzzle-graphql-schema-1.png\\" alt=\\"puzzle piece to visualise the series\\" style={{maxWidth: \'40%\'}} />\\n\\n</div>\\n\\nIf you\'re new to GraphQL Schema, check out our [GraphQL Schema Tutorial](https://tailcall.run/graphql/schemas-and-types/) to get up to speed with the basics.\\n\\n## The Power of GraphQL Schemas\\n\\nA well-designed GraphQL schema serves as the blueprint for your entire API. It defines:\\n\\n- The types of data available\\n- The relationships between those types\\n- The operations clients can perform (queries, mutations, subscriptions)\\n- The structure of requests and responses\\n\\nYour schema acts as a contract between your backend and frontend teams. Once published, clients can rely on its structure, enabling them to build UIs with confidence. A thoughtful schema design upfront can save significant refactoring down the road.\\n\\n## Our Example Application: TechTalent\\n\\nTo illustrate schema design principles, let\'s imagine we\'re building TechTalent - a platform connecting tech companies with job seekers. Our application will allow:\\n\\n- Companies to post job listings\\n- Candidates to create profiles and apply to jobs\\n- Recruiters to search candidates and manage applications\\n\\nWe\'ll design our schema step-by-step to support these core features.\\n\\n## Step 1: Identify Core Types\\n\\nThe first step is to identify the main entities in our domain. For TechTalent, our core types might include:\\n\\n- Company\\n- JobListing\\n- Candidate\\n- Application\\n- Recruiter\\n\\nLet\'s start by defining these as object types in our schema:\\n\\n```graphql\\ntype Company {\\n  id: ID!\\n  name: String!\\n  description: String\\n  # More fields to come\\n}\\n\\ntype JobListing {\\n  id: ID!\\n  title: String!\\n  description: String!\\n  # More fields to come\\n}\\n\\ntype Candidate {\\n  id: ID!\\n  name: String!\\n  email: String!\\n  # More fields to come\\n}\\n\\ntype Application {\\n  id: ID!\\n  # More fields to come\\n}\\n\\ntype Recruiter {\\n  id: ID!\\n  name: String!\\n  email: String!\\n  # More fields to come\\n}\\n```\\n\\nNotice we\'ve only included a few basic fields at this stage. We\'ll flesh these out as we progress.\\n\\n## Step 2: Model Relationships\\n\\nNext, we need to consider how these types relate to each other. In GraphQL, we model relationships by adding fields that reference other types. Let\'s update our types:\\n\\n```graphql\\ntype Company {\\n  id: ID!\\n  name: String!\\n  description: String\\n  jobListings: [JobListing!]!\\n  recruiters: [Recruiter!]!\\n}\\n\\ntype JobListing {\\n  id: ID!\\n  title: String!\\n  description: String!\\n  company: Company!\\n  applications: [Application!]!\\n}\\n\\ntype Candidate {\\n  id: ID!\\n  name: String!\\n  email: String!\\n  applications: [Application!]!\\n}\\n\\ntype Application {\\n  id: ID!\\n  jobListing: JobListing!\\n  candidate: Candidate!\\n  status: ApplicationStatus!\\n}\\n\\ntype Recruiter {\\n  id: ID!\\n  name: String!\\n  email: String!\\n  company: Company!\\n}\\n\\nenum ApplicationStatus {\\n  PENDING\\n  REVIEWED\\n  REJECTED\\n  ACCEPTED\\n}\\n```\\n\\nWe\'ve now established the core relationships:\\n\\n- Companies have job listings and recruiters\\n- Job listings belong to a company and have applications\\n- Candidates have applications\\n- Applications link a candidate to a job listing\\n- Recruiters belong to a company\\n\\nNote the use of the `ApplicationStatus` enum to represent the fixed set of possible statuses.\\n\\n## Step 3: Plan Query Operations\\n\\nWith our core types defined, let\'s consider what query operations our clients will need. We\'ll start with some basic CRUD (Create, Read, Update, Delete) operations:\\n\\n```graphql\\ntype Query {\\n  company(id: ID!): Company\\n  jobListing(id: ID!): JobListing\\n  candidate(id: ID!): Candidate\\n\\n  # List operations\\n  companies: [Company!]!\\n  jobListings(filters: JobListingFilters): [JobListing!]!\\n  candidates(filters: CandidateFilters): [Candidate!]!\\n}\\n\\ninput JobListingFilters {\\n  companyId: ID\\n  title: String\\n  # Add more filter options\\n}\\n\\ninput CandidateFilters {\\n  skills: [String!]\\n  experienceYears: Int\\n  # Add more filter options\\n}\\n```\\n\\nWe\'ve added basic queries to fetch individual entities by ID, as well as list queries for our main types. Notice the use of `input` types for filters - this allows for more flexible and extensible querying.\\n\\n## Step 4: Plan Mutation Operations\\n\\nNext, let\'s define some mutation operations to allow clients to modify data:\\n\\n```graphql\\ntype Mutation {\\n  # Company mutations\\n  createCompany(\\n    input: CreateCompanyInput!\\n  ): CreateCompanyPayload!\\n  updateCompany(\\n    id: ID!\\n    input: UpdateCompanyInput!\\n  ): UpdateCompanyPayload!\\n\\n  # Job Listing mutations\\n  createJobListing(\\n    input: CreateJobListingInput!\\n  ): CreateJobListingPayload!\\n  updateJobListing(\\n    id: ID!\\n    input: UpdateJobListingInput!\\n  ): UpdateJobListingPayload!\\n\\n  # Candidate mutations\\n  createCandidate(\\n    input: CreateCandidateInput!\\n  ): CreateCandidatePayload!\\n  updateCandidate(\\n    id: ID!\\n    input: UpdateCandidateInput!\\n  ): UpdateCandidatePayload!\\n\\n  # Application mutations\\n  submitApplication(\\n    input: SubmitApplicationInput!\\n  ): SubmitApplicationPayload!\\n  updateApplicationStatus(\\n    id: ID!\\n    status: ApplicationStatus!\\n  ): UpdateApplicationStatusPayload!\\n}\\n\\n# Input and Payload types for each mutation...\\n```\\n\\nNotice the pattern we\'re using for mutations:\\n\\n1. Each mutation has a corresponding input type\\n2. Each mutation returns a payload type\\n\\nThis structure offers several benefits:\\n\\n- Input types allow for easy addition of new fields in the future\\n- Payload types can include both the modified entity and any errors or metadata\\n- It provides a consistent structure across all mutations\\n\\nLet\'s look at an example input and payload type:\\n\\n```graphql\\ninput CreateJobListingInput {\\n  companyId: ID!\\n  title: String!\\n  description: String!\\n  requirements: [String!]!\\n  salary: SalaryInput\\n}\\n\\ninput SalaryInput {\\n  min: Int!\\n  max: Int!\\n  currency: String!\\n}\\n\\ntype CreateJobListingPayload {\\n  jobListing: JobListing\\n  errors: [Error!]\\n}\\n\\ntype Error {\\n  message: String!\\n  path: [String!]\\n}\\n```\\n\\nThis structure allows for detailed error reporting and future extensibility.\\n\\n## Step 5: Consider Authentication and Authorization\\n\\nIn a production application, we need to consider authentication and authorization. Let\'s add some operations for user management:\\n\\n```graphql\\ntype Mutation {\\n  # ... previous mutations\\n\\n  signup(input: SignupInput!): AuthPayload!\\n  login(input: LoginInput!): AuthPayload!\\n  logout: Boolean!\\n}\\n\\ninput SignupInput {\\n  email: String!\\n  password: String!\\n  name: String!\\n  role: UserRole!\\n}\\n\\ninput LoginInput {\\n  email: String!\\n  password: String!\\n}\\n\\ntype AuthPayload {\\n  token: String!\\n  user: User!\\n}\\n\\ntype User {\\n  id: ID!\\n  email: String!\\n  name: String!\\n  role: UserRole!\\n}\\n\\nenum UserRole {\\n  CANDIDATE\\n  RECRUITER\\n  ADMIN\\n}\\n```\\n\\nWe\'ve added basic authentication operations and a `User` type to represent authenticated users. In a real-world scenario, you\'d likely want to implement more robust authentication and authorization mechanisms.\\n\\n## Step 6: Implement Pagination\\n\\nAs our application grows, we\'ll need to implement pagination for our list queries. Let\'s update our `jobListings` query to use cursor-based pagination:\\n\\n```graphql\\ntype Query {\\n  # ... other queries\\n\\n  jobListings(\\n    first: Int\\n    after: String\\n    filters: JobListingFilters\\n  ): JobListingConnection!\\n}\\n\\ntype JobListingConnection {\\n  edges: [JobListingEdge!]!\\n  pageInfo: PageInfo!\\n}\\n\\ntype JobListingEdge {\\n  node: JobListing!\\n  cursor: String!\\n}\\n\\ntype PageInfo {\\n  hasNextPage: Boolean!\\n  endCursor: String\\n}\\n```\\n\\nThis implementation follows the Relay connection specification, which provides a standardized way to handle pagination in GraphQL.\\n\\n## Step 7: Plan for Real-time Updates\\n\\nFor certain features, we might want to provide real-time updates. Let\'s add a subscription to notify when new job listings are posted:\\n\\n```graphql\\ntype Subscription {\\n  newJobListing: JobListing!\\n}\\n```\\n\\nClients can subscribe to this operation to receive updates whenever a new job listing is created.\\n\\n## Step 8: Implement Custom Scalars\\n\\nOur schema might benefit from some custom scalar types for specific data formats. For example, let\'s add a `DateTime` scalar:\\n\\n```graphql\\nscalar DateTime\\n\\ntype JobListing {\\n  # ... other fields\\n  postedAt: DateTime!\\n  applicationDeadline: DateTime\\n}\\n```\\n\\nWe\'ll need to implement the serialization/deserialization logic for this scalar in our resolvers.\\n\\n## Step 9: Use Interfaces for Shared Fields\\n\\nAs our schema grows, we might notice some types sharing common fields. We can use interfaces to model this shared structure:\\n\\n```graphql\\ninterface Node {\\n  id: ID!\\n}\\n\\ninterface Timestamped {\\n  createdAt: DateTime!\\n  updatedAt: DateTime!\\n}\\n\\ntype Company implements Node & Timestamped {\\n  id: ID!\\n  createdAt: DateTime!\\n  updatedAt: DateTime!\\n  # ... other fields\\n}\\n\\ntype JobListing implements Node & Timestamped {\\n  id: ID!\\n  createdAt: DateTime!\\n  updatedAt: DateTime!\\n  # ... other fields\\n}\\n```\\n\\nThis approach promotes consistency and can make it easier to implement features that work across multiple types.\\n\\n## Step 10: Document Your Schema\\n\\nFinally, it\'s crucial to document your schema thoroughly. GraphQL allows for built-in documentation:\\n\\n```graphql\\n\\"\\"\\"\\nRepresents a company on the TechTalent platform.\\n\\"\\"\\"\\ntype Company implements Node & Timestamped {\\n  \\"\\"\\"\\n  Unique identifier for the company.\\n  \\"\\"\\"\\n  id: ID!\\n\\n  \\"\\"\\"\\n  The name of the company.\\n  \\"\\"\\"\\n  name: String!\\n\\n  # ... other fields\\n}\\n```\\n\\nGood documentation helps both your team and API consumers understand the purpose and usage of each type and field.\\n\\n## Visualizing the Schema\\n\\nTo better understand the relationships in our schema, let\'s visualize the core types:\\n\\n![Diagram Illustrating Relationships between various types ](../static/images/blog/entity-relationships.png)\\n\\nThis diagram illustrates the key relationships between our main entities, helping us ensure our schema accurately represents our domain.\\n\\nTo visualize your schema, you can use tools like [GraphQL Voyager](https://graphql-kit.com/graphql-voyager/).\\n\\n## Best Practices and Considerations\\n\\nAs we\'ve designed our schema, we\'ve touched on several best practices. Let\'s recap some key points and add a few more considerations:\\n\\n1. **Start with the UI in mind**: Design your schema based on how the data will be used in your UI, not just how it\'s stored in your database.\\n\\n2. **Use clear, consistent naming**: Adopt a naming convention (e.g., PascalCase for types, camelCase for fields) and stick to it.\\n\\n3. **Leverage GraphQL features**: Make use of enums, interfaces, and unions to create a rich, expressive schema.\\n\\n4. **Plan for change**: Use input types for mutations and consider versioning strategies for evolving your schema over time.\\n\\n5. **Optimize for performance**: Be mindful of N+1 query problems and consider implementing DataLoader or similar batching mechanisms.\\n\\n6. **Secure your schema**: Implement proper authentication and authorization. Consider using directives for field-level permissions.\\n\\n7. **Validate input**: Use non-nullable fields and custom scalars to enforce data integrity at the schema level.\\n\\n8. **Provide meaningful errors**: Return detailed error information in your mutation payloads to help clients handle failures gracefully.\\n\\n9. **Monitor and analyze**: Implement logging and monitoring to understand how your schema is being used and where optimizations can be made.\\n\\n10. **Keep it DRY**: Use interfaces and abstract types to reduce duplication in your schema.\\n\\n## Conclusion\\n\\nDesigning a production-grade GraphQL schema is an iterative process that requires careful thought and planning. By starting with core types and relationships, then gradually adding queries, mutations, and advanced features, we can build a schema that\'s both powerful and maintainable.\\n\\nRemember, your schema is a living document. As your application evolves, so too will your schema. By following these principles and best practices, you\'ll be well-equipped to design and maintain a GraphQL schema that can grow with your needs.\\n\\nThe TechTalent example we\'ve explored here demonstrates many real-world considerations, but every application will have its unique requirements. Always design with your specific use cases in mind, and don\'t be afraid to iterate as you learn more about how your API is used in practice.\\n\\nBy investing time in thoughtful schema design upfront, you\'ll create a solid foundation for your GraphQL API, enabling efficient development and a great experience for your API consumers.\\n\\nAlright greatttt! You have successfully completed the first part of a very intricate series!! Pat yourslef and maybe high five your cat! Here are the links to the next blogs in the series that have already been published.\\n\\n![cat giving high five](../static/images/blog/cat-high-five-gif.webp)\\n\\n- [Next Part](/blog/graphql-schema-part-2-1)"},{"id":"writing-a-graphql-backend-by-hand-is-long-gone","metadata":{"permalink":"/blog/writing-a-graphql-backend-by-hand-is-long-gone","source":"@site/blog/no-code-graphql-2024-05-30.md","title":"Writing a GraphQL Backend by Hand is Long Gone","description":"Writing a GraphQL backend by hand doesn\'t scale beyond a point.","date":"2024-05-30T00:00:00.000Z","tags":[{"inline":true,"label":"GraphQL","permalink":"/blog/tags/graph-ql"},{"inline":true,"label":"Node.js","permalink":"/blog/tags/node-js"},{"inline":true,"label":"JavaScript","permalink":"/blog/tags/java-script"}],"readingTime":6.265,"hasTruncateMarker":true,"authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=4","imageURL":"https://avatars.githubusercontent.com/u/194482?v=4"}],"frontMatter":{"title":"Writing a GraphQL Backend by Hand is Long Gone","subtitle":"Writing a GraphQL backend by hand doesn\'t scale beyond a point.","authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=4","imageURL":"https://avatars.githubusercontent.com/u/194482?v=4"}],"tags":["GraphQL","Node.js","JavaScript"],"description":"Writing a GraphQL backend by hand doesn\'t scale beyond a point.","image":"/images/blog/no-code-cover.png","hide_table_of_contents":true,"slug":"writing-a-graphql-backend-by-hand-is-long-gone","canonical_url":"https://tailcall.hashnode.dev/writing-a-graphql-backend-by-hand-is-long-gone"},"unlisted":false,"prevItem":{"title":"Design a GraphQL Schema So Good, It\'ll Make REST APIs Cry - Part 1","permalink":"/blog/graphql-schema"},"nextItem":{"title":"GraphQL vs REST vs gRPC - an unfair comparison","permalink":"/blog/graphql-vs-rest-vs-grpc"}},"content":"![Cover Image for Writing a GraphQL Backend by Hand is Long Gone](../static/images/blog/no-code-cover.png)\\nBuilding a GraphQL backend by hand might seem like a noble pursuit, but the landscape of API development is evolving rapidly, and so are the challenges that come with it. Today, the process is often fraught with complexity, performance bottlenecks, security vulnerabilities, and reliability issues. Yet again, we had a developer expressing [frustration](https://bessey.dev/blog/2024/05/24/why-im-over-graphql/) about the issues with GraphQL and the reasons for leaving our mighty ship. I wish to dive deeper into these challenges and explore why the future points towards automated, high-performance solutions.\\n\\n\x3c!-- truncate --\x3e\\n\\n<head>\\n<link rel=\\"canonical\\" href=\\"https://tailcall.hashnode.dev/writing-a-graphql-backend-by-hand-is-long-gone\\"/>\\n<title>Writing a GraphQL Backend by Hand is Long Gone</title>\\n</head>\\n\\n## Complexity with GraphQL\\n\\nIf you see, most of the concerns with GraphQL are around building a robust GraphQL backend. It\'s rarely about consuming GraphQL, because if you look closely at the GraphQL spec, you will find that it\'s focused on how to elegantly consume data. As long as the output of your backend matches what\'s expected in the query, the specification doesn\'t care about how the backend is implemented.\\n\\nHence, the main complexity with GraphQL comes with how GraphQL is built. One of the major hurdles in hand-coding a GraphQL backend is managing performance. Issues like batching, incorrect usage of data loaders, caching, and the notorious N+1 problem can cripple your application.\\n\\nManually implementing batching mechanisms and data loaders can be incredibly tedious. While libraries like [DataLoader](https://github.com/graphql/dataloader) can assist, integrating them seamlessly into your system requires a deep understanding of both your data and the GraphQL query patterns. Overuse of data loaders is so common with most GraphQL implementations that ultimately it becomes the main culprit for high latency.\\n\\nSecondly, traditional caching doesn\'t work with GraphQL, so you have to resort to all sorts of solutions, using persisted queries or some vendor-specific implementation of caching. Implementing effective caching strategies is essential for performance but it\'s tricky. Developers must decide what to cache, when to invalidate the cache, and how to manage cache consistency, which adds another layer of complexity.\\n\\nThe N+1 issue, boy, that\'s perhaps everyone\'s favorite issue with GraphQL. It arises when executing multiple upstream requests that could have been combined into one, leading to massive performance degradation. Detecting and solving this requires meticulous analysis of query patterns and database access, which requires developers to have the context of the whole query at once, generate a query plan, translate it to appropriate upstream calls, and then execute! That\'s a lot of complex engineering effort; building a general-purpose query engine is not for the faint-hearted, and in the midst of all this complex yet interesting work, I need to ship features!\\n\\n> [Grafast](https://grafast.org/grafast) is an upcoming generalized query planner that could make query-planning in JS a bit more tamed.\\n\\nGraphQL\u2019s flexibility can be a double-edged sword when it comes to security, necessitating robust mechanisms for authentication and authorization. Like caching, traditional route-based API access doesn\'t work with GraphQL. Implementing these security layers correctly involves ensuring that only authenticated users can access the GraphQL entity and that they can only access data or fields that they are authorized to see. This requires fine-grained control and often custom logic and the invention of a new standard that works just for you.\\n\\nLastly, but most importantly, ensuring your GraphQL API is reliable means tackling error handling, propagation, and telemetry. Proper error handling in GraphQL is crucial for providing meaningful feedback to clients and maintaining the integrity of your application. The GraphQL team recently started working on a [standard](https://graphql-http.com/) for serving GraphQL over HTTP, which won\'t be easy to integrate if you already have a GraphQL API running in production. Moreover, integrating telemetry within a GraphQL backend isn\'t easy either; it is a very involved process to integrate spans to trace GraphQL resolvers. And, if you have written your GraphQL layer by hand in JavaScript, be ready for some [significant performance degradation](https://github.com/DataDog/dd-trace-js/issues/1095).\\n\\n## GraphQL is more like SQL and less like REST\\n\\nWe talked about it in our [previous](graphql-vs-rest-vs-grpc-2024-03-30.md) blog why GraphQL isn\'t like REST or gRPC. I would argue that SQL is a closer elder sibling of GraphQL than REST or gRPC. Writing a GraphQL backend can be likened to building an SQL engine manually. Imagine if every time you wanted to interact with a database, you had to write the SQL engine from scratch. Every time you made a database change, you would need to rewrite your engine so that it can work with the new schema or indexes. It\u2019s inefficient and impractical; no one does that. Fortunately, modern databases come with embedded, high-performance SQL engines such as [Apache Calcite](https://calcite.apache.org/) that adhere to the SQL specification but abstract away the complexities around building it. These databases allow developers to focus on writing queries and managing data without worrying about the underlying mechanics, thanks to their sophisticated query engines.\\n\\nGraphQL, much like SQL, is a query language designed to allow clients to request exactly the data they need. Unlike REST, which relies on fixed endpoints, or gRPC, which focuses on remote procedure calls, GraphQL provides a flexible, hierarchical way to fetch and manipulate data, making it a closer analog to SQL in terms of expressiveness and precision. And I believe the future of GraphQL is going to be like the journey of this elder sibling.\\n\\n## The future of GraphQL\\n\\nThe future of GraphQL development is moving towards generalized automated solutions built on modern, low-level system stacks like Rust and Zig, and moving away from the prevalent hand-written Node.js-based solutions of today.\\n\\n[![Most common GraphQL implementations](../static/images/blog/graphql-stack.png)](https://hygraph.com/graphql-survey-2024#how-developers-build-graphql-apis)\\n\\n- These engines will connect to data sources of any type and build a GraphQL endpoint on top of them. They will find connections between other data sources, sometimes completely automatically and sometimes using hints given by the developer, creating a unified GraphQL experience.\\n\\n- Similar to SQL engines, which use JIT techniques to identify performance optimizations at runtime, GraphQL engines will become extremely smart about performance. My hope is that GraphQL will eventually move away from its dependency on the JSON protocol, into something more efficient such as protobuf.\\n\\n- There is definitely going to be a lot of work put into the standardization of the loose ends. GraphQL engines will eventually converge on error handling and error propagation strategies. GraphQL on HTTP is the first step in that direction. Authentication and Authorization too will very quickly become standard features of GraphQL, so you won\'t need to worry about inventing a new way of authentication. This will all be packed into a GraphQL standard. This might be a stretch, but if the standards team gets together, I think even GraphQL caching will be consistent across all GraphQL engines, and you will be able to switch from one caching solution to another without locking into a vendor-specific implementation.\\n\\nYou might have already seen a wave of open-source solutions that build GraphQL on top of existing data sources. One such solution paving the way is [Tailcall](https://tailcall.run). Tailcall\u2019s platform is designed to automate the creation, validation, and optimization of GraphQL backends. Sticking to standards and ensuring developers don\'t ever have to pay the heavy tax of using GraphQL that they do today, do check it out!\\n\\nLastly, if you are reading this today and thinking of writing a GraphQL server by hand, I urge you to reconsider and use something that does this for you. Before you know it, your handwritten solution will be deprecated in favor of something faster, easier, and more secure: an automatic GraphQL solution."},{"id":"graphql-vs-rest-vs-grpc","metadata":{"permalink":"/blog/graphql-vs-rest-vs-grpc","source":"@site/blog/graphql-vs-rest-vs-grpc-2024-03-30.md","title":"GraphQL vs REST vs gRPC - an unfair comparison","description":"Understand what makes GraphQL different from REST and gRPC.","date":"2024-03-30T00:00:00.000Z","tags":[],"readingTime":3.875,"hasTruncateMarker":true,"authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=5","imageURL":"https://avatars.githubusercontent.com/u/194482?v=5"}],"frontMatter":{"title":"GraphQL vs REST vs gRPC - an unfair comparison","authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=5","imageURL":"https://avatars.githubusercontent.com/u/194482?v=5"}],"description":"Understand what makes GraphQL different from REST and gRPC.","image":"/images/blog/gql-vs-rest-vs-grpc-cover.png","hide_table_of_contents":true,"slug":"graphql-vs-rest-vs-grpc","canonical_url":"https://tailcall.hashnode.dev/graphql-vs-rest-vs-grpc"},"unlisted":false,"prevItem":{"title":"Writing a GraphQL Backend by Hand is Long Gone","permalink":"/blog/writing-a-graphql-backend-by-hand-is-long-gone"},"nextItem":{"title":"GraphQL Conf 2023","permalink":"/blog/graphql-conf-2023"}},"content":"![Cover Image for GraphQL vs REST vs gRPC - an unfair comparison](../static/images/blog/gql-vs-rest-vs-grpc-cover.png)\\n\\n\x3c!-- truncate --\x3e\\n\\n<head>\\n<link rel=\\"canonical\\" href=\\"https://tailcall.hashnode.dev/graphql-vs-rest-vs-grpc\\"/>\\n<title>GraphQL vs REST vs gRPC - an unfair comparison</title>\\n</head>\\n\\nSince its inception, GraphQL has steadily gained popularity, often finding itself at the center of comparisons with other data query and manipulation languages such as REST and gRPC. The internet is replete with articles debating the merits and demerits of each, with some even questioning the viability of GraphQL. However, this discourse misses a crucial point: the unique strengths of GraphQL. This article aims to illuminate the distinct advantages GraphQL offers, particularly in addressing a common but complex challenge known as impedance mismatch.\\n\\nImpedance mismatch refers to the discordance between the capabilities of an existing API and the ideal features required for a specific use case. From the perspective of a platform engineer, the goal is to develop APIs that cater to a broad range of needs. Yet, crafting a unique API for every conceivable requirement is neither practical nor efficient. Consequently, engineers often end up creating generalized APIs. However, as a consumer, you might find these APIs lacking in some respects while being superfluous in others. Furthermore, as your needs evolve, so does your notion of the ideal API, exacerbating this mismatch. Herein lies the brilliance of GraphQL: it offers a framework for structuring data exposure and queries that significantly mitigates this issue.\\n\\nThe GraphQL specification introduces the concept of viewing data as a graph composed of nodes, which represent domain entities for a business, interconnected by relationships that define their interactions. For instance, in the development of a social network, a user entity might have the ability to create a post, which in turn could receive comments, illustrating the interconnected nature of data entities.\\n![Image Demonstrating a graph of entities](../static/images/blog/entity-graph.png)\\n\\nWith the data conceptualized as a graph, GraphQL advocates for a method of querying that allows for precise data retrieval. This selective querying capability enables developers to request exactly the data they need, distinguishing GraphQL from REST and gRPC which aren\'t truly a \\"queryable\\". The precision of GraphQL extends to the granularity of specifying individual fields within entities, facilitating extremely efficient and targeted queries.\\n![Image Demonstrating a relations between entities](../static/images/blog/entity-relation.png)\\n\\nNotably, the GraphQL specification does not prescribe any specific data storage methodologies but focuses on the manner in which data is queried, hence the designation \\"Graph Query Language.\\" This approach allows for queries tailored to specific requirements, such as obtaining posts by the current user along with comments on those posts. By enabling precise data queries, GraphQL helps in avoiding the inefficiencies associated with over-fetching or under-fetching data, thereby enhancing overall system performance.\\n\\nThe impedance mismatch is not solely a technical issue pertaining to the differences in API schemas. It extends into the realm of development processes as well. GraphQL significantly ameliorates this aspect by allowing the consumers of an API to begin their work even before the actual API is fully implemented. This is made possible through the agreement on a schema upfront. By decoupling the dependency between the consumer and the provider of the API, GraphQL facilitates a more efficient and flexible development process.\\n\\nComparing GraphQL with REST or gRPC on this front might not do justice to their distinct objectives. REST and gRPC are primarily designed as lightweight RPC protocols, not specifically to address impedance mismatch for which a full fledged query language is more suitable. A more apt comparison would be with OpenAPI, which also allows for API composition. However, OpenAPI\'s capabilities in fine-tuning what an API delivers are somewhat [constrained](https://swagger.io/specification/#composition-and-inheritance-polymorphism) compared to GraphQL\'s flexible querying capabilities.\\n\\nBeyond the technical resolution of impedance mismatch, GraphQL addresses a critical business problem: the inefficiency in software development that arises from this gap between actual and ideal APIs. This inefficiency leads to developers spending excessive time on API orchestration\u2014time that could be better spent on core application development. They find themselves constantly writing, revising, and optimizing APIs and their orchestration, as well as managing the fallout from breaking changes. By leveraging GraphQL, developers can significantly reduce these frictions, streamlining the development process and enhancing productivity. In essence, GraphQL not only solves a technical problem but also delivers substantial business value by enabling more efficient and flexible software development practices.\\n\\nGraphQL offers an excellent developer experience for API consumption with its intuitive query language that allows for retrieving deeply nested data independently of the upstream source. However, it does have some limitations. At [Tailcall](https://tailcall.run), we are dedicated to making GraphQL more accessible and easier to work with.\\n\\nIf you like what you just read, please do subscribe and share on twitter and linkedin \ud83d\ude4f"},{"id":"graphql-conf-2023","metadata":{"permalink":"/blog/graphql-conf-2023","source":"@site/blog/2023-graphql-conf-2023-09-29.md","title":"GraphQL Conf 2023","description":"A glimpse into the future of GraphQL! \ud83d\ude80.","date":"2023-09-29T00:00:00.000Z","tags":[],"readingTime":2.655,"hasTruncateMarker":true,"authors":[{"name":"Sujeet Sreenivasan","image_url":"https://avatars.githubusercontent.com/u/113442?v=5","imageURL":"https://avatars.githubusercontent.com/u/113442?v=5"}],"frontMatter":{"title":"GraphQL Conf 2023","authors":[{"name":"Sujeet Sreenivasan","image_url":"https://avatars.githubusercontent.com/u/113442?v=5","imageURL":"https://avatars.githubusercontent.com/u/113442?v=5"}],"description":"A glimpse into the future of GraphQL! \ud83d\ude80.","image":"/images/blog/graphql-conf-2023.png","hide_table_of_contents":true,"slug":"graphql-conf-2023","canonical_url":"https://tailcall.hashnode.dev/graphql-conf-2023"},"unlisted":false,"prevItem":{"title":"GraphQL vs REST vs gRPC - an unfair comparison","permalink":"/blog/graphql-vs-rest-vs-grpc"},"nextItem":{"title":"The truth about scaling Automatic Persisted Queries","permalink":"/blog/the-truth-about-scaling-automatic-persisted-queries"}},"content":"![A Photo from GraphQL Conf 2023](../static/images/blog/graphql-conf-2023.png)\\nGraphQLConf 2023 wasn\'t just another tech conference; it was a groundbreaking event hosted by the GraphQL Foundation. Bursting with riveting workshops, enlightening talks, and interactive sponsor booths, this conference was a deep dive into the ever-evolving world of GraphQL.\\n\\n\x3c!-- truncate --\x3e\\n<head>\\n<link rel=\\"canonical\\" href=\\"https://tailcall.hashnode.dev/graphql-conf-2023\\"/>\\n<title>GraphQL Conf 2023</title>\\n</head>\\nGone are the days when GraphQL was just for UI developers. This year\'s theme revolved around the long-term vision of GraphQL and its seamless integration into backend architecture. It was all about the bigger picture!\\n\\n### **Workshops & Talks Highlights**\\n\\n- **Is GraphQL BFF Necessary:** An electrifying discussion led by Tanmay from Hasura, as he unravels the significance of the BFF layer in the era after ReactJS. One profound takeaway?\\n\\n  > _GraphQL isn\'t just a fleeting tactic for instant gains\u2014it\'s a visionary strategy that propels businesses toward unparalleled success!_\\n\\n- **Interactive GraphQL with Envoy & Kubernetes**: The team from solo.io showcased the magic of adding GraphQL to an envoy gateway. It\'s all about giving clients more power while retaining essential gateway features.\\n\\n- **The Future of Efficiency**: Benjie Gillam\'s talk was a rollercoaster! He introduced grafast, a new GraphQL execution engine that optimizes data loading through query planning. One to watch!\\n\\n- **Rethinking Rate Limiting**: Meenakshi Dhanani from Postman took us on a journey through the intricacies of rate-limiting GraphQL queries. Traditional methods? Not so effective. Enter query cost analysis!\\n\\n- **GraphQL Fusion Unveiled**: Michael Staib from ChilliCream introduced GraphQL Fusion, a revolutionary approach to building distributed GraphQL APIs. The future of federating GraphQL APIs is looking bright!\\n\\n- **The Null Saga**: Stephen Spalding from Netflix delved into the history of \'null\' and introduced the Client Controlled Nullability proposal. A game-changer for GraphQL clients, we are definitely looking forward to this one!\\n\\n- **The Right Size for GraphQL**: Theo Browne\'s presentation was an eye-opener. He introduced us to scenarios where tRPC might be a better fit than GraphQL.\\n\\n- **Data Load 3.0:** Jens from Wundergraph talked about the massive performance gains one could potentially get by using a BFS algorithm in data loaders.\\n\\n### **Unconference Session: Where Everyone\'s a Speaker!**\\n\\nThis was our first time to such a thing. The conference kicked off with a dynamic unconference session. Everyone in attendance brainstormed discussion topics grouped them, and then dove deep into discussions. Our table delved into the multifaceted world of \\"Federation\\" - merging multiple GraphQL graphs into a supergraph. The consensus? The journey towards a supergraph is filled with challenges, but with tools like the Open Federation spec and GraphQL Fusion, the future looks promising!\\n\\n### **Networking & Global Connections**\\n\\nOne of the highlights of GraphQLConf 23 was the global representation. Meeting tech enthusiasts from the Netherlands, New Zealand, Poland, Romania, and more was truly inspiring. Special shoutout to Gerard Klijs from AxonIQ for his unique take on CQRS and GraphQL!\\n\\n### **Conclusion**\\n\\nDid you miss out on some sessions? No worries! All the talks are available on the GraphQL Foundation\'s [YouTube](https://www.youtube.com/playlist?list=PLP1igyLx8foE9SlDLI1Vtlshcon5r1jMJ) channel. Dive in and get inspired!\\n\\nGraphQLConf 2023 was more than just a conference for us; it was an experience. Here\'s to the future of GraphQL and the endless possibilities it holds! \ud83c\udf89"},{"id":"the-truth-about-scaling-automatic-persisted-queries","metadata":{"permalink":"/blog/the-truth-about-scaling-automatic-persisted-queries","source":"@site/blog/automatic-persisted-queries-2023-08-11.md","title":"The truth about scaling Automatic Persisted Queries","description":"Learn about the limitations and potential scaling issues that accompany Automatic Persisted Queries (APQ).","date":"2023-08-11T00:00:00.000Z","tags":[],"readingTime":6.075,"hasTruncateMarker":true,"authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=4","imageURL":"https://avatars.githubusercontent.com/u/194482?v=4"}],"frontMatter":{"title":"The truth about scaling Automatic Persisted Queries","authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=4","imageURL":"https://avatars.githubusercontent.com/u/194482?v=4"}],"description":"Learn about the limitations and potential scaling issues that accompany Automatic Persisted Queries (APQ).","image":"/images/blog/apq-cover.png","hide_table_of_contents":true,"slug":"the-truth-about-scaling-automatic-persisted-queries","canonical_url":"https://tailcall.hashnode.dev/the-truth-about-scaling-automatic-persisted-queries"},"unlisted":false,"prevItem":{"title":"GraphQL Conf 2023","permalink":"/blog/graphql-conf-2023"},"nextItem":{"title":"Unraveling the Challenges of BFF Federation","permalink":"/blog/unraveling-the-challenges-of-bff-federation"}},"content":"![Cover Image for The truth about scaling Automatic Persisted Queries](../static/images/blog/apq-cover.png)\\n\\nPersisted queries are often hailed as a solution to several challenges in GraphQL related to network performance, caching, and maintenance. However, they may not always be the silver bullet they appear to be. This post delves into the concept of persisted queries (PQ) and automatic persisted queries (APQ), highlighting the limitations and potential scaling issues that accompany these technologies.\\n\\n\x3c!-- truncate --\x3e\\n<head>\\n<link rel=\\"canonical\\" href=\\"https://tailcall.hashnode.dev/the-truth-about-scaling-automatic-persisted-queries\\"/>\\n<title>The truth about scaling Automatic Persisted Queries</title>\\n</head>\\n### The Problem\\n\\n#### Large Queries\\n\\nClients send queries to a GraphQL server as HTTP requests that include the query as the body. When these queries become large, they can lead to increased latency and network usage, degrading client performance.\\n\\nFor example, a normal GraphQL query might look like this:\\n\\n```bash\\ncurl -X POST -H \\"Content-Type: application/json\\" \\\\\\n  --data \'{\\"query\\": \\"{ largeQuery { field1 field2 ... } }\\"}\' \\\\\\n  http://your-graphql-server.com/graphql\\n```\\n\\nEach GraphQL query is parsed every time the server receives it. If it\'s large, the parsing can take a significant amount of time, increasing latency even further.\\n\\n#### Legacy Infrastructure\\n\\nExisting CDN infrastructure is designed to cache only GET calls. To make a GraphQL request, one must make a POST call. This limits the usage of CDNs for caching purposes.\\n\\n### Solution: Persisted Queries (PQ)\\n\\n#### Definition and Benefits\\n\\nTo enhance network performance for large query strings, GraphQL server supports Persisted Queries (PQ). A PQ is a GraphQL query cached server-side, identified by its SHA-256 hash. Clients send this identifier instead of the query, dramatically reducing request sizes (without affecting response), saving parsing time, and enabling GET calls instead of POST.\\n\\nA PQ request might look like this:\\n\\n```bash\\ncurl -X GET -H \\"Content-Type: application/json\\" \\\\\\n  --data-urlencode \'extensions={\\"persistedQuery\\":{\\"version\\":1,\\"sha256Hash\\":\\"<SHA 256>\\"}}\' \\\\\\n  http://your-graphql-server.com/graphql\\n```\\n\\n#### Application with CDNs\\n\\nUsing the PQ link automatically sends short hashed queries as GET requests, enabling CDNs to serve them.\\n\\n##### **Latency Reduction**\\n\\n- **No Parsing Overhead**: Since the query isn\'t sent to the server, the parsing stage, which can be computationally expensive, is eliminated. This saves valuable server processing time, directly reducing client latency.\\n\\n- **Network Efficiency**: By transmitting only the hash instead of the full query, the request size is dramatically reduced, leading to faster network transmission and lower latency.\\n\\n##### **Security Enhancements**\\n\\n- **Control Over Allowed Queries**: The server can start with a finite set of \\"allowed\\" queries, ensuring that unauthorized or unoptimized GraphQL requests cannot be made. This control is a significant safeguard for production environments, preventing potential abuse or inefficiencies.\\n\\n- **Reduction in Attack Surface**: By limiting the queries to a pre-defined set, the risk of malicious queries is reduced, enhancing the security profile of the application.\\n\\n#### Problem\\n\\nWhile PQs provide remarkable benefits, they are not without challenges:\\n\\n- **Schema Rigidity**: If you aim to keep the schema open and queries dynamic, supporting any possible query becomes complex.\\n\\n- **Maintenance of Cached Queries**: Managing the cache of allowed queries and keeping them in sync with evolving client needs can become a maintenance burden, especially in a fast-changing environment.\\n\\n### Automatic Persisted Queries (APQs)\\n\\n#### APQs vs PQs\\n\\nAPQs are a supposed improvement over PQs. In a PQ setup, the server runs with a known set of queries, meaning client changes require server updates. This has implications for maintenance costs, particularly in supporting multiple versions of queries and making a server deployment for every change in the client query. APQs were introduced to overcome these challenges.\\n\\n#### How APQs Work\\n\\nThe APQ process is a two-step approach:\\n\\n1. **Hash Request**: The client sends a request with the hash of the query. If the server recognizes the hash, it returns the corresponding response:\\n\\n   ```bash\\n   curl -X GET -H \\"Content-Type: application/json\\" \\\\\\n     --data-urlencode \'extensions={\\"persistedQuery\\":{\\"version\\":1,\\"sha256Hash\\":\\"<SHA 256>\\"}}\' \\\\\\n     http://your-graphql-server.com/graphql\\n   ```\\n\\n2. **Full Query Request**: If the server does not recognize the hash, it returns an error. The client then sends a new request that includes both the hash and the full query string:\\n\\n   ```bash\\n   curl --get http://localhost:4000/graphql \\\\\\n     --header \'content-type: application/json\' \\\\\\n     --data-urlencode \'{\\"query\\": \\"{ largeQuery { field1 field2 ... } }\\"}\' \\\\\\n     --data-urlencode \'extensions={\\"persistedQuery\\":{\\"version\\":1,\\"sha256Hash\\":\\"<HASH>\\"}}\'\\n   ```\\n\\n   The server parses the full query, caches it for future use, and returns the GraphQL response. Subsequent requests use the hash.\\n\\nThis process optimizes network performance while allowing flexibility in the queries that can be run. You can read more about APQ [here](https://www.apollographql.com/docs/apollo-server/performance/apq/)\\n\\n### Problems with APQs\\n\\n#### Thundering Herd Problem\\n\\nConsider a situation where a server has just been deployed or restarted, and the cache is empty. Now, multiple clients send hash requests for queries that are not yet cached.\\n\\n1. **Massive Error Responses**: Since the cache is empty, the server returns errors for all hash requests, signaling the clients to send the full query strings.\\n\\n2. **Simultaneous Full Query Requests**: All clients now simultaneously send full query requests, causing a sudden surge in demand.\\n\\n3. **Server Strain**: The server must parse and cache each unique query, placing significant strain on its resources. This can lead to increased latency and even server failure if the demand is too high.\\n\\n4. **Repeated Pattern**: If the server struggles to cache the queries quickly enough, the clients may continue to receive errors and retry the full query requests, perpetuating the problem.\\n\\nIn an environment with many clients and dynamically changing queries, the system can become vulnerable to sudden surges in demand. This vulnerability can undermine the performance benefits APQs are designed to provide, leading to potential system instability.\\n\\n#### Cache Limitations\\n\\nQueries are typically cached in memory, requiring cache warmup on each instance, hindering deployment on server-less solutions. An alternative could be using a centralized cache, but it typically nullifies performance gains due to serialization, deserialization, and IO call overhead.\\n\\n#### Security Concerns\\n\\nAutomatically persisting queries can cause memory leaks, as clients can send varying query combinations, exhausting server memory. Mitigation through cache size limits and eviction mechanisms may lead to frequent cache misses, leading to doubling request numbers.\\n\\n### Possible Solution\\n\\nPersistent queries are a great improvement over regular queries. They clearly improve performance and are more secure. APQs on the other hand though try to give more flexibility they can become quite messy to deal with as you scale. One alternative that is significantly more effective, is to run GraphQL on Edge itself. Essentially write your own CDN layer that is smart enough to understand that it\'s a graphQL and deploy it on edge with caching and whatnot! This is hard, and that\'s exactly what [Tailcall](https://tailcall.run) helps solve.\\n\\n### Conclusion\\n\\nAutomatic persisted queries, while offering some advantages in network performance, reveal significant challenges when it comes to scaling. The complexities of caching, potential security risks, and the inherent problems with automatic persistence highlight that persisted queries may not be the one-size-fits-all solution they are often portrayed as.\\n\\nThe question of whether to implement PQ or APQ must be approached with caution, taking into account the specific requirements and potential scalability issues of your system. While they may serve as a useful tool in certain scenarios, understanding the limitations and conducting thorough analysis is vital to avoid falling into the trap of a solution that doesn\'t truly scale. This blog post has aimed to shed light on these complexities, encouraging a more nuanced perspective on a topic that is often oversimplified."},{"id":"unraveling-the-challenges-of-bff-federation","metadata":{"permalink":"/blog/unraveling-the-challenges-of-bff-federation","source":"@site/blog/bff-challenges-2023-06-19.md","title":"Unraveling the Challenges of BFF Federation","description":"A different take on GraphQL Federation.","date":"2023-06-19T00:00:00.000Z","tags":[],"readingTime":10.425,"hasTruncateMarker":true,"authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=4","imageURL":"https://avatars.githubusercontent.com/u/194482?v=4"}],"frontMatter":{"title":"Unraveling the Challenges of BFF Federation","subtitle":"A different take on GraphQL Federation.","authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=4","imageURL":"https://avatars.githubusercontent.com/u/194482?v=4"}],"description":"A different take on GraphQL Federation.","image":"/images/blog/bff-cover.png","hide_table_of_contents":true,"slug":"unraveling-the-challenges-of-bff-federation","canonical_url":"https://tailcall.hashnode.dev/unraveling-the-challenges-of-bff-federation"},"unlisted":false,"prevItem":{"title":"The truth about scaling Automatic Persisted Queries","permalink":"/blog/the-truth-about-scaling-automatic-persisted-queries"},"nextItem":{"title":"No one talks about API Orchestration","permalink":"/blog/no-one-talks-about-api-orchestration"}},"content":"![Cover Image for Unraveling the Challenges of BFF Federation](../static/images/blog/bff-cover.png)\\nIn our [previous](https://blog.tailcall.run/no-one-talks-about-api-orchestration) blog post, we discussed the challenges of API Orchestration and its often overlooked role in a microservices architecture. We explored how, while it serves as an abstraction for frontend apps and websites, this abstraction\'s performance is very sensitive to network latency and device performance thus directly impacting end-user experience. One proposed solution was to create a Backend for Frontend (BFF) layer, essentially moving the frontend abstraction to powerful servers within your VPC. Although this approach effectively addresses the user experience problem and simplifies the work of front-end engineers, it introduces a new set of challenges for the backend, leading to difficulties in scaling the monolithic solution. Here\'s what the BFF architecture looked like:\\n\\n\x3c!-- truncate --\x3e\\n\\n<head>\\n<link rel=\\"canonical\\" href=\\"https://tailcall.hashnode.dev/unraveling-the-challenges-of-bff-federation\\"/>\\n<title>Unraveling the Challenges of BFF Federation</title>\\n</head>\\n\\n![Architecture Diagram for BFF](../static/images/blog/bff-architecture.png)\\n\\n## Using a BFF Federation\\n\\nFederation, as a concept, is not exclusive to GraphQL. In essence, it\'s about abstracting multiple data sources or services into a unified, single API interface that can be consumed by clients. This approach is not unique to any particular technology or framework and can be implemented with various tools and languages.\\n\\nHowever, GraphQL has played a significant role in popularizing the concept of federation. With its strong typing, introspective capabilities, and its natural fit for defining schemas across distributed services, it has provided an elegant solution to the challenge of federating APIs.\\n\\nWhile this blog discusses federation in the context of GraphQL, it\'s essential to understand that the core principles and challenges of the federation can be applied beyond GraphQL. Remember, the implementation of federation is not about a specific technology, but about the architectural approach to create a unified interface from multiple data sources.\\n\\nWith this in mind, let\'s delve into the pros and cons of the federation, using GraphQL as our main context for the discussion. As you\'ll see, the benefits and pitfalls of federation are relevant, whether you\'re using GraphQL or not.\\n\\nFederation is a concept that originates from the philosophy of microservices. This approach promotes the partitioning of large monolithic systems into smaller, more manageable components. In a federated architecture, instead of having a monolithic Backend-for-Frontend (BFF) handling all requests, you have multiple smaller BFFs that handle different aspects of the request.\\n\\nImagine a client makes a request to your system. This request still goes through an API gateway, which serves as the entry point to your system. However, instead of hitting a monolithic BFF, it now meets a BFF Router, specifically designed to understand and route requests to the appropriate BFFs.\\n\\nThe Router is smart. It understands the client\'s request and can break it down into smaller parts. It then delegates these smaller tasks to the appropriate services, each responsible for a specific aspect of the request. These services work in parallel, handling their part of the request, which often involves calling downstream microservices and orchestrating their responses.\\n\\nOnce the BFFs have finished their tasks, they send their responses back to the Router. The Router, in turn, takes these individual responses, combines them into a single response that fulfils the original request, and sends it back to the client.\\n\\nThis system, where individual services handle specific parts of a request in a coordinated manner, is often referred to as a Federation. The term \\"Apollo Federation\\" or \\"Super Graph\\" is commonly used to describe this setup when it\'s implemented with Apollo, a popular GraphQL implementation, but the concept is not limited to any specific technology or tool.\\n\\n![BFF Federation Architecture](../static/images/blog/bff-federation.png)\\n\\n## Federation Benefits\\n\\nMany large organizations using GraphQL in production have transitioned to this architecture to accommodate their scaling needs. The primary selling points of this architecture are:\\n\\n1. **Enhanced Team Ownership**: GraphQL Federation fosters a sense of ownership among teams by allowing each team to own and maintain its GraphQL service. With Federation, teams can operate independently, focusing on their specific domain without worrying about the overall schema. This separation of concerns leads to more maintainable code, faster development cycles, and increased productivity. It empowers teams to work in parallel, each owning a piece of the larger schema while ensuring that the entire system operates as a cohesive whole. This significantly enhances team efficiency and collaboration, particularly in larger organizations with multiple teams working on different services. This alone is by far the most significant aspect of using GraphQL Federation.\\n\\n2. **Incremental Adoption**: A major advantage of GraphQL Federation is its ability to support incremental adoption. This means teams can gradually wrap their domain-specific microservices with a GraphQL layer, one at a time, and integrate it into the federated schema without disrupting the entire system. This flexible approach minimizes the impact on existing workflows and reduces the risks associated with large-scale changes.  \\n   From the frontend perspective, GraphQL Federation offers a unified interface for querying the data. This simplifies the frontend code and enables the development of rich, interactive UIs with less effort. As soon as the first services are federated, frontend developers can begin transitioning their queries to the federated schema, reducing disruption and allowing for a smoother adoption process.  \\n   This incremental approach also allows teams to evaluate and demonstrate the value of federation at each step, building confidence and promoting buy-in across the organization. It ensures teams are not overwhelmed by the complexity of new technology or architecture and can adjust their practices as they learn.\\n\\n## Federation vs BFF\\n\\n![BFF vs Federation](../static/images/blog/bff-vs-federation.png)\\n\\nIt\'s not hard to see that GraphQL Federation carries some serious muscle over its monolithic adversary, the BFF. But before we declare a champion, let\'s take a few rounds to scrutinize the [limitations](https://blog.tailcall.run/no-one-talks-about-api-orchestration#heading-highly-specialized) we\'ve come across in our BFF solution, and see how the GraphQL Federation stands up under pressure. It\'s time for a head-to-head comparison!\\n\\n1. **Specialization**: Both BFF and GraphQL Federation require a certain amount of manual intervention. In the BFF approach, the entire layer is custom-built, meaning there\'s no ready-to-use solution, which necessitates significant manual management. On the other hand, GraphQL Federation provides an open-source, ready-to-use Apollo Router. However, it\'s not an all-inclusive solution, as the individual GraphQL services still need to be manually maintained and written by hand for specific use cases. While it\'s still a tough fight, the federation manages to land a jab here and gets a few extra points in this round.\\n\\n2. **Fragility**: Federation offers an enhanced strategy. In a federated architecture, when a GraphQL service malfunction, only its segment of the graph becomes inaccessible to the user. This results in a more resilient system, less prone to total failure, demonstrating the ability to continue the fight even after taking a hit. In this round, Federation steps up and delivers a solid punch.\\n\\n3. **Performance**: When it comes to Performance, the Federation architecture introduces an extra journey for each packet. The request has to travel through the router, then to the individual GraphQL services, before finally reaching the domain service. This journey can add a few milliseconds of latency, a difference that may not be perceptible to the end user. However, this seemingly small delay has a broader impact on the performance of the entire architecture. The addition of the router introduces a requirement for more infrastructure and increases the frequency of data serialization and deserialization. This increased complexity affects both the system\'s throughput and infrastructure costs. In this round, the Federation architecture might not be the clear knockout winner we were hoping for.\\n\\n4. **Monolith Tendency**: It\'s a clear knockout in this round for the Federation! It elegantly sidesteps the monolith tendency, keeping the architecture agile and modular. BFF, in contrast, takes a heavy fall with its tendency to become a monolithic layer over time.\\n\\n5. **Canary Release:** Federation, unlike BFF, reveals graph dependencies and compatibility issues at runtime, not compile time. This amps up the need for first-class canary releases. However, when it comes to canary support, it\'s a draw. Both fighters are still in the ring, each showing resilience in their own way. No knockout here, folks!\\n\\n6. **Coupled Release**: In the Federation architecture, each GraphQL service operates independently, significantly reducing the coupling between services and the router. This independence allows each team to manage its own release cycles, putting an end to the wide-scale halts that were commonplace with the BFF layer. However, it\'s important to note that each GraphQL service still maintains a tight connection with its corresponding downstream domain service. While this is a form of coupling, it\'s considerably less invasive than the BFF approach, where the entire layer was intertwined. Despite this necessary connection to the domain services, the Federation architecture proves to be more agile. In this round, GraphQL Federation edges out the BFF approach.\\n\\n7. **Organizational Friction:** With Federation, the responsibility for managing the architecture often falls squarely on the shoulders of backend engineers. The reason is simple: the complexity of the architecture and its intimate ties with downstream domain services necessitate a deep level of technical understanding. This is a departure from the BFF paradigm, where frontend teams could claim ownership of this part of the infrastructure. The intricate nature of the Federation, however, makes this almost untenable. When put head-to-head with BFFs, the Federation seems to take a step back in this regard. The power to control abstraction slips away from the consumer. In this round, BFFs manage to hold their ground.\\n\\n8. **Legacy Gateway:** Just as in the BFF model, the API gateway maintains its place in the Federation architecture, and rightfully so. However, we find ourselves reestablishing a substantial amount of resiliency and caching logic within these new layers, duplicating efforts previously expended on a traditional gateway. This redundancy marks a lack of efficiency in the Federation approach, signaling a tie in this round.\\n\\nOverall, this round favors GraphQL Federation. It proves to be a significantly more robust architecture when evaluated based on the aforementioned criteria. Let\'s explore further and assess how it performs in isolation and as the company expands.\\n\\n## Pitfalls of GraphQL Federation\\n\\nWhile GraphQL Federation has numerous benefits, it is not without its downsides. Here are some points of caution that should be considered when deciding to use this architecture:\\n\\n1. **Cost and Complexity:** GraphQL Federation introduces significant complexity into the architecture. Setting up, maintaining, and testing a federated graph can be a challenge as it requires a deep understanding of both GraphQL and distributed systems. Additionally, this architecture demands more infrastructure and a larger team for maintenance. As such, the adoption and migration process can be complex and costly. Typically, only large organizations with platform teams, robust budgets, and a governing body to maintain the schema\'s sanctity and system reliability, tend to consider adopting this approach. The inherent complexity and cost implications make the Federation a less likely choice for small to medium-sized organizations.\\n\\n2. **Ownership Challenges:** It is often argued that domain service owners maintain their individual GraphQL layers. However, this doesn\'t always reflect the reality. Services can frequently be divided or merged, leading to uncertainty about how to modify the GraphQL layer. This results in a complex web of requests from GraphQL services to domain services outside the team\'s control.\\n\\n3. **Infrastructure Scaling:** Each subgraph in a federated architecture operates on a separate piece of infrastructure, scaling independently. This brings its own set of challenges. For instance, when a subgraph is divided or merged, computing and scaling requirements need to be re-evaluated. Moreover, a deployment in another subgraph can trigger a substantial increase in load from the router on your subgraph, potentially causing unexpected stress on your infrastructure. This underscores the need for robust scaling and load-balancing strategies within a federated architecture.\\n\\nWhile GraphQL Federation has the potential to solve some issues of traditional BFF architecture, it brings in its own set of challenges. Therefore, it\'s important to evaluate these considerations based on the specific requirements and constraints of your project before deciding to implement this architecture.\\n\\n## We are onto something\\n\\nWhen examining the underlying issue, the debate essentially revolves around microservices and monoliths. Undoubtedly, the federated solution offers better scalability compared to a monolithic architecture; however, it also introduces a myriad of distinct challenges related to maintenance and costs that warrant careful consideration. This is not the end of the discussion, as client requests pass through CDNs and the Gateway before reaching the router, and we have yet to explore those components of the infrastructure. In the following sections, we will delve into these components and further investigate how they interact, as well as delve deeper into GraphQL."},{"id":"no-one-talks-about-api-orchestration","metadata":{"permalink":"/blog/no-one-talks-about-api-orchestration","source":"@site/blog/api-orchestration-2023-06-12.md","title":"No one talks about API Orchestration","description":"A Forsaken Piece Of Every Microservice Architecture","date":"2023-06-12T00:00:00.000Z","tags":[],"readingTime":10.235,"hasTruncateMarker":true,"authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=4","imageURL":"https://avatars.githubusercontent.com/u/194482?v=4"}],"frontMatter":{"title":"No one talks about API Orchestration","subtitle":"A Forsaken Piece Of Every Microservice Architecture.","authors":[{"name":"Tushar Mathur","title":"CEO @ Tailcall | Love to talk about programming, scale, distributed systems and building high performance systems.","url":"https://github.com/tusharmath","image_url":"https://avatars.githubusercontent.com/u/194482?v=4","imageURL":"https://avatars.githubusercontent.com/u/194482?v=4"}],"description":"A Forsaken Piece Of Every Microservice Architecture","image":"/images/blog/bff-architecture.png","hide_table_of_contents":true,"slug":"no-one-talks-about-api-orchestration","canonical_url":"https://tailcall.hashnode.dev/no-one-talks-about-api-orchestration"},"unlisted":false,"prevItem":{"title":"Unraveling the Challenges of BFF Federation","permalink":"/blog/unraveling-the-challenges-of-bff-federation"}},"content":"![bff-architecture.png](../static/images/blog/bff-architecture.png)\\n\\n\x3c!-- truncate --\x3e\\n\\n<head>\\n<link rel=\\"canonical\\" href=\\"https://tailcall.hashnode.dev/no-one-talks-about-api-orchestration\\"/>\\n<title>No one talks about API Orchestration</title>\\n</head>\\n\\nBeing in the industry for many years, building and consuming microservices, I have realized that there is one problem that no one really talks about when it comes to microservices ie. API Orchestration. As engineers, we love our microservices, small independent components that are responsible for doing just one thing. The promise that was sold when I was a kid was you can build these small independent services and compose them together to build an app, very fast and reliably. It took me years to realize that the necessary tooling for \\"composing\\" just doesn\'t exist! There are tools for distributed tracing, observability, caching, discovery, etc. But to compose services to build a product is completely offloaded to front-end engineers! There were two things that were happening in the tech ecosystem:\\n\\n1. **Rich User Interfaces:** Responsive websites that worked on desktop and mobile are dead. To build a successful B2C business, you need to build for all three platforms viz. Android, iOS, and Web (Desktop/PWA). The applications need to look slick, rich in information, and have snappy response times. Development on multiple platforms requires a nuanced understanding of the stack and a lot of duplication of code.\\n\\n2. **Microservice Proliferation:** Companies these days bootstrap themselves on microservices instead of monoliths. This is because the tooling to build microservices has gotten a lot better, and reusable components are available either in open-source or as a SAAS solution. This allows developers to focus on their core business logic and move fast.\\n\\n## Microservice\\n\\nMicroservices architecture is a design pattern in which a large application is built as a suite of modular services, each of which runs its process and communicates with other services through well-defined interfaces, typically using a lightweight messaging protocol. This approach has several benefits over a monolithic architecture, including improved scalability, resilience, and maintainability. In a microservices architecture, each service has a specific role and is independently deployable, so developers can work on different services in parallel and deploy them independently of each other. This can make the development process more agile and allow for faster deployment of new features.\\n\\n![Microservices Architecture](../static/images/blog/microservices-architecture.png)\\n\\nAn API gateway is a server that acts as a single point of entry for certain types of requests. It can receive requests from the client, route them to the appropriate backend service, and then return the response from the backend service to the client. An API gateway can also perform tasks such as authentication, rate limiting, and caching. This makes it a useful component in a microservices architecture, where each service has its API and the API gateway acts as the \\"front door\\" for clients to access the services.\\n\\n## API Composition\\n\\nAPI composition refers to the process of combining multiple APIs to create a new API or a new functionality. This can be done by sending requests to multiple APIs and combining the results, or by creating a new API that acts as a fa\xe7ade for the underlying APIs.\\n\\n> \ud83d\udca1 API Composition is also known as API Orchestration. This is however vastly different from Microservice Orchestration.\\n\\nFor example, consider a scenario where a client application wants to display a user\'s profile information and recent posts on a social media platform. In this case, the client can send two separate requests to two different APIs: one to retrieve the user\'s profile information, and another to retrieve their recent posts. The client can then combine the results from these two APIs to create a single response that contains all the required information. This new response can be considered as the output of the composed API.\\n\\nTo build a rich user interface, API composition is necessary on the client side. One of the main challenges with API composition on the client side is that it can lead to increased complexity in the client application. This is because the client needs to handle the process of sending requests to multiple APIs and combining the results, which can add to the overall size and complexity of the client code.\\n\\nAnother challenge with API composition on the client side is that it can result in reduced performance and increased latency. This is because the client needs to make multiple separate requests to different APIs, which can take more time and result in a slower response from the composed API.\\n\\nIn addition, API composition on the client side can also lead to increased security risks. This is because the client needs to handle sensitive information, such as API keys and authentication credentials, which can be vulnerable to attacks if not properly secured. The client doesn\'t have access to powerful CPUs or a reliable network either. This makes the composition problem even more challenging to implement and manage. It is therefore often more efficient and effective to perform API composition on the server side instead.\\n\\n## Backend For Frontend\\n\\nA BFF layer can help to solve the challenges of API composition by providing a separate backend service that is optimized for each specific frontend client. This can enable the BFF to perform API composition on behalf of the client, which can help to improve the performance and reliability of the composed API. The BFF layer typically sits as a separate component in the overall architecture, between the frontend client and the microservices. It can communicate with both the frontend client and the microservices using well-defined interfaces and protocols, such as REST or gRPC.\\n\\nThe BFF can take advantage of a powerful CPU and access to a fast network to improve the performance and reliability of the composed API. It can also provide added flexibility and control over the composition process. This can make it a useful tool for developers who want to create new APIs by combining the functionality of multiple underlying APIs.\\n\\n![BFF Architecture](../static/images/blog/bff-architecture.png)\\n\\nBFFs truly solve the problems mentioned above to a great extent, however they introduce new set of challenges viz.\\n\\n### Highly Specialized\\n\\nOne of the challenges with using a BFF layer is that it is a highly specialized solution that requires a significant amount of hand-written code. Unlike an API gateway, there is no standard BFF solution that can be deployed out-of-the-box, and each BFF implementation must be custom-tailored to the specific requirements of the frontend client. This lack of standardization and reusability can make the BFF solution more complex and difficult to maintain.\\n\\n### Fragile\\n\\nAnother challenge with using a BFF layer is that it can be fragile and susceptible to failure. The BFF solution is dependent on the developers to follow best practices and handle all error scenarios, and if these steps are not taken, the solution can be prone to bugs and performance issues. Additionally, the BFF solution must be thoroughly tested, including performance testing, unit testing, and integration testing, to ensure that it is reliable and performs well in production. This can require significant effort and expertise, and if these steps are not properly followed, the BFF solution can be fragile and prone to failure. Also, it\'s worth mentioning that a BFF layer is an entry point to all your backend, it going down basically means nothing is accessible for the user so this layer needs to be robust and resilient to exceptions.\\n\\n### Performance\\n\\nBecause BFF layers are typically custom-written for each use case, it can be difficult to predict the performance impact of a small code change. Issues such as unoptimized algorithms, inefficient caching, and unnecessary downstream requests can go unnoticed and only be discovered very late in the development cycle. Typically companies perform thorough benchmarking and load testing before anything goes live. This results in a very high time to market even for minor changes.\\n\\n### Monolith\\n\\nEventually, this layer turns out to be a big monolith touching every service in your backend. The layer contains a lot of handwritten spaghetti code that\'s hard to maintain. Onboarding new engineers also becomes harder and upgrading libraries or architecture gets costlier. Any tiny change requires a full-fledged deployment on your infrastructure.\\n\\n### Canary Support (or lack thereof)\\n\\nEvery change that happens in the backend requires the deployment of the BFF layer. In fact, any feature that is built on the client also requires changes on the BFF layer. Such frequent changes can not be exposed to 100% of users because the reliability and performance of this system are unknown. A common way to solve this problem is to use [blue-green](https://www.redhat.com/en/topics/devops/what-is-blue-green-deployment) deployments. This requires additional infrastructure and complex routing mechanisms. First-class support to do canary releases is very important and should be part of a modern BFF layer, however, most companies rely on DevOps for its support.\\n\\n### Coupled Release\\n\\nBFF layers can\'t be deployed independently since they act as a bridge between the clients and the services. Generally, the services need to go live first, and they need to make sure that the change is compatible with the current version of the BFF layer running in production. The interesting problem is in case there is a bug in the microservice and it needs to be reverted, even the BFF layer needs to be reverted. This kind of coupling makes it operationally very expensive to manage.\\n\\n### Organizational Friction\\n\\nThe Backends for Frontends (BFF) pattern is designed to create a tailor-made backend service for each user interface (e.g., desktop, mobile, etc.), with the aim of simplifying the client-side and improving the user experience.\\n\\nHowever, in practice, this architecture sometimes creates friction within the organization, particularly when BFFs are developed and maintained by the backend team. Here are a few reasons why:\\n\\n1. **Communication and Responsiveness:** As the backend team is typically in charge of the BFF, front-end teams often have to wait for them to make necessary changes. This slows down the development process, especially when backlogs are high or priorities differ.\\n\\n2. **Different Skillsets:** Backend and frontend developers often specialize in different programming languages and paradigms. If the backend team is in charge of the BFF, they might not be as comfortable or efficient at dealing with issues that are more closely related to the frontend.\\n\\n3. **Lack of Ownership:** Frontend teams often feel that they lack ownership and control over the part of the system that directly impacts their work. This leads to decreased motivation and productivity.\\n\\nOne potential solution to these issues is to shift the ownership of the BFFs to the front-end teams. Since these teams are the primary consumers of the BFFs, they could be better placed to design, implement, and maintain them. This would not only empower the front-end teams but also free up backend teams to focus on their core responsibilities.\\n\\nHowever, this solution is not without its own challenges. For one, front-end teams would need to upskill to handle their new responsibilities. Also, the organization would need to ensure that there are clear lines of communication between the front-end and backend teams, so that any changes to shared resources can be coordinated effectively.\\n\\n### Legacy Gateway\\n\\nBFF layers often end up implementing some of the cross-cutting concerns of an API gateway such as rate limiting, authentication, throttling, etc. This makes its purpose quite confusing in the sense that do we need an API gateway if we are using a BFF layer. Moreover, it\'s not very clear if we use an API gateway with a BFF layer, where should we place it? Should we place it between the clients and the BFF layer or the BFF layer and the service mesh? These are subjective decisions that each company ends up making as there is no standard way of doing this. However, it\'s worth mentioning that legacy gateways do introduce a gap that\'s being attempted to be filled by a BFF layer.\\n\\n> BFF, Presentation Layer, Facade, Middleware, UI Layer, Orchestration Layer, API Adapter \u2014 Are all different nomenclatures used for the same thing.\\n\\nTo summarize, BFFs do indeed address the issues of API orchestration to a significant extent; however, they also present a new set of challenges for organizations to tackle. Clearly, there is more to the story. In our [next blog post](https://blog.tailcall.run/unraveling-the-challenges-of-bff-federation), we will discuss some of the solutions that large organizations with unlimited budgets have implemented to overcome this problem. So, please subscribe if you haven\'t already."}]}}')}}]);