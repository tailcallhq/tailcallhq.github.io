{"searchDocs":[{"title":"First Blog Post","type":0,"sectionRef":"#","url":"/blog/first-blog-post/","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":"","version":null},{"title":"Long Blog Post","type":0,"sectionRef":"#","url":"/blog/long-blog-post/","content":"This is the summary of a very long blog post, Use a &lt;!-- truncate --&gt; comment to limit blog post size in the list view. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":"","version":null},{"title":"MDX Blog Post","type":0,"sectionRef":"#","url":"/blog/mdx-blog-post/","content":"Blog posts support Docusaurus Markdown features, such as MDX. tip Use the power of React to create interactive blog posts. &lt;button onClick={() =&gt; alert(&quot;button clicked!&quot;)}&gt;Click me!&lt;/button&gt; Click me!","keywords":"","version":null},{"title":"Welcome","type":0,"sectionRef":"#","url":"/blog/welcome/","content":"Docusaurus blogging features are powered by the blog plugin. Simply add Markdown files (or folders) to the blog directory. Regular blog authors can be added to authors.yml. The blog post date can be extracted from filenames, such as: 2019-05-30-welcome.md2019-05-30-welcome/index.md A blog post folder can be convenient to co-locate blog post images: The blog supports tags as well! And if you don't want a blog: just delete this directory, and use blog: false in your Docusaurus config.","keywords":"","version":null},{"title":"Installation","type":0,"sectionRef":"#","url":"/docs/getting_started/","content":"","keywords":"","version":"Next"},{"title":"NPM‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#npm","content":"If you don't already have nodejs installed, you can find the instructions here. Install Tailcall by running the following command in your terminal: npm i -g @tailcallhq/tailcall Verify that Tailcall is installed correctly by running: tc note Do not use the --force flag during npm installations, as it ignores installing platform-specific builds. ","version":"Next","tagName":"h2"},{"title":"Yarn‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#yarn","content":"Install Tailcall by running the following command in your terminal: yarn global add @tailcallhq/tailcall Verify that Tailcall is installed correctly by running: tc  ","version":"Next","tagName":"h2"},{"title":"Homebrew‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#homebrew","content":"If you don't already have Homebrew installed, you can find the instructions here. Add the Tailcall repository to Homebrew by running the following command in your terminal: brew tap tailcallhq/tailcall brew install tailcall Verify that Tailcall is installed correctly by running: tc Once installation is done, upgrades can be performed via: brew update brew upgrade tailcall  ","version":"Next","tagName":"h2"},{"title":"Curl‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#curl","content":"Follow the steps below to manually install the cli on your system: curl -sSL https://raw.githubusercontent.com/tailcallhq/tailcall/master/install.sh | bash -s --  This command fetches and executes the Tailcall installation script. The installed files are located in the ~/.tailcall directory. Upon completion of the installation, extend your PATH environment variable to include the ~/.tailcall/bin directory: export PATH=$PATH:~/.tailcall/bin  ","version":"Next","tagName":"h2"},{"title":"Docker‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#docker","content":"If you want to install Tailcall with Docker, follow the steps below. Before starting, ensure Docker is installed on your system. If not, you can download it from here. Pull the latest Tailcall Docker image using the following command: docker pull tailcall.docker.scarf.sh/tailcallhq/tailcall/tc-server: This command fetches the latest version of the Tailcall Docker image from the Docker registry. Run the Tailcall Docker container with the following command: docker run -p 8080:8080 -p 8081:8081 tailcall.docker.scarf.sh/tailcallhq/tailcall/tc-server: This command starts the Tailcall server in a Docker container. Similar to the homebrew installation, it exposes a the graphQL endpoint on port 8080. ","version":"Next","tagName":"h2"},{"title":"Problem Statement","type":0,"sectionRef":"#","url":"/docs/","content":"","keywords":"","version":"Next"},{"title":"Microservice Architecture‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#microservice-architecture","content":"This is what a typical microservices architecture looks like:  The clients (Mobile/Web) make requests to the microservices through an API gateway. An API gateway is a server that acts as a single point of entry for any type of request. It is responsible for routing them to the appropriate backend service and then returning the response from the backend service to the client. An API gateway can also perform tasks such as authentication, rate limiting, and caching. This makes it a useful component in a microservices architecture, where each service has its API and the API gateway acts as the &quot;front door&quot; for clients to access the services. ","version":"Next","tagName":"h2"},{"title":"API Composition‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#api-composition","content":"API composition refers to the process of combining multiple APIs to create a new API or a new functionality. This can be done by sending requests to multiple APIs and combining the results, or by creating a new API that acts as a fa√ßade for the underlying APIs. info API Composition is also known as API Orchestration. This is however vastly different from Microservice Orchestration. For example, consider a scenario where a client application wants to display a timeline of posts with the profile information of each user on a social media platform. In this case, the client can send two separate requests to two different APIs and combines them together as follows: First to /posts to retrieve recent posts, with the following response: type Post { id: ID! title: String! body: String! userId: ID! # Reference to user by it's id. } Second, with the userId from the above post response, make a request to /users to retrieve the user's profile information, with the following response: type User { id: ID! name: String! email: String! } The client can then combine the results from these two APIs to create a single response that contains all the required information. This new response can be considered as the output of the composed API. type Post { id: ID! title: String! body: String! user: User! # Reference to the complete user object }  ","version":"Next","tagName":"h2"},{"title":"Composition on Clients‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#composition-on-clients","content":"The composition on the client side remains unstandardised. There is often a problem of over fetching where the client makes a request to get some data, but the server ends up sending more than what‚Äôs required on the screen. And under fetching where the client end up making multiple API calls to get relevant data for a particular screen. This, with a modest hardware and in conjunction with flaky network conditions makes the overall solution unreliable and non-performant. info Modest hardware and flaky network conditions on the client side results in poor user-experience. ","version":"Next","tagName":"h2"},{"title":"1. Increased Complexity‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#1-increased-complexity","content":"To build a rich user interface, API composition is necessary on the client side. One of the main challenges with API composition on the client side is that it can lead to increased complexity in the client application. This is because the client needs to handle the process of sending requests to multiple APIs and combining the results, which can add to the overall size and complexity of the client code. ","version":"Next","tagName":"h3"},{"title":"2. Reduced Performance‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#2-reduced-performance","content":"Another challenge with API composition on the client side is that it can result in reduced performance and increased latency. This is because the client needs to make multiple requests to different APIs, which can take more time and result in a slower response from the composed API. ","version":"Next","tagName":"h3"},{"title":"3. Increased Risk‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#3-increased-risk","content":"In addition, API composition on the client side can also lead to increased security risks. This is because the client needs to handle sensitive information, such as API keys and authentication credentials, which can be vulnerable to attacks if not properly secured. The client doesn't have access to powerful CPUs or a reliable network either. This makes the composition problem even more challenging to implement and manage. It is therefore often more efficient and effective to perform API composition on the server side instead. ","version":"Next","tagName":"h3"},{"title":"Backend For Frontend (BFF)‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#backend-for-frontend-bff","content":"A BFF layer can help to solve the challenges of API composition by providing a separate backend service that is optimized for each specific frontend client. This can enable the BFF to perform API composition on behalf of the client, which can help to improve the performance and reliability of the composed API. The BFF layer typically sits as a separate component in the overall architecture, between the frontend client and the microservices. It can communicate with both the frontend client and the microservices using well-defined interfaces and protocols, such as REST or gRPC.  info BFFs can dramatically improve the reliability and performance of the system, there by having a direct impact on user-experience. The BFF can take advantage of a powerful CPU and access to a fast network to improve the performance and reliability of the composed API. It can also provide added flexibility and control over the composition process. This can make it a useful tool for developers who want to create new APIs by combining the functionality of multiple underlying APIs. However, there are a few challenges with a BFF layer: ","version":"Next","tagName":"h2"},{"title":"1. Highly Specialized‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#1-highly-specialized","content":"One of the challenges with using a BFF layer is that it is a highly specialized solution that requires a significant amount of hand-written code. Unlike an API gateway, there is no standard BFF solution that can be deployed out-of-the-box, and each BFF implementation must be custom-tailored to the specific requirements of the frontend client. This lack of standardization and reusability can make the BFF solution more complex and difficult to maintain. ","version":"Next","tagName":"h3"},{"title":"2. Fragile‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#2-fragile","content":"Another challenge with using a BFF layer is that it can be fragile and susceptible to failure. The BFF solution is dependent on the developers to follow best practices and handle all error scenarios, and if these steps are not taken, the solution can be prone to bugs and performance issues. Additionally, the BFF solution must be thoroughly tested, including performance testing, unit testing, and integration testing, to ensure that it is reliable and performs well in production. This can require significant effort and expertise, and if these steps are not properly followed, the BFF solution can be fragile and prone to failure. Also, it's worth mentioning that a BFF layer is an entry point to all your backend, it going down basically means nothing is accessible for the user so this layer needs to be robust and resilient to exceptions. ","version":"Next","tagName":"h3"},{"title":"3. Speculative Performance‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#3-speculative-performance","content":"Because BFF layers are typically custom-written for each use case, it can be difficult to predict the performance impact of a small code change. Issues such as unoptimized algorithms, inefficient caching, and unnecessary downstream requests can go unnoticed and only be discovered very late in the development cycle. Typically companies perform thorough benchmarking and load testing before anything goes live. This results in a very high time to market even for minor changes. ","version":"Next","tagName":"h3"},{"title":"4. Monolith‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#4-monolith","content":"Eventually, this layer turns out to be a big monolith touching every service in your backend. The layer contains a lot of handwritten spaghetti code that's hard to maintain. Onboarding new engineers also become harder and upgrading libraries or architecture gets costlier. Any tiny change requires a full-fledged deployment on your infrastructure. ","version":"Next","tagName":"h3"},{"title":"5. Canary Support (Lack thereof)‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#5-canary-support-lack-thereof","content":"Every change that happens in the backend requires the deployment of the BFF layer. Any feature that is built on the client also requires changes on the BFF layer. Such frequent changes can not be exposed to 100% of users because the reliability and performance of this system are unknown. A common way to solve this problem is to use Blue-Green deployments. This requires additional infrastructure and complex routing mechanisms. First-class support to do canary releases is very important and should be part of a modern BFF layer, however, most companies rely on DevOps for its support. ","version":"Next","tagName":"h3"},{"title":"6. Coupled Release‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#6-coupled-release","content":"BFF layers can't be deployed independently since they act as a bridge between the clients and the services. Generally, the services need to go live first, and they need to make sure that the change is compatible with the current version of the BFF layer running in production. The interesting problem is in case there is a bug in the microservice and it needs to be reverted, even the BFF layer needs to be reverted. This kind of coupling makes it operationally very expensive to manage. ","version":"Next","tagName":"h3"},{"title":"7. Legacy Gateway‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#7-legacy-gateway","content":"BFF layers often end up implementing some of the cross-cutting concerns of an API gateway such as rate limiting, authentication, throttling, etc. This makes its purpose quite confusing if we already have an API gateway. Moreover, it's not very clear if we use an API gateway with a BFF layer, where should we place it? Should we place it between the clients and the BFF layer or the BFF layer and the service mesh? These are subjective decisions that each company ends up making as there is no standard way of doing this. However, it's worth mentioning that legacy gateways do introduce a gap that's being attempted to be filled by a BFF layer. info BFF, Presentation Layer, Facade, Middleware, Frontend Layer, Orchestration Layer, API Adapter ‚Äî Are all different nomenclatures used for the same thing. ","version":"Next","tagName":"h3"},{"title":"8. Organizational Friction‚Äã","type":1,"pageTitle":"Problem Statement","url":"/docs/#8-organizational-friction","content":"The Backends for Frontend (BFF) pattern, while designed to enhance user experience, introduces undeniable organizational friction. These issues include communication delays that hinder development, incompatible skill-sets and perspective of what a BFF layer should be doing causing inefficiencies, and a diminished sense of ownership affecting the frontend teams' productivity. While one might suggest transferring BFF ownership to frontend teams as a potential solution, it's not a foolproof fix. This shift necessitates an expansion of skill-sets among frontend teams and demands enhanced coordination, presenting its own challenges. At Tailcall, we are fervently committed to resolving this issue. We perceive this intricate conundrum as a compelling fusion of organizational dynamics and technical intricacies. It presents a uniquely riveting challenge that propels us beyond the confines of conventional software development paradigms. ","version":"Next","tagName":"h3"},{"title":"Execute","type":0,"sectionRef":"#","url":"/docs/getting_started/execute/","content":"Execute Open a web browser and go to http://localhost:8000. This should load the GraphiQL interface. In the query editor of GraphiQL, enter the following query query { users { id name posts { title } } } After running the query in GraphiQL, expect to see a JSON response structured like this: { &quot;data&quot;: { &quot;users&quot;: [ { &quot;id&quot;: 1, &quot;name&quot;: &quot;Leanne Graham&quot;, &quot;posts&quot;: [ { &quot;title&quot;: &quot;sunt aut facere repellat provident occaecati excepturi optio reprehenderit&quot; } // Additional posts truncated for brevity ] }, { &quot;id&quot;: 2, &quot;name&quot;: &quot;Ervin Howell&quot;, &quot;posts&quot;: [ { &quot;title&quot;: &quot;et ea vero quia laudantium autem&quot; }, { &quot;title&quot;: &quot;in quibusdam tempore odit est dolorem&quot; } // Additional posts truncated for brevity ] } // Additional users truncated for brevity ] } } You can now add additional fields, and compose more queries together!","keywords":"","version":"Next"},{"title":"Configuration","type":0,"sectionRef":"#","url":"/docs/getting_started/configuration/","content":"Configuration For our first example, we are going to compose a GraphQL schema from the REST APIs at https://jsonplaceholder.typicode.com, a free online REST API with some fake data. We will use the API at /users to get a list of users, and /users/:id/posts to get the posts for each user, and compose them into a single GraphQL schema. Create a file called jsonplaceholder.graphql and paste the following contents into it. # Specify a base url for all http requests schema @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query } type Query { # Specify the http path for the users query users: [User] @http(path: &quot;/users&quot;) } # Create a user type with the fields returned by the users api type User { id: Int! name: String! username: String! email: String! # Extend the user type with the posts field # Use the current user's id to construct the path posts: [Post] @http(path: &quot;/users/{{value.id}}/posts&quot;) } # Create a post type with the fields returned by the posts api type Post { id: Int! title: String! body: String! } The above file is a standard .graphQL file, with a few additions such as @server and @http directives. So basically we specify the GraphQL schema and how to resolve that GraphQL schema in the same file, without having to write any code! Here is a quick overview of what the above schema does:","keywords":"","version":"Next"},{"title":"Launch","type":0,"sectionRef":"#","url":"/docs/getting_started/launch/","content":"Launch Now, run the following command to start the server with the full path to the jsonplaceholder.graphql file that you created above. tc start ./jsonplaceholder.graphql If the command succeeds, you should see logs like the following below. üöÄ Tailcall launched at [0.0.0.0:8000] üåç Playground: http://0.0.0.0:8000 The server starts with the schema provided and prints out a load of meta information. We will cover those in detail in a bit. For now, open the playground URL in a new tab in your browser and try it out for yourself!","keywords":"","version":"Next"},{"title":"CLI","type":0,"sectionRef":"#","url":"/docs/guides/cli/","content":"","keywords":"","version":"Next"},{"title":"check‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#check","content":"The check command validates a composition spec. Notably, this command can detect potential N+1 issues. To use the check command, follow this format: tc check [options] &lt;file&gt;...  The check command offers various options that control different settings, such as the display of the blueprint, endpoints, and schema of the composition spec. ","version":"Next","tagName":"h2"},{"title":"--n-plus-one-queries‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#--n-plus-one-queries","content":"This flag triggers the detection of N+1 issues. Type: BooleanDefault: false tc check --n-plus-one-queries &lt;file&gt;...  ","version":"Next","tagName":"h3"},{"title":"--schema‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#--schema","content":"This option enables the display of the schema of the composition spec. Type: BooleanDefault: false tc check --schema &lt;file1&gt; &lt;file2&gt; ... &lt;fileN&gt;  The check command allows for multiple files. Specify each file path, separated by a space, after the options. Example: tc check --schema ./path/to/file1.graphql ./path/to/file2.graphql  ","version":"Next","tagName":"h3"},{"title":"start‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#start","content":"The start command launches the TailCall Server, acting as an GraphQL proxy with specific configurations. The server can publish various GraphQL configurations, also known as composition specs. To start the server, use the following command: tc start &lt;file1&gt; &lt;file2&gt; ... &lt;fileN&gt;  The start command allows for multiple files. Specify each file path, separated by a space, after the options. Example: tc start ./path/to/file1.graphql ./path/to/file2.graphql  ","version":"Next","tagName":"h2"},{"title":"init‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#init","content":"The init command bootstraps a new TailCall project. It creates the necessary GraphQL schema files in the provided file path. tc init &lt;file_path&gt;  This command prompts for additional file creation and configuration, creating a .tailcallrc.graphql file by default. ","version":"Next","tagName":"h2"},{"title":"Operator Composition","type":0,"sectionRef":"#","url":"/docs/guides/composition/","content":"Operator Composition This example illustrates the concept of composition in GraphQL, which allows you to combine multiple operations (known as &quot;operators&quot;) to build more complex transformations of data. The given schema is defining two data types - User and Post. The User type has fields id and name, and the Post type initially has fields user and userId. type User { id: Int name: String } type Post { user: User @inline(path: [&quot;name&quot;]) @modify(name: &quot;userName&quot;) @http(path: &quot;/users/{{userId}}&quot;) userId: Int! } However, it uses a series of operators to modify the user field. The @inline(path: [&quot;name&quot;]) operator is used to drill down into the User object, specifically targeting the name field. This is equivalent to fetching the User.name property. The @modify(name: &quot;userName&quot;) operator is used to name the inlined name field to userName. So, instead of a user field that is a User object, we now have a userName field that is a String. The @http(path: &quot;/users/{{userId}}&quot;) operator is used to instruct the resolver to make an HTTP request to fetch the user data from a specified path (i.e., /users/{{userId}}), where {{userId}} is a placeholder that would be replaced with the actual userId when making the request. The schema after this transformation looks like this: type User { id: Int name: String } type Post { userName: String userId: Int! } So, we've used composition of operators to take a complex object (the User inside the Post), extract a specific part of it (name), name that part (userName), and then instruct GraphQL how to fetch the data using an HTTP request. info It is important to note that the order of the operators doesn't matter. The resulting schema will always be the same. This is a powerful mechanism that allows you to make your GraphQL schema more precise, easier to understand, and more suitable for the specific needs of your application.","keywords":"","version":"Next"},{"title":"Context","type":0,"sectionRef":"#","url":"/docs/guides/context/","content":"","keywords":"","version":"Next"},{"title":"Context in Tailcall‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#context-in-tailcall","content":"In Tailcall, as in all GraphQL implementations, Context is a variable that is accessible to every Operator. It is used to store and access data that needs to be shared between operators. The Context can be described using the following Typescript interface: interface Context { args: Map&lt;string, Json&gt; value: Json parent: Context env: Map&lt;string, string&gt; headers: Map&lt;string, string&gt; }  ","version":"Next","tagName":"h2"},{"title":"args‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#args","content":"These are the arguments passed to the current query. They can be used to access the arguments of the query. For example, type Query { user(id: ID!): User @http(path: &quot;/users/{{args.id}}&quot;) }  In this example, args.id is used to access the id argument passed to the user query. ","version":"Next","tagName":"h3"},{"title":"value‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#value","content":"This represents the value of the current node. For instance, type Post { id: ID! title: String! body: String! comments: [Comment] @http(path: &quot;/posts/{{value.id}}/comments&quot;) }  In the example above, value.id is used to access the id field of the Post type. ","version":"Next","tagName":"h3"},{"title":"parent‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#parent","content":"This denotes the context of the parent node. type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users&quot;, query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}], matchPath: [&quot;id&quot;], matchKey: &quot;userId&quot;) }  In this case, value.userId is a way to get the userId information from the &quot;parent&quot; context of the Post type. Essentially, it's extracting a list or &quot;array&quot; of userId fields from multiple Post types. Think of value as a container that holds the results of a post query, with userId being the specific key you want to fetch from that container. ","version":"Next","tagName":"h3"},{"title":"env‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#env","content":"This represents global environment variables for the server. This is set once when the server starts. type Query { users: [User]! @http(baseUrl: &quot;{{env.API_ENDPOINT}}&quot;, path: &quot;/users&quot;) }  In the above example, env.API_ENDPOINT refers to an environment variable called API_ENDPOINT, which should be defined in your server settings. ","version":"Next","tagName":"h3"},{"title":"headers‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#headers","content":"These are the headers of the request that was received by the Tailcall server. type Query { commentsForUser: [Comment] @http(path: &quot;/users/{{headers.userId}}/comments&quot;) }  Here, headers.userId refers to a header called userId that should be present in the context. The server can use this userId to fetch comments for the specified user. ","version":"Next","tagName":"h3"},{"title":"Tackling N + 1","type":0,"sectionRef":"#","url":"/docs/guides/n+1/","content":"","keywords":"","version":"Next"},{"title":"Scenario‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#scenario","content":"Consider we're developing a feature that involves consuming data from the JSON Placeholder API. The feature requires fetching posts and the details of the authors of these posts. Here's an illustration of how this might typically be implemented: ","version":"Next","tagName":"h2"},{"title":"Fetching Posts‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#fetching-posts","content":"First, we send a request to retrieve all posts: curl https://jsonplaceholder.typicode.com/posts  The above request fetches a list of posts from the API, each of which includes a userId field indicating the author of the post. ","version":"Next","tagName":"h3"},{"title":"Fetching Users‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#fetching-users","content":"Then, for each post, we need to get the author's details. A request for a specific user might look like this: curl https://jsonplaceholder.typicode.com/users/1  If we received 100 posts from our first request, we would then make 100 more requests to get each post's author details, resulting in a total of 101 requests. The N+1 problem, demonstrated using the JSON Placeholder API, refers to the issue where an initial API request generates multiple additional requests. For instance, acquiring 100 posts and then making another request for each post's author details culminates in 101 total requests. info In real-world applications with thousands of posts and users, this problem intensifies. Each user request can yield hundreds or thousands of additional server requests, stressing server resources, and leading to slower response times, higher server costs, and a degraded user experience. This situation can even lead to server downtime due to the high volume of requests, impacting service availability. Therefore, it's crucial to address the N+1 problem during the design and development of applications involving numerous API requests. Solutions to this issue will be discussed in subsequent sections. ","version":"Next","tagName":"h3"},{"title":"Using the CLI‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#using-the-cli","content":"The TailCall CLI is a potent tool for developers, helping identify N+1 issues in GraphQL applications even before any requests are made or configurations are published in production. This proactive approach allows for potential issues to be mitigated right from the development stage. Before diving into the usage, ensure you have familiarized yourself with the basics of the TailCall CLI. If you haven't already, please refer to the Installation guide, which will walk you through the setup process and help you understand the key commands. ","version":"Next","tagName":"h2"},{"title":"Jsonplaceholder Example‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#jsonplaceholder-example","content":"Here is a sample .graphql file that we'll be examining: schema @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{value.userId}}&quot;) }  This schema allows clients to fetch a list of posts, with each post including its associated user data. However, as currently defined, it suffers from the N+1 problem: each post will trigger an additional request to fetch its associated user data. We will demonstrate how to identify this issue using the TailCall CLI in the next section. ","version":"Next","tagName":"h3"},{"title":"Running the TailCall CLI‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#running-the-tailcall-cli","content":"With the check command, TailCall CLI can assist you in identifying potential N+1 issues in a GraphQL file: tc check ./jsonplaceholder.graphql No errors found. N + 1: 1  The N + 1: 1 line tells you that the TailCall CLI has detected one potential N+1 issue. For a deeper understanding of these issues, you can use the --n-plus-one-queries parameter: tc-dev check ./jsonplaceholder.graphql --n-plus-one-queries No errors found. N + 1: 1 query { posts { user } }  This parameter uncovers the minimal query that can trigger an N+1 problem. In the above case, query { posts { user } }, represents the minimal query that could lead to an N+1 problem. It illustrates that within the posts query, each post is triggering an additional request to fetch its associated user data. ","version":"Next","tagName":"h3"},{"title":"Solving Using Batching‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#solving-using-batching","content":"Batching is an effective technique to group multiple similar requests into one, substantially reducing the number of server calls. The TailCall CLI provides this capability to address the typical N+1 issue that arises in GraphQL. To tap into this feature, modify the @http directive on Post.user in your GraphQL schema as follows: type Post { id: Int! userId: Int! title: String! body: String! user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}] groupBy: [&quot;id&quot;] ) }  ","version":"Next","tagName":"h2"},{"title":"Understanding the Update‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#understanding-the-update","content":"The described changes introduce significant tweaks to the @http directive and incorporate the @groupBy operator: query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}]: Here, TailCall CLI is instructed to generate a URL where the user id aligns with the userId from the parent Post. For a batch of posts, the CLI compiles a single URL, such as /users?id=1&amp;id=2&amp;id=3...id=10, consolidating multiple requests into one. groupBy: [&quot;id&quot;]: This parameter instructs the system to convert the list of responses into a map internally, using the user's id as the unique key. In essence, it allows the system to differentiate each user value in the response list. By using this approach, you can reduce the number of requests from 101 (for 100 posts plus one initial request for the post list) to just 2. This significant optimization effectively handles the N+1 problem, thereby enhancing your application's efficiency and user experience. ","version":"Next","tagName":"h3"},{"title":"Watch Mode","type":0,"sectionRef":"#","url":"/docs/guides/watch-mode/","content":"","keywords":"","version":"Next"},{"title":"Use case‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#use-case","content":"Running a server in watch mode offers several key benefits: Real-time Feedback : Watch mode ensures that your server stays up-to-date with your code changes. It immediately reflects those changes, providing you with real-time feedback during development.Efficency : Manually restarting the server each time you modify code can be tedious and time-consuming. Watch mode automates this process, making development more efficient.Debugging : It helps you quickly identify and fix issues as they arise, reducing the debugging time. When your server automatically restarts upon code changes, you catch errors sooner. ","version":"Next","tagName":"h2"},{"title":"Using entr‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#using-entr","content":"entr is a powerful file-watching utility that makes running a server in watch mode a breeze. Let's go through the steps for the installation process for different operating system : ","version":"Next","tagName":"h2"},{"title":"Installation‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#installation","content":"Homebrew‚Äã Open the Terminal, which you can find in the &quot;Utilities&quot; folder within the &quot;Applications&quot; folder. Install Homebrew if you haven't already. Run the following command in your Terminal: /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot; Once Homebrew is installed, you can install entr by running the following command: brew install entr To verify the installation, run: entr --version  If the installation is done correctly it will shown the latest version of the entr Windows Subsystem‚Äã Install Windows Subsystem for Linux (WSL) on your Windows machine by following Microsoft's official documentation. After setting up WSL, open the Linux terminal by running: wsl -d &lt;DistributionName&gt; Replace &lt;DistributionName&gt; with the name of the Linux distribution that you have installed. Install entr within the Linux terminal using the package manager of your chosen Linux distribution. For example, on Ubuntu, you can use: sudo apt update sudo apt install entr Verify the installation by running: entr --version  If the installation is done correctly it will shown the latest version of the entr apt-get‚Äã On Linux, you can install entr using your distribution's package manager. For example, on Ubuntu, use: sudo apt update sudo apt install entr To verify the installation, run: entr --version  If the installation is done correctly it will shown the latest version of the entr ","version":"Next","tagName":"h3"},{"title":"Watch Mode‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#watch-mode","content":"To run your server in watch mode using entr, you'll utilize the ls command to list the files you want to monitor. The general syntax is as follows: ls *.graphql | entr -r tc start ./jsonplaceholder.graphql  This command uses entr to continuously monitor the jsonplaceholder.graphql file and when it changes, It runs the tc start command with the file as an argument The above command is described in detail below : ls *.graphql : This part of the code lists the file or files you want to monitor for changes. In this case, it lists the file named &quot;jsonplaceholder.graphql&quot; within the &quot;examples&quot; directory. | : The pipe symbol ('|') is used to take the output of the preceding command (the file listing) and feed it as input to the following command (entr). entr -r tc start ./jsonplaceholder.graphql : This is the command that will be executed whenever the file &quot;jsonplaceholder.graphql&quot; changes. entr is a command-line tool for running arbitrary commands whenever files change. It monitors the files specified in the previous command (ls ./jsonplaceholder.graphql) r : This flag tells entr to continue running the command even if it encounters errors (it runs the command repeatedly). tc start ./jsonplaceholder.graphql : This is the command to run when changes are detected. It is executing a command tc start with the file path./jsonplaceholder.graphql as an argument ","version":"Next","tagName":"h3"},{"title":"Some Best Practices‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#some-best-practices","content":"To make the most of running a server in watch mode with entr, consider the following best practices: Selective File Watching: Be selective about which files you monitor with entr. Watching unnecessary files can lead to increased CPU and memory usage. Focus on the essential files related to your project. Organize Your Project: Maintain a well-organized project structure to make it easier to identify which files need monitoring. Clear Output: Clear the terminal output before running entr to have a clean workspace. Version Control: Ensure that your project is under version control (e.g., Git) to track changes and easily revert if necessary. Update entr: Kepp entr up to date with the latest version to benefit from bug fixes and improvements. By following these best practices and using entr effectively, you can significantly improve your development workflow. Experiment with entr, adapt it to your project's specific requirements, and enjoy a smoother and more efficient development process. Happy coding! ","version":"Next","tagName":"h2"},{"title":"Architecture","type":0,"sectionRef":"#","url":"/docs/intro/architecture/","content":"","keywords":"","version":"Next"},{"title":"High-Level Architecture‚Äã","type":1,"pageTitle":"Architecture","url":"/docs/intro/architecture/#high-level-architecture","content":"The clients and the services remain the same with an addition of three components viz. The Composition Spec (also known as the ‚ÄúBlueprint‚Äù), Schema Registry, and the Tailcall Proxy.  The Schema Registry serves as a repository for the metadata that outlines how the APIs are structured. This metadata encompasses a range of information, including details about the service endpoint, the input schema associated with the endpoint, and any pertinent security and resilience parameters. Upon receipt of a client request via the proxy, the system dynamically retrieves the corresponding metadata from the registry. It then uses this information to shape its logic and effectively communicate with the client's microservices, ensuring efficient and secure request handling. ","version":"Next","tagName":"h2"},{"title":"Composition Specification (Blueprint)‚Äã","type":1,"pageTitle":"Architecture","url":"/docs/intro/architecture/#composition-specification-blueprint","content":"The Composition Specification (Spec) encompasses all necessary data required for constructing APIs. It comprises the schema of valid request-response pairs, host and protocol specifics, and anticipations for resiliency such as throttling and caching mechanisms. Additionally, it encapsulates critical security aspects, including authentication and authorization measures, among others. This all-encompassing document ensures each component in the API architecture aligns with the defined standards, thus ensuring a robust and secure system.  ","version":"Next","tagName":"h2"},{"title":"Publish‚Äã","type":1,"pageTitle":"Architecture","url":"/docs/intro/architecture/#publish","content":"Once the composition specification is ready, we publish the specification on the tailcall registry. The publishing process has multiple steps. We run all the validations and check if there are any invalid states in the composition specification provided by the developer. We also identify performance bottlenecks in the way APIs are composed for eg: the N + 1 problem. info The N + 1 problem in API composition refers to a situation where a single request to an API results in multiple additional requests being made. This can occur when an API returns a list of objects that each require additional data from another API, resulting in a separate request for each object. This can lead to poor performance and increased load on the API. The problem can be solved by using techniques such as &quot;eager loading&quot; or &quot;batching&quot; to reduce the number of requests made. We recommend standard best practices for API composition so that developers can integrate it on day one. We also apply many optimizations eg: including constant folding, inlining, data-loader, etc. Before publishing a unique sha256 hash is generated for the specification provided by the developer (We will learn more about this in the coming sections) As a final step in this publishing process, a unified endpoint is automatically generated, ensuring seamless API integration. ","version":"Next","tagName":"h2"},{"title":"Client Consumption‚Äã","type":1,"pageTitle":"Architecture","url":"/docs/intro/architecture/#client-consumption","content":"When the client makes a request it needs to make sure the hash is sent as a part of the request. This is the same hash that‚Äôs produced before publishing on the registry. curl 'https://cloud.tailcall.com/graphql/d5fb012' \\ --data-raw '{&quot;query&quot;: &quot;{ posts { title body user { name email } } } }&quot;}'  ","version":"Next","tagName":"h2"},{"title":"Hash Code‚Äã","type":1,"pageTitle":"Architecture","url":"/docs/intro/architecture/#hash-code","content":"The SHA-256 hash for the composition specification isn't created merely from the textual representation of the specification. Instead, it is derived from the semantic meaning of the specification - that is, the underlying logic, structure, and purpose behind the API composition, rather than the literal text or syntax. This method provides a more stable hash because changes in comment, formatting, or syntax, which do not affect the overall function or purpose of the API, do not alter the hash. The hash, therefore, remains consistent unless there are changes to the specification's semantic meaning. This approach ensures that the hash serves as an accurate and reliable identifier for each unique orchestration. This is the most important and differentiated feature of the system because it allows us to do the following: Versioning: Each change is version controlled. You can run multiple versions of the specification at the same time in production, without actually maintaining the source code of each one of them or using the additional infrastructure.Canary Releases: This becomes a first-class feature of the proxy. Because the spec is versioned we can control the exposure of a newly developed feature easily.Immutability: Every specification is immutable, ensuring that once deployed and stabilized in production, it cannot be altered at runtime. This characteristic enhances the safety of product rollbacks.Breaking Changes: As each specification operates independently, deploying breaking changes in production won't affect existing clients, maintaining operational stability and integrity.  Hope the architecture makes sense. If you have any questions, please feel free to reach out to us on our discord channel, we would love to hear from you. ","version":"Next","tagName":"h2"},{"title":"Operators","type":0,"sectionRef":"#","url":"/docs/guides/operators/","content":"","keywords":"","version":"Next"},{"title":"@server‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#server","content":"The @server directive, when applied at the schema level, offers a comprehensive set of server configurations. It dictates how the server behaves and helps tune tailcall for various use-cases. schema @server(...[ServerSettings]...){ query: Query mutation: Mutation }  In this templated structure, replace ...[ServerSettings]... with specific configurations tailored to your project's needs. Adjust and expand these settings as necessary. The various ServerSettings options and their details are explained below. ","version":"Next","tagName":"h2"},{"title":"port‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#port","content":"This refers to the port on which the Tailcall will be running. If not specified, the default port is 8000. schema @server(port: 8090) { query: Query mutation: Mutation }  In this example, the port is set to 8090. This means that the Tailcall will be accessible at http://localhost:8090. tip Always lean towards non-standard ports, steering clear of typical ones like 80 or 8080. Ensure your chosen port is unoccupied. ","version":"Next","tagName":"h3"},{"title":"enableCacheControlHeader‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#enablecachecontrolheader","content":"The enableCacheControlHeader configuration, when activated, instructs Tailcall to transmit Cache-Control headers in its responses. The max-age value in the header, is the least of the values in the responses received by tailcall from the upstream services. By default, this is set to false meaning no header is set. schema @server(enableCacheControlHeader: true) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"},{"title":"enableGraphiql‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#enablegraphiql","content":"This configuration dictates the path on which the GraphiQL interface is hosted within Tailcall. GraphiQL is a built-in, interactive in-browser GraphQL IDE that simplifies query development and testing. By designating a path, such as /graphiql, you grant access to this IDE at that specific URL endpoint, like http://localhost:8000/graphiql. If not provided, GraphiQL won't be available. It's a ready-to-use feature in Tailcall, requiring no additional setup. schema @server(port: 8000, enableGraphiql: &quot;/graphiql&quot;) { query: Query mutation: Mutation }  tip While the GraphiQL interface is a powerful tool for development, it's recommended to disable it in production environments, especially if you're not exposing GraphQL APIs directly to users. This ensures an added layer of security and reduces unnecessary exposure. ","version":"Next","tagName":"h3"},{"title":"vars‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#vars","content":"This configuration allows you to define local variables that can be leveraged during the server's operations. These variables are particularly handy when you need to store constant configurations, secrets, or other shared information that various operations might require. schema @server(vars: {key: &quot;apiKey&quot;, value: &quot;YOUR_API_KEY_HERE&quot;}) { query: Query mutation: Mutation } type Query { externalData: Data @http(path: &quot;/external-api/data&quot;, headers: [{key: &quot;Authorization&quot;, value: &quot;Bearer {{vars.apiKey}}&quot;}]) }  In the provided example, a variable named apiKey is set with a placeholder value of &quot;YOUR_API_KEY_HERE&quot;. This configuration implies that whenever Tailcall fetches data from the externalData endpoint, it includes the apiKey in the Authorization header of the HTTP request. tip Local variables, like apiKey, can be instrumental in securing access to external services or providing a unified place for configurations. Ensure that sensitive information stored this way is well protected and not exposed unintentionally, especially if your Tailcall configuration is publicly accessible. ","version":"Next","tagName":"h3"},{"title":"enableIntrospection‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#enableintrospection","content":"This setting governs whether introspection queries are permitted on the server. Introspection is an intrinsic feature of GraphQL, allowing clients to fetch information about the schema directly. This can be instrumental for tools and client applications to understand the types, fields, and operations available. By default, this setting is enabled (true). schema @server(enableIntrospection: false) { query: Query mutation: Mutation }  tip Although introspection is beneficial during development and debugging stages, it's wise to consider disabling it in production environments. Turning off introspection in live deployments can enhance security by preventing potential attackers from easily discerning the schema and any associated business logic or data structures. ","version":"Next","tagName":"h3"},{"title":"enableQueryValidation‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#enablequeryvalidation","content":"The enableQueryValidation configuration specifies whether the server should validate incoming GraphQL queries against the defined schema. Validating each query ensures its conformity to the schema, preventing errors from invalid or malformed queries. However, there are situations where you might opt to disable it, notably when seeking to enhance server performance at the cost of such checks. This defaults to true if not specified. schema @server(enableQueryValidation: false) { query: Query mutation: Mutation }  In the example above, enableQueryValidation is set to false, bypassing the validation phase for incoming queries. tip This should be enabled in dev environment to make sure the queries sent are correct and validated, however in production env, you could consider disabling it for improved performance. ","version":"Next","tagName":"h3"},{"title":"enableResponseValidation‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#enableresponsevalidation","content":"Tailcall automatically can infer the schema of the http endpoints for you. This information can be used to validate responses that are received from the upstream services. Enabling this setting allows you to perform exactly that. If this is not specified, the default setting for enableResponseValidation is false. schema @server(enableResponseValidation: true) { query: Query mutation: Mutation }  tip Disabling this setting will offer major performance improvements, but at the potential expense of data. ","version":"Next","tagName":"h3"},{"title":"globalResponseTimeout‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#globalresponsetimeout","content":"The globalResponseTimeout configuration determines the maximum duration a query is allowed to run before it's terminated by the server. Essentially, it acts as a safeguard against long-running queries that could strain resources or pose security concerns. If not explicitly defined, there might be a system-specific or default value that applies. schema @server(globalResponseTimeout: 5000) { query: Query mutation: Mutation }  In this given example, the globalResponseTimeout is set to 5000 milliseconds, or 5 seconds. This means any query execution taking longer than this duration will be automatically terminated by the server. tip It's crucial to set an appropriate response timeout, especially in production environments. This not only optimizes resource utilization but also acts as a security measure against potential denial-of-service attacks where adversaries might run complex queries to exhaust server resources. ","version":"Next","tagName":"h3"},{"title":"@upstream‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#upstream","content":"The upstream directive allows you to control various aspects of the upstream server connection. This includes settings like connection timeouts, keep-alive intervals, and more. If not specified, default values are used. schema @upstream(...[UpstreamSetting]...){ query: Query mutation: Mutation }  The various UpstreamSetting options and their details are explained below. ","version":"Next","tagName":"h2"},{"title":"poolIdleTimeout‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#poolidletimeout","content":"The time in seconds that the connection pool will wait before closing idle connections. schema @upstream(poolIdleTimeout: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"},{"title":"poolMaxIdlePerHost‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#poolmaxidleperhost","content":"The maximum number of idle connections that will be maintained per host. schema @upstream(poolMaxIdlePerHost: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"},{"title":"keepAliveInterval‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#keepaliveinterval","content":"The time in seconds between each keep-alive message sent to maintain the connection. schema @upstream(keepAliveInterval: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"},{"title":"keepAliveTimeout‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#keepalivetimeout","content":"The time in seconds that the connection will wait for a keep-alive message before closing. schema @upstream(keepAliveTimeout: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"},{"title":"keepAliveWhileIdle‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#keepalivewhileidle","content":"A boolean value that determines whether keep-alive messages should be sent while the connection is idle. schema @upstream(keepAliveWhileIdle: false, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"},{"title":"proxy‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#proxy","content":"The proxy setting defines an intermediary server through which the upstream requests will be routed before reaching their intended endpoint. By specifying a proxy URL, you introduce an additional layer, enabling custom routing and security policies. schema @upstream(proxy: {url: &quot;http://localhost:3000&quot;}, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }  In the provided example, we've set the proxy's url to &quot;http://localhost:3000&quot;. This configuration ensures that all requests aimed at the designated baseURL are first channeled through this proxy. To illustrate, if the baseURL is &quot;http://jsonplaceholder.typicode.com&quot;, any request targeting it would be initially sent to &quot;http://localhost:3000&quot; before being redirected to its final destination. ","version":"Next","tagName":"h3"},{"title":"connectTimeout‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#connecttimeout","content":"The time in seconds that the connection will wait for a response before timing out. schema @upstream(connectTimeout: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"},{"title":"timeout‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#timeout","content":"The maximum time in seconds that the connection will wait for a response. schema @upstream(timeout: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"},{"title":"tcpKeepAlive‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#tcpkeepalive","content":"The time in seconds between each TCP keep-alive message sent to maintain the connection. schema @upstream(tcpKeepAlive: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"},{"title":"userAgent‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#useragent","content":"The User-Agent header value to be used in HTTP requests. schema @upstream(userAgent: &quot;Tailcall/1.0&quot;, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"},{"title":"allowedHeaders‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#allowedheaders","content":"The allowedHeaders configuration specifies which HTTP headers are permitted to be forwarded to upstream services when making requests. If allowedHeaders isn't specified, no incoming headers will be forwarded to the upstream services, which can provide an added layer of security but might restrict essential data flow. schema @upstream(allowedHeaders: [&quot;Authorization&quot;, &quot;X-Api-Key&quot;]) { query: Query mutation: Mutation }  In the example above, the allowedHeaders is set to allow only Authorization and X-Api-Key headers. This means that requests containing these headers will forward them to upstream services, while all others will be ignored. It ensures that only expected headers are communicated to dependent services, emphasizing security and consistency. ","version":"Next","tagName":"h3"},{"title":"baseURL‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#baseurl","content":"This refers to the default base URL for your APIs. If it's not explicitly mentioned in the @upstream operator, then each @http operator must specify its own baseURL. If neither @server nor @http provides a baseURL, it results in a compilation error. schema @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }  In this representation, the baseURL is set as http://jsonplaceholder.typicode.com. Thus, all API calls made by @http will prepend this URL to their respective paths. tip Ensure that your base URL remains free from specific path segments. GOOD: @upstream(baseURL: http://jsonplaceholder.typicode.com)BAD: @upstream(baseURL: http://jsonplaceholder.typicode.com/api) ","version":"Next","tagName":"h3"},{"title":"enableHttpCache‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#enablehttpcache","content":"When activated, directs Tailcall to utilize HTTP caching mechanisms. These mechanisms, in accordance with the HTTP Caching RFC, are designed to improve performance by reducing unnecessary data fetches. If left unspecified, this feature defaults to false. schema @upstream(enableHttpCache: false) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"},{"title":"batch‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#batch","content":"An object that specifies the batch settings, including maxSize (the maximum size of the batch), delay (the delay in milliseconds between each batch), and headers (an array of HTTP headers to be included in the batch). schema @upstream(batch: {maxSize: 1000, delay: 10, headers: [&quot;X-Server&quot;, &quot;Authorization&quot;]}) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"},{"title":"@http‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#http","content":"This @http operator serves as an indication of a field or node that is underpinned by a REST API. For Example: type Query { user(id: ID!): User @http(path: &quot;/users&quot;) }  In this example, the @http operator is added to the user field of the Query type. This means that the user field is underpinned by a REST API. The path argument is used to specify the path of the REST API. In this case, the path is /users. This means that the GraphQL server will make a GET request to https://jsonplaceholder.typicode.com/users when the user field is queried. ","version":"Next","tagName":"h2"},{"title":"baseURL‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#baseurl-1","content":"This refers to the base URL of the API. If not specified, the default base URL is the one specified in the @server operator. type Query { user(id: ID!): User @http(path: &quot;/users&quot;, baseURL: &quot;https://jsonplaceholder.typicode.com&quot;) }  ","version":"Next","tagName":"h3"},{"title":"path‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#path","content":"This refers to the API endpoint you're going to call. For instance https://jsonplaceholder.typicode.com/users`. type Query { user(id: ID!): User @http(path: &quot;/users&quot;) }  If your API endpoint contains dynamic segments, you can use Mustache templates to substitute variables. For example, to fetch a specific user, the path can be written as /users/{{args.id}}. type Query { user(id: ID!): User @http(path: &quot;/users/{{args.id}}&quot;) }  ","version":"Next","tagName":"h3"},{"title":"method‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#method","content":"This refers to the HTTP method of the API call. Commonly used methods include GET, POST, PUT, DELETE, etc. If not specified, the default method is GET. For example: type Mutation { createUser(input: UserInput!): User @http(method: &quot;POST&quot;, path: &quot;/users&quot;) }  ","version":"Next","tagName":"h3"},{"title":"query‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#query","content":"This represents the query parameters of your API call. You can pass it as a static object or use Mustache template for dynamic parameters. These parameters will be added to the URL. For example: type Query { userPosts(id: ID!): [Post] @http(path: &quot;/posts&quot;, query: [{key: &quot;userId&quot;, value: &quot;{{args.id}}&quot;}]) }  ","version":"Next","tagName":"h3"},{"title":"body‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#body","content":"The body of the API call. It's used for methods like POST or PUT that send data to the server. You can pass it as a static object or use a Mustache template to substitute variables from the GraphQL variables. For example: type Mutation { createUser(input: UserInput!): User @http(method: &quot;POST&quot;, path: &quot;/users&quot;, body: &quot;{{args.input}}&quot;) }  In the example above, the createUser mutation sends a POST request to /users, with the input object converted to JSON and included in the request body. ","version":"Next","tagName":"h3"},{"title":"headers‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#headers","content":"The headers parameter allows you to customize the headers of the HTTP request made by the @http operator. It is used by specifying a key-value map of header names and their values. For instance: type Mutation { createUser(input: UserInput!): User @http(path: &quot;/users&quot;, headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}]) }  In this example, a request to /users will include an additional HTTP header X-Server with the value Tailcall. You can make use of mustache templates to provide dynamic values for headers, derived from the arguments or context provided in the request. For example: type Mutation { users(name: String): User @http(path: &quot;/users&quot;, headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}, {key: &quot;User-Name&quot;, value: &quot;{{args.name}}&quot;}]) }  In this scenario, the User-Name header's value will dynamically adjust according to the name argument passed in the request. ","version":"Next","tagName":"h3"},{"title":"groupBy‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#groupby","content":"The groupBy parameter groups multiple data requests into a single call. For more details please refer out n + 1 guide. type Post { id: Int! name: String! user: User @http(path: &quot;/users&quot;, query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}], groupBy: [&quot;id&quot;]) }  query: {key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}]: Here, TailCall CLI is instructed to generate a URL where the user id aligns with the userId from the parent Post. For a batch of posts, the CLI compiles a single URL, such as /users?id=1&amp;id=2&amp;id=3...id=10, consolidating multiple requests into one. ","version":"Next","tagName":"h3"},{"title":"@modify‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#modify","content":"The @modify operator in GraphQL provides the flexibility to alter the attributes of a field or a node within your GraphQL schema. Here's how you can use this operator: ","version":"Next","tagName":"h2"},{"title":"name‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#name","content":"You can rename a field or a node in your GraphQL schema using the name argument in the @modify operator. This can be helpful when the field name in your underlying data source doesn't match the desired field name in your schema. For instance: type User { id: Int! @modify(name: &quot;userId&quot;) }  @modify(name: &quot;userId&quot;) tells GraphQL that although the field is referred to as idin the underlying data source, it should be presented as userId in your schema. ","version":"Next","tagName":"h3"},{"title":"omit‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#omit","content":"You can exclude a field or a node from your GraphQL schema using the omit argument in the @modify operator. This can be useful if you want to keep certain data hidden from the client. For instance: type User { id: Int! @modify(omit: true) }  @modify(omit: true) tells GraphQL that the id field should not be included in the schema, thus it won't be accessible to the client. ","version":"Next","tagName":"h3"},{"title":"@inline‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#inline","content":"The @inline operator simplifies data structures and fetch processes by 'inlining' or flattening a field or node within your schema. It works by modifying the schema and the data transformation process, essentially streamlining how nested data is accessed and presented. For instance, consider a schema: schema { query: Query } type Post { id: Int! user: User! } type User { id: Int! name: String! email: String! address: Address! } type Address { street: String! city: String! state: String! } type Query { postUserStreet(id: Int): Post! @inline(path: [&quot;user&quot;, &quot;address&quot;, &quot;street&quot;]) }  The @inline operator, in this case, is applied to the postUserStreet field of the Query type. It includes a path argument, indicating the chain of fields to be traversed from Post to the field to be inlined. Post application, the schema becomes: schema { query: Query } type Query { postUserStreet(id: Int): String }  As seen, the Post, User, and Address types are eliminated from the schema. The postUserStreet now directly returns a String representing the address street, thereby simplifying the client-side data fetch process. @inline operator also take cares of nullablity of the fields. If any of the fields in the path is nullable, the resulting type will be nullable. Additionally, @inline supports indexing, meaning you can specify the array index to be inlined. If a field users is of type [User], and you want to inline the first user, you can specify the path as [&quot;users&quot;,&quot;0&quot;,&quot;name&quot;]. type Post { firstUser: User @inline(path: [&quot;users&quot;, &quot;0&quot;, &quot;name&quot;]) @http(path: &quot;/users&quot;) }  In conclusion, the @inline operator helps tidy up your schema and streamline data fetching by reducing query depth, promoting better performance and simplicity. ","version":"Next","tagName":"h2"},{"title":"@const‚Äã","type":1,"pageTitle":"Operators","url":"/docs/guides/operators/#const","content":"The @const operators allows us to embed a constant response for the schema. For eg: schema { query: Query } type Query { user: User @const(data: {name: &quot;John&quot;, age: 12}) } type User { name: String age: Int }  The const operator will also validate the provided value at compile time to make sure that it matches the of the field. If the schema of the provided value doesn't match the type of the field, a descriptive error message is show on the console. ","version":"Next","tagName":"h2"}],"options":{"id":"default"}}