{"searchDocs":[{"title":"Introduction","type":0,"sectionRef":"#","url":"/docs/","content":"Introduction Good APIs craft a broad spectrum of functionalities. Yet, the broader their scope, the more they diverge from being the perfect fit for any specific use case. This fundamental discrepancy ‚Äî the impedance mismatch between the general capabilities of an API and the precise needs of a particular scenario ‚Äî amplifies the necessity for an orchestration layer. Such a layer adeptly bridges this gap, tailor-fitting generic APIs to meet exact requirements with finesse. Tailcall stands at the forefront of this innovation, seamlessly transforming the way APIs are integrated and interacted with. Tailcall introduces a robust DSL (Domain-Specific Language), enabling developers to fine-tune how APIs are orchestrated. This DSL facilitates specifying different caching and batching strategies to enhance the system's efficiency. It also enables precise governance and access control mechanisms. Tailcall serves as a central hub for team collaboration, offering a unified point for managing all APIs, documentation, and more. Once configured, it positions itself between the clients and microservices, adeptly managing all requests and orchestrating them as needed. Manually crafting BFF (Backend for Frontend) layers has become outdated. With Tailcall, API orchestration evolves into a streamlined and highly optimized process. It functions as an essential intermediary, intelligently directing requests and assembling responses from each microservice. This approach diminishes the development burden associated with traditional BFF layers but also bolsters performance, reliability, and scalability throughout the application infrastructure.","keywords":"","version":"Next"},{"title":"Installation","type":0,"sectionRef":"#","url":"/docs/getting_started/","content":"","keywords":"","version":"Next"},{"title":"NPM‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#npm","content":" If you don't already have nodejs installed, you can find the instructions here. Install Tailcall by running the following command in your terminal: npm i -g @tailcallhq/tailcall To verify the correct installation of Tailcall, run: tailcall note Do not use the --force flag during npm installations, as it ignores installing platform-specific builds.  ","version":"Next","tagName":"h2"},{"title":"Yarn‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#yarn","content":" Install Tailcall by running the following command in your terminal: yarn global add @tailcallhq/tailcall To verify the correct installation of Tailcall, run: tailcall   ","version":"Next","tagName":"h2"},{"title":"Homebrew‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#homebrew","content":" If you don't already have Homebrew installed, you can find the instructions here. Add the Tailcall repository to Homebrew by running the following command in your terminal: brew tap tailcallhq/tailcall brew install tailcall To verify the correct installation of Tailcall, run: tailcall After completing the installation, perform upgrades with: brew update brew upgrade tailcall   ","version":"Next","tagName":"h2"},{"title":"Curl‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#curl","content":" Follow the steps below to manually install the cli on your system:  curl -sSL https://raw.githubusercontent.com/tailcallhq/tailcall/master/install.sh | bash -s --   This command fetches and executes the Tailcall installation script. The ~/.tailcall directory contains the installed files.  Upon completion of the installation, extend your PATH environment variable to include the ~/.tailcall/bin directory:  export PATH=$PATH:~/.tailcall/bin   ","version":"Next","tagName":"h2"},{"title":"Docker‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#docker","content":" To install Tailcall with Docker, follow the steps below. Before starting, make sure you have Docker installed on your system. If not, download it from here.  Pull the latest Tailcall Docker image using the following command: docker pull tailcall.docker.scarf.sh/tailcallhq/tailcall/tc-server: This command fetches the latest version of the Tailcall Docker image from the Docker registry. Run the Tailcall Docker container with the following command: docker run -p 8080:8080 -p 8081:8081 tailcall.docker.scarf.sh/tailcallhq/tailcall/tc-server: This command launches the Tailcall server in a Docker container, exposing the GraphQL endpoint on port 8080. ","version":"Next","tagName":"h2"},{"title":"Launch","type":0,"sectionRef":"#","url":"/docs/getting_started/launch/","content":"Launch Now, run the following command to start the server with the full path to the file that you created earlier. graphqlymljson tailcall start ./jsonplaceholder.graphql If the command succeeds, you should see logs like the following below. üöÄ Tailcall launched at [0.0.0.0:8000] üåç Playground: http://0.0.0.0:8000 The server starts with the schema provided and prints out a load of meta information. We will cover those in detail in a bit. For now, open the playground URL in a new tab in your browser and try it out for yourself!","keywords":"","version":"Next"},{"title":"Execute","type":0,"sectionRef":"#","url":"/docs/getting_started/execute/","content":"Execute Open a web browser and go to http://localhost:8000. This should load the GraphiQL interface. In the query editor of GraphiQL, enter the following query query { users { id name posts { title } } } After running the query in GraphiQL, expect to see a JSON response structured like this: { &quot;data&quot;: { &quot;users&quot;: [ { &quot;id&quot;: 1, &quot;name&quot;: &quot;Leanne Graham&quot;, &quot;posts&quot;: [ { &quot;title&quot;: &quot;sunt aut facere repellat provident occaecati excepturi option reprehenderit&quot; } // Posts truncated for brevity ] }, { &quot;id&quot;: 2, &quot;name&quot;: &quot;Ervin Howell&quot;, &quot;posts&quot;: [ { &quot;title&quot;: &quot;et ea vero quia laudantium autem&quot; }, { &quot;title&quot;: &quot;in quibusdam tempore odit est dolorem&quot; } // Posts truncated for brevity ] } // Users truncated for brevity ] } } You can now add more fields, and compose more queries together!","keywords":"","version":"Next"},{"title":"Apollo Studio","type":0,"sectionRef":"#","url":"/docs/guides/apollo-studio/","content":"","keywords":"","version":"Next"},{"title":"Creating a monolith graph‚Äã","type":1,"pageTitle":"Apollo Studio","url":"/docs/guides/apollo-studio/#creating-a-monolith-graph","content":" Before you configure tailcall, you will need to create a Monolith graph on Apollo Studio. Go to your organization's home page and click on Create your first graph, if this is your first graph or Create New Graph if you have existing graphs. Change the Graph title, Graph ID and other fields as desired and make sure to change Graph Architecture to Monolith, assuming tailcall is booted in monolith mode. Once you are done, click on Next. You'll see the following screen. Copy the fields APOLLO_KEY and APOLLO_GRAPH_REF as they are required by tailcall to be able to send the usage metrics. Next we need to connect Apollo with our running instance of Tailcall. There are two ways to let Apollo know about your GraphQL schema: Navigate to Local Introspection. If you have a deployed instance of your GraphQL server you can put the URL pointing to that in Endpoint URL and click on Introspect and Upload. If not, start a local instance of tailcall and put the local url here, similar to how is shown in the image below. You can start a local instance of Tailcall by running tailcall start (click here to know more). Or, Navigate to Local Schema and insert your schema generated by tailcall and click Upload. You can get the schema by running tailcall check (click here to know more).  You have now created a Monolith graph in Apollo Studio. The next step is to configure tailcall to use the APOLLO_API_KEY and APOLLO_GRAPH_REF. Follow detailed instructions here.  ","version":"Next","tagName":"h2"},{"title":"Checking the metrics in Apollo Studio‚Äã","type":1,"pageTitle":"Apollo Studio","url":"/docs/guides/apollo-studio/#checking-the-metrics-in-apollo-studio","content":" To see the metrics for you queries follow these instructions:  Start tailcall with the appropriate configuration for Apollo (click here to know more). Below is an example of what a config may look like: schema @server(port: 8000, graphiql: true) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) @telemetry( export: { apollo: { api_key: &quot;&lt;APOLLO_API_KEY from Apollo Website&gt;&quot; graph_ref: &quot;&lt;APOLLO_GRAPH_REF from Apollo Website&gt;&quot; } } ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! } Visit http://localhost:8000/graphql and create a query with an appropriate name (below is an example query named MyQuery) and run it multiple times to send the metrics to Apollo Studio. tip Naming the query is not required to be able to send the metrics, but it helps to organize the metrics with appropriate names when viewed in Apollo Studio. query MyQuery { posts { id title } } To see the metrics click on the VARIANT NAME of your graph. In the example below, the variant name is current. You will see the following page. From here click on insights icon as highlighted on the left side of the image. You will now be able to see all the information related to your queries here  important If you don't see the name of your query here, try running the query multiple times and waiting for some time. Since the metric isn't sent to Apollo Studio for each query, instead they are batched together and sent at once for efficiency reasons. ","version":"Next","tagName":"h2"},{"title":"CLI","type":0,"sectionRef":"#","url":"/docs/guides/cli/","content":"","keywords":"","version":"Next"},{"title":"check‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#check","content":" The check command validates a composition spec. Notably, this command can detect potential N+1 issues. To use the check command, follow this format:  tailcall check [options] &lt;file&gt;...   The check command offers options that control settings such as the display of the generated schema, n + 1 issues etc.  ","version":"Next","tagName":"h2"},{"title":"--n-plus-one-queries‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#--n-plus-one-queries","content":" This flag triggers the detection of N+1 issues.  Type: BooleanDefault: false  tailcall check --n-plus-one-queries &lt;file&gt;...   ","version":"Next","tagName":"h3"},{"title":"--schema‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#--schema","content":" This option enables the display of the schema of the composition spec.  Type: BooleanDefault: false  tailcall check --schema &lt;file1&gt; &lt;file2&gt; ... &lt;fileN&gt;   The check command allows for files. Specify each file path, separated by a space, after the options.  Example:  tailcall check --schema ./path/to/file1.graphql ./path/to/file2.graphql   ","version":"Next","tagName":"h3"},{"title":"--format‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#--format","content":" This is an optional command which allows changing the format of the input file. It accepts gql or graphql,yml or yaml, json .  tailcall check ./path/to/file1.graphql ./path/to/file2.graphql --format json   ","version":"Next","tagName":"h3"},{"title":"start‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#start","content":" The start command launches the TailCall Server, acting as a GraphQL proxy with specific configurations. The server can publish GraphQL configurations.  To start the server, use the following command:  tailcall start &lt;file1&gt; &lt;file2&gt; ... &lt;fileN&gt; &lt;http_path1&gt; &lt;http_path2&gt; .. &lt;http_pathN&gt;   The start command allows for files and supports loading configurations over HTTP. You can mix file system paths with HTTP paths. Specify each path, separated by a space, after the options.  Example:  tailcall start ./path/to/file1.graphql ./path/to/file2.graphql http://example.com/file2.graphql   ","version":"Next","tagName":"h2"},{"title":"init‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#init","content":" The init command bootstraps a new TailCall project. It creates the necessary GraphQL schema files in the provided file path.  tailcall init &lt;file_path&gt;   This command prompts for file creation and configuration, creating a .tailcallrc.graphql file by default. ","version":"Next","tagName":"h2"},{"title":"Configuration","type":0,"sectionRef":"#","url":"/docs/getting_started/configuration/","content":"Configuration For our first example, we are going to compose a GraphQL schema from the REST APIs at https://jsonplaceholder.typicode.com, a free online REST API with some fake data. We will use the API at /users to get a list of users, and /users/:id/posts to get the posts for each user, and compose them into a single GraphQL schema. We can use the following formats to define our GraphQL schema: .graphql, .yml, .json. Create one of the following files and paste the contents into it. graphqlymljson schema # Specify server configuration: Start tailcall server at 0.0.0.0:8000 and enable GraphiQL playground @server(port: 8000, graphiql: true) # Specify a base url for all http requests @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query } type Query { # Specify the http path for the users query users: [User] @http(path: &quot;/users&quot;) } # Create a user type with the fields returned by the users api type User { id: Int! name: String! username: String! email: String! # Extend the user type with the posts field # Use the current user's id to construct the path posts: [Post] @http(path: &quot;/users/{{value.id}}/posts&quot;) } # Create a post type with the fields returned by the posts api type Post { id: Int! title: String! body: String! } The above file is a standard .graphQL file, with some minor additions such as @upstream and @http directives. Basically we specify the GraphQL schema and how to resolve that GraphQL schema in the same file, without having to write any code!","keywords":"","version":"Next"},{"title":"Client Tuning","type":0,"sectionRef":"#","url":"/docs/guides/client-tuning/","content":"","keywords":"","version":"Next"},{"title":"HTTP (Hypertext Transfer Protocol)‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#http-hypertext-transfer-protocol","content":" HTTP, the most widely used protocol for communication between clients and servers, carries your request to the server and then brings back the data to your client. TCP forms the foundation of HTTP.  ","version":"Next","tagName":"h3"},{"title":"HTTP Versions: 1.x, 2, and 3‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#http-versions-1x-2-and-3","content":" Each version has enhanced HTTP's flexibility and performance.  HTTP/1.x: Creates a separate TCP connection for each HTTP request (or reuses one sequentially).HTTP/2: Introduces multiplexing to allow concurrent sending of requests and responses over a single TCP connection, enhancing performance.HTTP/3: Employs QUIC instead of TCP, further reducing connection setup time and improving packet loss and network change handling.  note The server determines the HTTP version. Thus, if the server supports HTTP/1, the client cannot make an HTTP/2 request, even if compatible. If the client supports HTTP/1, the server should, according to the specification, downgrade to serve the request over HTTP/1.  ","version":"Next","tagName":"h3"},{"title":"TCP (Transmission Control Protocol)‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#tcp-transmission-control-protocol","content":" TCP ensures the data sent and received over the internet reaches its destination and in order.  TCP, like dialing a number before talking on the phone, establishes a connection between the client and server before exchanging data using HTTP. This guide will show how to tune Tailcall's HTTP client to enhance this connection's performance. Learn more about TCP in detail here.  ","version":"Next","tagName":"h3"},{"title":"QUIC (Quick UDP Internet Connections)‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#quic-quick-udp-internet-connections","content":" Developed by Google, QUIC aims to make web communications faster and more efficient than TCP. It reduces connection establishment time, handles packet loss better, and supports multiplexed streams over a single connection, preventing a slow request from holding up others. HTTP/3 uses QUIC. Learn more about QUIC in detail here.  ","version":"Next","tagName":"h3"},{"title":"Why Managing Connections is Important?‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#why-managing-connections-is-important","content":" Performance Overhead: Establishing TCP connections with HTTP/1.x consumes time due to the complete TCP handshake for each new connection. This process adds latency and increases system resources. Limited Ports on Client Side: A unique combination of an IP address and a port number is necessary for each TCP connection from a client. With each new connection, the IP remains the same because the client is the same, but a new port gets used. The number of available ports on a machine is 65535. These ports get shared among all processes, and not all are available for use. Excessive creation of new connections can lead to port exhaustion on the client side, preventing new connections and causing system failures across running processes. tip Use lsof and netstat commands to check the ports to process mapping.  Connection pooling mitigates these issues by reusing existing connections for requests, reducing connection establishment frequency (and thus handshake overhead) and conserving client-side ports. This approach enhances application performance by minimizing the resources and time spent on managing connections.  ","version":"Next","tagName":"h3"},{"title":"Tuning HTTP Client‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#tuning-http-client","content":" Tailcall uses connection pooling by default and sets up with default tuning suitable for most use cases. You might need to further tune the HTTP client to improve your application's performance. Tailcall DSL provides an operator named @upstream for this purpose.  note Connection pooling optimizes HTTP/1. Since HTTP/2 and HTTP/3 support multiplexing, pooling enabled does not noticeably affect performance.  When using HTTP/1.x, tune the connection pool with the following parameters:  ","version":"Next","tagName":"h2"},{"title":"poolMaxIdlePerHost‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#poolmaxidleperhost","content":" poolMaxIdlePerHost specifies the allowed number of idle connections per host, defaulting to 60. Example:  schema @upstream( poolMaxIdlePerHost: 60 ) { query: Query }   Too idle connections can unnecessarily consume memory and ports, while too few might cause delays as new connections need frequent establishment. poolMaxIdlePerHost ensures judicious use of network and memory resources, avoiding wastage on seldom-used connections.  For applications connecting to hosts, set this value lower to keep connections available for other hosts. Conversely, if you have hosts and all requests must resolve through them, maintain a higher value for this setting.  ","version":"Next","tagName":"h3"},{"title":"tcpKeepAlive‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#tcpkeepalive","content":" tcpKeepAlive keeps TCP connections alive for a duration, during inactivity, by periodically sending packets to the server to check if the connection remains open. In connection pooling, tcpKeepAlive maintains reusable connections in a ready-to-use state. This setting is useful for long-lived connections, preventing -lived connections, preventing the client from using a connection the server has closed due to inactivity. Without tcpKeepAlive, connections in the pool might get dropped by the server or intermediate network devices (like firewalls or load balancers). When your client tries to use such a dropped connection, it would fail, causing delays and errors. Keeping connections alive and monitored means you can efficiently reuse them, reducing the overhead of establishing new connections frequently.  Tailcall provides a parameter named tcpKeepAlive for the upstream which defaults to 5 seconds. Example: schema  @upstream ( tcpKeepAlive: 300 ) { query: Query }   ","version":"Next","tagName":"h3"},{"title":"connectTimeout‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#connecttimeout","content":" connectTimeout specifically applies to the phase where your client attempts to establish a connection with the server. When making a connection request, the client tries to resolve the DNS, complete the SSL handshake, and establish a TCP connection. In environments where pods are frequently created and destroyed, maintaining a low connectTimeout is crucial to avoid unnecessary delays. In systems using connection pooling, the system aborts the attempt if it cannot establish a connection within the connectTimeout period. This approach prevents indefinite waiting for a connection to establish, which could cause delays and timeouts.  Tailcall offers a connectTimeout parameter to set the connection timeout in seconds for the HTTP client, defaulting to 60 seconds. Example:  schema @upstream( connectTimeout: 10 ) { query: Query }   In summary, maximizing HTTP client performance requires understanding the underlying protocols and configuring client settings through testing. This ensures efficient, robust, and high-performing client-server communication, crucial for the smooth operation of modern web applications. ","version":"Next","tagName":"h3"},{"title":"Context","type":0,"sectionRef":"#","url":"/docs/guides/context/","content":"","keywords":"","version":"Next"},{"title":"Context in Tailcall‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#context-in-tailcall","content":" In Tailcall, as in all GraphQL implementations, every Operator can access Context. Operators use Context to store and retrieve data necessary for shared operations.  You can describe the Context with the following Typescript interface:  interface Context { args: Map&lt;string, Json&gt; value: Json parent: Context env: Map&lt;string, string&gt; headers: Map&lt;string, string&gt; }   ","version":"Next","tagName":"h2"},{"title":"args‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#args","content":" These arguments pass to the current query, allowing access to the query's arguments. For example,  type Query { user(id: ID!): User @http(path: &quot;/users/{{args.id}}&quot;) }   In this example, you use args.id to access the id argument passed to the user query.  ","version":"Next","tagName":"h3"},{"title":"value‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#value","content":" This field represents the value of the current node. For instance,  type Post { id: ID! title: String! body: String! comments: [Comment] @http(path: &quot;/posts/{{value.id}}/comments&quot;) }   Here, value.id provides access to the id field of the Post type.  ","version":"Next","tagName":"h3"},{"title":"parent‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#parent","content":" This field indicates the context of the parent node.  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}] matchPath: [&quot;id&quot;] matchKey: &quot;userId&quot; ) }   In this scenario, value.userId helps retrieve the userId information from the &quot;parent&quot; context of the Post type, effectively extracting a list of userId fields from the Post types. Consider value as a container holding the results of a post query, with userId as the specific key you want to extract.  ","version":"Next","tagName":"h3"},{"title":"env‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#env","content":" This field represents global environment variables for the server, set once when the server starts.  type Query { users: [User]! @http(baseUrl: &quot;{{env.API_ENDPOINT}}&quot;, path: &quot;/users&quot;) }   Here, env.API_ENDPOINT refers to an environment variable named API_ENDPOINT, defined in your server settings.  ","version":"Next","tagName":"h3"},{"title":"headers‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#headers","content":" These headers come from the request received by the Tailcall server.  type Query { commentsForUser: [Comment] @http(path: &quot;/users/{{headers.userId}}/comments&quot;) }   Here, headers.userId refers to a header called userId that should be present in the context. The server can use this userId to fetch comments for the specified user. ","version":"Next","tagName":"h3"},{"title":"Naming Conventions","type":0,"sectionRef":"#","url":"/docs/guides/conventions/","content":"","keywords":"","version":"Next"},{"title":"General Naming Principles‚Äã","type":1,"pageTitle":"Naming Conventions","url":"/docs/guides/conventions/#general-naming-principles","content":" Consistency is Key: Ensure that naming conventions are uniform across your entire schema to maintain clarity and consistency.Descriptive Over Generic: Opt for descriptive, specific names rather than broad, generic ones to avoid ambiguity.Avoid Abbreviations: Avoid the use of acronyms, initialism, and abbreviations to keep your schema intuitive and understandable.  ","version":"Next","tagName":"h2"},{"title":"Detailed Naming Cases‚Äã","type":1,"pageTitle":"Naming Conventions","url":"/docs/guides/conventions/#detailed-naming-cases","content":" ","version":"Next","tagName":"h2"},{"title":"Fields, Arguments, and Directives‚Äã","type":1,"pageTitle":"Naming Conventions","url":"/docs/guides/conventions/#fields-arguments-and-directives","content":" Adopt camelCase: Utilize camelCase for field names, argument names, and directive names to achieve a clear, consistent structure.  type Query { postTitle(userId: Int): String } directive @includeIf on FIELD   ","version":"Next","tagName":"h3"},{"title":"Types‚Äã","type":1,"pageTitle":"Naming Conventions","url":"/docs/guides/conventions/#types","content":" Prefer PascalCase: Use PascalCase for defining types, enabling easy identification and differentiation.  type Post { ... } enum StatusEnum { ... } interface UserInterface { ... } union SearchResult = ... scalar Date   Enum Values in SCREAMING_SNAKE_CASE: Distinguish enum values by using SCREAMING_SNAKE_CASE.  enum StatusEnum { PUBLISHED DRAFT }   ","version":"Next","tagName":"h3"},{"title":"Field Naming Best Practices‚Äã","type":1,"pageTitle":"Naming Conventions","url":"/docs/guides/conventions/#field-naming-best-practices","content":" ","version":"Next","tagName":"h2"},{"title":"Queries‚Äã","type":1,"pageTitle":"Naming Conventions","url":"/docs/guides/conventions/#queries","content":" Avoid get or list Prefixes: Refrain from using prefixes like get or list in your query names to ensure predictability and consistency.  type Query { # üëé Avoid getPosts: [Post] # üëç Prefer posts: [Post] }   Maintain consistency between root and nested fields:  # üëé Avoid query PostQuery { getPosts { id getUser { name } } } # üëç Prefer query PostQuery { posts { id user { name } } }   ","version":"Next","tagName":"h3"},{"title":"Mutations‚Äã","type":1,"pageTitle":"Naming Conventions","url":"/docs/guides/conventions/#mutations","content":" Verb Prefixes for Mutations: Begin mutation field names with a verb to indicate the action being performed, improving schema readability.  type Mutation { # üëé Avoid postAdd(input: AddPostInput): AddPostPayload! # üëç Prefer addPost(input: AddPostInput): AddPostPayload! }   ","version":"Next","tagName":"h3"},{"title":"Type Naming Conventions‚Äã","type":1,"pageTitle":"Naming Conventions","url":"/docs/guides/conventions/#type-naming-conventions","content":" ","version":"Next","tagName":"h2"},{"title":"Input Types‚Äã","type":1,"pageTitle":"Naming Conventions","url":"/docs/guides/conventions/#input-types","content":" Input Suffix: Denote input types by appending Input to their names, specifying their use case.  input AddPostInput { title: String! body: String! userId: Int! }   ","version":"Next","tagName":"h3"},{"title":"Output Types‚Äã","type":1,"pageTitle":"Naming Conventions","url":"/docs/guides/conventions/#output-types","content":" Response or Payload Suffix: Use a consistent suffix like Response or Payload for the output types resulting from mutations.  type Mutation { addPost(input: AddPostInput!): AddPostResponse! } type AddPostResponse { success: Boolean! post: Post }   ","version":"Next","tagName":"h3"},{"title":"Advanced Naming Strategies‚Äã","type":1,"pageTitle":"Naming Conventions","url":"/docs/guides/conventions/#advanced-naming-strategies","content":" ","version":"Next","tagName":"h2"},{"title":"Resolving Namespace Conflicts‚Äã","type":1,"pageTitle":"Naming Conventions","url":"/docs/guides/conventions/#resolving-namespace-conflicts","content":" For addressing naming conflicts across different domains within your schema:  Use PascalCase Prefix: Distinguish similar types from distinct domains for clear separation without resorting to underscores. This method ensures a cleaner, more professional look while maintaining the integrity and readability of your schema.  type BlogPost { ... } type ForumPost { ... }   ","version":"Next","tagName":"h3"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"Naming Conventions","url":"/docs/guides/conventions/#conclusion","content":" Implementing a consistent, descriptive, and intuitive naming convention is crucial for developing an understandable and maintainable GraphQL schema. By following the best practices outlined you can improve the clarity and effectiveness of your schema. ","version":"Next","tagName":"h2"},{"title":"Http Cache","type":0,"sectionRef":"#","url":"/docs/guides/http-cache/","content":"","keywords":"","version":"Next"},{"title":"Understanding HTTP Caching‚Äã","type":1,"pageTitle":"Http Cache","url":"/docs/guides/http-cache/#understanding-http-caching","content":" HTTP Caching involves saving copies of HTTP responses to serve identical future requests directly from the cache, bypassing the need for new API calls. This reduces latency, conserves bandwidth, and alleviates the load on upstream services by utilizing a cache keyed by request URLs and headers.  By default, HTTP caching is turned off in Tailcall. Enabling it requires setting the httpCache parameter to true in the @upstream configuration. Tailcall employs a in-memory Least_Recently_Used (LRU) cache mechanism to manage stored responses, adhering to upstream-provided caching directives like Cache-Control to optimize the caching process and minimize redundant upstream API requests.  ","version":"Next","tagName":"h3"},{"title":"Enabling HTTP Caching‚Äã","type":1,"pageTitle":"Http Cache","url":"/docs/guides/http-cache/#enabling-http-caching","content":" To activate HTTP caching, adjust the upstream configuration in Tailcall by setting httpCache to true, as shown in the following example:  schema @server(port: 4000) @upstream( baseURL: &quot;https://api.example.com&quot; httpCache: true ) { query: Query }   This configuration instructs Tailcall to cache responses from the designated upstream API.  ","version":"Next","tagName":"h3"},{"title":"Cache-Control headers in responses‚Äã","type":1,"pageTitle":"Http Cache","url":"/docs/guides/http-cache/#cache-control-headers-in-responses","content":" Enabling the cacheControl setting in Tailcall ensures that Cache-Control headers are included in the responses returned to clients. When activated, Tailcall dynamically sets the max-age directive in the Cache-Control header to the minimum max-age value encountered in any of the responses from upstream services. This approach guarantees that the caching duration for the composite response is conservative, aligning with the shortest cache validity period provided by the upstream services. By default, this feature is disabled (false), meaning Tailcall will not modify or add Cache-Control headers unless explicitly instructed to do so. This setting is distinct from the general HTTP cache setting, which controls whether responses are cached internally by Tailcall; cacheControl specifically controls the caching instructions sent to clients.  Here is how you can enable the cacheControl setting within your Tailcall schema to apply these caching instructions:  schema @server(headers: {cacheControl: true}) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"Best Practices for Enhancing REST API Performance with Tailcall‚Äã","type":1,"pageTitle":"Http Cache","url":"/docs/guides/http-cache/#best-practices-for-enhancing-rest-api-performance-with-tailcall","content":" The combination of httpCache and cacheControl provides a comprehensive caching solution. While httpCache focuses on internal caching to reduce the impact of high latency and frequent requests, cacheControl manages client-side caching policies, ensuring an optimal balance between performance, data freshness, and efficient resource use.  These caching primitives are beneficial for REST APIs that are latency-sensitive, have a high rate of request repetition, or come with explicit caching headers indicating cacheable responses. Together, they tackle the common challenges of optimizing REST API performance by minimizing unnecessary network traffic and server load while ensuring response accuracy.  To further enhance the performance of any API with Tailcall, integrating the @cache directive offers protocol agnostic control over caching at the field level within a GraphQL schema. ","version":"Next","tagName":"h3"},{"title":"Environment Variables","type":0,"sectionRef":"#","url":"/docs/guides/environment-variables/","content":"","keywords":"","version":"Next"},{"title":"Need for Environment Variables‚Äã","type":1,"pageTitle":"Environment Variables","url":"/docs/guides/environment-variables/#need-for-environment-variables","content":" Applications rely on external tools, authentication methods, and configurations. For proper functioning, our code needs to access these values.  Consider a scenario of JWT authentication. When signing tokens for our users, we need:  Expiry time: The duration after which the token expires.Secret key: The key for encrypting the token.Issuer: The token issuer, often the organization's name.  There are two ways to manage this:  Hardcode the values in our code: This approach, while simple, poses a massive security risk by exposing sensitive information and requires code changes and application redeployment for updates. Store the values in environment variables: Storing sensitive values in the OS of the server running your application allows runtime access without code modifications, keeping sensitive information secure and simplifying value changes.  ","version":"Next","tagName":"h2"},{"title":"Environment Variables‚Äã","type":1,"pageTitle":"Environment Variables","url":"/docs/guides/environment-variables/#environment-variables","content":" With Tailcall, you can seamlessly integrate environment variables into your GraphQL schema. Tailcall supports this through a env Context variable. All operators share this Context, allowing you to resolve values in your schema.  Example schema:  type Query { users: [User]! @http( baseUrl: &quot;https://jsonplaceholder.typicode.com&quot; path: &quot;/users&quot; ) }   Here, we fetch a list of users from the JSONPlaceholder API. The users field will contain the fetched value at runtime. This works fine, but what if we want to change the API endpoint? We would need to update the code and redeploy the application, which is cumbersome.  We can address this issue using environment variables. Replace the API endpoint with an environment variable, allowing us to change the variable's value without altering our codebase.  type Query { users: [User]! @http(baseUrl: &quot;{{env.API_ENDPOINT}}&quot;, path: &quot;/users&quot;) }   Here, you must set API_ENDPOINT as an environment variable on the device running your server. Upon startup, the server retrieves this value and makes it accessible through the env Context variable.  This approach allows us to change the API endpoint without modifying our codebase. For instance, we might use different API endpoints for development (stage-api.example.com) and production (api.example.com) environments.  Remember, environment variables are not limited to the baseUrl or @http operator. You can use them throughout your schema, as a Mustache template handles their evaluation.  Here's another example, using an environment variable in the headers of @grpc:  type Query { users: [User] @grpc( service: &quot;UserService&quot; method: &quot;ListUsers&quot; protoPath: &quot;./proto/user_service.proto&quot; baseURL: &quot;https://grpc-server.example.com&quot; headers: [ {key: &quot;X-API-KEY&quot;, value: &quot;{{env.API_KEY}}&quot;} ] ) }   ","version":"Next","tagName":"h2"},{"title":"Security Aspects and Best Practices‚Äã","type":1,"pageTitle":"Environment Variables","url":"/docs/guides/environment-variables/#security-aspects-and-best-practices","content":" Environment variables help reduce security risks, but it's crucial to understand that they do not remove these risks entirely because the values are in plain text. Even if configuration values are not always highly sensitive, there is still a potential for compromising secrets. To ensure your secrets remain secure, consider the following tips:  Use a .env file: It's a common practice to create a .env file in your project's root directory for storing all environment variables. Avoid committing this file to your version control system; instead, add it to .gitignore to prevent public exposure of your secrets. For clarity and collaboration, maintain a .env.example file that enumerates all the necessary environment variables for your application, thereby guiding other developers on what variables they need to set. Within Tailcall (or in other environments), you can make use of this .env file by exporting its key-value pairs to your operating system. For example, if your .env file looks like this: API_ENDPOINT=https://jsonplaceholder.typicode.com Export it to your OS with: export $(cat .env | xargs) On Windows: Get-Content .env | Foreach-Object { [System.Environment]::SetEnvironmentVariable($_.Split(&quot;=&quot;)[0], $_.Split(&quot;=&quot;)[1], &quot;User&quot;) } After this, you can access API_ENDPOINT in your codebase. Use Kubernetes Secrets: When deploying your application with Kubernetes, use its Secrets feature to manage environment variables. This approach ensures your secrets remain private and are not embedded in your codebase, while also making it easier to update values as necessary. Store Secrets Through Cloud Provider GUIs: For deployments using a cloud provider, use their GUI for environment variable management. These interfaces are intuitive and practical for containerized applications that automatically scale.  Following these practices ensures effective and secure management of your environment variables. ","version":"Next","tagName":"h2"},{"title":"Logging","type":0,"sectionRef":"#","url":"/docs/guides/logging/","content":"","keywords":"","version":"Next"},{"title":"error‚Äã","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#error","content":" This is the highest severity level. It indicates a critical issue that may lead to the failure of the program or a part of it.  TAILCALL_LOG_LEVEL=error tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=error tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"warn‚Äã","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#warn","content":" This log level signifies potential issues or warnings that do not necessarily result in immediate failure but may require attention.  TAILCALL_LOG_LEVEL=warn tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=warn tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"info‚Äã","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#info","content":" This level offers general information about the program's execution, providing insights into its state and activities.  TAILCALL_LOG_LEVEL=info tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=info tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"debug‚Äã","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#debug","content":" The debug log level is useful for developers during the debugging process, providing detailed information about the program's internal workings.  TAILCALL_LOG_LEVEL=debug tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=debug tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"trace‚Äã","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#trace","content":" The trace log level is the most detailed logging level, used for fine-grained debugging. This level provides exhaustive details about the program's execution flow.  TAILCALL_LOG_LEVEL=trace tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=trace tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"off‚Äã","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#off","content":" This level serves as a special indicator for generating no logs, allowing the option to disable logging entirely.  TAILCALL_LOG_LEVEL=off tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=off tailcall &lt;COMMAND&gt;   info The default log level is info.  Log levels are hierarchical, meaning if you set the log level to a specific level, it includes all the levels above it. For example, setting the log level to info will include logs at the info, warn, and error levels, but exclude debug and trace logs.    info You can specify log levels in either uppercase or lowercase; both yield the same result. For example, TAILCALL_LOG_LEVEL=DEBUG and TAILCALL_LOG_LEVEL=debug are same. ","version":"Next","tagName":"h3"},{"title":"HTTP Filters","type":0,"sectionRef":"#","url":"/docs/guides/http-filters/","content":"","keywords":"","version":"Next"},{"title":"Getting Started‚Äã","type":1,"pageTitle":"HTTP Filters","url":"/docs/guides/http-filters/#getting-started","content":" To leverage this functionality, a JavaScript function named onRequest must be created in a worker.js file. This function serves as middleware, allowing for the interception and modification of the request. Here is a simple example of a worker.js file that logs the request and returns the original request without any modifications.  function onRequest({request}) { console.log(`${request.method} ${request.url}`) return {request} }   Once you have a worker file ready, you link that file to the tailcall configuration using the @link operator.  schema @link(type: Script, src: &quot;./worker.js&quot;) { query: Query }   Once the worker is linked, you can start the server using the usual start command. Making requests to tailcall will now be intercepted by the worker and logged to the console.  ","version":"Next","tagName":"h2"},{"title":"Modify Request‚Äã","type":1,"pageTitle":"HTTP Filters","url":"/docs/guides/http-filters/#modify-request","content":" You can modify the request by returning a request object from the onRequest function. Below is an example where we are modifying the request to add a custom header.  function onRequest({request}) { request.headers[&quot;x-custom-header&quot;] = &quot;Hello, Tailcall!&quot; return {request} }   ","version":"Next","tagName":"h2"},{"title":"Create Response‚Äã","type":1,"pageTitle":"HTTP Filters","url":"/docs/guides/http-filters/#create-response","content":" You can respond with custom responses by returning a response object from the onRequest function. Below is an example where we are responding with a custom response for all requests that start with https://api.example.com.  function onRequest({request}) { if (request.url.startsWith(&quot;https://api.example.com&quot;)) { return { response: { status: 200, headers: { &quot;content-type&quot;: &quot;application/json&quot; }, body: JSON.stringify({message: &quot;Hello, Tailcall!&quot;}) } } } else { return {request} }   ","version":"Next","tagName":"h2"},{"title":"Response Redirect‚Äã","type":1,"pageTitle":"HTTP Filters","url":"/docs/guides/http-filters/#response-redirect","content":" Sometimes you might want to redirect the request to a different URL. You can do this by returning a response object with a status of 301 or 302 and a Location header. The following example redirects all requests to https://example.com to https://tailcall.com.  function onRequest({request}) { if (request.url.startsWith(&quot;https://example.com&quot;)) { return { response: { status: 301, headers: { Location: &quot;https://tailcall.com&quot;, }, }, } } else { return {request} } }   important The new request that's created as a result of the redirect will not be intercepted by the worker.  ","version":"Next","tagName":"h2"},{"title":"Schema‚Äã","type":1,"pageTitle":"HTTP Filters","url":"/docs/guides/http-filters/#schema","content":" The onRequest function takes a single argument that contains the request object. The return value of the onRequest function can be a request object, or a response object. It can not be null or undefined.  ","version":"Next","tagName":"h2"},{"title":"Request‚Äã","type":1,"pageTitle":"HTTP Filters","url":"/docs/guides/http-filters/#request","content":" The request object has the following shape:  type Request = { method: string url: string headers: {[key: string]: string} body?: string }   tip By default the headers field will be empty in most cases, unless headers are whitelisted via the allowedHeaders setting in @upstream.  The http filter doesn't have access to the request's body. However the modified request that's returned can optionally provide the body.  ","version":"Next","tagName":"h3"},{"title":"Response‚Äã","type":1,"pageTitle":"HTTP Filters","url":"/docs/guides/http-filters/#response","content":" The response object has the following shape:  type Response = { status: number headers: {[key: string]: string} body?: string }  ","version":"Next","tagName":"h3"},{"title":"Tailcall on AWS","type":0,"sectionRef":"#","url":"/docs/guides/tailcall-on-aws/","content":"","keywords":"","version":"Next"},{"title":"Logging‚Äã","type":1,"pageTitle":"Tailcall on AWS","url":"/docs/guides/tailcall-on-aws/#logging","content":" All Tailcall logs will be uploaded to and stored in AWS CloudWatch. Logs of all levels are stored by default, so that you can filter the logs as necessary when viewing them in CloudWatch.  If you would like to filter the logs before they get ingested, you can create the config/.env file and specify the minimum log level with the LOG_LEVEL environment variable. The available levels are: TRACE (default), DEBUG, INFO, WARN and ERROR. ","version":"Next","tagName":"h2"},{"title":"Scalars","type":0,"sectionRef":"#","url":"/docs/guides/scalar/","content":"","keywords":"","version":"Next"},{"title":"Default Scalars‚Äã","type":1,"pageTitle":"Scalars","url":"/docs/guides/scalar/#default-scalars","content":" Here is a list of default scalars that are built into the GraphQL Spec:  Scalar\tDescription\tSpecificationInt\tA type representing non-fractional signed whole numbers. Values can range up to (2^31 - 1).\tGraphQL Specification for Int Float\tA type for signed double-precision floating-point numbers.\tGraphQL Specification for Float String\tA sequence of UTF-8 characters, representing textual data.\tGraphQL Specification for String Boolean\tA boolean type that represents true or false.\tGraphQL Specification for Boolean ID\tA unique identifier, typically used to refetch an object or as a cache key.\tGraphQL Specification for ID  ","version":"Next","tagName":"h2"},{"title":"Tailcall Scalars‚Äã","type":1,"pageTitle":"Scalars","url":"/docs/guides/scalar/#tailcall-scalars","content":" These are the current set of custom scalars supported by Tailcall:  Scalar\tDescription\tSpecificationEmail\tA string that conforms to the email format as defined in the HTML specification, utilizing the Unicode character set.\tHTML Specification for Valid Email Addresses PhoneNumber\tA string format adhering to the E.164 international standard, which outlines the numbering plan for the worldwide public switched telephone network (PSTN) and certain data networks.\tE.164 International Numbering Plan Date\tA string that represents dates and times in the Internet protocols, following the ISO 8601 standard via the Gregorian calendar.\tRFC 3339 Date and Time Internet Formats Url\tA standardized format for Uniform Resource Identifiers (URI) that includes both the generic URI syntax and guidelines for resolving URI references, which may be in relative form.\tRFC 3986 Uniform Resource Identifier JSON\tA lightweight data interchange format based on the ECMAScript Programming Language Standard, designed for human-readable data representation.\tRFC 7159 The JavaScript Object Notation (JSON) Data Interchange Format  If none of the scalars make sense for your use case, consider opening an issue on the Tailcall github repository.  ","version":"Next","tagName":"h2"},{"title":"Example Usage‚Äã","type":1,"pageTitle":"Scalars","url":"/docs/guides/scalar/#example-usage","content":" Let's try using these custom scalars in our GraphQL schema.  schema @server( port: 8000 graphiql: true hostname: &quot;localhost&quot; ) { query: Query } type Query { email(value: Email!): Email! @const(data: &quot;{{args.value}}&quot;) }   ","version":"Next","tagName":"h2"},{"title":"Valid Query Example‚Äã","type":1,"pageTitle":"Scalars","url":"/docs/guides/scalar/#valid-query-example","content":" Here is an example of a valid query that passes the custom scalar validations:  ","version":"Next","tagName":"h3"},{"title":"Invalid Query Example‚Äã","type":1,"pageTitle":"Scalars","url":"/docs/guides/scalar/#invalid-query-example","content":" And here is an example of an invalid query that fails the custom scalar validations as expected:  tip We recommend utilizing JSON as a scalar for cases where no other scalar type fits your needs. . ","version":"Next","tagName":"h3"},{"title":"Operators","type":0,"sectionRef":"#","url":"/docs/operators/","content":"Operators Tailcall DSL builds on your existing GraphQL knowledge by allowing the addition of some custom operators. These operators provide powerful compile time guarantees to ensure your API composition is tight and robust. The system automatically generates highly optimized resolver logic for your types using the operator information. Here is a list of all the custom operators supported by Tailcall: Certainly! Here's the table with hyperlinks added back to the operator names: Operator\tDescription@addField\tSimplifies data structures and queries by adding, inlining, or flattening fields or nodes within the schema. @cache\tEnables caching for the query, field or type applied to. @call\tInvokes a query or mutation from another query or mutation field. @const\tAllows embedding of a constant response within the schema. @graphQL\tResolves a field or node by a GraphQL API. @grpc\tResolves a field or node by a gRPC API. @http\tResolves a field or node by a REST API. @link\tImports external resources such as config files, certs, protobufs, etc in the schema. @modify\tEnables changes to attributes of fields or nodes in the schema. @omit\tExcludes fields or nodes from the generated schema, making them inaccessible through the GraphQL API. @server\tProvides server configurations for behavior tuning and tailcall optimization in specific use-cases. @telemetry\tIntegrates with open-telemetry to provide observability of the running tailcall service. @upstream\tControls aspects of the upstream server connection, including timeouts and keep-alive settings.","keywords":"","version":"Next"},{"title":"Tackling N + 1","type":0,"sectionRef":"#","url":"/docs/guides/n+1/","content":"","keywords":"","version":"Next"},{"title":"Scenario‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#scenario","content":" Consider we're developing a feature that involves consuming data from the JSON Placeholder API. The feature requires fetching posts and the details of the authors of these posts.  Here's an illustration of a typical implementation:  ","version":"Next","tagName":"h2"},{"title":"Fetching Posts‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#fetching-posts","content":" First, we send a request to retrieve all posts:  curl https://jsonplaceholder.typicode.com/posts   The above request fetches a list of posts from the API, each of which includes a userId field indicating the author of the post.  ","version":"Next","tagName":"h3"},{"title":"Fetching Users‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#fetching-users","content":" Then, for each post, we need to get the author's details. A request for a specific user might look like this:  curl https://jsonplaceholder.typicode.com/users/1   If we received 100 posts from our first request, we would then make 100 more requests to get each post's author details, resulting in a total of 101 requests.  The N+1 problem, illustrated with the JSON Placeholder API, occurs when one API request triggers more. For example, fetching 100 posts then requesting each post's author details results in 101 requests.  info In real-world applications featuring thousands of posts and users, the problem becomes more severe. Each user request can generate hundreds or thousands of server requests, straining server resources and resulting in slower response times, increased server costs, and a diminished user experience. This issue may even cause server downtime due to the overwhelming number of requests, affecting service availability. Thus, addressing the N+1 problem during the design and development phases of applications that make extensive API requests is essential. We will explore solutions to this issue in the following sections.  ","version":"Next","tagName":"h3"},{"title":"Using the CLI‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#using-the-cli","content":" The TailCall CLI serves as a powerful tool for developers, identifying N+1 issues in GraphQL applications even before making any requests or publishing configurations in production. This proactive approach enables the mitigation of potential issues from the development stage.  Before diving into the usage, ensure you have familiarized yourself with the basics of the TailCall CLI. If you haven't already, please refer to the installation guide, which will walk you through the setup process and help you understand the key commands.  ","version":"Next","tagName":"h2"},{"title":"Jsonplaceholder Example‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#jsonplaceholder-example","content":" Here is a sample .graphql file that we'll be examining:  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{value.userId}}&quot;) }   This schema enables clients to retrieve a list of posts, each including its associated user data. Yet, in its present form, it's affected by the N+1 problem: fetching each post necessitates a separate request for its associated user data.  The following section will show how to detect this issue with the TailCall CLI.  ","version":"Next","tagName":"h3"},{"title":"Running the TailCall CLI‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#running-the-tailcall-cli","content":" With the check command, TailCall CLI can assist you in identifying potential N+1 issues in a GraphQL file:  tailcall check ./jsonplaceholder.graphql INFO File read: ./examples/jsonplaceholder.graphql ... ok INFO Config ./examples/jsonplaceholder.graphql ... ok INFO N + 1 detected: 1   The N + 1: 1 line tells you that the TailCall CLI has detected one potential N+1 issue.  For a deeper understanding of these issues, you can use the --n-plus-one-queries parameter:  tailcall check ./jsonplaceholder.graphql --n-plus-one-queries INFO File read: ./examples/jsonplaceholder.graphql ... ok INFO Config ./examples/jsonplaceholder.graphql ... ok INFO N + 1 detected: 1 query { posts { user } }   This parameter uncovers the minimal query that can trigger an N+1 problem. In the above case, query { posts { user } }, represents the minimal query that could lead to an N+1 problem. It illustrates that within the posts query, each post is triggering an extra request to fetch its associated user data.  ","version":"Next","tagName":"h3"},{"title":"Solving Using Batching‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#solving-using-batching","content":" It's an effective technique to group similar requests into one, greatly reducing the number of server calls. The TailCall CLI provides this capability to address the typical N+1 issue that arises in GraphQL.  To tap into this feature, edit the @http directive on Post.user in your GraphQL schema as follows:  type Post { id: Int! userId: Int! title: String! body: String! user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}] batchKey: [&quot;id&quot;] ) }   The described changes introduce two significant tweaks to the @http directive and incorporate the batchKey configuration:  query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}]: In this configuration, the TailCall CLI generates a URL that aligns the user id with the userId from the parent Post. For a batch of posts, the CLI compiles a single URL, such as /users?id=1&amp;id=2&amp;id=3...id=10, consolidating the requests into one. batchKey: [&quot;id&quot;]: This parameter instructs the system to convert the list of responses into a map internally, using the user's id as the unique key. In essence, it allows the system to differentiate each user value in the response list.  By using this approach, you can reduce the number of requests from 101 (for 100 posts plus one initial request for the post list) down to 2. This significant optimization effectively handles the N+1 problem, thereby enhancing your application's efficiency and user experience. ","version":"Next","tagName":"h2"},{"title":"GraphQL on gRPC","type":0,"sectionRef":"#","url":"/docs/guides/grpc/","content":"","keywords":"","version":"Next"},{"title":"What is gRPC?‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#what-is-grpc","content":" This guide assumes a basic familiarity with gRPC. It is a high-performance framework created by Google for remote procedure calls (RPCs). Its key features include:  HTTP/2 Transport: Ensures efficient and fast data transfer.Protocol Buffers (Protobuf): Serves as a powerful interface description language.Efficiency: Offers binary serialization, reduces latency, and supports data streaming.  This combination of features makes gRPC ideal for microservices and distributed systems. If you need a more detailed understanding or are new to gRPC, we recommend visiting the official gRPC website for comprehensive documentation and resources.  Now, let's explore how gRPC can be integrated into our proxy gateway to enhance communication and data exchange in distributed systems.  ","version":"Next","tagName":"h2"},{"title":"gRPC upstream‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#grpc-upstream","content":" We need some gRPC service available to be able to execute requests from the Tailcall gateway. For pure example purposes, we will build some simple gRPC services.  ","version":"Next","tagName":"h2"},{"title":"Protobuf definition‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#protobuf-definition","content":" First, we need to create an example protobuf file that will define the structure of the data we want to transmit using gRPC. Here is the definition of NewsService that implements CRUD operations on news data that we'll put into the news.proto file.  syntax = &quot;proto3&quot;; import &quot;google/protobuf/empty.proto&quot;; package news; // Define message type for News with all its fields message News { int32 id = 1; string title = 2; string body = 3; string postImage = 4; } // Message with the id of a single news message NewsId { int32 id = 1; } // List of IDs of news to get multiple responses message MultipleNewsId { repeated NewsId ids = 1; } // List of all news message NewsList { repeated News news = 1; } // NewsService defines read and write operations for news items service NewsService { // GetAllNews retrieves all news items without any arguments rpc GetAllNews (google.protobuf.Empty) returns (NewsList) {} // GetNews fetches a single news item by its ID rpc GetNews (NewsId) returns (News) {} // GetMultipleNews retrieves multiple news items based on their IDs rpc GetMultipleNews (MultipleNewsId) returns (NewsList) {} }   ","version":"Next","tagName":"h3"},{"title":"Implement gRPC service‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#implement-grpc-service","content":" Now having the protobuf file you can write a server that implements NewsService at any language you want that supports gRPC. Tailcall organization has a sample node.js service inside this repo that you can pull to your local machine. To spin up the sample service run inside the repo and wait for logs about the service running.  npm i npm start   ","version":"Next","tagName":"h3"},{"title":"Tailcall config‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#tailcall-config","content":" Now when we have a running gRPC service we're going to write Tailcall's config to make the integration. To do this we need to specify GraphQL types corresponding to gRPC types we have defined in the protobuf file. Let's create a new file grpc.graphql file with the following content:  # The GraphQL representation for News message type type News { id: Int title: String body: String postImage: String } # Input type that is used to fetch news data by its id input NewsInput { id: Int } # Resolves multiple news entries type NewsData { news: [News]! }   Now when we have corresponding types in schema we want to define GraphQL Query that specifies the operation we can execute onto news. We can extend our config with the next Query:  type Query { # Get all news i.e. NewsService.GetAllNews news: NewsData! # Get single news by id i.e. NewsService.GetNews newsById(news: NewsInput!): News! }   Also, let's specify options for Tailcall's ingress and egress at the beginning of the config using @server and @upstream operators.  schema @server(port: 8000, graphiql: true) @upstream( baseURL: &quot;http://localhost:50051&quot; httpCache: true ) { query: Query }   To specify the protobuf file to read types from, use the @link operator with the type Protobuf on the schema. id is an important part of the definition that will be used by the @grpc operator later  schema @link(id: &quot;news&quot;, src: &quot;./news.proto&quot;, type: Protobuf)   Now you can connect GraphQL types to gRPC types. To do this you may want to explore more about @grpc operator. Its usage is pretty straightforward and requires you to specify the path to a method that should be used to make a call. The method name will start with the package name, followed by the service name and the method name, all separated by the . symbol.  If you need to provide any input to the gRPC method call you can specify it with the body option that allows you to specify a Mustache template and therefore it could use any input data like args and value to construct the body request. The body value is specified in the JSON format if you need to create the input manually and cannot use args input.  type Query { news: NewsData! @grpc(method: &quot;news.news.NewsService.GetAllNews&quot;) newsById(news: NewsInput!): News! @grpc( service: &quot;news.news.NewsService.GetNews&quot; body: &quot;{{args.news}}&quot; ) }   Wrapping up the whole result config that may look like this:  # file: app.graphql schema @server(port: 8000, graphiql: true) @upstream( baseURL: &quot;http://localhost:50051&quot; httpCache: true ) @link(id: &quot;news&quot;, src: &quot;./news.proto&quot;, type: Protobuf) { query: Query } type Query { news: NewsData! @grpc(method: &quot;news.news.NewsService.GetAllNews&quot;) newsById(news: NewsInput!): News! @grpc( method: &quot;news.news.NewsService.GetNews&quot; body: &quot;{{args.news}}&quot; ) } type News { id: Int title: String body: String postImage: String } input NewsInput { id: Int } type NewsData { news: [News]! }   Start the server by pointing it to the config.  tailcall start ./app.graphql   And now you can go to the page http://127.0.0.1:8000/graphql and execute some GraphQL queries e.g.:  { news { news { id title body } } }   Or  { newsById(news: {id: 2}) { id title body } }   ","version":"Next","tagName":"h2"},{"title":"Batching‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#batching","content":" Another important feature of the @grpc operator is that it allows you to implement request batching for remote data almost effortlessly as soon as you have gRPC methods that resolve multiple responses for multiple inputs in a single request.  In our protobuf example file, we have a method called GetMultipleNews that we can use. To enable batching we need to enable @upstream.batch option first and specify batchKey option for the @grpc operator.  schema @server(port: 8000, graphiql: true) @upstream( baseURL: &quot;http://localhost:50051&quot; httpCache: true batch: {delay: 10} ) @link(id: &quot;news&quot;, src: &quot;./news.proto&quot;, type: Protobuf) { query: Query } type Query { newsById(news: NewsInput!): News! @grpc( method: &quot;news.NewsService.GetNews&quot; body: &quot;{{args.news}}&quot; batchKey: [&quot;news&quot;, &quot;id&quot;] ) }   Restart the Tailcall server and make the query with multiple news separately, e.g.:  { n1: newsById(news: {id: 1}) { id title body } n2: newsById(news: {id: 2}) { id title body } }   Those 2 requests will be executed inside a single request to the gRPC method GetMultipleNews  ","version":"Next","tagName":"h2"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#conclusion","content":" Well done on integrating a gRPC service with the Tailcall gateway! This tutorial has demonstrated the straightforward and efficient process, showcasing Tailcall's compatibility with advanced communication protocols like gRPC.  You can find this working example and test it by yourself by the next links:  node-grpc - example implementation for gRPC service in node.jsgRPC example config - Tailcall's config to integrate with gRPC service above  ","version":"Next","tagName":"h2"},{"title":"Key Takeaways‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#key-takeaways","content":" Simplicity of Integration: The integration of gRPC with Tailcall seamlessly enhances the overall capability of your system to handle high-performance and efficient data composition.Scalability and Performance: By leveraging the power of gRPC along with Tailcall, we've laid a foundation for building scalable and high-performing distributed systems.  ","version":"Next","tagName":"h3"},{"title":"Next Steps‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#next-steps","content":" With the basics in place, we encourage you to explore further:  Dive Deeper: Tailcall gateway offers a lot of other features and configurations that you can utilize. Dive deeper into our documentation to explore more advanced settings and customization options.Explore Other Guides: Our documentation includes a variety of guides and tutorials that can help you leverage the full potential of Tailcall in different scenarios. Whether it's adding security layers, load balancing, or detailed logging, there's a lot more to explore. ","version":"Next","tagName":"h3"},{"title":"Watch Mode","type":0,"sectionRef":"#","url":"/docs/guides/watch-mode/","content":"","keywords":"","version":"Next"},{"title":"Use case‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#use-case","content":" Running a server in watch mode offers a lot of key benefits:  Real-time Feedback: Watch mode ensures that your server remains up-to-date with your code changes, instantly reflecting those changes and providing you with real-time feedback during development.Efficiency: Manually restarting the server each time you change code can be tedious and time-consuming. Watch mode automates this process, enhancing development efficiency.Debugging: It enables you to identify and resolve issues as they occur, reducing debugging time. With your server automatically restarting upon code changes, you detect errors earlier.  ","version":"Next","tagName":"h2"},{"title":"Using entr‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#using-entr","content":" It's a powerful file-watching utility that makes running a server in watch mode a breeze. Let's go through the steps for the installation process for different operating system :  ","version":"Next","tagName":"h2"},{"title":"Installation‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#installation","content":" Homebrew‚Äã  Open the Terminal, which you can find in the &quot;Utilities&quot; folder within the &quot;Applications&quot; folder. Install Homebrew if you haven't already. Run the following command in your Terminal: /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot; After installing Homebrew, proceed to install entr by executing the following command: brew install entr To verify the installation, run: entr --version   Upon successful installation, it will display the latest version of entr.  Windows Subsystem‚Äã  Install Windows Subsystem for Linux (WSL) on your Windows machine by following Microsoft's official documentation. After setting up WSL, open the Linux terminal by running: wsl -d &lt;DistributionName&gt; Replace &lt;DistributionName&gt; with the name of the Linux distribution that you have installed. Install entr within the Linux terminal using the package manager of your chosen Linux distribution. For example, on Ubuntu, you can use: sudo apt update sudo apt install entr Verify the installation by running: entr --version   A successful installation will display the latest version of entr.  apt-get‚Äã  On Linux, you can install entr using your distribution's package manager. For example, on Ubuntu, use: sudo apt update sudo apt install entr To verify the installation, run: entr --version   If you install it, it will show the latest version of the entr  ","version":"Next","tagName":"h3"},{"title":"Watch Mode‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#watch-mode","content":" To run your server in watch mode with entr, use the ls command to list the files you want to track. The general syntax is as follows:  ls *.graphql | entr -r tailcall start ./jsonplaceholder.graphql   This command uses entr to continuously track the jsonplaceholder.graphql file and when it changes, It runs the tailcall start command with the file as an argument  Detailing the above command as follows:  ls *.graphql : This part of the code lists the file or files you want to track for changes. In this case, it lists the file named &quot;jsonplaceholder.graphql&quot; within the &quot;examples&quot; directory. | : The pipe symbol ('|') takes the output of the preceding command (the file listing) and feeds it as input to the following command (entr). entr -r tc start ./jsonplaceholder.graphql : Whenever the file &quot;jsonplaceholder.graphql&quot; changes, this command executes.  entr is a command-line tool for running arbitrary commands whenever files change. It tracks the files specified in the previous command (ls ./jsonplaceholder.graphql) r : This flag instructs entr to persist in running the command through errors, ensuring continuous operation. tc start ./jsonplaceholder.graphql : This command runs upon detecting changes, executing tc start with the file path./jsonplaceholder.graphql as an argument  ","version":"Next","tagName":"h3"},{"title":"Some Best Practices‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#some-best-practices","content":" To make the most of running a server in watch mode with entr, consider the following best practices:  Selective File Watching: Be selective about which files you track with entr. Watching unnecessary files can lead to increased CPU and memory usage. Focus on the essential files related to your project. Organize Your Project: Maintain a well-organized project structure to make it easier to identify which files need tracking. Clear Output: Clear the terminal output before running entr to have a clean workspace. Version Control: Ensure that your project is under version control (e.g., Git) to track changes and revert if necessary. Update entr: Ensure entr is always updated to the latest version for bug fixes and enhancements.  By following these best practices and using entr effectively, you can greatly improve your development workflow. Experiment with entr, adapt it to your project's specific requirements, and enjoy a smoother and more efficient development process. Happy coding! ","version":"Next","tagName":"h2"},{"title":"@addField","type":0,"sectionRef":"#","url":"/docs/operators/add-field/","content":"@addField The @addField operator simplifies data structures and queries by adding a field that inline or flattens a nested field or node within your schema. It modifies the schema and the data transformation process, making nested data more accessible and straightforward to present. For instance, consider a schema: schema { query: Query } type User @addField(name: &quot;street&quot;, path: [&quot;address&quot;, &quot;street&quot;]) { id: Int! name: String! username: String! email: String! phone: String website: String address: Address @modify(omit: true) } type Address { street: String! city: String! state: String! } type Query { user(id: Int!): User @http(path: &quot;/users/{{args.id}}&quot;) } Suppose we focus on the street field in Address. In this case, applying the @addField operator to the User type creates a street field within the User type. It uses a path argument to specify the sequence of fields from a declared field (address), leading to the Address field to add. We also can apply @modify(omit: true) to remove the address field from the schema, as the street field from Address is now directly accessible on the User type. Post application, the schema becomes: schema { query: Query } type User { id: Int! name: String! username: String! email: String! phone: String website: String street: String } type Query { user(id: Int): Post! } In the above example, since we added a @modify(omit: true) on the address field, the schema no longer includes the Address type. The @addField operator also take cares of nullablity of the fields. If any of the fields in the path is nullable, the resulting type will be nullable. @addField also supports indexing, allowing for the specification of an array index for inline inclusion. For instance, if a field posts is of type [Post], and the goal is to access the title of the first post, specify the path as [&quot;posts&quot;,&quot;0&quot;,&quot;title&quot;]. type User @addField( name: &quot;firstPostTitle&quot; path: [&quot;posts&quot;, &quot;0&quot;, &quot;title&quot;] ) { id: Int! name: String! username: String! email: String! phone: String website: String posts: Post @http(path: &quot;/users/{{value.id}}/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! } In conclusion, the @addField operator helps tidy up your schema and streamline data fetching by reducing query depth, promoting better performance and simplicity.","keywords":"","version":"Next"},{"title":"@const","type":0,"sectionRef":"#","url":"/docs/operators/const/","content":"","keywords":"","version":"Next"},{"title":"Static‚Äã","type":1,"pageTitle":"@const","url":"/docs/operators/const/#static","content":" This feature allows for the inclusion of a constant response within the schema definition itself. It is useful for scenarios where the response is unchanging. e.g:  schema { query: Query } type Query { user: User @const(data: {name: &quot;John&quot;, age: 12}) } type User { name: String age: Int }   The const operator also checks the provided value at compile time to ensure it matches the field's schema. If not, the console displays a descriptive error message.  ","version":"Next","tagName":"h2"},{"title":"Dynamic‚Äã","type":1,"pageTitle":"@const","url":"/docs/operators/const/#dynamic","content":" Beyond static data embedding, the @const directive extends its utility to support dynamic data injection through Mustache template syntax. This feature enables the use of placeholders within the constant data, which are then dynamically replaced with actual values at runtime. It supports both scalar values and complex objects, including lists and nested objects, offering flexibility in tailoring responses to specific needs. e.g:  schema { query: Query } type Query { user: User @const( data: { name: &quot;John&quot; workEmail: &quot;john@xyz.com&quot; personalEmail: &quot;john@xyz.com&quot; } ) } type User { name: String age: Int personalEmail: String workEmail: String emails: Emails @const( data: { emails: { workEmail: &quot;{{value.workEmail}}&quot; personalEmail: &quot;{{value.personalEmail}}&quot; } } ) } type Emails { workEmail: String personalEmail: String }   In this example, the @const directive dynamically generate an Emails object based on the provided template data. The placeholders within the template ({{value.workEmail}} and {{value.personalEmail}}) gets replaced with the actual values specified in the User type, allowing for dynamic content generation while still adhering to the schema's structure. ","version":"Next","tagName":"h2"},{"title":"@cache","type":0,"sectionRef":"#","url":"/docs/operators/cache/","content":"","keywords":"","version":"Next"},{"title":"maxAge‚Äã","type":1,"pageTitle":"@cache","url":"/docs/operators/cache/#maxage","content":" @cache(maxAge: Int)   This parameter is a non-zero unsigned integer specifying the duration, in milliseconds, that retains the cached value.  ","version":"Next","tagName":"h2"},{"title":"Usage‚Äã","type":1,"pageTitle":"@cache","url":"/docs/operators/cache/#usage","content":" Consider the following GraphQL schema example:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int title: String userId: Int @cache(maxAge: 100) user: User @http(path: &quot;/user/{{value.userId}}&quot;) @cache(maxAge: 200) } type User { id: Int name: String email: String }   In this configuration, the system caches the result of the user field due to its association with an HTTP resolver. But it does not cache the values of userId and title because they lack individual resolvers; the resolver for the posts field retrieves their values, employing the @http(path: &quot;/posts&quot;) directive.  Applying the @cache directive at the type level affects all fields within that type. For example:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post @cache(maxAge: 100) { id: Int title: String userId: Int user: User @http(path: &quot;/user/{{value.userId}}&quot;) } type User { id: Int name: String email: String }   You can simplify this configuration to show that applying the @cache directive to a type means every field within that type inherits it:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int @cache(maxAge: 100) title: String @cache(maxAge: 100) userId: Int @cache(maxAge: 100) user: User @http(path: &quot;/user/{{value.userId}}&quot;) @cache(maxAge: 100) } type User { id: Int name: String email: String }   Since the @cache directive does not affect fields without resolvers, the effective configuration can be further reduced as follows:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int title: String userId: Int user: User @http(path: &quot;/user/{{value.userId}}&quot;) @cache(maxAge: 100) } type User { id: Int name: String email: String }   When applying the @cache directive both at the type level and on individual fields within that type, the field-level directive takes precedence:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post @cache(maxAge: 200) { id: Int title: String userId: Int user: User @http(path: &quot;/user/{{value.userId}}&quot;) @cache(maxAge: 100) } type User { id: Int name: String email: String }   Thus, in the configuration above, while all fields inherit the @cache(maxAge: 200) directive at the type level, the user field's explicit @cache(maxAge: 100) directive takes precedence.  ","version":"Next","tagName":"h2"},{"title":"Cache Key‚Äã","type":1,"pageTitle":"@cache","url":"/docs/operators/cache/#cache-key","content":" The caching mechanism generates a hash based on information related to the applied query to serve as the cache key for the corresponding value.  For instance, the system caches the user field in the following configuration, using the hash of the interpolated string &quot;/user/{{value.userId}}&quot; as the cache key. For example, if Post.userId equals 1, the system generates the cache key by hashing the string &quot;/users/1&quot;. ","version":"Next","tagName":"h2"},{"title":"@graphQL","type":0,"sectionRef":"#","url":"/docs/operators/graphql/","content":"","keywords":"","version":"Next"},{"title":"baseURL‚Äã","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#baseurl","content":" This refers to the base URL of the API. If not specified, the default base URL is the one specified in the @upstream operator.  type Query { users: [User] @graphQL( name: &quot;users&quot; baseURL: &quot;https://graphqlzero.almansi.me/api&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"name‚Äã","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#name","content":" The root field's name on the upstream to request data from. For example:  type Query { users: [User] @graphQL(name: &quot;userList&quot;) }   When Tailcall receives a query for the users field, it will request a query for userList from the upstream.  ","version":"Next","tagName":"h3"},{"title":"args‚Äã","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#args","content":" Named arguments for the requested field. For example:  type Query { user: User @graphQL( name: &quot;user&quot; args: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}] ) }   Will request the next query from the upstream for the first user's name:  query { user(id: 1) { name } }   ","version":"Next","tagName":"h3"},{"title":"headers‚Äã","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#headers","content":" The headers parameter allows customizing the headers of the GraphQL request made by the @graphQL operator. Specifying a key-value map of header names and their values achieves this.  For instance:  type Mutation { users: User @graphQL( name: &quot;users&quot; headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}] ) }   In this example, a request to /users will include the HTTP header X-Server with the value Tailcall.  ","version":"Next","tagName":"h3"},{"title":"batch‚Äã","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#batch","content":" In case the upstream GraphQL server supports request batching, we can specify the batch argument to batch requests to a single upstream into a single batch request. For example:  schema @upstream( batch: { maxSize: 1000 delay: 10 headers: [&quot;X-Server&quot;, &quot;Authorization&quot;] } ) { query: Query mutation: Mutation } type Query { users: [User] @graphQL(name: &quot;users&quot;, batch: true) posts: [Post] @graphQL(name: &quot;posts&quot;, batch: true) }   Make sure you have also specified batch settings to the @upstream and to the @graphQL operator. ","version":"Next","tagName":"h3"},{"title":"@grpc","type":0,"sectionRef":"#","url":"/docs/operators/grpc/","content":"","keywords":"","version":"Next"},{"title":"method‚Äã","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#method","content":" This parameter specifies the gRPC service and method to be invoked, formatted as &lt;package&gt;.&lt;service&gt;.&lt;method&gt;:  type Query { users: [User] @grpc(method: &quot;proto.users.UserService.ListUsers&quot;) }   ","version":"Next","tagName":"h2"},{"title":"baseURL‚Äã","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#baseurl","content":" Defines the base URL for the gRPC API. If not specified, the URL set in the @upstream directive is used by default:  type Query { users: [User] @grpc( baseURL: &quot;https://grpc-server.example.com&quot; method: &quot;proto.users.UserService.ListUsers&quot; ) }   ","version":"Next","tagName":"h2"},{"title":"body‚Äã","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#body","content":" This parameter outlines the arguments for the gRPC call, allowing for both static and dynamic inputs:  type UserInput { id: ID } type Query { user(id: UserInput!): User @grpc( body: &quot;{{args.id}}&quot; method: &quot;proto.users.UserService.GetUser&quot; ) }   ","version":"Next","tagName":"h2"},{"title":"headers‚Äã","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#headers","content":" Custom headers for the gRPC request can be defined, facilitating the transmission of authentication tokens or other contextual data:  type Query { users: [User] @grpc( headers: [ {key: &quot;X-CUSTOM-HEADER&quot;, value: &quot;custom-value&quot;} ] method: &quot;proto.users.UserService.ListUsers&quot; ) }   ","version":"Next","tagName":"h2"},{"title":"batchKey‚Äã","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#batchkey","content":" This argument is employed to optimize batch requests by grouping them based on specified response keys, enhancing performance in scenarios requiring multiple, similar requests:  type Query { users(id: UserInput!): [User] @grpc( batchKey: [&quot;id&quot;] method: &quot;proto.users.UserService.ListUsers&quot; baseURL: &quot;https://grpc-server.example.com&quot; ) }   info Read about n + 1 to learn how to use the batchKey setting. ","version":"Next","tagName":"h2"},{"title":"@call","type":0,"sectionRef":"#","url":"/docs/operators/call/","content":"","keywords":"","version":"Next"},{"title":"query‚Äã","type":1,"pageTitle":"@call","url":"/docs/operators/call/#query","content":" Specify the root query field to invoke, alongside the requisite arguments, using the @call directive for a concise and efficient query structure.  type Post { userId: Int! user: User @call(query: &quot;user&quot;, args: {id: &quot;{{value.userId}}&quot;}) }   ","version":"Next","tagName":"h3"},{"title":"mutation‚Äã","type":1,"pageTitle":"@call","url":"/docs/operators/call/#mutation","content":" Similarly, the @call directive can facilitate calling a mutation from another mutation field, employing the mutation parameter for field specification and the args parameter for argument delineation.  type Mutation { insertPost(input: PostInput, overwrite: Boolean): Post @http( body: &quot;{{args.input}}&quot; method: &quot;POST&quot; path: &quot;/posts&quot; query: {overwrite: &quot;{{args.overwrite}}&quot;} ) upsertPost(input: PostInput): Post @call( mutation: &quot;insertPost&quot; args: {input: &quot;{{args.input}}&quot;, overwrite: true} ) }   ","version":"Next","tagName":"h3"},{"title":"args‚Äã","type":1,"pageTitle":"@call","url":"/docs/operators/call/#args","content":" The args parameter in the @call directive facilitates passing arguments to the targeted query or mutation, represented as a key-value mapping where each key corresponds to an argument name and its associated value.  type Post { userId: Int! user: User @call(query: &quot;user&quot;, args: {&quot;id&quot;: &quot;{{value.userId}}&quot;}) }   tip The @call directive is predominantly advantageous in complex, large-scale configurations. For those new to GraphQL or Tailcall, it may be beneficial to explore this directive after familiarizing yourself with the foundational aspects of GraphQL. ","version":"Next","tagName":"h2"},{"title":"@omit","type":0,"sectionRef":"#","url":"/docs/operators/omit/","content":"","keywords":"","version":"Next"},{"title":"How it works‚Äã","type":1,"pageTitle":"@omit","url":"/docs/operators/omit/#how-it-works","content":" When applied to a field or node, the @omit operator instructs the Tailcall not to include that field or node in the schema. This means that clients cannot query or mutate data in those fields.  ","version":"Next","tagName":"h2"},{"title":"Example‚Äã","type":1,"pageTitle":"@omit","url":"/docs/operators/omit/#example","content":" Consider a scenario where you have a User type with an embedded Address type. If you want to exclude the Address type from the schema to simplify the API, you can use the @omit operator:  type Address { city: String street: String } type User { name: String address: Address @omit }   In this example, the address field will not be accessible or visible through the GraphQL API.  ","version":"Next","tagName":"h2"},{"title":"Comparison with modify‚Äã","type":1,"pageTitle":"@omit","url":"/docs/operators/omit/#comparison-with-modify","content":" The @omit operator and @modify(omit: true) essentially serve the same purpose in excluding fields from the schema, but they differ in syntax and flexibility. In fact, one can consider @omit as a shorthand or alias for the more verbose @modify(omit: true).  @omit offers a concise way to directly exclude a field or node without additional arguments. @modify(omit: true), as part of the broader @modify operator, provides more options, such as field renaming through the name argument. This makes it a more flexible choice when you need more than field exclusion.  For more details on the @modify operator and its capabilities, including omitting fields, see the @modify documentation. ","version":"Next","tagName":"h2"},{"title":"@link","type":0,"sectionRef":"#","url":"/docs/operators/link/","content":"","keywords":"","version":"Next"},{"title":"How it Works‚Äã","type":1,"pageTitle":"@link","url":"/docs/operators/link/#how-it-works","content":" The @link directive requires specifying a source src, the resource's type type, and an optional identifier id.  src: The source of the link is defined here. It can be either a URL or a file path. When a file path is given, it's relative to the file's location that is importing the link. type: This specifies the link's type, which determines how the imported resource is integrated into the schema. For a list of supported types, see the Supported Types section. id: This is an optional field that assigns a unique identifier to the link. It's helpful for referring to the link within the schema.  ","version":"Next","tagName":"h2"},{"title":"Example‚Äã","type":1,"pageTitle":"@link","url":"/docs/operators/link/#example","content":" The following example illustrates how to utilize the @link directive to incorporate a Protocol Buffers (.proto) file for a gRPC service into your GraphQL schema.  schema @server(port: 8000, graphiql: true) @upstream( baseURL: &quot;http://news.local&quot; httpCache: true batch: {delay: 10} ) @link( id: &quot;news&quot; src: &quot;../src/grpc/news.proto&quot; type: Protobuf ) { query: Query } type Query { news: NewsData! @grpc(method: &quot;news.NewsService.GetAllNews&quot;) } type News { id: Int title: String body: String postImage: String } type NewsData { news: [News]! }   ","version":"Next","tagName":"h2"},{"title":"Supported Types‚Äã","type":1,"pageTitle":"@link","url":"/docs/operators/link/#supported-types","content":" The @link directive enriches your configuration by supporting the integration of external resources. Each link type is designed to serve a specific purpose, enhancing the functionality and flexibility of your schema. Below is a detailed overview of each supported link type:  ","version":"Next","tagName":"h2"},{"title":"Config‚Äã","type":1,"pageTitle":"@link","url":"/docs/operators/link/#config","content":" The Config link type is essential for importing other configuration files. This feature enables a modular approach to schema management by allowing configurations from the imported file to override overlapping settings in the main schema. This functionality is useful in large projects, where maintaining a single monolithic schema file becomes impractical. By using Config, developers can split their schema configurations into manageable pieces, thus promoting better organization and scalability.  Example use case:  Modularizing schema configurations for different environments (development, staging, production).Reusing common configurations across multiple schema files.  ","version":"Next","tagName":"h3"},{"title":"Protobuf‚Äã","type":1,"pageTitle":"@link","url":"/docs/operators/link/#protobuf","content":" The Protobuf link type integrates Protocol Buffers definitions by importing .proto files. This integration is crucial for Tailcall to communicate with gRPC services. By including .proto definitions, the Tailcall server can directly interact with gRPC services, allowing for efficient and type-safe communication.  For detailed integration steps and best practices, refer to the gRPC Integration Guide.  ","version":"Next","tagName":"h3"},{"title":"Script‚Äã","type":1,"pageTitle":"@link","url":"/docs/operators/link/#script","content":" The Script link type allows the config to link to an external JavaScript file. This file can contain custom logic that is executed in response to HTTP request-response events. This feature enables developers to implement custom behaviors, such as adding headers to responses or filtering requests based on specific criteria.  Example script for adding a custom header to all outgoing requests:  function onRequest({request}) { // Add a custom header for all outgoing requests request.headers[&quot;X-Custom-Header&quot;] = &quot;Processed&quot; // Return the updated request return {request} }   ","version":"Next","tagName":"h3"},{"title":"Cert‚Äã","type":1,"pageTitle":"@link","url":"/docs/operators/link/#cert","content":" The Cert link type is designed for importing SSL/TLS certificates, a crucial component for enabling HTTPS in your Tailcall server. This link type ensures that your Tailcall server can expose connections over HTTPS.  tip When using the Cert link type, specify the path to the certificate file. Ensure the certificate is up-to-date and issued by a trusted certificate authority (CA) to avoid security warnings or connection issues.  Example use case:  Securing communication between the Tailcall server and clients.Enhancing privacy and security by encrypting data in transit.  ","version":"Next","tagName":"h3"},{"title":"Key‚Äã","type":1,"pageTitle":"@link","url":"/docs/operators/link/#key","content":" The Key link type imports the private key associated with your SSL/TLS certificate, enabling HTTPS for your Tailcall server. The private key is a critical security element that decrypts information encrypted by the corresponding public key in the SSL/TLS certificate.  When configuring the Key link type, provide the path to your private key file. Ensure the private key matches the imported certificate specified by the Cert link above, and is protected by appropriate file permissions to maintain security.  ","version":"Next","tagName":"h3"},{"title":"Operation‚Äã","type":1,"pageTitle":"@link","url":"/docs/operators/link/#operation","content":" The Operation link type connects your schema to a set of predefined, GraphQL spec-compliant queries and mutations. This functionality allows for the validation and optimization of these operations by the Tailcall server.  Each type serves a specific purpose, enabling the flexible integration of external resources into your GraphQL schema. ","version":"Next","tagName":"h3"},{"title":"@modify","type":0,"sectionRef":"#","url":"/docs/operators/modify/","content":"","keywords":"","version":"Next"},{"title":"name‚Äã","type":1,"pageTitle":"@modify","url":"/docs/operators/modify/#name","content":" You can rename a field or a node in your GraphQL schema using the name argument in the @modify operator. This can be helpful when the field name in your underlying data source doesn't match the desired field name in your schema. For instance:  type User { id: Int! @modify(name: &quot;userId&quot;) }   @modify(name: &quot;userId&quot;) informs GraphQL to present the field known as id in the underlying data source as userId in your schema.  ","version":"Next","tagName":"h2"},{"title":"omit‚Äã","type":1,"pageTitle":"@modify","url":"/docs/operators/modify/#omit","content":" You can exclude a field or a node from your GraphQL schema using the omit argument in the @modify operator. This can be useful if you want to keep certain data hidden from the client. For instance:  type User { id: Int! @modify(omit: true) }   @modify(omit: true) instructs GraphQL to exclude the id field from the schema, making it inaccessible to the client.  tip @omit is a standalone operator and is an alias/shorthand for modify(omit: true) checkout documentation ","version":"Next","tagName":"h2"},{"title":"@http","type":0,"sectionRef":"#","url":"/docs/operators/http/","content":"","keywords":"","version":"Next"},{"title":"baseURL‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#baseurl","content":" Specifies the API's base URL. If unspecified, it defaults to the URL in the @upstream operator.  type Query { users: [User] @http( path: &quot;/users&quot; baseURL: &quot;https://jsonplaceholder.typicode.com&quot; ) }   ","version":"Next","tagName":"h2"},{"title":"path‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#path","content":" Refers to the API endpoint, for example, https://jsonplaceholder.typicode.com/users.  type Query { users: [User] @http(path: &quot;/users&quot;) }   If your API endpoint contains dynamic segments, you can substitute variables using Mustache templates. For example, to fetch a specific user, you can write the path as /users/{{args.id}}.  type Query { user(id: ID!): User @http(path: &quot;/users/{{args.id}}&quot;) }   ","version":"Next","tagName":"h2"},{"title":"method‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#method","content":" Specifies the HTTP method for the API call. The default method is GET if not specified.  type Mutation { createUser(input: UserInput!): User @http(method: &quot;POST&quot;, path: &quot;/users&quot;) }   ","version":"Next","tagName":"h2"},{"title":"query‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#query","content":" Represents the API call's query parameters, either as a static object or with dynamic parameters using Mustache templates. These parameters append to the URL.  type Query { userPosts(id: ID!): [Post] @http( path: &quot;/posts&quot; query: [{key: &quot;userId&quot;, value: &quot;{{args.id}}&quot;}] ) }   ","version":"Next","tagName":"h2"},{"title":"body‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#body","content":" Defines the API call's body, necessary for methods like POST or PUT. Pass it as a static object or use Mustache templates for variable substitution from the GraphQL variables.  type Mutation { createUser(input: UserInput!): User @http( method: &quot;POST&quot; path: &quot;/users&quot; body: &quot;{{args.input}}&quot; ) }   In the example above, the createUser mutation sends a POST request to /users, with the input object converted to JSON and included in the request body.  ","version":"Next","tagName":"h2"},{"title":"headers‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#headers","content":" Customizes the HTTP request headers made by the @http operator. Specify a key-value map of header names and values.  For instance:  type Mutation { createUser(input: UserInput!): User @http( path: &quot;/users&quot; headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}] ) }   In this example, a request to /users will include a HTTP header X-Server with the value Tailcall.  You can make use of mustache templates to provide dynamic values for headers, derived from the arguments or context provided in the request. For example:  type Mutation { users(name: String): User @http( path: &quot;/users&quot; headers: [ {key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;} {key: &quot;User-Name&quot;, value: &quot;{{args.name}}&quot;} ] ) }   In this scenario, the User-Name header's value will dynamically adjust according to the name argument passed in the request.  ","version":"Next","tagName":"h2"},{"title":"batchKey‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#batchkey","content":" Groups data requests into a single call, enhancing efficiency. Refer to our n + 1 guide for more details.  type Post { id: Int! name: String! user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}] batchKey: [&quot;id&quot;] ) }   query: {key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}]: Instructs TailCall CLI to generate a URL aligning the user id with userId from the parent Post, compiling a single URL for a batch of posts, such as /users?id=1&amp;id=2&amp;id=3...id=10, consolidating requests into one. ","version":"Next","tagName":"h2"},{"title":"@telemetry","type":0,"sectionRef":"#","url":"/docs/operators/telemetry/","content":"","keywords":"","version":"Next"},{"title":"Traces‚Äã","type":1,"pageTitle":"@telemetry","url":"/docs/operators/telemetry/#traces","content":" Here are the traces that are captured by the @telemetry directive:  Trace Name\tDescriptionhandle_request\tCaptures the span for processing the HTTP request on the server side, providing foundational observability. field::resolver\tDenotes spans for fields with defined resolvers, offering insights into field names and execution times for resolver logic. expr::eval\tNested within the field::resolver spans, these granulated spans detail the execution of expressions in resolving a field, highlighting the hierarchical execution pattern of nested expressions.  ","version":"Next","tagName":"h2"},{"title":"Metrics‚Äã","type":1,"pageTitle":"@telemetry","url":"/docs/operators/telemetry/#metrics","content":" The @telemetry directive also captures the following metrics:  Metric\tDescriptioncache::hit_rate\tReflects the cache hit rate for the cache powered by the @cache directive  ","version":"Next","tagName":"h2"},{"title":"export‚Äã","type":1,"pageTitle":"@telemetry","url":"/docs/operators/telemetry/#export","content":" The export field defines how the open-telemetry data should be exported and in which format. The following are the supported formats:  ","version":"Next","tagName":"h2"},{"title":"otlp‚Äã","type":1,"pageTitle":"@telemetry","url":"/docs/operators/telemetry/#otlp","content":" Utilizes the OTLP format to export telemetry data to backend systems, supported by most modern tracing and analytics platforms. Here is an example using [honeycomb.io]:  schema @telemetry( export: { otlp: { url: &quot;https://api.honeycomb.io:443&quot; headers: [ { key: &quot;x-honeycomb-team&quot; value: &quot;{{env.HONEYCOMB_API_KEY}}&quot; } {key: &quot;x-honeycomb-dataset&quot;, value: &quot;tailcall&quot;} ] } } ) { query: Query }   You can configure the OTLP exporter with the following options:  Field\tDescriptionurl\tDefines the URL for the OTLP Collector. headers\tSets additional headers for requests to the OTLP Collector.  ","version":"Next","tagName":"h2"},{"title":"prometheus‚Äã","type":1,"pageTitle":"@telemetry","url":"/docs/operators/telemetry/#prometheus","content":" Facilitates metrics export in a Prometheus compatible format, providing a dedicated endpoint for metrics.  schema @telemetry(export: {prometheus: {path: &quot;/metrics&quot;}}) { query: Query }   You can configure the Prometheus exporter with the following options:  Field\tDescriptionpath\tDesignates the endpoint path for Prometheus metrics, defaulting to /metrics. format\tControls the format viz. text or protobuf, for sending data to Prometheus.  ","version":"Next","tagName":"h2"},{"title":"stdout‚Äã","type":1,"pageTitle":"@telemetry","url":"/docs/operators/telemetry/#stdout","content":" Outputs all telemetry data to stdout, ideal for testing or local development environments.  schema @telemetry(export: {stdout: {pretty: true}}) { query: Query }   You can configure the stdout exporter with the following options:  Field\tDescriptionpretty\tEnables formatted output of telemetry data for enhanced readability.  ","version":"Next","tagName":"h2"},{"title":"apollo‚Äã","type":1,"pageTitle":"@telemetry","url":"/docs/operators/telemetry/#apollo","content":" Facilitates seamless integration with Apollo Studio, enhancing the observability of GraphQL services. By leveraging this field, developers gain access to valuable insights into the performance and behavior of their GraphQL APIs.  schema @telemetry( export: { otlp: { api_key: &quot;{{env.APOLLO_API_KEY}}&quot; graph_ref: &quot;graph-id@current&quot; platform: &quot;website.com&quot; version: &quot;1.0.0&quot; } } ) { query: Query }   You can configure the apollo exporter with the following options:  Field\tDescriptionapi_key\tThe API Key generated from Apollo Studio. graph_ref\tThe Graph Ref, which is the graph_id and the variant concatenated using @(i.e. &lt;graph_id&gt;@&lt;variant&gt;) platform\tAn arbitrary value which can contain the name of your website or some other value to identify your deployment uniqely, in case you have multiple deployments. version\tVersion of Apollo which is being used.  By integrating the @telemetry directive into your GraphQL schema, you empower your development teams with critical insights into application performance, enabling proactive optimization and maintenance. ","version":"Next","tagName":"h2"},{"title":"@server","type":0,"sectionRef":"#","url":"/docs/operators/server/","content":"","keywords":"","version":"Next"},{"title":"workers‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#workers","content":" Setting workers to 32 means that the Tailcall server will use 32 worker threads.  schema @server(workers: 32) { query: Query mutation: Mutation }   This example sets the workers to 32, meaning the Tailcall server will use 32 worker threads.  ","version":"Next","tagName":"h2"},{"title":"port‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#port","content":" Setting the port to 8090 means that Tailcall will be accessible at http://localhost:8000.  schema @server(port: 8090) { query: Query mutation: Mutation }   This example sets the port to 8090, making Tailcall accessible at http://localhost:8090.  tip Always choose non-standard ports, avoiding typical ones like 80 or 8080. Make sure your chosen port is free.  ","version":"Next","tagName":"h2"},{"title":"headers‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#headers","content":" Allows intelligent configuration of the final response headers that's produced by Tailcall.  ","version":"Next","tagName":"h2"},{"title":"cacheControl‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#cachecontrol","content":" Activating the cacheControl configuration directs Tailcall to send Cache-Control headers in its responses. The max-age value in the header matches the smallest of the values in the responses Tailcall receives from upstream services. By default, this is false, which means Tailcall does not set any header.  schema @server(headers: {cacheControl: true}) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"graphiql‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#graphiql","content":" Enabling the graphiql configuration activates the GraphiQL IDE at the root (/) path within Tailcall. GraphiQL is a built-in, interactive in-browser GraphQL IDE, designed to streamline query development and testing. By default, this feature is off.  schema @server(port: 8000, graphiql: true) { query: Query mutation: Mutation }   tip While the GraphiQL interface is a powerful tool for development, consider disabling it in production environments if you're not exposing GraphQL APIs directly to users. This ensures an added layer of security and reduces unnecessary exposure.  ","version":"Next","tagName":"h2"},{"title":"vars‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#vars","content":" This configuration allows defining local variables for use during the server's operations. These variables are handy for storing constant configurations, secrets, or other shared information that operations might need.  schema @server( vars: {key: &quot;apiKey&quot;, value: &quot;YOUR_API_KEY_HERE&quot;} ) { query: Query mutation: Mutation } type Query { externalData: Data @http( path: &quot;/external-api/data&quot; headers: [ { key: &quot;Authorization&quot; value: &quot;Bearer {{vars.apiKey}}&quot; } ] ) }   In the provided example, setting a variable named apiKey with a placeholder value of &quot;YOUR_API_KEY_HERE&quot; implies that whenever Tailcall fetches data from the externalData endpoint, it includes the apiKey in the Authorization header of the HTTP request.  tip Local variables, like apiKey, are instrumental in securing access to external services or providing a unified place for configurations. Ensure that sensitive information stored this way is well protected and not exposed unintentionally, if your Tailcall configuration is publicly accessible.  ","version":"Next","tagName":"h2"},{"title":"introspection‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#introspection","content":" This setting controls the server's allowance of introspection queries. Introspection, a core feature of GraphQL, allows clients to directly fetch schema information. This capability proves crucial for tools and client applications in comprehending the available types, fields, and operations. By default, the server enables this setting (true).  schema @server(introspection: false) { query: Query mutation: Mutation }   tip Although introspection is beneficial during development and debugging stages, consider disabling it in production environments. Turning off introspection in live deployments can enhance security by preventing potential attackers from discerning the schema and any associated business logic or data structures.  ","version":"Next","tagName":"h2"},{"title":"queryValidation‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#queryvalidation","content":" The queryValidation configuration determines if the server checks incoming GraphQL queries against the defined schema. Each query check ensures it matches the schema, preventing errors from incorrect or malformed queries. In some situations, you might want to disable it, notably to enhance server performance at the cost of these checks. This defaults to false if not specified.  schema @server(queryValidation: true) { query: Query mutation: Mutation }   The example above sets queryValidation to true, enabling the validation phase for incoming queries.  tip Enable this in the development environment to ensure the queries sent are correct and validated. In the production environment, consider disabling it for improved performance.  ","version":"Next","tagName":"h2"},{"title":"responseValidation‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#responsevalidation","content":" Tailcall can automatically infer the schema of the HTTP endpoints for you. This information can check responses received from the upstream services. Enabling this setting allows you to do that. If not specified, the default setting for responseValidation is false.  schema @server(responseValidation: true) { query: Query mutation: Mutation }   tip Disabling this setting will offer major performance improvements, but at the potential expense of data integrity.  ","version":"Next","tagName":"h2"},{"title":"responseHeaders‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#responseheaders","content":" The responseHeader is an array of key-value pairs. These headers get added to the response of every request made to the server. This can be useful for adding headers like Access-Control-Allow-Origin to allow cross-origin requests, or some headers like X-Allowed-Roles for use by downstream services.  schema @server( responseHeaders: [ {key: &quot;X-Allowed-Roles&quot;, value: &quot;admin,user&quot;} ] ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"globalResponseTimeout‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#globalresponsetimeout","content":" The globalResponseTimeout configuration sets the max duration a query can run before the server terminates it. Essentially, it acts as a safeguard against long-running queries that could strain resources or pose security concerns.  If not explicitly defined, there might be a system-specific or default value that applies.  schema @server(globalResponseTimeout: 5000) { query: Query mutation: Mutation }   In this given example, setting the globalResponseTimeout to 5000 milliseconds, or 5 seconds, means any query execution taking longer than this duration will be automatically terminated by  tip Setting an appropriate response timeout in production environments is crucial. This optimizes resource use and serves as a security measure against potential denial-of-service attacks, where adversaries might run complex queries to exhaust server resources.  ","version":"Next","tagName":"h2"},{"title":"version‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#version","content":" The server uses the HTTP version. If not specified, the default value is HTTP1. The available options are HTTP1 and HTTP2.  schema @server(version: HTTP2) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"cert‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#cert","content":" The path to certificate(s) for running the server over HTTP2 (HTTPS). If not specified, the default value is null.  schema @server(cert: &quot;./cert.pem&quot;) { query: Query mutation: Mutation }   tip The certificate can be of any extension, but it's highly recommended to use standards (pem, crt, key).  ","version":"Next","tagName":"h2"},{"title":"key‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#key","content":" The path to the key for running the server over HTTP2 (HTTPS). If not specified, the default value is null.  schema @server(key: &quot;./key.pem&quot;) { query: Query mutation: Mutation }   tip The key can be of any extension, but it's highly recommended to use standards (pem, crt, key).  ","version":"Next","tagName":"h2"},{"title":"batchRequests‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#batchrequests","content":" Batching in GraphQL combines requests into one, reducing server round trips.  schema @server( port: 8000 batchRequests: true )   ","version":"Next","tagName":"h2"},{"title":"Trade-offs‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#trade-offs","content":" Batching can improve performance but may introduce latency if one request in the batch takes longer. It also makes network traffic debugging harder. ","version":"Next","tagName":"h3"},{"title":"@upstream","type":0,"sectionRef":"#","url":"/docs/operators/upstream/","content":"","keywords":"","version":"Next"},{"title":"poolIdleTimeout‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#poolidletimeout","content":" The connection pool waits for this duration in seconds before closing idle connections.  schema @upstream( poolIdleTimeout: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"poolMaxIdlePerHost‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#poolmaxidleperhost","content":" The max number of idle connections each host will maintain.  schema @upstream( poolMaxIdlePerHost: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"keepAliveInterval‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#keepaliveinterval","content":" The time in seconds between each keep-alive message sent to maintain the connection.  schema @upstream( keepAliveInterval: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"keepAliveTimeout‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#keepalivetimeout","content":" The time in seconds that the connection will wait for a keep-alive message before closing.  schema @upstream( keepAliveTimeout: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"keepAliveWhileIdle‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#keepalivewhileidle","content":" A boolean value that determines whether to send keep-alive messages while the connection is idle.  schema @upstream( keepAliveWhileIdle: false baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"proxy‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#proxy","content":" The proxy setting defines an intermediary server that routes upstream requests before they reach their intended endpoint. By specifying a proxy URL, you introduce a layer, enabling custom routing and security policies.  schema @upstream( proxy: {url: &quot;http://localhost:3000&quot;} baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   In the provided example, we've set the proxy's url to &quot;http://localhost:3000&quot;. This configuration ensures that all requests aimed at the designated baseURL first go through this proxy. To illustrate, if the baseURL is &quot;http://jsonplaceholder.typicode.com&quot;, any request targeting it initially goes to &quot;http://localhost:3000&quot; before the proxy redirects it to its final destination.  ","version":"Next","tagName":"h2"},{"title":"connectTimeout‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#connecttimeout","content":" The time in seconds that the connection will wait for a response before timing out.  schema @upstream( connectTimeout: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"timeout‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#timeout","content":" The max time in seconds that the connection will wait for a response.  schema @upstream( timeout: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"tcpKeepAlive‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#tcpkeepalive","content":" The time in seconds between each TCP keep-alive message sent to maintain the connection.  schema @upstream( tcpKeepAlive: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"userAgent‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#useragent","content":" The User-Agent header value for HTTP requests.  schema @upstream( userAgent: &quot;Tailcall/1.0&quot; baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"allowedHeaders‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#allowedheaders","content":" The allowedHeaders configuration defines a set of whitelisted HTTP headers that can be forwarded to upstream services during requests. Without specifying allowedHeaders, the system will not forward any incoming headers to upstream services, offering an extra security layer but potentially limiting necessary data flow. Tailcall compares the provided whitelisted headers in a case-insensitive format.  schema @upstream( allowedHeaders: [&quot;Authorization&quot;, &quot;X-Api-Key&quot;] ) { query: Query mutation: Mutation }   In the example above, the configuration for allowedHeaders permits Authorization and X-Api-Key headers. Thus, requests with these headers will forward them to upstream services; the system ignores all others. This configuration ensures communication of the expected headers to dependent services, emphasizing security and consistency.  ","version":"Next","tagName":"h2"},{"title":"baseURL‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#baseurl","content":" This refers to the default base URL for your APIs. If it's not explicitly mentioned in the @upstream operator, then each @http operator must specify its own baseURL. If neither @upstream nor @http provides a baseURL, it results in a compilation error.  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   In this representation, http://jsonplaceholder.typicode.com serves as the baseURL. Thus, all API calls made by @http prepend this URL to their respective paths.  tip Ensure that your base URL remains free from specific path segments. GOOD: @upstream(baseURL: http://jsonplaceholder.typicode.com)BAD: @upstream(baseURL: http://jsonplaceholder.typicode.com/api)  ","version":"Next","tagName":"h2"},{"title":"httpCache‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#httpcache","content":" When activated, directs Tailcall to use HTTP caching mechanisms, following the HTTP Caching RFC to enhance performance by minimizing unnecessary data fetches. If left unspecified, this feature defaults to false.  schema @upstream(httpCache: false) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"Tips‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#tips","content":" Use batching when other optimization techniques fail to resolve performance issues.Apply batching and thoroughly assess its impact.Understand that batching may make debugging more challenging.  ","version":"Next","tagName":"h3"},{"title":"batch‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#batch","content":" An object that specifies the batch settings, including maxSize (the max size of the batch), delay (the delay in milliseconds between each batch), and headers (an array of HTTP headers that the batch will include).  schema @upstream( batch: { maxSize: 1000 delay: 10 headers: [&quot;X-Server&quot;, &quot;Authorization&quot;] } ) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h2"}],"options":{"highlightResult":true,"id":"default"}}