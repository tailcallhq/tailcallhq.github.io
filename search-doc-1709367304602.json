{"searchDocs":[{"title":"Long Blog Post","type":0,"sectionRef":"#","url":"/blog/long-blog-post/","content":"This is the summary of a very long blog post, Use a &lt;!-- truncate --&gt; comment to limit blog post size in the list view. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":"","version":null},{"title":"First Blog Post","type":0,"sectionRef":"#","url":"/blog/first-blog-post/","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":"","version":null},{"title":"MDX Blog Post","type":0,"sectionRef":"#","url":"/blog/mdx-blog-post/","content":"Blog posts support Docusaurus Markdown features, such as MDX. tip Use the power of React to create interactive blog posts. &lt;button onClick={() =&gt; alert(&quot;button clicked!&quot;)}&gt;Click me!&lt;/button&gt; Click me!","keywords":"","version":null},{"title":"Welcome","type":0,"sectionRef":"#","url":"/blog/welcome/","content":"Docusaurus blogging features are powered by the blog plugin. Simply add Markdown files (or folders) to the blog directory. Regular blog authors can be added to authors.yml. The blog post date can be extracted from filenames, such as: 2019-05-30-welcome.md2019-05-30-welcome/index.md A blog post folder can be convenient to co-locate blog post images: The blog supports tags as well! And if you don't want a blog: just delete this directory, and use blog: false in your Docusaurus config.","keywords":"","version":null},{"title":"Introduction","type":0,"sectionRef":"#","url":"/docs/","content":"Introduction Good APIs craft a broad spectrum of functionalities. Yet, the broader their scope, the more they diverge from being the perfect fit for any specific use case. This fundamental discrepancy ‚Äî the impedance mismatch between the general capabilities of an API and the precise needs of a particular scenario ‚Äî amplifies the necessity for an orchestration layer. Such a layer adeptly bridges this gap, tailor-fitting generic APIs to meet exact requirements with finesse. Tailcall stands at the forefront of this innovation, seamlessly transforming the way APIs are integrated and interacted with. Tailcall introduces a robust DSL (Domain-Specific Language), enabling developers to fine-tune how APIs are orchestrated. This DSL facilitates specifying different caching and batching strategies to enhance the system's efficiency. It also enables precise governance and access control mechanisms. Tailcall serves as a central hub for team collaboration, offering a unified point for managing all APIs, documentation, and more. Once configured, it positions itself between the clients and microservices, adeptly managing all requests and orchestrating them as needed. Manually crafting BFF (Backend for Frontend) layers has become outdated. With Tailcall, API orchestration evolves into a streamlined and highly optimized process. It functions as an essential intermediary, intelligently directing requests and assembling responses from each microservice. This approach diminishes the development burden associated with traditional BFF layers but also bolsters performance, reliability, and scalability throughout the application infrastructure.","keywords":"","version":"Next"},{"title":"Installation","type":0,"sectionRef":"#","url":"/docs/getting_started/","content":"","keywords":"","version":"Next"},{"title":"NPM‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#npm","content":" If you don't already have nodejs installed, you can find the instructions here. Install Tailcall by running the following command in your terminal: npm i -g @tailcallhq/tailcall To verify the correct installation of Tailcall, run: tailcall note Do not use the --force flag during npm installations, as it ignores installing platform-specific builds.  ","version":"Next","tagName":"h2"},{"title":"Yarn‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#yarn","content":" Install Tailcall by running the following command in your terminal: yarn global add @tailcallhq/tailcall To verify the correct installation of Tailcall, run: tailcall   ","version":"Next","tagName":"h2"},{"title":"Homebrew‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#homebrew","content":" If you don't already have Homebrew installed, you can find the instructions here. Add the Tailcall repository to Homebrew by running the following command in your terminal: brew tap tailcallhq/tailcall brew install tailcall To verify the correct installation of Tailcall, run: tailcall After completing the installation, perform upgrades with: brew update brew upgrade tailcall   ","version":"Next","tagName":"h2"},{"title":"Curl‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#curl","content":" Follow the steps below to manually install the cli on your system:  curl -sSL https://raw.githubusercontent.com/tailcallhq/tailcall/master/install.sh | bash -s --   This command fetches and executes the Tailcall installation script. The ~/.tailcall directory contains the installed files.  Upon completion of the installation, extend your PATH environment variable to include the ~/.tailcall/bin directory:  export PATH=$PATH:~/.tailcall/bin   ","version":"Next","tagName":"h2"},{"title":"Docker‚Äã","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#docker","content":" To install Tailcall with Docker, follow the steps below. Before starting, make sure you have Docker installed on your system. If not, download it from here.  Pull the latest Tailcall Docker image using the following command: docker pull tailcall.docker.scarf.sh/tailcallhq/tailcall/tc-server: This command fetches the latest version of the Tailcall Docker image from the Docker registry. Run the Tailcall Docker container with the following command: docker run -p 8080:8080 -p 8081:8081 tailcall.docker.scarf.sh/tailcallhq/tailcall/tc-server: This command launches the Tailcall server in a Docker container, exposing the GraphQL endpoint on port 8080. ","version":"Next","tagName":"h2"},{"title":"Execute","type":0,"sectionRef":"#","url":"/docs/getting_started/execute/","content":"Execute Open a web browser and go to http://localhost:8000. This should load the GraphiQL interface. In the query editor of GraphiQL, enter the following query query { users { id name posts { title } } } After running the query in GraphiQL, expect to see a JSON response structured like this: { &quot;data&quot;: { &quot;users&quot;: [ { &quot;id&quot;: 1, &quot;name&quot;: &quot;Leanne Graham&quot;, &quot;posts&quot;: [ { &quot;title&quot;: &quot;sunt aut facere repellat provident occaecati excepturi option reprehenderit&quot; } // Posts truncated for brevity ] }, { &quot;id&quot;: 2, &quot;name&quot;: &quot;Ervin Howell&quot;, &quot;posts&quot;: [ { &quot;title&quot;: &quot;et ea vero quia laudantium autem&quot; }, { &quot;title&quot;: &quot;in quibusdam tempore odit est dolorem&quot; } // Posts truncated for brevity ] } // Users truncated for brevity ] } } You can now add more fields, and compose more queries together!","keywords":"","version":"Next"},{"title":"Launch","type":0,"sectionRef":"#","url":"/docs/getting_started/launch/","content":"Launch Now, run the following command to start the server with the full path to the file that you created earlier. graphqlymljson tailcall start ./jsonplaceholder.graphql If the command succeeds, you should see logs like the following below. üöÄ Tailcall launched at [0.0.0.0:8000] üåç Playground: http://0.0.0.0:8000 The server starts with the schema provided and prints out a load of meta information. We will cover those in detail in a bit. For now, open the playground URL in a new tab in your browser and try it out for yourself!","keywords":"","version":"Next"},{"title":"Client Tuning","type":0,"sectionRef":"#","url":"/docs/guides/client-tuning/","content":"","keywords":"","version":"Next"},{"title":"HTTP (Hypertext Transfer Protocol)‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#http-hypertext-transfer-protocol","content":" HTTP, the most widely used protocol for communication between clients and servers, carries your request to the server and then brings back the data to your client. TCP forms the foundation of HTTP.  ","version":"Next","tagName":"h3"},{"title":"HTTP Versions: 1.x, 2, and 3‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#http-versions-1x-2-and-3","content":" Each version has enhanced HTTP's flexibility and performance.  HTTP/1.x: Creates a separate TCP connection for each HTTP request (or reuses one sequentially).HTTP/2: Introduces multiplexing to allow concurrent sending of requests and responses over a single TCP connection, enhancing performance.HTTP/3: Employs QUIC instead of TCP, further reducing connection setup time and improving packet loss and network change handling.  note The server determines the HTTP version. Thus, if the server supports HTTP/1, the client cannot make an HTTP/2 request, even if compatible. If the client supports HTTP/1, the server should, according to the specification, downgrade to serve the request over HTTP/1.  ","version":"Next","tagName":"h3"},{"title":"TCP (Transmission Control Protocol)‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#tcp-transmission-control-protocol","content":" TCP ensures the data sent and received over the internet reaches its destination and in order.  TCP, like dialing a number before talking on the phone, establishes a connection between the client and server before exchanging data using HTTP. This guide will show how to tune Tailcall's HTTP client to enhance this connection's performance. Learn more about TCP in detail here.  ","version":"Next","tagName":"h3"},{"title":"QUIC (Quick UDP Internet Connections)‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#quic-quick-udp-internet-connections","content":" Developed by Google, QUIC aims to make web communications faster and more efficient than TCP. It reduces connection establishment time, handles packet loss better, and supports multiplexed streams over a single connection, preventing a slow request from holding up others. HTTP/3 uses QUIC. Learn more about QUIC in detail here.  ","version":"Next","tagName":"h3"},{"title":"Why Managing Connections is Important?‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#why-managing-connections-is-important","content":" Performance Overhead: Establishing TCP connections with HTTP/1.x consumes time due to the complete TCP handshake for each new connection. This process adds latency and increases system resources. Limited Ports on Client Side: A unique combination of an IP address and a port number is necessary for each TCP connection from a client. With each new connection, the IP remains the same because the client is the same, but a new port gets used. The number of available ports on a machine is 65535. These ports get shared among all processes, and not all are available for use. Excessive creation of new connections can lead to port exhaustion on the client side, preventing new connections and causing system failures across running processes. tip Use lsof and netstat commands to check the ports to process mapping.  Connection pooling mitigates these issues by reusing existing connections for requests, reducing connection establishment frequency (and thus handshake overhead) and conserving client-side ports. This approach enhances application performance by minimizing the resources and time spent on managing connections.  ","version":"Next","tagName":"h3"},{"title":"Tuning HTTP Client‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#tuning-http-client","content":" Tailcall uses connection pooling by default and sets up with default tuning suitable for most use cases. You might need to further tune the HTTP client to improve your application's performance. Tailcall DSL provides an operator named @upstream for this purpose.  note Connection pooling optimizes HTTP/1. Since HTTP/2 and HTTP/3 support multiplexing, pooling enabled does not noticeably affect performance.  When using HTTP/1.x, tune the connection pool with the following parameters:  ","version":"Next","tagName":"h2"},{"title":"poolMaxIdlePerHost‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#poolmaxidleperhost","content":" poolMaxIdlePerHost specifies the allowed number of idle connections per host, defaulting to 60. Example:  schema @upstream( poolMaxIdlePerHost: 60 ) { query: Query }   Too idle connections can unnecessarily consume memory and ports, while too few might cause delays as new connections need frequent establishment. poolMaxIdlePerHost ensures judicious use of network and memory resources, avoiding wastage on seldom-used connections.  For applications connecting to hosts, set this value lower to keep connections available for other hosts. Conversely, if you have hosts and all requests must resolve through them, maintain a higher value for this setting.  ","version":"Next","tagName":"h3"},{"title":"tcpKeepAlive‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#tcpkeepalive","content":" tcpKeepAlive keeps TCP connections alive for a duration, during inactivity, by periodically sending packets to the server to check if the connection remains open. In connection pooling, tcpKeepAlive maintains reusable connections in a ready-to-use state. This setting is useful for long-lived connections, preventing -lived connections, preventing the client from using a connection the server has closed due to inactivity. Without tcpKeepAlive, connections in the pool might get dropped by the server or intermediate network devices (like firewalls or load balancers). When your client tries to use such a dropped connection, it would fail, causing delays and errors. Keeping connections alive and monitored means you can efficiently reuse them, reducing the overhead of establishing new connections frequently.  Tailcall provides a parameter named tcpKeepAlive for the upstream which defaults to 5 seconds. Example: schema  @upstream ( tcpKeepAlive: 300 ) { query: Query }   ","version":"Next","tagName":"h3"},{"title":"connectTimeout‚Äã","type":1,"pageTitle":"Client Tuning","url":"/docs/guides/client-tuning/#connecttimeout","content":" connectTimeout specifically applies to the phase where your client attempts to establish a connection with the server. When making a connection request, the client tries to resolve the DNS, complete the SSL handshake, and establish a TCP connection. In environments where pods are frequently created and destroyed, maintaining a low connectTimeout is crucial to avoid unnecessary delays. In systems using connection pooling, the system aborts the attempt if it cannot establish a connection within the connectTimeout period. This approach prevents indefinite waiting for a connection to establish, which could cause delays and timeouts.  Tailcall offers a connectTimeout parameter to set the connection timeout in seconds for the HTTP client, defaulting to 60 seconds. Example:  schema @upstream( connectTimeout: 10 ) { query: Query }   In summary, maximizing HTTP client performance requires understanding the underlying protocols and configuring client settings through testing. This ensures efficient, robust, and high-performing client-server communication, crucial for the smooth operation of modern web applications. ","version":"Next","tagName":"h3"},{"title":"CLI","type":0,"sectionRef":"#","url":"/docs/guides/cli/","content":"","keywords":"","version":"Next"},{"title":"check‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#check","content":" The check command validates a composition spec. Notably, this command can detect potential N+1 issues. To use the check command, follow this format:  tailcall check [options] &lt;file&gt;...   The check command offers options that control settings such as the display of the generated schema, n + 1 issues etc.  ","version":"Next","tagName":"h2"},{"title":"--n-plus-one-queries‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#--n-plus-one-queries","content":" This flag triggers the detection of N+1 issues.  Type: BooleanDefault: false  tailcall check --n-plus-one-queries &lt;file&gt;...   ","version":"Next","tagName":"h3"},{"title":"--schema‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#--schema","content":" This option enables the display of the schema of the composition spec.  Type: BooleanDefault: false  tailcall check --schema &lt;file1&gt; &lt;file2&gt; ... &lt;fileN&gt;   The check command allows for files. Specify each file path, separated by a space, after the options.  Example:  tailcall check --schema ./path/to/file1.graphql ./path/to/file2.graphql   ","version":"Next","tagName":"h3"},{"title":"compose‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#compose","content":" The compose merges configuration files into one. To use the compose command, follow this format:  Example:  tailcall compose ./path/to/file1.graphql ./path/to/file2.graphql   ","version":"Next","tagName":"h2"},{"title":"--format‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#--format","content":" This specifies the format of the desired composed file. It accepts gql or graphql,yml or yaml, json . Default is json.  tailcall compose ./path/to/file1.graphql ./path/to/file2.graphql --format gql   ","version":"Next","tagName":"h3"},{"title":"start‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#start","content":" The start command launches the TailCall Server, acting as a GraphQL proxy with specific configurations. The server can publish GraphQL configurations.  To start the server, use the following command:  tailcall start &lt;file1&gt; &lt;file2&gt; ... &lt;fileN&gt; &lt;http_path1&gt; &lt;http_path2&gt; .. &lt;http_pathN&gt;   The start command allows for files and supports loading configurations over HTTP. You can mix file system paths with HTTP paths. Specify each path, separated by a space, after the options.  Example:  tailcall start ./path/to/file1.graphql ./path/to/file2.graphql http://example.com/file2.graphql   ","version":"Next","tagName":"h2"},{"title":"init‚Äã","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#init","content":" The init command bootstraps a new TailCall project. It creates the necessary GraphQL schema files in the provided file path.  tailcall init &lt;file_path&gt;   This command prompts for file creation and configuration, creating a .tailcallrc.graphql file by default. ","version":"Next","tagName":"h2"},{"title":"Environment Variables","type":0,"sectionRef":"#","url":"/docs/guides/environment-variables/","content":"","keywords":"","version":"Next"},{"title":"Need for Environment Variables‚Äã","type":1,"pageTitle":"Environment Variables","url":"/docs/guides/environment-variables/#need-for-environment-variables","content":" Applications rely on external tools, authentication methods, and configurations. For proper functioning, our code needs to access these values.  Consider a scenario of JWT authentication. When signing tokens for our users, we need:  Expiry time: The duration after which the token expires.Secret key: The key for encrypting the token.Issuer: The token issuer, often the organization's name.  There are two ways to manage this:  Hardcode the values in our code: This approach, while simple, poses a massive security risk by exposing sensitive information and requires code changes and application redeployment for updates. Store the values in environment variables: Storing sensitive values in the OS of the server running your application allows runtime access without code modifications, keeping sensitive information secure and simplifying value changes.  ","version":"Next","tagName":"h2"},{"title":"Environment Variables‚Äã","type":1,"pageTitle":"Environment Variables","url":"/docs/guides/environment-variables/#environment-variables","content":" With Tailcall, you can seamlessly integrate environment variables into your GraphQL schema. Tailcall supports this through a env Context variable. All operators share this Context, allowing you to resolve values in your schema.  Example schema:  type Query { users: [User]! @http(baseUrl: &quot;https://jsonplaceholder.typicode.com&quot;, path: &quot;/users&quot;) }   Here, we fetch a list of users from the JSONPlaceholder API. The users field will contain the fetched value at runtime. This works fine, but what if we want to change the API endpoint? We would need to update the code and redeploy the application, which is cumbersome.  We can address this issue using environment variables. Replace the API endpoint with an environment variable, allowing us to change the variable's value without altering our codebase.  type Query { users: [User]! @http(baseUrl: &quot;{{env.API_ENDPOINT}}&quot;, path: &quot;/users&quot;) }   Here, you must set API_ENDPOINT as an environment variable on the device running your server. Upon startup, the server retrieves this value and makes it accessible through the env Context variable.  This approach allows us to change the API endpoint without modifying our codebase. For instance, we might use different API endpoints for development (stage-api.example.com) and production (api.example.com) environments.  Remember, environment variables are not limited to the baseUrl or @http operator. You can use them throughout your schema, as a Mustache template handles their evaluation.  Here's another example, using an environment variable in the headers of @grpc:  type Query { users: [User] @grpc( service: &quot;UserService&quot; method: &quot;ListUsers&quot; protoPath: &quot;./proto/user_service.proto&quot; baseURL: &quot;https://grpc-server.example.com&quot; headers: [{key: &quot;X-API-KEY&quot;, value: &quot;{{env.API_KEY}}&quot;}] ) }   ","version":"Next","tagName":"h2"},{"title":"Security Aspects and Best Practices‚Äã","type":1,"pageTitle":"Environment Variables","url":"/docs/guides/environment-variables/#security-aspects-and-best-practices","content":" Environment variables help reduce security risks, but it's crucial to understand that they do not remove these risks entirely because the values are in plain text. Even if configuration values are not always highly sensitive, there is still a potential for compromising secrets. To ensure your secrets remain secure, consider the following tips:  Use a .env file: It's a common practice to create a .env file in your project's root directory for storing all environment variables. Avoid committing this file to your version control system; instead, add it to .gitignore to prevent public exposure of your secrets. For clarity and collaboration, maintain a .env.example file that enumerates all the necessary environment variables for your application, thereby guiding other developers on what variables they need to set. Within Tailcall (or in other environments), you can make use of this .env file by exporting its key-value pairs to your operating system. For example, if your .env file looks like this: API_ENDPOINT=https://jsonplaceholder.typicode.com Export it to your OS with: export $(cat .env | xargs) On Windows: Get-Content .env | Foreach-Object { [System.Environment]::SetEnvironmentVariable($_.Split(&quot;=&quot;)[0], $_.Split(&quot;=&quot;)[1], &quot;User&quot;) } After this, you can access API_ENDPOINT in your codebase. Use Kubernetes Secrets: When deploying your application with Kubernetes, use its Secrets feature to manage environment variables. This approach ensures your secrets remain private and are not embedded in your codebase, while also making it easier to update values as necessary. Store Secrets Through Cloud Provider GUIs: For deployments using a cloud provider, use their GUI for environment variable management. These interfaces are intuitive and practical for containerized applications that automatically scale.  Following these practices ensures effective and secure management of your environment variables. ","version":"Next","tagName":"h2"},{"title":"Configuration","type":0,"sectionRef":"#","url":"/docs/getting_started/configuration/","content":"Configuration For our first example, we are going to compose a GraphQL schema from the REST APIs at https://jsonplaceholder.typicode.com, a free online REST API with some fake data. We will use the API at /users to get a list of users, and /users/:id/posts to get the posts for each user, and compose them into a single GraphQL schema. We can use the following formats to define our GraphQL schema: .graphql, .yml, .json. Create one of the following files and paste the contents into it. graphqlymljson jsonplaceholder.graphql schema # Specify server configuration: Start tailcall server at 0.0.0.0:8000 and enable GraphiQL playground @server(port: 8000, graphiql: true) # Specify a base url for all http requests @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query } type Query { # Specify the http path for the users query users: [User] @http(path: &quot;/users&quot;) } # Create a user type with the fields returned by the users api type User { id: Int! name: String! username: String! email: String! # Extend the user type with the posts field # Use the current user's id to construct the path posts: [Post] @http(path: &quot;/users/{{value.id}}/posts&quot;) } # Create a post type with the fields returned by the posts api type Post { id: Int! title: String! body: String! } The above file is a standard .graphQL file, with some minor additions such as @upstream and @http directives. Basically we specify the GraphQL schema and how to resolve that GraphQL schema in the same file, without having to write any code!","keywords":"","version":"Next"},{"title":"Http Cache","type":0,"sectionRef":"#","url":"/docs/guides/http-cache/","content":"","keywords":"","version":"Next"},{"title":"Understanding HTTP Caching‚Äã","type":1,"pageTitle":"Http Cache","url":"/docs/guides/http-cache/#understanding-http-caching","content":" HTTP Caching involves saving copies of HTTP responses to serve identical future requests directly from the cache, bypassing the need for new API calls. This reduces latency, conserves bandwidth, and alleviates the load on upstream services by utilizing a cache keyed by request URLs and headers.  By default, HTTP caching is turned off in Tailcall. Enabling it requires setting the httpCache parameter to true in the @upstream configuration. Tailcall employs a in-memory Least_Recently_Used (LRU) cache mechanism to manage stored responses, adhering to upstream-provided caching directives like Cache-Control to optimize the caching process and minimize redundant upstream API requests.  ","version":"Next","tagName":"h3"},{"title":"Enabling HTTP Caching‚Äã","type":1,"pageTitle":"Http Cache","url":"/docs/guides/http-cache/#enabling-http-caching","content":" To activate HTTP caching, adjust the upstream configuration in Tailcall by setting httpCache to true, as shown in the following example:  schema @server(port: 4000) @upstream( baseURL: &quot;https://api.example.com&quot; httpCache: true ) { query: Query }   This configuration instructs Tailcall to cache responses from the designated upstream API.  ","version":"Next","tagName":"h3"},{"title":"Cache-Control headers in responses‚Äã","type":1,"pageTitle":"Http Cache","url":"/docs/guides/http-cache/#cache-control-headers-in-responses","content":" Enabling the cacheControlHeader setting in Tailcall ensures that Cache-Control headers are included in the responses returned to clients. When activated, Tailcall dynamically sets the max-age directive in the Cache-Control header to the minimum max-age value encountered in any of the responses from upstream services. This approach guarantees that the caching duration for the composite response is conservative, aligning with the shortest cache validity period provided by the upstream services. By default, this feature is disabled (false), meaning Tailcall will not modify or add Cache-Control headers unless explicitly instructed to do so. This setting is distinct from the general HTTP cache setting, which controls whether responses are cached internally by Tailcall; cacheControlHeader specifically controls the caching instructions sent to clients.  Here is how you can enable the cacheControlHeader setting within your Tailcall schema to apply these caching instructions:  schema @server(cacheControlHeader: true) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"Best Practices for Enhancing REST API Performance with Tailcall‚Äã","type":1,"pageTitle":"Http Cache","url":"/docs/guides/http-cache/#best-practices-for-enhancing-rest-api-performance-with-tailcall","content":" The combination of httpCache and cacheControlHeader provides a comprehensive caching solution. While httpCache focuses on internal caching to reduce the impact of high latency and frequent requests, cacheControlHeader manages client-side caching policies, ensuring an optimal balance between performance, data freshness, and efficient resource use.  These caching primitives are beneficial for REST APIs that are latency-sensitive, have a high rate of request repetition, or come with explicit caching headers indicating cacheable responses. Together, they tackle the common challenges of optimizing REST API performance by minimizing unnecessary network traffic and server load while ensuring response accuracy.  To further enhance the performance of any API with Tailcall, integrating the @cache directive offers protocol agnostic control over caching at the field level within a GraphQL schema. ","version":"Next","tagName":"h3"},{"title":"Logging","type":0,"sectionRef":"#","url":"/docs/guides/logging/","content":"","keywords":"","version":"Next"},{"title":"error‚Äã","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#error","content":" This is the highest severity level. It indicates a critical issue that may lead to the failure of the program or a part of it.  TAILCALL_LOG_LEVEL=error tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=error tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"warn‚Äã","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#warn","content":" This log level signifies potential issues or warnings that do not necessarily result in immediate failure but may require attention.  TAILCALL_LOG_LEVEL=warn tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=warn tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"info‚Äã","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#info","content":" This level offers general information about the program's execution, providing insights into its state and activities.  TAILCALL_LOG_LEVEL=info tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=info tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"debug‚Äã","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#debug","content":" The debug log level is useful for developers during the debugging process, providing detailed information about the program's internal workings.  TAILCALL_LOG_LEVEL=debug tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=debug tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"trace‚Äã","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#trace","content":" The trace log level is the most detailed logging level, used for fine-grained debugging. This level provides exhaustive details about the program's execution flow.  TAILCALL_LOG_LEVEL=trace tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=trace tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"off‚Äã","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#off","content":" This level serves as a special indicator for generating no logs, allowing the option to disable logging entirely.  TAILCALL_LOG_LEVEL=off tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=off tailcall &lt;COMMAND&gt;   info The default log level is info.  Log levels are hierarchical, meaning if you set the log level to a specific level, it includes all the levels above it. For example, setting the log level to info will include logs at the info, warn, and error levels, but exclude debug and trace logs.    info You can specify log levels in either uppercase or lowercase; both yield the same result. For example, TAILCALL_LOG_LEVEL=DEBUG and TAILCALL_LOG_LEVEL=debug are same. ","version":"Next","tagName":"h3"},{"title":"Context","type":0,"sectionRef":"#","url":"/docs/guides/context/","content":"","keywords":"","version":"Next"},{"title":"Context in Tailcall‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#context-in-tailcall","content":" In Tailcall, as in all GraphQL implementations, every Operator can access Context. Operators use Context to store and retrieve data necessary for shared operations.  You can describe the Context with the following Typescript interface:  interface Context { args: Map&lt;string, Json&gt; value: Json parent: Context env: Map&lt;string, string&gt; headers: Map&lt;string, string&gt; }   ","version":"Next","tagName":"h2"},{"title":"args‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#args","content":" These arguments pass to the current query, allowing access to the query's arguments. For example,  type Query { user(id: ID!): User @http(path: &quot;/users/{{args.id}}&quot;) }   In this example, you use args.id to access the id argument passed to the user query.  ","version":"Next","tagName":"h3"},{"title":"value‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#value","content":" This field represents the value of the current node. For instance,  type Post { id: ID! title: String! body: String! comments: [Comment] @http(path: &quot;/posts/{{value.id}}/comments&quot;) }   Here, value.id provides access to the id field of the Post type.  ","version":"Next","tagName":"h3"},{"title":"parent‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#parent","content":" This field indicates the context of the parent node.  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users&quot;, query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}], matchPath: [&quot;id&quot;], matchKey: &quot;userId&quot;) }   In this scenario, value.userId helps retrieve the userId information from the &quot;parent&quot; context of the Post type, effectively extracting a list of userId fields from the Post types. Consider value as a container holding the results of a post query, with userId as the specific key you want to extract.  ","version":"Next","tagName":"h3"},{"title":"env‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#env","content":" This field represents global environment variables for the server, set once when the server starts.  type Query { users: [User]! @http(baseUrl: &quot;{{env.API_ENDPOINT}}&quot;, path: &quot;/users&quot;) }   Here, env.API_ENDPOINT refers to an environment variable named API_ENDPOINT, defined in your server settings.  ","version":"Next","tagName":"h3"},{"title":"headers‚Äã","type":1,"pageTitle":"Context","url":"/docs/guides/context/#headers","content":" These headers come from the request received by the Tailcall server.  type Query { commentsForUser: [Comment] @http(path: &quot;/users/{{headers.userId}}/comments&quot;) }   Here, headers.userId refers to a header called userId that should be present in the context. The server can use this userId to fetch comments for the specified user. ","version":"Next","tagName":"h3"},{"title":"Watch Mode","type":0,"sectionRef":"#","url":"/docs/guides/watch-mode/","content":"","keywords":"","version":"Next"},{"title":"Use case‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#use-case","content":" Running a server in watch mode offers a lot of key benefits:  Real-time Feedback: Watch mode ensures that your server remains up-to-date with your code changes, instantly reflecting those changes and providing you with real-time feedback during development.Efficiency: Manually restarting the server each time you change code can be tedious and time-consuming. Watch mode automates this process, enhancing development efficiency.Debugging: It enables you to identify and resolve issues as they occur, reducing debugging time. With your server automatically restarting upon code changes, you detect errors earlier.  ","version":"Next","tagName":"h2"},{"title":"Using entr‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#using-entr","content":" It's a powerful file-watching utility that makes running a server in watch mode a breeze. Let's go through the steps for the installation process for different operating system :  ","version":"Next","tagName":"h2"},{"title":"Installation‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#installation","content":" Homebrew‚Äã  Open the Terminal, which you can find in the &quot;Utilities&quot; folder within the &quot;Applications&quot; folder. Install Homebrew if you haven't already. Run the following command in your Terminal: /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot; After installing Homebrew, proceed to install entr by executing the following command: brew install entr To verify the installation, run: entr --version   Upon successful installation, it will display the latest version of entr.  Windows Subsystem‚Äã  Install Windows Subsystem for Linux (WSL) on your Windows machine by following Microsoft's official documentation. After setting up WSL, open the Linux terminal by running: wsl -d &lt;DistributionName&gt; Replace &lt;DistributionName&gt; with the name of the Linux distribution that you have installed. Install entr within the Linux terminal using the package manager of your chosen Linux distribution. For example, on Ubuntu, you can use: sudo apt update sudo apt install entr Verify the installation by running: entr --version   A successful installation will display the latest version of entr.  apt-get‚Äã  On Linux, you can install entr using your distribution's package manager. For example, on Ubuntu, use: sudo apt update sudo apt install entr To verify the installation, run: entr --version   If you install it, it will show the latest version of the entr  ","version":"Next","tagName":"h3"},{"title":"Watch Mode‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#watch-mode","content":" To run your server in watch mode with entr, use the ls command to list the files you want to track. The general syntax is as follows:  ls *.graphql | entr -r tailcall start ./jsonplaceholder.graphql   This command uses entr to continuously track the jsonplaceholder.graphql file and when it changes, It runs the tailcall start command with the file as an argument  Detailing the above command as follows:  ls *.graphql : This part of the code lists the file or files you want to track for changes. In this case, it lists the file named &quot;jsonplaceholder.graphql&quot; within the &quot;examples&quot; directory. | : The pipe symbol ('|') takes the output of the preceding command (the file listing) and feeds it as input to the following command (entr). entr -r tc start ./jsonplaceholder.graphql : Whenever the file &quot;jsonplaceholder.graphql&quot; changes, this command executes.  entr is a command-line tool for running arbitrary commands whenever files change. It tracks the files specified in the previous command (ls ./jsonplaceholder.graphql) r : This flag instructs entr to persist in running the command through errors, ensuring continuous operation. tc start ./jsonplaceholder.graphql : This command runs upon detecting changes, executing tc start with the file path./jsonplaceholder.graphql as an argument  ","version":"Next","tagName":"h3"},{"title":"Some Best Practices‚Äã","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#some-best-practices","content":" To make the most of running a server in watch mode with entr, consider the following best practices:  Selective File Watching: Be selective about which files you track with entr. Watching unnecessary files can lead to increased CPU and memory usage. Focus on the essential files related to your project. Organize Your Project: Maintain a well-organized project structure to make it easier to identify which files need tracking. Clear Output: Clear the terminal output before running entr to have a clean workspace. Version Control: Ensure that your project is under version control (e.g., Git) to track changes and revert if necessary. Update entr: Ensure entr is always updated to the latest version for bug fixes and enhancements.  By following these best practices and using entr effectively, you can greatly improve your development workflow. Experiment with entr, adapt it to your project's specific requirements, and enjoy a smoother and more efficient development process. Happy coding! ","version":"Next","tagName":"h2"},{"title":"Operators","type":0,"sectionRef":"#","url":"/docs/operators/","content":"Operators Tailcall DSL builds on your existing GraphQL knowledge by allowing the addition of some custom operators. These operators provide powerful compile time guarantees to ensure your API composition is tight and robust. The system automatically generates highly optimized resolver logic for your types using the operator information. Here is a list of all the custom operators supported by Tailcall: Certainly! Here's the table with hyperlinks added back to the operator names: Operator\tDescription@addField\tSimplifies data structures and queries by adding, inlining, or flattening fields or nodes within the schema. @cache\tEnables caching for the query, field or type applied to. @const\tAllows embedding of a constant response within the schema. @graphQL\tResolves a field or node by a GraphQL API. @grpc\tResolves a field or node by a gRPC API. @http\tResolves a field or node by a REST API. @modify\tEnables changes to attributes of fields or nodes in the schema. @omit\tExcludes fields or nodes from the generated schema, making them inaccessible through the GraphQL API. @server\tProvides server configurations for behavior tuning and tailcall optimization in specific use-cases. @upstream\tControls aspects of the upstream server connection, including timeouts and keep-alive settings.","keywords":"","version":"Next"},{"title":"Tackling N + 1","type":0,"sectionRef":"#","url":"/docs/guides/n+1/","content":"","keywords":"","version":"Next"},{"title":"Scenario‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#scenario","content":" Consider we're developing a feature that involves consuming data from the JSON Placeholder API. The feature requires fetching posts and the details of the authors of these posts.  Here's an illustration of a typical implementation:  ","version":"Next","tagName":"h2"},{"title":"@addField","type":0,"sectionRef":"#","url":"/docs/operators/add-field/","content":"@addField The @addField operator simplifies data structures and queries by adding a field that inline or flattens a nested field or node within your schema. It modifies the schema and the data transformation process, making nested data more accessible and straightforward to present. For instance, consider a schema: schema { query: Query } type User @addField(name: &quot;street&quot;, path: [&quot;address&quot;, &quot;street&quot;]) { id: Int! name: String! username: String! email: String! phone: String website: String address: Address @modify(omit: true) } type Address { street: String! city: String! state: String! } type Query { user(id: Int!): User @http(path: &quot;/users/{{args.id}}&quot;) } Suppose we focus on the street field in Address. In this case, applying the @addField operator to the User type creates a street field within the User type. It uses a path argument to specify the sequence of fields from a declared field (address), leading to the Address field to add. We also can apply @modify(omit: true) to remove the address field from the schema, as the street field from Address is now directly accessible on the User type. Post application, the schema becomes: schema { query: Query } type User { id: Int! name: String! username: String! email: String! phone: String website: String street: String } type Query { user(id: Int): Post! } In the above example, since we added a @modify(omit: true) on the address field, the schema no longer includes the Address type. The @addField operator also take cares of nullablity of the fields. If any of the fields in the path is nullable, the resulting type will be nullable. @addField also supports indexing, allowing for the specification of an array index for inline inclusion. For instance, if a field posts is of type [Post], and the goal is to access the title of the first post, specify the path as [&quot;posts&quot;,&quot;0&quot;,&quot;title&quot;]. type User @addField(name: &quot;firstPostTitle&quot;, path: [&quot;posts&quot;, &quot;0&quot;, &quot;title&quot;]) { id: Int! name: String! username: String! email: String! phone: String website: String posts: Post @http(path: &quot;/users/{{value.id}}/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! } In conclusion, the @addField operator helps tidy up your schema and streamline data fetching by reducing query depth, promoting better performance and simplicity.","keywords":"","version":"Next"},{"title":"GraphQL on gRPC","type":0,"sectionRef":"#","url":"/docs/guides/grpc/","content":"","keywords":"","version":"Next"},{"title":"What is gRPC?‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#what-is-grpc","content":" This guide assumes a basic familiarity with gRPC. It is a high-performance framework created by Google for remote procedure calls (RPCs). Its key features include:  HTTP/2 Transport: Ensures efficient and fast data transfer.Protocol Buffers (Protobuf): Serves as a powerful interface description language.Efficiency: Offers binary serialization, reduces latency, and supports data streaming.  This combination of features makes gRPC ideal for microservices and distributed systems. If you need a more detailed understanding or are new to gRPC, we recommend visiting the official gRPC website for comprehensive documentation and resources.  Now, let's explore how gRPC can be integrated into our proxy gateway to enhance communication and data exchange in distributed systems.  ","version":"Next","tagName":"h2"},{"title":"gRPC upstream‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#grpc-upstream","content":" We need some gRPC service available to be able to execute requests from the Tailcall gateway. For pure example purposes, we will build some simple gRPC services.  ","version":"Next","tagName":"h2"},{"title":"Protobuf definition‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#protobuf-definition","content":" First, we need to create an example protobuf file that will define the structure of the data we want to transmit using gRPC. Here is the definition of NewsService that implements CRUD operations on news data that we'll put into the news.proto file.  syntax = &quot;proto3&quot;; import &quot;google/protobuf/empty.proto&quot;; package news; // Define message type for News with all its fields message News { int32 id = 1; string title = 2; string body = 3; string postImage = 4; } // Message with the id of a single news message NewsId { int32 id = 1; } // List of IDs of news to get multiple responses message MultipleNewsId { repeated NewsId ids = 1; } // List of all news message NewsList { repeated News news = 1; } // NewsService defines read and write operations for news items service NewsService { // GetAllNews retrieves all news items without any arguments rpc GetAllNews (google.protobuf.Empty) returns (NewsList) {} // GetNews fetches a single news item by its ID rpc GetNews (NewsId) returns (News) {} // GetMultipleNews retrieves multiple news items based on their IDs rpc GetMultipleNews (MultipleNewsId) returns (NewsList) {} }   ","version":"Next","tagName":"h3"},{"title":"Implement gRPC service‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#implement-grpc-service","content":" Now having the protobuf file you can write a server that implements NewsService at any language you want that supports gRPC. Tailcall organization has a sample node.js service inside this repo that you can pull to your local machine. To spin up the sample service run inside the repo and wait for logs about the service running.  npm i npm start   ","version":"Next","tagName":"h3"},{"title":"Tailcall config‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#tailcall-config","content":" Now when we have a running gRPC service we're going to write Tailcall's config to make the integration. To do this we need to specify GraphQL types corresponding to gRPC types we have defined in the protobuf file. Let's create a new file grpc.graphql file with the following content:  # The GraphQL representation for News message type type News { id: Int title: String body: String postImage: String } # Input type that is used to fetch news data by its id input NewsInput { id: Int } # Resolves multiple news entries type NewsData { news: [News]! }   Now when we have corresponding types in schema we want to define GraphQL Query that specifies the operation we can execute onto news. We can extend our config with the next Query:  type Query { # Get all news i.e. NewsService.GetAllNews news: NewsData! # Get single news by id i.e. NewsService.GetNews newsById(news: NewsInput!): News! }   Also, let's specify options for Tailcall's ingress and egress at the beginning of the config using @server and @upstream operators.  schema @server(port: 8000, graphiql: true) @upstream(baseURL: &quot;http://localhost:50051&quot;, httpCache: true) { query: Query }   To specify the protobuf file to read types from, use the @link operator with the type Protobuf on the schema. id is an important part of the definition that will be used by the @grpc operator later  schema @link(id: &quot;news&quot;, src: &quot;./news.proto&quot;, type: Protobuf)   Now you can connect GraphQL types to gRPC types. To do this you may want to explore more about @grpc operator. Its usage is pretty straightforward and requires you to specify the path to a method that should be used to make a call. The method name will start with the package name, followed by the service name and the method name, all separated by the . symbol.  If you need to provide any input to the gRPC method call you can specify it with the body option that allows you to specify a Mustache template and therefore it could use any input data like args and value to construct the body request. The body value is specified in the JSON format if you need to create the input manually and cannot use args input.  type Query { news: NewsData! @grpc(method: &quot;news.news.NewsService.GetAllNews&quot;) newsById(news: NewsInput!): News! @grpc(service: &quot;news.news.NewsService.GetNews&quot;, body: &quot;{{args.news}}&quot;) }   Wrapping up the whole result config that may look like this:  # file: app.graphql schema @server(port: 8000, graphiql: true) @upstream(baseURL: &quot;http://localhost:50051&quot;, httpCache: true) @link(id: &quot;news&quot;, src: &quot;./news.proto&quot;, type: Protobuf) { query: Query } type Query { news: NewsData! @grpc(method: &quot;news.news.NewsService.GetAllNews&quot;) newsById(news: NewsInput!): News! @grpc(method: &quot;news.news.NewsService.GetNews&quot;, body: &quot;{{args.news}}&quot;) } type News { id: Int title: String body: String postImage: String } input NewsInput { id: Int } type NewsData { news: [News]! }   Start the server by pointing it to the config.  tailcall start ./app.graphql   And now you can go to the page http://127.0.0.1:8000/graphql and execute some GraphQL queries e.g.:  { news { news { id title body } } }   Or  { newsById(news: {id: 2}) { id title body } }   ","version":"Next","tagName":"h2"},{"title":"Batching‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#batching","content":" Another important feature of the @grpc operator is that it allows you to implement request batching for remote data almost effortlessly as soon as you have gRPC methods that resolve multiple responses for multiple inputs in a single request.  In our protobuf example file, we have a method called GetMultipleNews that we can use. To enable batching we need to enable @upstream.batch option first and specify groupBy option for the @grpc operator.  schema @server(port: 8000, graphiql: true) @upstream(baseURL: &quot;http://localhost:50051&quot;, httpCache: true, batch: {delay: 10}) @link(id: &quot;news&quot;, src: &quot;./news.proto&quot;, type: Protobuf) { query: Query } type Query { newsById(news: NewsInput!): News! @grpc( method: &quot;news.NewsService.GetNews&quot; body: &quot;{{args.news}}&quot; groupBy: [&quot;news&quot;, &quot;id&quot;] ) }   Restart the Tailcall server and make the query with multiple news separately, e.g.:  { n1: newsById(news: {id: 1}) { id title body } n2: newsById(news: {id: 2}) { id title body } }   Those 2 requests will be executed inside a single request to the gRPC method GetMultipleNews  ","version":"Next","tagName":"h2"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#conclusion","content":" Well done on integrating a gRPC service with the Tailcall gateway! This tutorial has demonstrated the straightforward and efficient process, showcasing Tailcall's compatibility with advanced communication protocols like gRPC.  You can find this working example and test it by yourself by the next links:  node-grpc - example implementation for gRPC service in node.jsgRPC example config - Tailcall's config to integrate with gRPC service above  ","version":"Next","tagName":"h2"},{"title":"Key Takeaways‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#key-takeaways","content":" Simplicity of Integration: The integration of gRPC with Tailcall seamlessly enhances the overall capability of your system to handle high-performance and efficient data composition.Scalability and Performance: By leveraging the power of gRPC along with Tailcall, we've laid a foundation for building scalable and high-performing distributed systems.  ","version":"Next","tagName":"h3"},{"title":"Next Steps‚Äã","type":1,"pageTitle":"GraphQL on gRPC","url":"/docs/guides/grpc/#next-steps","content":" With the basics in place, we encourage you to explore further:  Dive Deeper: Tailcall gateway offers a lot of other features and configurations that you can utilize. Dive deeper into our documentation to explore more advanced settings and customization options.Explore Other Guides: Our documentation includes a variety of guides and tutorials that can help you leverage the full potential of Tailcall in different scenarios. Whether it's adding security layers, load balancing, or detailed logging, there's a lot more to explore. ","version":"Next","tagName":"h3"},{"title":"Fetching Posts‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#fetching-posts","content":" First, we send a request to retrieve all posts:  curl https://jsonplaceholder.typicode.com/posts   The above request fetches a list of posts from the API, each of which includes a userId field indicating the author of the post.  ","version":"Next","tagName":"h3"},{"title":"Fetching Users‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#fetching-users","content":" Then, for each post, we need to get the author's details. A request for a specific user might look like this:  curl https://jsonplaceholder.typicode.com/users/1   If we received 100 posts from our first request, we would then make 100 more requests to get each post's author details, resulting in a total of 101 requests.  The N+1 problem, illustrated with the JSON Placeholder API, occurs when one API request triggers more. For example, fetching 100 posts then requesting each post's author details results in 101 requests.  info In real-world applications featuring thousands of posts and users, the problem becomes more severe. Each user request can generate hundreds or thousands of server requests, straining server resources and resulting in slower response times, increased server costs, and a diminished user experience. This issue may even cause server downtime due to the overwhelming number of requests, affecting service availability. Thus, addressing the N+1 problem during the design and development phases of applications that make extensive API requests is essential. We will explore solutions to this issue in the following sections.  ","version":"Next","tagName":"h3"},{"title":"Using the CLI‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#using-the-cli","content":" The TailCall CLI serves as a powerful tool for developers, identifying N+1 issues in GraphQL applications even before making any requests or publishing configurations in production. This proactive approach enables the mitigation of potential issues from the development stage.  Before diving into the usage, ensure you have familiarized yourself with the basics of the TailCall CLI. If you haven't already, please refer to the Installation guide, which will walk you through the setup process and help you understand the key commands.  ","version":"Next","tagName":"h2"},{"title":"Jsonplaceholder Example‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#jsonplaceholder-example","content":" Here is a sample .graphql file that we'll be examining:  schema @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{value.userId}}&quot;) }   This schema enables clients to retrieve a list of posts, each including its associated user data. Yet, in its present form, it's affected by the N+1 problem: fetching each post necessitates a separate request for its associated user data.  The following section will show how to detect this issue with the TailCall CLI.  ","version":"Next","tagName":"h3"},{"title":"Running the TailCall CLI‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#running-the-tailcall-cli","content":" With the check command, TailCall CLI can assist you in identifying potential N+1 issues in a GraphQL file:  tailcall check ./jsonplaceholder.graphql No errors found. N + 1: 1   The N + 1: 1 line tells you that the TailCall CLI has detected one potential N+1 issue.  For a deeper understanding of these issues, you can use the --n-plus-one-queries parameter:  tailcall check ./jsonplaceholder.graphql --n-plus-one-queries No errors found. N + 1: 1 query { posts { user } }   This parameter uncovers the minimal query that can trigger an N+1 problem. In the above case, query { posts { user } }, represents the minimal query that could lead to an N+1 problem. It illustrates that within the posts query, each post is triggering an extra request to fetch its associated user data.  ","version":"Next","tagName":"h3"},{"title":"Solving Using Batching‚Äã","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#solving-using-batching","content":" It's an effective technique to group similar requests into one, greatly reducing the number of server calls. The TailCall CLI provides this capability to address the typical N+1 issue that arises in GraphQL.  To tap into this feature, edit the @http directive on Post.user in your GraphQL schema as follows:  type Post { id: Int! userId: Int! title: String! body: String! user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}] groupBy: [&quot;id&quot;] ) }   The described changes introduce significant tweaks to the @http directive and incorporate the @groupBy operator:  query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}]: In this configuration, the TailCall CLI generates a URL that aligns the user id with the userId from the parent Post. For a batch of posts, the CLI compiles a single URL, such as /users?id=1&amp;id=2&amp;id=3...id=10, consolidating the requests into one. groupBy: [&quot;id&quot;]: This parameter instructs the system to convert the list of responses into a map internally, using the user's id as the unique key. In essence, it allows the system to differentiate each user value in the response list.  By using this approach, you can reduce the number of requests from 101 (for 100 posts plus one initial request for the post list) down to 2. This significant optimization effectively handles the N+1 problem, thereby enhancing your application's efficiency and user experience. ","version":"Next","tagName":"h2"},{"title":"@const","type":0,"sectionRef":"#","url":"/docs/operators/const/","content":"@const The @const directive in GraphQL is a powerful tool for embedding data directly into your schema, offering two primary functionalities: Static Response: This feature allows for the inclusion of a constant response within the schema definition itself. It is useful for scenarios where the response is static and unchanging. e.g: schema { query: Query } type Query { user: User @const(data: {name: &quot;John&quot;, age: 12}) } type User { name: String age: Int } The const operator also checks the provided value at compile time to ensure it matches the field's schema. If not, the console displays a descriptive error message. Dynamic Template: Beyond static data embedding, the @const directive extends its utility to support dynamic data injection through Mustache template syntax. This feature enables the use of placeholders within the constant data, which are then dynamically replaced with actual values at runtime. It supports both scalar values and complex objects, including lists and nested objects, offering flexibility in tailoring responses to specific needs. e.g: schema { query: Query } type Query { user: User @const(data: {name: &quot;John&quot;, workEmail: &quot;john@xyz.com&quot;, personalEmail: &quot;john@xyz.com&quot;}) } type User { name: String age: Int personalEmail: String workEmail: String emails: Emails @const(data: {emails: {workEmail: &quot;{{value.workEmail}}&quot;, personalEmail: &quot;{{value.personalEmail}}&quot;}}) } type Emails { workEmail: String personalEmail: String } In this example, the @const directive dynamically generate an Emails object based on the provided template data. The placeholders within the template ({{value.workEmail}} and {{value.personalEmail}}) gets replaced with the actual values specified in the User type, allowing for dynamic content generation while still adhering to the schema's structure.","keywords":"","version":"Next"},{"title":"@cache","type":0,"sectionRef":"#","url":"/docs/operators/cache/","content":"","keywords":"","version":"Next"},{"title":"maxAge‚Äã","type":1,"pageTitle":"@cache","url":"/docs/operators/cache/#maxage","content":" @cache(maxAge: Int)   This parameter is a non-zero unsigned integer specifying the duration, in milliseconds, that retains the cached value.  ","version":"Next","tagName":"h2"},{"title":"Usage‚Äã","type":1,"pageTitle":"@cache","url":"/docs/operators/cache/#usage","content":" Consider the following GraphQL schema example:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int title: String userId: Int @cache(maxAge: 100) user: User @http(path: &quot;/user/{{value.userId}}&quot;) @cache(maxAge: 200) } type User { id: Int name: String email: String }   In this configuration, the system caches the result of the user field due to its association with an HTTP resolver. But it does not cache the values of userId and title because they lack individual resolvers; the resolver for the posts field retrieves their values, employing the @http(path: &quot;/posts&quot;) directive.  Applying the @cache directive at the type level affects all fields within that type. For example:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post @cache(maxAge: 100) { id: Int title: String userId: Int user: User @http(path: &quot;/user/{{value.userId}}&quot;) } type User { id: Int name: String email: String }   You can simplify this configuration to show that applying the @cache directive to a type means every field within that type inherits it:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int @cache(maxAge: 100) title: String @cache(maxAge: 100) userId: Int @cache(maxAge: 100) user: User @http(path: &quot;/user/{{value.userId}}&quot;) @cache(maxAge: 100) } type User { id: Int name: String email: String }   Since the @cache directive does not affect fields without resolvers, the effective configuration can be further reduced as follows:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int title: String userId: Int user: User @http(path: &quot;/user/{{value.userId}}&quot;) @cache(maxAge: 100) } type User { id: Int name: String email: String }   When applying the @cache directive both at the type level and on individual fields within that type, the field-level directive takes precedence:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post @cache(maxAge: 200) { id: Int title: String userId: Int user: User @http(path: &quot;/user/{{value.userId}}&quot;) @cache(maxAge: 100) } type User { id: Int name: String email: String }   Thus, in the configuration above, while all fields inherit the @cache(maxAge: 200) directive at the type level, the user field's explicit @cache(maxAge: 100) directive takes precedence.  ","version":"Next","tagName":"h2"},{"title":"Cache Key‚Äã","type":1,"pageTitle":"@cache","url":"/docs/operators/cache/#cache-key","content":" The caching mechanism generates a hash based on information related to the applied query to serve as the cache key for the corresponding value.  For instance, the system caches the user field in the following configuration, using the hash of the interpolated string &quot;/user/{{value.userId}}&quot; as the cache key. For example, if Post.userId equals 1, the system generates the cache key by hashing the string &quot;/users/1&quot;. ","version":"Next","tagName":"h2"},{"title":"@grpc","type":0,"sectionRef":"#","url":"/docs/operators/grpc/","content":"","keywords":"","version":"Next"},{"title":"Understanding the Proto File Structure‚Äã","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#understanding-the-proto-file-structure","content":" The .proto file delineates the structure and methods of the gRPC service. A simplified example of such a file is as follows:  syntax = &quot;proto3&quot;; package users; service UserService { rpc ListUsers (UserListRequest) returns (UserListReply) {} rpc GetUser (UserGetRequest) returns (UserGetReply) {} } message UserListRequest { // Definitions of request parameters } message UserListReply { // Structure of the reply } message UserGetRequest { // Definitions of request parameters } message UserGetReply { // Structure of the reply }   important It is mandatory to have a package name in a protobuf file.  Linking this file within a GraphQL schema is facilitated by the @link directive, as shown below:  schema @link(src: &quot;./users.proto&quot;, type: Protobuf) { query: Query }   Tailcall automatically resolves the protobuf file for any methods referenced in the @grpc directive.  ","version":"Next","tagName":"h2"},{"title":"Directive Parameters‚Äã","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#directive-parameters","content":" method‚Äã  This parameter specifies the gRPC service and method to be invoked, formatted as &lt;package&gt;.&lt;service&gt;.&lt;method&gt;:  type Query { users: [User] @grpc(method: &quot;proto.users.UserService.ListUsers&quot;) }   baseURL‚Äã  Defines the base URL for the gRPC API. If not specified, the URL set in the @upstream directive is used by default:  type Query { users: [User] @grpc(baseURL: &quot;https://grpc-server.example.com&quot;, method: &quot;proto.users.UserService.ListUsers&quot;) }   body‚Äã  This parameter outlines the arguments for the gRPC call, allowing for both static and dynamic inputs:  type UserInput { id: ID } type Query { user(id: UserInput!): User @grpc(body: &quot;{{args.id}}&quot;, method: &quot;proto.users.UserService.GetUser&quot;) }   headers‚Äã  Custom headers for the gRPC request can be defined, facilitating the transmission of authentication tokens or other contextual data:  type Query { users: [User] @grpc(headers: [{key: &quot;X-CUSTOM-HEADER&quot;, value: &quot;custom-value&quot;}], method: &quot;proto.users.UserService.ListUsers&quot;) }   groupBy‚Äã  This argument is employed to optimize batch requests by grouping them based on specified response keys, enhancing performance in scenarios requiring multiple, similar requests:  type Query { users(id: UserInput!): [User] @grpc(groupBy: [&quot;id&quot;], method: &quot;proto.users.UserService.ListUsers&quot;, baseURL: &quot;https://grpc-server.example.com&quot;) }   info Read about n + 1 to learn how to use the groupBy setting. ","version":"Next","tagName":"h3"},{"title":"@graphQL","type":0,"sectionRef":"#","url":"/docs/operators/graphql/","content":"","keywords":"","version":"Next"},{"title":"@graphQL‚Äã","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#graphql","content":" The @graphQL operator allows to specify GraphQL API server request to fetch data from.  type Query { users: [User] @graphQL(name: &quot;userList&quot;) }   The @graphQL operator facilitates fetching a list of users from the GraphQL API upstream. The name argument specifies the root field's name on the upstream server. The upcoming request to the Tailcall server determines the User type's inner fields for the request. Depending on the operation type within which one finds the @graphQL operator, the Tailcall config determines the query's operation type.  For the next request with the config above:  query { users { id name } }   Tailcall will request the next query for the upstream:  query { userList { id name } }   ","version":"Next","tagName":"h2"},{"title":"baseURL‚Äã","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#baseurl","content":" This refers to the base URL of the API. If not specified, the default base URL is the one specified in the @upstream operator.  type Query { users: [User] @graphQL(name: &quot;users&quot;, baseURL: &quot;https://graphqlzero.almansi.me/api&quot;) }   ","version":"Next","tagName":"h3"},{"title":"name‚Äã","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#name","content":" The root field's name on the upstream to request data from. For example:  type Query { users: [User] @graphQL(name: &quot;userList&quot;) }   When Tailcall receives a query for the users field, it will request a query for userList from the upstream.  ","version":"Next","tagName":"h3"},{"title":"args‚Äã","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#args","content":" Named arguments for the requested field. For example:  type Query { user: User @graphQL(name: &quot;user&quot;, args: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}]) }   Will request the next query from the upstream for the first user's name:  query { user(id: 1) { name } }   ","version":"Next","tagName":"h3"},{"title":"headers‚Äã","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#headers","content":" The headers parameter allows customizing the headers of the GraphQL request made by the @graphQL operator. Specifying a key-value map of header names and their values achieves this.  For instance:  type Mutation { users: User @graphQL(name: &quot;users&quot;, headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}]) }   In this example, a request to /users will include the HTTP header X-Server with the value Tailcall.  ","version":"Next","tagName":"h3"},{"title":"batch‚Äã","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#batch","content":" In case the upstream GraphQL server supports request batching, we can specify the batch argument to batch requests to a single upstream into a single batch request. For example:  schema @upstream(batch: {maxSize: 1000, delay: 10, headers: [&quot;X-Server&quot;, &quot;Authorization&quot;]}) { query: Query mutation: Mutation } type Query { users: [User] @graphQL(name: &quot;users&quot;, batch: true) posts: [Post] @graphQL(name: &quot;posts&quot;, batch: true) }   Make sure you have also specified batch settings to the @upstream and to the @graphQL operator. ","version":"Next","tagName":"h3"},{"title":"@modify","type":0,"sectionRef":"#","url":"/docs/operators/modify/","content":"","keywords":"","version":"Next"},{"title":"name‚Äã","type":1,"pageTitle":"@modify","url":"/docs/operators/modify/#name","content":" You can rename a field or a node in your GraphQL schema using the name argument in the @modify operator. This can be helpful when the field name in your underlying data source doesn't match the desired field name in your schema. For instance:  type User { id: Int! @modify(name: &quot;userId&quot;) }   @modify(name: &quot;userId&quot;) informs GraphQL to present the field known as id in the underlying data source as userId in your schema.  ","version":"Next","tagName":"h2"},{"title":"omit‚Äã","type":1,"pageTitle":"@modify","url":"/docs/operators/modify/#omit","content":" You can exclude a field or a node from your GraphQL schema using the omit argument in the @modify operator. This can be useful if you want to keep certain data hidden from the client. For instance:  type User { id: Int! @modify(omit: true) }   @modify(omit: true) instructs GraphQL to exclude the id field from the schema, making it inaccessible to the client.  tip @omit is a standalone operator and is an alias/shorthand for modify(omit: true) checkout documentation ","version":"Next","tagName":"h2"},{"title":"@omit","type":0,"sectionRef":"#","url":"/docs/operators/omit/","content":"","keywords":"","version":"Next"},{"title":"How it works‚Äã","type":1,"pageTitle":"@omit","url":"/docs/operators/omit/#how-it-works","content":" When applied to a field or node, the @omit operator instructs the Tailcall not to include that field or node in the schema. This means that clients cannot query or mutate data in those fields.  ","version":"Next","tagName":"h2"},{"title":"Example‚Äã","type":1,"pageTitle":"@omit","url":"/docs/operators/omit/#example","content":" Consider a scenario where you have a User type with an embedded Address type. If you want to exclude the Address type from the schema to simplify the API, you can use the @omit operator:  type Address { city: String street: String } type User { name: String address: Address @omit }   In this example, the address field will not be accessible or visible through the GraphQL API.  ","version":"Next","tagName":"h2"},{"title":"Comparison with modify‚Äã","type":1,"pageTitle":"@omit","url":"/docs/operators/omit/#comparison-with-modify","content":" The @omit operator and @modify(omit: true) essentially serve the same purpose in excluding fields from the schema, but they differ in syntax and flexibility. In fact, one can consider @omit as a shorthand or alias for the more verbose @modify(omit: true).  @omit offers a concise way to directly exclude a field or node without additional arguments. @modify(omit: true), as part of the broader @modify operator, provides more options, such as field renaming through the name argument. This makes it a more flexible choice when you need more than field exclusion.  For more details on the @modify operator and its capabilities, including omitting fields, see the @modify documentation. ","version":"Next","tagName":"h2"},{"title":"@http","type":0,"sectionRef":"#","url":"/docs/operators/http/","content":"","keywords":"","version":"Next"},{"title":"baseURL‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#baseurl","content":" Specifies the API's base URL. If unspecified, it defaults to the URL in the @upstream operator.  type Query { users: [User] @http(path: &quot;/users&quot;, baseURL: &quot;https://jsonplaceholder.typicode.com&quot;) }   ","version":"Next","tagName":"h2"},{"title":"path‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#path","content":" Refers to the API endpoint, for example, https://jsonplaceholder.typicode.com/users.  type Query { users: [User] @http(path: &quot;/users&quot;) }   If your API endpoint contains dynamic segments, you can substitute variables using Mustache templates. For example, to fetch a specific user, you can write the path as /users/{{args.id}}.  type Query { user(id: ID!): User @http(path: &quot;/users/{{args.id}}&quot;) }   ","version":"Next","tagName":"h2"},{"title":"method‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#method","content":" Specifies the HTTP method for the API call. The default method is GET if not specified.  type Mutation { createUser(input: UserInput!): User @http(method: &quot;POST&quot;, path: &quot;/users&quot;) }   ","version":"Next","tagName":"h2"},{"title":"query‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#query","content":" Represents the API call's query parameters, either as a static object or with dynamic parameters using Mustache templates. These parameters append to the URL.  type Query { userPosts(id: ID!): [Post] @http(path: &quot;/posts&quot;, query: [{key: &quot;userId&quot;, value: &quot;{{args.id}}&quot;}]) }   ","version":"Next","tagName":"h2"},{"title":"body‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#body","content":" Defines the API call's body, necessary for methods like POST or PUT. Pass it as a static object or use Mustache templates for variable substitution from the GraphQL variables.  type Mutation { createUser(input: UserInput!): User @http(method: &quot;POST&quot;, path: &quot;/users&quot;, body: &quot;{{args.input}}&quot;) }   In the example above, the createUser mutation sends a POST request to /users, with the input object converted to JSON and included in the request body.  ","version":"Next","tagName":"h2"},{"title":"headers‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#headers","content":" Customizes the HTTP request headers made by the @http operator. Specify a key-value map of header names and values.  For instance:  type Mutation { createUser(input: UserInput!): User @http(path: &quot;/users&quot;, headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}]) }   In this example, a request to /users will include a HTTP header X-Server with the value Tailcall.  You can make use of mustache templates to provide dynamic values for headers, derived from the arguments or context provided in the request. For example:  type Mutation { users(name: String): User @http(path: &quot;/users&quot;, headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}, {key: &quot;User-Name&quot;, value: &quot;{{args.name}}&quot;}]) }   In this scenario, the User-Name header's value will dynamically adjust according to the name argument passed in the request.  ","version":"Next","tagName":"h2"},{"title":"groupBy‚Äã","type":1,"pageTitle":"@http","url":"/docs/operators/http/#groupby","content":" Groups data requests into a single call, enhancing efficiency. Refer to our n + 1 guide for more details.  type Post { id: Int! name: String! user: User @http(path: &quot;/users&quot;, query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}], groupBy: [&quot;id&quot;]) }   query: {key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}]: Instructs TailCall CLI to generate a URL aligning the user id with userId from the parent Post, compiling a single URL for a batch of posts, such as /users?id=1&amp;id=2&amp;id=3...id=10, consolidating requests into one. ","version":"Next","tagName":"h2"},{"title":"@upstream","type":0,"sectionRef":"#","url":"/docs/operators/upstream/","content":"","keywords":"","version":"Next"},{"title":"poolIdleTimeout‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#poolidletimeout","content":" The connection pool waits for this duration in seconds before closing idle connections.  schema @upstream(poolIdleTimeout: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"poolMaxIdlePerHost‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#poolmaxidleperhost","content":" The max number of idle connections each host will maintain.  schema @upstream(poolMaxIdlePerHost: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"keepAliveInterval‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#keepaliveinterval","content":" The time in seconds between each keep-alive message sent to maintain the connection.  schema @upstream(keepAliveInterval: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"keepAliveTimeout‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#keepalivetimeout","content":" The time in seconds that the connection will wait for a keep-alive message before closing.  schema @upstream(keepAliveTimeout: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"keepAliveWhileIdle‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#keepalivewhileidle","content":" A boolean value that determines whether to send keep-alive messages while the connection is idle.  schema @upstream(keepAliveWhileIdle: false, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"proxy‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#proxy","content":" The proxy setting defines an intermediary server that routes upstream requests before they reach their intended endpoint. By specifying a proxy URL, you introduce a layer, enabling custom routing and security policies.  schema @upstream(proxy: {url: &quot;http://localhost:3000&quot;}, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   In the provided example, we've set the proxy's url to &quot;http://localhost:3000&quot;. This configuration ensures that all requests aimed at the designated baseURL first go through this proxy. To illustrate, if the baseURL is &quot;http://jsonplaceholder.typicode.com&quot;, any request targeting it initially goes to &quot;http://localhost:3000&quot; before the proxy redirects it to its final destination.  ","version":"Next","tagName":"h2"},{"title":"connectTimeout‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#connecttimeout","content":" The time in seconds that the connection will wait for a response before timing out.  schema @upstream(connectTimeout: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"timeout‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#timeout","content":" The max time in seconds that the connection will wait for a response.  schema @upstream(timeout: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"tcpKeepAlive‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#tcpkeepalive","content":" The time in seconds between each TCP keep-alive message sent to maintain the connection.  schema @upstream(tcpKeepAlive: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"userAgent‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#useragent","content":" The User-Agent header value for HTTP requests.  schema @upstream(userAgent: &quot;Tailcall/1.0&quot;, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"allowedHeaders‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#allowedheaders","content":" The allowedHeaders configuration defines the HTTP headers that can forward to upstream services during requests. Without specifying allowedHeaders, the system will not forward any incoming headers to upstream services, offering an extra security layer but potentially limiting necessary data flow.  schema @upstream(allowedHeaders: [&quot;Authorization&quot;, &quot;X-Api-Key&quot;]) { query: Query mutation: Mutation }   In the example above, the configuration for allowedHeaders permits Authorization and X-Api-Key headers. Thus, requests with these headers will forward them to upstream services; the system ignores all others. This configuration ensures communication of the expected headers to dependent services, emphasizing security and consistency.  ","version":"Next","tagName":"h2"},{"title":"baseURL‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#baseurl","content":" This refers to the default base URL for your APIs. If it's not explicitly mentioned in the @upstream operator, then each @http operator must specify its own baseURL. If neither @upstream nor @http provides a baseURL, it results in a compilation error.  schema @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   In this representation, http://jsonplaceholder.typicode.com serves as the baseURL. Thus, all API calls made by @http prepend this URL to their respective paths.  tip Ensure that your base URL remains free from specific path segments. GOOD: @upstream(baseURL: http://jsonplaceholder.typicode.com)BAD: @upstream(baseURL: http://jsonplaceholder.typicode.com/api)  ","version":"Next","tagName":"h2"},{"title":"httpCache‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#httpcache","content":" When activated, directs Tailcall to use HTTP caching mechanisms, following the HTTP Caching RFC to enhance performance by minimizing unnecessary data fetches. If left unspecified, this feature defaults to false.  schema @upstream(httpCache: false) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"Tips‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#tips","content":" Use batching when other optimization techniques fail to resolve performance issues.Apply batching and thoroughly assess its impact.Understand that batching may make debugging more challenging.  ","version":"Next","tagName":"h3"},{"title":"batch‚Äã","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#batch","content":" An object that specifies the batch settings, including maxSize (the max size of the batch), delay (the delay in milliseconds between each batch), and headers (an array of HTTP headers that the batch will include).  schema @upstream(batch: {maxSize: 1000, delay: 10, headers: [&quot;X-Server&quot;, &quot;Authorization&quot;]}) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h2"},{"title":"@server","type":0,"sectionRef":"#","url":"/docs/operators/server/","content":"","keywords":"","version":"Next"},{"title":"workers‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#workers","content":" Setting workers to 32 means that the Tailcall server will use 32 worker threads.  schema @server(workers: 32) { query: Query mutation: Mutation }   This example sets the workers to 32, meaning the Tailcall server will use 32 worker threads.  ","version":"Next","tagName":"h2"},{"title":"port‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#port","content":" Setting the port to 8090 means that Tailcall will be accessible at http://localhost:8000.  schema @server(port: 8090) { query: Query mutation: Mutation }   This example sets the port to 8090, making Tailcall accessible at http://localhost:8090.  tip Always choose non-standard ports, avoiding typical ones like 80 or 8080. Make sure your chosen port is free.  ","version":"Next","tagName":"h2"},{"title":"cacheControlHeader‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#cachecontrolheader","content":" Activating the cacheControlHeader configuration directs Tailcall to send Cache-Control headers in its responses. The max-age value in the header matches the smallest of the values in the responses Tailcall receives from upstream services. By default, this is false, which means Tailcall does not set any header.  schema @server(cacheControlHeader: true) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"graphiql‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#graphiql","content":" Enabling the graphiql configuration activates the GraphiQL IDE at the root (/) path within Tailcall. GraphiQL is a built-in, interactive in-browser GraphQL IDE, designed to streamline query development and testing. By default, this feature is off.  schema @server(port: 8000, graphiql: true) { query: Query mutation: Mutation }   tip While the GraphiQL interface is a powerful tool for development, consider disabling it in production environments if you're not exposing GraphQL APIs directly to users. This ensures an added layer of security and reduces unnecessary exposure.  ","version":"Next","tagName":"h2"},{"title":"vars‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#vars","content":" This configuration allows defining local variables for use during the server's operations. These variables are handy for storing constant configurations, secrets, or other shared information that operations might need.  schema @server(vars: {key: &quot;apiKey&quot;, value: &quot;YOUR_API_KEY_HERE&quot;}) { query: Query mutation: Mutation } type Query { externalData: Data @http(path: &quot;/external-api/data&quot;, headers: [{key: &quot;Authorization&quot;, value: &quot;Bearer {{vars.apiKey}}&quot;}]) }   In the provided example, setting a variable named apiKey with a placeholder value of &quot;YOUR_API_KEY_HERE&quot; implies that whenever Tailcall fetches data from the externalData endpoint, it includes the apiKey in the Authorization header of the HTTP request.  tip Local variables, like apiKey, are instrumental in securing access to external services or providing a unified place for configurations. Ensure that sensitive information stored this way is well protected and not exposed unintentionally, if your Tailcall configuration is publicly accessible.  ","version":"Next","tagName":"h2"},{"title":"introspection‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#introspection","content":" This setting controls the server's allowance of introspection queries. Introspection, a core feature of GraphQL, allows clients to directly fetch schema information. This capability proves crucial for tools and client applications in comprehending the available types, fields, and operations. By default, the server enables this setting (true).  schema @server(introspection: false) { query: Query mutation: Mutation }   tip Although introspection is beneficial during development and debugging stages, consider disabling it in production environments. Turning off introspection in live deployments can enhance security by preventing potential attackers from discerning the schema and any associated business logic or data structures.  ","version":"Next","tagName":"h2"},{"title":"queryValidation‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#queryvalidation","content":" The queryValidation configuration determines if the server checks incoming GraphQL queries against the defined schema. Each query check ensures it matches the schema, preventing errors from incorrect or malformed queries. In some situations, you might want to disable it, notably to enhance server performance at the cost of these checks. This defaults to false if not specified.  schema @server(queryValidation: true) { query: Query mutation: Mutation }   The example above sets queryValidation to true, enabling the validation phase for incoming queries.  tip Enable this in the development environment to ensure the queries sent are correct and validated. In the production environment, consider disabling it for improved performance.  ","version":"Next","tagName":"h2"},{"title":"responseValidation‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#responsevalidation","content":" Tailcall can automatically infer the schema of the HTTP endpoints for you. This information can check responses received from the upstream services. Enabling this setting allows you to do that. If not specified, the default setting for responseValidation is false.  schema @server(responseValidation: true) { query: Query mutation: Mutation }   tip Disabling this setting will offer major performance improvements, but at the potential expense of data integrity.  ","version":"Next","tagName":"h2"},{"title":"responseHeaders‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#responseheaders","content":" The responseHeader is an array of key-value pairs. These headers get added to the response of every request made to the server. This can be useful for adding headers like Access-Control-Allow-Origin to allow cross-origin requests, or some headers like X-Allowed-Roles for use by downstream services.  schema @server(responseHeaders: [{key: &quot;X-Allowed-Roles&quot;, value: &quot;admin,user&quot;}]) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"globalResponseTimeout‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#globalresponsetimeout","content":" The globalResponseTimeout configuration sets the max duration a query can run before the server terminates it. Essentially, it acts as a safeguard against long-running queries that could strain resources or pose security concerns.  If not explicitly defined, there might be a system-specific or default value that applies.  schema @server(globalResponseTimeout: 5000) { query: Query mutation: Mutation }   In this given example, setting the globalResponseTimeout to 5000 milliseconds, or 5 seconds, means any query execution taking longer than this duration will be automatically terminated by  tip Setting an appropriate response timeout in production environments is crucial. This optimizes resource use and serves as a security measure against potential denial-of-service attacks, where adversaries might run complex queries to exhaust server resources.  ","version":"Next","tagName":"h2"},{"title":"version‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#version","content":" The server uses the HTTP version. If not specified, the default value is HTTP1. The available options are HTTP1 and HTTP2.  schema @server(version: HTTP2) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"cert‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#cert","content":" The path to certificate(s) for running the server over HTTP2 (HTTPS). If not specified, the default value is null.  schema @server(cert: &quot;./cert.pem&quot;) { query: Query mutation: Mutation }   tip The certificate can be of any extension, but it's highly recommended to use standards (pem, crt, key).  ","version":"Next","tagName":"h2"},{"title":"key‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#key","content":" The path to the key for running the server over HTTP2 (HTTPS). If not specified, the default value is null.  schema @server(key: &quot;./key.pem&quot;) { query: Query mutation: Mutation }   tip The key can be of any extension, but it's highly recommended to use standards (pem, crt, key).  ","version":"Next","tagName":"h2"},{"title":"batchRequests‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#batchrequests","content":" Batching in GraphQL combines requests into one, reducing server round trips.  schema @server( port: 8000 batchRequests: true )   ","version":"Next","tagName":"h2"},{"title":"Trade-offs‚Äã","type":1,"pageTitle":"@server","url":"/docs/operators/server/#trade-offs","content":" Batching can improve performance but may introduce latency if one request in the batch takes longer. It also makes network traffic debugging harder. ","version":"Next","tagName":"h3"}],"options":{"highlightResult":true,"id":"default"}}