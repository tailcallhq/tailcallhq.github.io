{"searchDocs":[{"title":"Guidelines","type":0,"sectionRef":"#","url":"/docs/contribution-guidelines/","content":"","keywords":"","version":"Next"},{"title":"The Basics‚Äã","type":1,"pageTitle":"Guidelines","url":"/docs/contribution-guidelines/#the-basics","content":" Fork and Clone: Fork the repository on GitHub and clone your fork locally. git clone https://github.com/yourusername/tailcall.git Set Up Your Environment: Install Rust: Use rustup to install Rust and the nightly toolchain.Install Prettier: Required for linting, install Prettier.Build the Application: Navigate to the project directory and execute cargo build.Start the Server: Run cargo run -- start ./examples/jsonplaceholder.graphql to start the server and access the GraphiQL interface at https://tailcall.run/playground.  ","version":"Next","tagName":"h2"},{"title":"Making and Discussing Changes‚Äã","type":1,"pageTitle":"Guidelines","url":"/docs/contribution-guidelines/#making-and-discussing-changes","content":" Create a New Branch: Always work on a new branch created from the latest main branch. git checkout -b feature/your-feature-name Develop Incrementally: Use small, stacked PRs for complex features. Break down large tasks into smaller, manageable pieces, each with its own PR. If you are working on a large bounty item add the bounty on your main PR and create stacked PRs wrt to your main PR. Discuss on Discord: For real-time discussions, use the #contributors channel on Discord. Create a thread for each PR to facilitate focused discussions.  ","version":"Next","tagName":"h2"},{"title":"Pull Requests and Code Quality‚Äã","type":1,"pageTitle":"Guidelines","url":"/docs/contribution-guidelines/#pull-requests-and-code-quality","content":" Keep PRs Small: Focus each PR on a single topic to simplify review and potential reverts. Describe your changes clearly in the PR description, explaining the solution and linking to any relevant discussions or issues. Commit Clearly: Write concise, descriptive commit messages. Each commit should represent a self-contained change. Submit PRs: Push your branch to GitHub and open a PR against the main branch. In the PR description, detail the purpose of your changes and any additional context needed. Code Review: Engage with reviewers on GitHub and address feedback promptly. Use discussions on Discord to resolve complex issues or debates efficiently.  ","version":"Next","tagName":"h2"},{"title":"Community Engagement‚Äã","type":1,"pageTitle":"Guidelines","url":"/docs/contribution-guidelines/#community-engagement","content":" Star and Share: Star the repository if you find it helpful and share your contributions on social media using #tailcall and tagging @tailcallhq.  ","version":"Next","tagName":"h2"},{"title":"Final Notes‚Äã","type":1,"pageTitle":"Guidelines","url":"/docs/contribution-guidelines/#final-notes","content":" Tailcall thrives through your contributions. We aim to maintain a respectful and inclusive community. Thank you for helping to enhance Tailcall for everyone! ","version":"Next","tagName":"h2"},{"title":"Bounty","type":0,"sectionRef":"#","url":"/docs/contributors/bounty/","content":"","keywords":"","version":"Next"},{"title":"Our Philosophy‚Äã","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#our-philosophy","content":" We‚Äôre all about meritocracy here. That means the best ideas and implementations win! We love seeing your quality work and fast moves. And yes, we recognize and appreciate your efforts when you exceed expectations.  ","version":"Next","tagName":"h2"},{"title":"Quick & Quality‚Äã","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#quick--quality","content":" Speedy Gonzalez: We like fast results! Quick feedback, quick updates. The faster, the better!A+ Quality: But hey, don‚Äôt rush it if it means cutting corners. We want your best ‚Äì make it shine!  ","version":"Next","tagName":"h2"},{"title":"Teamwork Makes the Dream Work‚Äã","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#teamwork-makes-the-dream-work","content":" Join Us on Discord: Our Discord server is THE place to collaborate, get tips, and find your next bestie. Let‚Äôs make magic together.Share the Love: Inspired by someone‚Äôs PR? Working together? Feel free to /split that bounty ‚Äì sharing is caring!  ","version":"Next","tagName":"h2"},{"title":"How to Dive In‚Äã","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#how-to-dive-in","content":" Pick a Challenge: Use /attempt in the comments to call dibs on an issue. It‚Äôs like saying ‚ÄúI got this!‚ÄùShow Your Work: Got an issue? Great! Now, whip up a draft PR within 24 hours to show you‚Äôre on it.Go for Gold: Once you‚Äôre ready, switch that draft to Ready for Review. Make sure it‚Äôs polished and gleaming!Extra Mile Alert: We‚Äôve got bonuses for those who add that special touch. Clean up, optimize, or fix something extra? We‚Äôre here for it!  ","version":"Next","tagName":"h2"},{"title":"The Rules of the Game‚Äã","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#the-rules-of-the-game","content":" Be Quick or Be‚Ä¶ Late: No PR within 24 hours? Then it‚Äôs open season for that issue again.There Can Be One Winner: Multiple folks can try, but it's the top PR that emerges victorious. If there's a tie, the first submission takes the prize.No Copycats: Be original; be yourself. Avoid merely copying someone else's hard work.Consider Before You Contribute: If there‚Äôs already a PR in progress, perhaps take a moment to review it before submitting your own.  ","version":"Next","tagName":"h2"},{"title":"Identifying Plagiarism‚Äã","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#identifying-plagiarism","content":" To keep our Bounty Program fair and fun, we have a strict no-plagiarism policy. Here‚Äôs how we keep it original:  Manual Review: Our team manually checks all submissions to spot any sneaky copy-pasting.Raise the Alarm: If you think someone‚Äôs trying to pull a fast one, let us know ASAP! Before the copycat's PR gets merged, shout it out in our Discord channel and drop a comment on their PR.  Caught cheating? That means disqualification from the current bounty, a possible ban from future bounties, and a heads-up to the community. So, keep it real and let‚Äôs make this program a blast for everyone!  ","version":"Next","tagName":"h2"},{"title":"Wrapping Up‚Äã","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#wrapping-up","content":" We‚Äôre stoked to have you! This program is your chance to shine and get rewarded while at it. Stick to these friendly guidelines, and let‚Äôs make something awesome together. We look forward to seeing what you bring to the table. ","version":"Next","tagName":"h2"},{"title":"Micro Benchmarks","type":0,"sectionRef":"#","url":"/docs/contributors/micro-benchmark/","content":"","keywords":"","version":"Next"},{"title":"Running Benchmarks‚Äã","type":1,"pageTitle":"Micro Benchmarks","url":"/docs/contributors/micro-benchmark/#running-benchmarks","content":" Install cargo-criterion and rust-script: cargo install cargo-criterion rust-script Execute the benchmarks: cargo bench This command will run all benchmarks and display the results. To run a specific benchmark you could modify the command and pass a pattern to the command: cargo bench -- 'foo.*bar'   ","version":"Next","tagName":"h2"},{"title":"Comparing Benchmarks‚Äã","type":1,"pageTitle":"Micro Benchmarks","url":"/docs/contributors/micro-benchmark/#comparing-benchmarks","content":" To facilitate benchmark comparison, we have developed a Rust script capable of contrasting the outcomes of two benchmarks.  # Checkout the base branch git checkout main # Run the benchmarks for the main branch and store the result in a file cargo bench --message-format=json &gt; main.json # Checkout the feature branch git checkout feature # Run the benchmarks again in your feature branch cargo bench --message-format=json &gt; feature.json # Perform a comparison check between the two branches ./scripts/criterion_compare.rs main.json feature.json table   If the benchmarks indicate a degradation exceeding 10%, the script will terminate with an error. You can refer to the automatically generated benches/benchmark.md file to identify which benchmarks underperformed and investigate the corresponding code changes before submitting a pull request. ","version":"Next","tagName":"h2"},{"title":"Telemetry","type":0,"sectionRef":"#","url":"/docs/contributors/telemetry/","content":"Telemetry At Tailcall, we adhere to high observability standards in line with the OpenTelemetry specification. Our implementation utilizes several key Rust crates: rust-opentelemetry and associated crates are used to support the collection and export of telemetry data.tracing and tracing-opentelemetry facilitate the definition of logs and traces. Integration with OpenTelemetry allows for the automatic transfer of this data to the OpenTelemetry system. This layered approach ensures that the tracing library, which is effective across various scenarios, can also function as a standalone telemetry system for logging when OpenTelemetry integration is not required. When developing any features that necessitate observability, consider the following guidelines: Implement traces for tasks that represent a significant operation. This practice aids in the efficient diagnosis of issues and performance bottlenecks.Name spans clearly and specifically, adhering to the guidelines outlined in the OpenTelemetry specifications. Avoid names that introduce a high cardinality of potential values.Due to the constraints of tracing libraries, span names must be static strings. This limitation can be overcome by adding an extra field named otel.name to provide more dynamic descriptions (see the tracing-opentelemetry documentation for more details).Attribute naming should follow OpenTelemetry's semantic conventions. Utilize constants available in the opentelemetry_semantic_conventions crate for standardized attribute names.","keywords":"","version":"Next"},{"title":"Mutability","type":0,"sectionRef":"#","url":"/docs/contributors/mutability/","content":"","keywords":"","version":"Next"},{"title":"Using References‚Äã","type":1,"pageTitle":"Mutability","url":"/docs/contributors/mutability/#using-references","content":" When calling functions that do not need to modify the values they receive, pass references to these values. This avoids unnecessary copying and preserves the original data integrity.üí∞  Consider a function that calculates the total number of items in a list. This function does not alter the list, so pass the list as a reference:  fn count_items(items: &amp;Vec&lt;i32&gt;) -&gt; usize { items.len() } let my_items = vec![1, 2, 3]; let total = count_items(&amp;my_items);   ","version":"Next","tagName":"h2"},{"title":"Using Ownership‚Äã","type":1,"pageTitle":"Mutability","url":"/docs/contributors/mutability/#using-ownership","content":" When calling functions that need to modify the values they receive, pass ownership of these values to the function. This makes it clear that the function might change the value. Ensure that the modified values are returned from the function if further use is required.  Consider a function that adds an item to a list. Since this modifies the list, pass the list with ownership and return the modified list:  fn add_item(mut items: Vec&lt;i32&gt;, item: i32) -&gt; Vec&lt;i32&gt; { items.push(item); items } let my_items = vec![1, 2, 3]; let updated_items = add_item(my_items, 4);   ","version":"Next","tagName":"h2"},{"title":"Using Mutable References‚Äã","type":1,"pageTitle":"Mutability","url":"/docs/contributors/mutability/#using-mutable-references","content":" Mutable references are particularly useful when you need to modify the data a function receives without taking ownership of it. This approach is ideal for types that behave like classical stateful services, where maintaining state across multiple function calls is necessary.  Consider a caching mechanism where data needs to be frequently updated or retrieved based on function calls. In this case, using a mutable reference allows the cache to be updated without transferring ownership each time:  struct Cache { data: HashMap&lt;String, String&gt;, } impl Cache { fn add_entry(&amp;mut self, key: String, value: String) { self.data.insert(key, value); } fn get_entry(&amp;self, key: &amp;str) -&gt; Option&lt;&amp;String&gt; { self.data.get(key) } } let mut my_cache = Cache { data: HashMap::new() }; my_cache.add_entry(&quot;session1&quot;.to_string(), &quot;User123&quot;.to_string()); if let Some(user) = my_cache.get_entry(&quot;session1&quot;) { println!(&quot;Cached user: {}&quot;, user); }   note Even though in Rust mutability is a lot more tamed than other languages, as a standard we try to stay away from mutable references as much as possible.  ","version":"Next","tagName":"h2"},{"title":"Exceptions‚Äã","type":1,"pageTitle":"Mutability","url":"/docs/contributors/mutability/#exceptions","content":" The approach outlined above may not be suitable for performance-sensitive components or frequently executed sections of code (hot code paths). In such scenarios, prioritize efficiency and adopt optimization strategies to enhance performance. Sometimes the API design of a dependent library can also influence the way we write code. These are all the exceptions where it's ok to move away from the above set guidelines. ","version":"Next","tagName":"h2"},{"title":"Getting Started with GraphQL","type":0,"sectionRef":"#","url":"/docs/","content":"","keywords":"","version":"Next"},{"title":"Installing the Tailcall CLI‚Äã","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#installing-the-tailcall-cli","content":"  You can install the latest version - by using NPM.   ","version":"Next","tagName":"h2"},{"title":"NPM‚Äã","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#npm","content":" If you don't already have nodejs installed, you can find the instructions here. Install Tailcall by running the following command in your terminal: npm i -g @tailcallhq/tailcall To verify the correct installation of Tailcall, run: tailcall note Do not use the --force flag during npm installations, as it ignores installing platform-specific builds.  ","version":"Next","tagName":"h3"},{"title":"Yarn‚Äã","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#yarn","content":" Install Tailcall by running the following command in your terminal: yarn global add @tailcallhq/tailcall To verify the correct installation of Tailcall, run: tailcall   ","version":"Next","tagName":"h3"},{"title":"Homebrew‚Äã","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#homebrew","content":" If you don't already have Homebrew installed, you can find the instructions here. Add the Tailcall repository to Homebrew by running the following command in your terminal: brew tap tailcallhq/tailcall brew install tailcall To verify the correct installation of Tailcall, run: tailcall After completing the installation, perform upgrades with: brew update brew upgrade tailcall   ","version":"Next","tagName":"h3"},{"title":"Curl‚Äã","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#curl","content":" Follow the steps below to manually install the cli on your system:  curl -sSL https://tailcall.run/install.sh | bash -s --   This command fetches and executes the Tailcall installation script. The ~/.tailcall directory contains the installed files.  Upon completion of the installation, extend your PATH environment variable to include the ~/.tailcall/bin directory:  # export PATH=$PATH:~/.tailcall/bin   ","version":"Next","tagName":"h3"},{"title":"Docker‚Äã","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#docker","content":" To install Tailcall with Docker, follow the steps below. Please note that currently, this installation method only works on Linux/amd64 systems. Before starting, make sure you have Docker installed on your system. If not, download it from here.  Pull the latest Tailcall Docker image using the following command: docker pull tailcall.docker.scarf.sh/tailcallhq/tailcall/tc-server: This command fetches the latest version of the Tailcall Docker image from the Docker registry. Run the Tailcall Docker container with the following command: docker run -d --name graphql-server -p 8000:8000 \\ -v /path/to/your/configs:/etc/tailcall \\ --entrypoint &quot;/bin/sh&quot; \\ ghcr.io/tailcallhq/tailcall/tc-server: \\ -c &quot;export PATH=$PATH:~/.tailcall/bin &amp;&amp; tailcall start /etc/tailcall/config.graphql&quot; This command launches the GraphQL server in a Docker container, exposing the GraphQL endpoint on port 8080.  ","version":"Next","tagName":"h3"},{"title":"Initializing a GraphQL project‚Äã","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#initializing-a-graphql-project","content":" Once you have installed the Tailcall binaries, you can simply use the init command to initialize your GraphQL project.  tailcall init &lt;directory&gt;   The command will ask you a few questions and based on your input bootstrap a new GraphQL project with a few files:  .tailcallrc.schema.json: Provides autocomplete in your editor when the configuration is written in json or yml format..graphqlrc.yml: An IDE configuration that references your GraphQL configuration (if it's in .graphql format) and the following .tailcallrc.graphql..tailcallrc.graphql: Contains Tailcall specific auto-completions for .graphql format.main.graphql: This is your root configuration that contains  ","version":"Next","tagName":"h2"},{"title":"Writing a GraphQL Configuration‚Äã","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#writing-a-graphql-configuration","content":" For our first example, we are going to compose a GraphQL schema from the REST APIs at https://jsonplaceholder.typicode.com, a free online REST API with some fake data. We will use the API at /users to get a list of users, and /users/:id/posts to get the posts for each user, and compose them into a single GraphQL schema.  We can use the following formats to define our GraphQL schema: .graphql, .yml, .json.  Create one of the following files and paste the contents into it.  graphqlymljson schema # Specify server configuration: Start GraphQL server at 0.0.0.0:8000 @server(port: 8000) # Specify a base url for all http requests @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query } type Query { # Specify the http path for the users query users: [User] @http(path: &quot;/users&quot;) } # Create a user type with the fields returned by the users api type User { id: Int! name: String! username: String! email: String! # Extend the user type with the posts field # Use the current user's id to construct the path posts: [Post] @http(path: &quot;/users/{{.value.id}}/posts&quot;) } # Create a post type with the fields returned by the posts api type Post { id: Int! title: String! body: String! }   The above file is a standard .graphQL file, with some minor additions such as @upstream and @http directives. Basically we specify the GraphQL schema and how to resolve that GraphQL schema in the same file, without having to write any code!  ","version":"Next","tagName":"h2"},{"title":"Starting the GraphQL server‚Äã","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#starting-the-graphql-server","content":" Now, run the following command to start the server with the full path to the file that you created earlier.  graphqlymljson tailcall start ./jsonplaceholder.graphql   If the command succeeds, you should see logs like the following below.  INFO File read: ./jsonplaceholder.graphql ... ok INFO N + 1 detected: 0 INFO üöÄ Tailcall launched at [0.0.0.0:8000] over HTTP/1.1 INFO üåç Playground: https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql   The server starts with the schema provided and prints out a load of meta information. We will cover those in detail in a bit. For now, open the playground URL in a new tab in your browser and try it out for yourself!  ","version":"Next","tagName":"h2"},{"title":"Making GraphQL requests to the server‚Äã","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#making-graphql-requests-to-the-server","content":" Open a web browser and go to https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql. This should load the GraphiQL interface. In the query editor of GraphiQL, enter the following query query { users { id name posts { title } } } After running the query in GraphiQL, expect to see a JSON response structured like this: { &quot;data&quot;: { &quot;users&quot;: [ { &quot;id&quot;: 1, &quot;name&quot;: &quot;Leanne Graham&quot;, &quot;posts&quot;: [ { &quot;title&quot;: &quot;sunt aut facere repellat provident occaecati excepturi option reprehenderit&quot; } // Posts truncated for brevity ] }, { &quot;id&quot;: 2, &quot;name&quot;: &quot;Ervin Howell&quot;, &quot;posts&quot;: [ { &quot;title&quot;: &quot;et ea vero quia laudantium autem&quot; }, { &quot;title&quot;: &quot;in quibusdam tempore odit est dolorem&quot; } // Posts truncated for brevity ] } // Users truncated for brevity ] } }   ","version":"Next","tagName":"h2"},{"title":"Deploying GraphQL on Production‚Äã","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#deploying-graphql-on-production","content":" Now that you have a running GraphQL server, you can follow our Github Actions Guide to deploy the application on one of the following cloud providers.  AWS LambdaFly.io ","version":"Next","tagName":"h2"},{"title":"Macro Benchmarks","type":0,"sectionRef":"#","url":"/docs/contributors/wrk-benchmark/","content":"","keywords":"","version":"Next"},{"title":"Prerequisites‚Äã","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#prerequisites","content":" Rust and Cargo (https://rustup.rs/)wrk benchmarking tool (Installation instructions: https://github.com/wg/wrk)  ","version":"Next","tagName":"h2"},{"title":"Step 1: Build Tailcall‚Äã","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#step-1-build-tailcall","content":" Ensure you are on the desired branch you want to benchmark, and then build Tailcall in release mode to optimize performance:  cargo build --release   ","version":"Next","tagName":"h2"},{"title":"Step 2: Start the Server‚Äã","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#step-2-start-the-server","content":" Start the Tailcall server by setting the appropriate environment variable to control log output and using the release binary:  export TC_LOG_LEVEL=error cargo run --release -- start ./jsonplaceholder.graphql   This command sets the log level to error to minimize logging output, which can affect performance during benchmarks.  ","version":"Next","tagName":"h2"},{"title":"Step 3: Verify Server is Running‚Äã","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#step-3-verify-server-is-running","content":" Before running wrk, verify that the server is responsive. Use curl to send a request:  curl -X POST -H &quot;Content-Type: application/json&quot; \\ -d '{&quot;operationName&quot;:null,&quot;variables&quot;:{},&quot;query&quot;:&quot;{posts{title}}&quot;}' \\ http://127.0.0.1:8000/graphql   Repeat this a couple of times to ensure the server is handling requests correctly.  ","version":"Next","tagName":"h2"},{"title":"Step 4: Customize WRK Setup with Lua Script‚Äã","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#step-4-customize-wrk-setup-with-lua-script","content":" To customize the wrk setup, create a Lua script named wrk_script.lua and paste the following content:  wrk.method = &quot;POST&quot; wrk.body = '{&quot;operationName&quot;:null,&quot;variables&quot;:{},&quot;query&quot;:&quot;{posts{title}}&quot;}' wrk.headers[&quot;Connection&quot;] = &quot;keep-alive&quot; wrk.headers[&quot;Content-Type&quot;] = &quot;application/json&quot;   This script configures wrk to send POST requests with a specific JSON body and headers.  ","version":"Next","tagName":"h2"},{"title":"Step 5: Run the Benchmark‚Äã","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#step-5-run-the-benchmark","content":" Open another terminal window and execute wrk to start the benchmark. Here is a basic example:  wrk -t12 -c400 -d30s -s wrk_script.lua http://127.0.0.1:8000/graphql   This command uses 12 threads and maintains 400 open HTTP connections over a duration of 30 seconds, targeting the server running on localhost port 8000.  ","version":"Next","tagName":"h2"},{"title":"Step 6: Interpreting Results‚Äã","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#step-6-interpreting-results","content":" wrk will output statistics about the tests, which include:  Total number of requests completedThroughput, measured in requests per secondLatency distribution  These metrics help assess the performance capabilities and robustness of your server under high load conditions. ","version":"Next","tagName":"h2"},{"title":"Integration Testing","type":0,"sectionRef":"#","url":"/docs/contributors/integration-testing/","content":"","keywords":"","version":"Next"},{"title":"How does it work?‚Äã","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#how-does-it-work","content":" Execution Spec implements a custom markdown-based testing framework for Tailcall. The framework is designed to help write integration tests for GraphQL configs.  ","version":"Next","tagName":"h2"},{"title":"Run all tests‚Äã","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#run-all-tests","content":" The integration tests are executed as usual integration test so you can use test options and filters like with usual test.  cargo test   To run integration tests skipping other tests run following command:  cargo test --test execution_spec   After running you will get an output of all executed integration tests.  ","version":"Next","tagName":"h3"},{"title":"Run a single test‚Äã","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#run-a-single-test","content":" Similar to filtering unit tests to execute a single markdown configuration you can pass it's name to the test command:  cargo test --test execution_spec grpc Compiling tailcall-fixtures v0.1.0 (/Users/tushar/Documents/Projects/tailcall/tailcall-fixtures) Compiling tailcall v0.1.0 (/Users/tushar/Documents/Projects/tailcall) Finished `test` profile [unoptimized + debuginfo] target(s) in 15.96s Running tests/execution_spec.rs (target/debug/deps/execution_spec-6779d7c5c29b9b0b) running 18 tests test run_execution_spec::test-grpc-invalid-method-format.md ... ok test run_execution_spec::test-grpc-invalid-proto-id.md ... ok test run_execution_spec::test-grpc-group-by.md ... ok test run_execution_spec::test-grpc-missing-fields.md ... ok test run_execution_spec::test-grpc-nested-optional.md ... ok test run_execution_spec::test-grpc-nested-data.md ... ok test run_execution_spec::test-grpc-proto-path.md ... ok test run_execution_spec::grpc-proto-with-same-package.md ... ok test run_execution_spec::grpc-reflection.md ... ok test run_execution_spec::test-grpc-optional.md ... ok test run_execution_spec::test-grpc-service-method.md ... ok test run_execution_spec::test-grpc-service.md ... ok test run_execution_spec::grpc-error.md ... ok test run_execution_spec::grpc-simple.md ... ok test run_execution_spec::grpc-batch.md ... ok test run_execution_spec::grpc-url-from-upstream.md ... ok test run_execution_spec::grpc-override-url-from-upstream.md ... ok test run_execution_spec::test-grpc.md ... ok   In the above command all tests with the name grpc will be executed.  ","version":"Next","tagName":"h3"},{"title":"Skipping a test‚Äã","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#skipping-a-test","content":" Skipping the test is also possible by passing the --skip parameter:  cargo test --test execution_spec -- --skip grpc   Sometimes, you might want to skip the test per permanently for everyone and the CI. You could achieve it by setting the skip configuration in your markdown:  --- skip: true --- &lt;!-- Rest of the configurations --&gt;   ","version":"Next","tagName":"h3"},{"title":"Folder Structure‚Äã","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#folder-structure","content":" All execution_spec tests are located in tests/execution. The results generated by these tests are stored as snapshots in tests/core/snapshots. An execution_spec test is always a markdown file with a .md extension.  ","version":"Next","tagName":"h2"},{"title":"File Structure‚Äã","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#file-structure","content":" Each .md file runs in its own scope, so no two tests can interfere with each other. The file structure is as follows:  ","version":"Next","tagName":"h2"},{"title":"Heading‚Äã","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#heading","content":" The heading of file is used to provide metadata about the test. It is a YAML front matter block that contains the following fields:  identity - This instructs the runner to check if the configuration when parsed and then printed back, is the same as the original configuration. This is useful to check whenever a new feature is added in the configuration and the parsers + printer needs to be updated.error - This instructs the runner to expect a validation error while parsing the configuration. This is useful to test validation logic written while converting config to blueprint.skip - This is a special annotation that ensures that the test is skipped.  --- identity: true error: true skip: true ---   The rest of the file is the test's body consisting of code blocks and descriptions.  ","version":"Next","tagName":"h3"},{"title":"Config‚Äã","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#config","content":" Codeblocks can be enhanced with additional meta information for the test parser to make sense of the code. So for example a GraphQL configuration could be written in a code block with the graphql language and a @config meta information could be attached to it.  ```graphql @config schema { query: Query } type Query { users: [User] posts: [Post] } ```   For each config a few tests are automatically executed:  We check if the config written is valid. If it's not and unless error: true is set in the front matter, the test will fail.We check if the config when parsed and then printed back is the same as the original config. This is useful to check whenever a new feature is added in the configuration and the parsers + printer needs to be updated.We check if the config when merged with an empty configuration is the same as the original config. This is useful to check whenever a new feature is added in the configuration and the merger needs to be updated.We autogenerate the schema of the GraphQL server and snapshot it for later. This is useful to see what would the final GraphQL schema look like.  ","version":"Next","tagName":"h3"},{"title":"Test‚Äã","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#test","content":" An @test block specifies HTTP requests that the runner should perform in YAML format. It solely contains requests. The response for each request is automatically generated and compared with the snapshot.  note There may be at most one @test block in a test.  Example:  ```yml @test - method: POST url: http://localhost:8080/graphql body: query: query { user { name } } ```   ","version":"Next","tagName":"h3"},{"title":"Mock‚Äã","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#mock","content":" Mock provides a way to match requests and send back a predefined response. It is used to mock HTTP &amp; gRPC requests in the test.  ```yml @mock - request: # The method to match on (default: Any) method: POST # The URL to match on (default: Any) url: http://jsonplaceholder.typicode.com/users/1 # Predefined response response: status: 200 body: id: 1 name: foo # Number of time we expect this request to be hit (default: 1) expectedHits: 1 # Whether we should assert the number of hits (default: true) assertHits: true ```   ","version":"Next","tagName":"h3"},{"title":"Env‚Äã","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#env","content":" An @env block specifies environment variables in YAML that the runner should use in the app context. There may be at most one @env block in a test.  Example:  ```yml @env TEST_ID: 1 ```   ","version":"Next","tagName":"h3"},{"title":"File‚Äã","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#file","content":" A @file block creates a file in the spec's virtual file system. The @config block will have exclusive access to files created in this way: the true filesystem is not available to it.  Every @file block has the filename declared in the header. The language of the code block is optional and does not matter.  Example:  ```js @file:worker.js function onRequest({request}) { request.headers[&quot;x-test&quot;] = &quot;test&quot; return {request} } ``` ```graphql @config schema @link(file: &quot;worker.js&quot;) { query: Query } ```   In the above example we are able to link the worker.js file to the schema and write an integration test where all the requests will be modified by the onRequest function.  ","version":"Next","tagName":"h3"},{"title":"Snapshots‚Äã","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#snapshots","content":" Tailcall uses the Insta snapshot engine. Snapshots are automatically generated with a .new suffix if there is no pre-existing snapshot, or if the compared data didn't match the existing snapshot.  Instead of writing result cases in tests and updating them when behaviour changes, a snapshot-based testing workflow relies on auto-generation. Whenever a .new snapshot is generated, it means one of the following:  Your code made an unexpected breaking change, and you need to fix it.Your code made an expected breaking change, and you need to accept the new snapshot.  You need to determine which one is the case, and take action accordingly.  Usage of cargo-insta is recommended:  cargo insta test --review   This will regenerate all snapshots without interrupting the test every time there's a diff, and it will also open the snapshot review interface, so that you can accept or reject .new snapshots.  To clean unused snapshots, run:  cargo insta test --delete-unreferenced-snapshots  ","version":"Next","tagName":"h2"},{"title":"Unit Testing","type":0,"sectionRef":"#","url":"/docs/contributors/testing/","content":"","keywords":"","version":"Next"},{"title":"Running Tests‚Äã","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#running-tests","content":" To execute tests locally on your machine, follow these steps:  Ensure the Rust toolchain is installed on your machine. Execute all tests with the following command in the terminal: cargo test To run a specific test or group of tests, modify the command accordingly: cargo test test_name To view all output from tests (useful if you have added debug logs to your tests), use the command: cargo test -- --show-output For more details and options on how tests function, please refer to the Rust Book Testing Chapter and the rustc tests guide.  ","version":"Next","tagName":"h2"},{"title":"Filtering Running Tests‚Äã","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#filtering-running-tests","content":" To execute a specific set of tests or exclude some tests, use the following commands:  To run tests that match a certain pattern:  cargo test test_pattern # e.g., to run grpc related tests: cargo test grpc   To run a specific test by passing the full module path:  cargo test -- --exact test_name # e.g., for grpc protobuf conversion: cargo test -- --exact grpc::protobuf::tests::convert_value   To skip certain tests:  cargo test -- --skip test_pattern # e.g., to ignore grpc related tests: cargo test -- --skip grpc   For more available options, please refer to rustc filter's documentation.  ","version":"Next","tagName":"h3"},{"title":"Writing Tests‚Äã","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#writing-tests","content":" ","version":"Next","tagName":"h2"},{"title":"Unit Tests‚Äã","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#unit-tests","content":" Unit tests should focus on individual components, ensuring each functions as expected:  Place unit tests in the same file as your code, under a #[cfg(test)] module. Use descriptive function names for your tests, for eg: #[cfg(test)] mod tests { #[test] fn test_addition() { assert_eq!(2 + 2, 4); } } For every new feature or bug fix, structure your tests as follows: Set up the value using helper methods in tests. Compare an actual and an expected value. Assert the two values on separate lines. Ensure there is one assertion per test. For eg: use pretty_assertions::assert_eq; fn test_something_important() { // Setup let value = setup_something_using_a_function(); // Compute Actual let actual = perform_some_operation_on_the_value(value); // Compute Expected let expected = ExpectedValue {foo: 1, bar: 2}; // Compare Actual and Expected assert_eq!(actual, expected); } Before submitting a pull request, verify all tests pass.  ","version":"Next","tagName":"h3"},{"title":"Integration Tests‚Äã","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#integration-tests","content":" Integration testing is conducted using our markdown-based DSL. Please refer to its own documentation for detailed information.  ","version":"Next","tagName":"h3"},{"title":"Naming Conventions‚Äã","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#naming-conventions","content":" Test functions should begin with test_ followed by a description of their purpose.Use underscores to separate words in the test function names for readability.  ","version":"Next","tagName":"h2"},{"title":"What to Test‚Äã","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#what-to-test","content":" In essence, test everything! Write unit tests for modules that can be tested independently and supplement them with integration tests to ensure the overall system stability.  ","version":"Next","tagName":"h2"},{"title":"Troubleshooting Common Issues‚Äã","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#troubleshooting-common-issues","content":" Ensure your branch is up-to-date with the latest commits from the main branch.Verify that your environment conforms to the required configurations (e.g., versions of Rust and dependencies).Confirm that test failures are not caused by your changes (e.g., run tests with a clean build on the main branch). ","version":"Next","tagName":"h2"},{"title":"Deploy Tailcall GraphQL on Fly.io","type":0,"sectionRef":"#","url":"/docs/deploy-tailcall-graphql-fly-actions/","content":"","keywords":"","version":"Next"},{"title":"Generate API Key for Fly.io‚Äã","type":1,"pageTitle":"Deploy Tailcall GraphQL on Fly.io","url":"/docs/deploy-tailcall-graphql-fly-actions/#generate-api-key-for-flyio","content":" Follow these steps to generate an API key:  Go to the Fly.io dashboard. Click on Tokens in the left sidebar. Optionally, provide a name and an expiry date for the token. Click on Create Organization Token to generate the token. Copy the generated token and store it securely. You will need this token as input to the tailcallhq/gh-action when deploying to Fly.io.  ","version":"Next","tagName":"h2"},{"title":"Setting Up the Project Repository‚Äã","type":1,"pageTitle":"Deploy Tailcall GraphQL on Fly.io","url":"/docs/deploy-tailcall-graphql-fly-actions/#setting-up-the-project-repository","content":" Next, create a new repository on GitHub and use the tailcallhq/gh-action GitHub action to deploy it. The easiest way to get started is by using this template repository: https://github.com/tailcallhq/deploy-tailcall.  Go to the repository and click on Use this template to create a new repository. Name your repository and click on Create repository. After creating the repository, add the Fly.io API token to the repository secrets. To do this, click on Settings. Click on Secrets and variables in the left sidebar to expand the section, then click on Actions. Click on New repository secret to add a new secret. Name the secret FLY_API_TOKEN or any preferred name, and paste the Fly.io API token you generated earlier into the value field. Click on Add secret to save it.  You are now ready to deploy your tailcall server on Fly.io.  ","version":"Next","tagName":"h2"},{"title":"Deploy on Fly.io‚Äã","type":1,"pageTitle":"Deploy Tailcall GraphQL on Fly.io","url":"/docs/deploy-tailcall-graphql-fly-actions/#deploy-on-flyio","content":" In this example, we will deploy a simple GraphQL server using tailcall on Fly.io, which converts the JSONPlaceholder REST API to a GraphQL API.  Below is the configuration present in the template repository, which will be used for this deployment.  tip You can learn more about the configuration here  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) }   To deploy the server, update the provider to fly in the deploy-tailcall job in the .github/workflows/main.yml file, as shown below.  on: [push] jobs: deploy_tailcall: runs-on: ubuntu-latest name: Deploy Tailcall steps: - name: Checkout repository uses: actions/checkout@v2 - name: Deploy Tailcall id: deploy-tailcall uses: tailcallhq/gh-action@&lt;version&gt; # Replace &lt;version&gt; with the desired version with: provider: &quot;fly&quot; # Specifies the cloud provider as 'fly' fly-api-token: ${{ secrets.FLY_API_TOKEN }} fly-app-name: &lt;app-name&gt; # Replace &lt;app-name&gt; with the desired app name fly-region: &quot;lax&quot; tailcall-config: &quot;./config.graphql&quot;   important When specifying the fly-app-name in your GitHub Actions workflow for deploying to Fly.io, ensure the app name you choose is unique across all Fly.io users.  Fly.io requires each app name to be globally unique. If the name you select is already taken by another user, your deployment will fail. To avoid this issue, consider using a name that includes unique identifiers such as your organization name, project name, etc. If you do not specify the app name, &lt;orgname&gt;-&lt;reponame&gt; will be used.  After updating the main.yml file, commit the changes and push them to the repository. This will trigger the deployment of the tailcall server on Fly.io. Once the deployment is successful, you can access the GraphQL playground at https://tailcall.run/playground/?u=https://&lt;fly-app-name&gt;.fly.dev/graphql. ","version":"Next","tagName":"h2"},{"title":"Github Action for Deploying GraphQL","type":0,"sectionRef":"#","url":"/docs/deploy-graphql-github-actions/","content":"","keywords":"","version":"Next"},{"title":"Deploying to Fly‚Äã","type":1,"pageTitle":"Github Action for Deploying GraphQL","url":"/docs/deploy-graphql-github-actions/#deploying-to-fly","content":" Below is an example of how to deploy a tailcall server to Fly using the tailcallhq/gh-action action.  on: [push] jobs: deploy_tailcall: runs-on: ubuntu-latest name: Deploy Tailcall steps: - name: Checkout repository uses: actions/checkout@v2 - name: Deploy Tailcall id: deploy-tailcall uses: tailcallhq/gh-action@&lt;version&gt; # Replace &lt;version&gt; with the desired version with: provider: &quot;fly&quot; # Specifies the cloud provider as 'fly' fly-api-token: ${{ secrets.FLY_API_TOKEN }} fly-app-name: &quot;tailcall&quot; fly-region: &quot;lax&quot; tailcall-config: &quot;config.graphql&quot;   ","version":"Next","tagName":"h2"},{"title":"Inputs for tailcallhq/gh-action‚Äã","type":1,"pageTitle":"Github Action for Deploying GraphQL","url":"/docs/deploy-graphql-github-actions/#inputs-for-tailcallhqgh-action","content":" Following are the inputs for the tailcallhq/gh-action action when deploying to Fly:  Input\tDescriptionprovider\tWhen deploying to Fly, this should be set to fly. tailcall-config\tThe path of the tailcall configuration file. tailcall-version\tSpecifies the version of tailcall to use for deployment. If not provided, the Action defaults to the latest available version. fly-api-token\tThe Fly API token required for authentication. Ensure this value is stored securely, such as in GitHub Secrets. fly-app-name\tThe name of the Fly app being deployed. Defaults to &lt;orgname&gt;-&lt;reponame&gt; if not specified. fly-region\tThe region where the Fly app will be deployed. Defaults to ord if not specified.  ","version":"Next","tagName":"h3"},{"title":"Deploying to AWS Lambda‚Äã","type":1,"pageTitle":"Github Action for Deploying GraphQL","url":"/docs/deploy-graphql-github-actions/#deploying-to-aws-lambda","content":" on: [push] jobs: deploy_tailcall: runs-on: ubuntu-latest name: Deploy Tailcall steps: - name: Checkout repository uses: actions/checkout@v2 - name: Deploy Tailcall id: deploy-tailcall uses: tailcallhq/gh-action@&lt;version&gt; # Replace &lt;version&gt; with the desired version with: provider: &quot;aws&quot; aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} aws-region: &quot;us-east-1&quot; aws-iam-role: &quot;iam_for_tailcall&quot; terraform-api-token: ${{ secrets.TERRAFORM_API_TOKEN }} tailcall-config: &quot;config.graphql&quot;   ","version":"Next","tagName":"h2"},{"title":"Inputs for tailcallhq/gh-action‚Äã","type":1,"pageTitle":"Github Action for Deploying GraphQL","url":"/docs/deploy-graphql-github-actions/#inputs-for-tailcallhqgh-action-1","content":" Following are the inputs for the tailcallhq/gh-action action when deploying to AWS Lambda:  Input\tDescriptionprovider\tWhen deploying to AWS Lambda, this should be set to aws. tailcall-config\tThe path to the tailcall configuration file used for deployment. tailcall-version\tSpecifies the version of tailcall to use for deployment. If not provided, the Action defaults to the latest available version. aws-access-key-id\tThe AWS access key ID required for authentication. Ensure this value is stored securely, such as in GitHub Secrets. aws-secret-access-key\tThe AWS secret access key required for authentication. Store this securely, such as in GitHub Secrets. aws-region\tThe AWS region where the Lambda function will be deployed (e.g., us-east-1). aws-iam-role\tThe IAM role name to be created and used for the deployment. If not specified, defaults to iam_for_tailcall. aws-lambda-function-name\tThe name assigned to the created Lambda function. Defaults to tailcall if not specified. terraform-api-token\tThe Terraform Cloud API token required for authentication. Ensure this value is stored securely, such as in GitHub Secrets. ","version":"Next","tagName":"h3"},{"title":"Optimizing Performance of your GraphQL Server","type":0,"sectionRef":"#","url":"/docs/graphql-client-performance-tuning/","content":"","keywords":"","version":"Next"},{"title":"HTTP (Hypertext Transfer Protocol)‚Äã","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#http-hypertext-transfer-protocol","content":" HTTP, the most widely used protocol for communication between clients and servers, carries your request to the server and then brings back the data to your client. TCP forms the foundation of HTTP.  ","version":"Next","tagName":"h3"},{"title":"HTTP Versions: 1.x, 2, and 3‚Äã","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#http-versions-1x-2-and-3","content":" Each version has enhanced HTTP's flexibility and performance.  HTTP/1.x: Creates a separate TCP connection for each HTTP request (or reuses one sequentially).HTTP/2: Introduces multiplexing to allow concurrent sending of requests and responses over a single TCP connection, enhancing performance.HTTP/3: Employs QUIC instead of TCP, further reducing connection setup time and improving packet loss and network change handling.  note The server determines the HTTP version. Thus, if the server supports HTTP/1, the client cannot make an HTTP/2 request, even if compatible. If the client supports HTTP/1, the server should, according to the specification, downgrade to serve the request over HTTP/1.  ","version":"Next","tagName":"h3"},{"title":"TCP (Transmission Control Protocol)‚Äã","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#tcp-transmission-control-protocol","content":" TCP ensures the data sent and received over the internet reaches its destination and in order.  TCP, like dialing a number before talking on the phone, establishes a connection between the client and server before exchanging data using HTTP. This guide will show how to tune Tailcall's HTTP client to enhance this connection's performance. Learn more about TCP in detail here.  ","version":"Next","tagName":"h3"},{"title":"QUIC (Quick UDP Internet Connections)‚Äã","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#quic-quick-udp-internet-connections","content":" Developed by Google, QUIC aims to make web communications faster and more efficient than TCP. It reduces connection establishment time, handles packet loss better, and supports multiplexed streams over a single connection, preventing a slow request from holding up others. HTTP/3 uses QUIC. Learn more about QUIC in detail here.  ","version":"Next","tagName":"h3"},{"title":"Why Managing Connections is Important?‚Äã","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#why-managing-connections-is-important","content":" Performance Overhead: Establishing TCP connections with HTTP/1.x consumes time due to the complete TCP handshake for each new connection. This process adds latency and increases system resources. Limited Ports on Client Side: A unique combination of an IP address and a port number is necessary for each TCP connection from a client. With each new connection, the IP remains the same because the client is the same, but a new port gets used. The number of available ports on a machine is 65535. These ports get shared among all processes, and not all are available for use. Excessive creation of new connections can lead to port exhaustion on the client side, preventing new connections and causing system failures across running processes. tip Use lsof and netstat commands to check the ports to process mapping.  Connection pooling mitigates these issues by reusing existing connections for requests, reducing connection establishment frequency (and thus handshake overhead) and conserving client-side ports. This approach enhances application performance by minimizing the resources and time spent on managing connections.  ","version":"Next","tagName":"h3"},{"title":"Tuning HTTP Client‚Äã","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#tuning-http-client","content":" Tailcall uses connection pooling by default and sets up with default tuning suitable for most use cases. You might need to further tune the HTTP client to improve your application's performance. Tailcall DSL provides a directive named @upstream for this purpose.  note Connection pooling optimizes HTTP/1. Since HTTP/2 and HTTP/3 support multiplexing, pooling enabled does not noticeably affect performance.  When using HTTP/1.x, tune the connection pool with the following parameters:  ","version":"Next","tagName":"h2"},{"title":"poolMaxIdlePerHost‚Äã","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#poolmaxidleperhost","content":" poolMaxIdlePerHost specifies the allowed number of idle connections per host, defaulting to 60. Example:  schema @upstream( poolMaxIdlePerHost: 60 ) { query: Query }   Too idle connections can unnecessarily consume memory and ports, while too few might cause delays as new connections need frequent establishment. poolMaxIdlePerHost ensures judicious use of network and memory resources, avoiding wastage on seldom-used connections.  For applications connecting to hosts, set this value lower to keep connections available for other hosts. Conversely, if you have hosts and all requests must resolve through them, maintain a higher value for this setting.  ","version":"Next","tagName":"h3"},{"title":"tcpKeepAlive‚Äã","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#tcpkeepalive","content":" tcpKeepAlive keeps TCP connections alive for a duration, during inactivity, by periodically sending packets to the server to check if the connection remains open. In connection pooling, tcpKeepAlive maintains reusable connections in a ready-to-use state. This setting is useful for long-lived connections, preventing -lived connections, preventing the client from using a connection the server has closed due to inactivity. Without tcpKeepAlive, connections in the pool might get dropped by the server or intermediate network devices (like firewalls or load balancers). When your client tries to use such a dropped connection, it would fail, causing delays and errors. Keeping connections alive and monitored means you can efficiently reuse them, reducing the overhead of establishing new connections frequently.  Tailcall provides a parameter named tcpKeepAlive for the upstream which defaults to 5 seconds. Example: schema  @upstream ( tcpKeepAlive: 300 ) { query: Query }   ","version":"Next","tagName":"h3"},{"title":"connectTimeout‚Äã","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#connecttimeout","content":" connectTimeout specifically applies to the phase where your client attempts to establish a connection with the server. When making a connection request, the client tries to resolve the DNS, complete the SSL handshake, and establish a TCP connection. In environments where pods are frequently created and destroyed, maintaining a low connectTimeout is crucial to avoid unnecessary delays. In systems using connection pooling, the system aborts the attempt if it cannot establish a connection within the connectTimeout period. This approach prevents indefinite waiting for a connection to establish, which could cause delays and timeouts.  Tailcall offers a connectTimeout parameter to set the connection timeout in seconds for the HTTP client, defaulting to 60 seconds. Example:  schema @upstream( connectTimeout: 10 ) { query: Query }   In summary, maximizing HTTP client performance requires understanding the underlying protocols and configuring client settings through testing. This ensures efficient, robust, and high-performing client-server communication, crucial for the smooth operation of modern web applications. ","version":"Next","tagName":"h3"},{"title":"GraphQL Best Practices","type":0,"sectionRef":"#","url":"/docs/graphql-best-practices-tailcall/","content":"","keywords":"","version":"Next"},{"title":"General Naming Principles‚Äã","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#general-naming-principles","content":" Consistency is Key: Ensure that naming conventions are uniform across your entire schema to maintain clarity and consistency.Descriptive Over Generic: Opt for descriptive, specific names rather than broad, generic ones to avoid ambiguity.Avoid Abbreviations: Avoid the use of acronyms, initialism, and abbreviations to keep your schema intuitive and understandable.  ","version":"Next","tagName":"h2"},{"title":"Detailed Naming Cases‚Äã","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#detailed-naming-cases","content":" ","version":"Next","tagName":"h2"},{"title":"Fields, Arguments, and Directives‚Äã","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#fields-arguments-and-directives","content":" Adopt camelCase: Utilize camelCase for field names, argument names, and directive names to achieve a clear, consistent structure.  type Query { postTitle(userId: Int): String } directive @includeIf on FIELD   ","version":"Next","tagName":"h3"},{"title":"Types‚Äã","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#types","content":" Prefer PascalCase: Use PascalCase for defining types, enabling easy identification and differentiation.  type Post { ... } enum StatusEnum { ... } interface UserInterface { ... } union SearchResult = ... scalar Date   Enum Values in SCREAMING_SNAKE_CASE: Distinguish enum values by using SCREAMING_SNAKE_CASE.  enum StatusEnum { PUBLISHED DRAFT }   ","version":"Next","tagName":"h3"},{"title":"Field Naming Best Practices‚Äã","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#field-naming-best-practices","content":" ","version":"Next","tagName":"h2"},{"title":"Queries‚Äã","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#queries","content":" Avoid get or list Prefixes: Refrain from using prefixes like get or list in your query names to ensure predictability and consistency.  type Query { # üëé Avoid getPosts: [Post] # üëç Prefer posts: [Post] }   Maintain consistency between root and nested fields:  # üëé Avoid query PostQuery { getPosts { id getUser { name } } } # üëç Prefer query PostQuery { posts { id user { name } } }   ","version":"Next","tagName":"h3"},{"title":"Mutations‚Äã","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#mutations","content":" Verb Prefixes for Mutations: Begin mutation field names with a verb to indicate the action being performed, improving schema readability.  type Mutation { # üëé Avoid postAdd(input: AddPostInput): AddPostPayload! # üëç Prefer addPost(input: AddPostInput): AddPostPayload! }   ","version":"Next","tagName":"h3"},{"title":"Type Naming Conventions‚Äã","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#type-naming-conventions","content":" ","version":"Next","tagName":"h2"},{"title":"Input Types‚Äã","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#input-types","content":" Input Suffix: Denote input types by appending Input to their names, specifying their use case.  input AddPostInput { title: String! body: String! userId: Int! }   ","version":"Next","tagName":"h3"},{"title":"Output Types‚Äã","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#output-types","content":" Response or Payload Suffix: Use a consistent suffix like Response or Payload for the output types resulting from mutations.  type Mutation { addPost(input: AddPostInput!): AddPostResponse! } type AddPostResponse { success: Boolean! post: Post }   ","version":"Next","tagName":"h3"},{"title":"Advanced Naming Strategies‚Äã","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#advanced-naming-strategies","content":" ","version":"Next","tagName":"h2"},{"title":"Resolving Namespace Conflicts‚Äã","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#resolving-namespace-conflicts","content":" For addressing naming conflicts across different domains within your schema:  Use PascalCase Prefix: Distinguish similar types from distinct domains for clear separation without resorting to underscores. This method ensures a cleaner, more professional look while maintaining the integrity and readability of your schema.  type BlogPost { ... } type ForumPost { ... }   ","version":"Next","tagName":"h3"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#conclusion","content":" Implementing a consistent, descriptive, and intuitive naming convention is crucial for developing an understandable and maintainable GraphQL schema. By following the best practices outlined you can improve the clarity and effectiveness of your schema. ","version":"Next","tagName":"h2"},{"title":"Sequencing & Parallelism","type":0,"sectionRef":"#","url":"/docs/graphql-data-access-parallel-vs-sequence/","content":"","keywords":"","version":"Next"},{"title":"Examples‚Äã","type":1,"pageTitle":"Sequencing & Parallelism","url":"/docs/graphql-data-access-parallel-vs-sequence/#examples","content":" ","version":"Next","tagName":"h2"},{"title":"Example 1: Fetching a Specific User and Their Posts‚Äã","type":1,"pageTitle":"Sequencing & Parallelism","url":"/docs/graphql-data-access-parallel-vs-sequence/#example-1-fetching-a-specific-user-and-their-posts","content":" Imagine you're building a blog and want to display a specific user's profile page containing their information and all their posts.  Schema:  type Query { # Retrieve a specific user by ID user(id: Int!): User @http(path: &quot;/users/{{.value.id}}&quot;) } type User { id: Int! name: String! username: String! email: String! # Access user's posts using their ID in the path posts: [Post] @http(path: &quot;/users/{{.value.id}}/posts&quot;) } type Post { id: Int! title: String! body: String! }   GraphQL Query:  query getUserAndPosts($userId: Int!) { # Fetch the user by ID user(id: $userId) { id name username email # Sequentially retrieve all posts for the fetched user posts { id title body } } }   Tailcall understands that retrieving the user's posts depends on knowing the user's ID, which is obtained in the first step. Therefore, it automatically fetches the user first and then uses their ID to retrieve all their posts in a sequential manner.  ","version":"Next","tagName":"h3"},{"title":"Example 2: Searching Multiple Posts and Users by ID‚Äã","type":1,"pageTitle":"Sequencing & Parallelism","url":"/docs/graphql-data-access-parallel-vs-sequence/#example-2-searching-multiple-posts-and-users-by-id","content":" Suppose you're building a social media platform and want to display profiles of specific users and their recent posts.  Schema:  type Query { # Retrieve users from the &quot;/users&quot; endpoint users: [User] @http(path: &quot;/users&quot;) } type User { id: Int! name: String! username: String! email: String! # Access user's posts using their ID in the path posts: [Post] @http(path: &quot;/users/{{.value.id}}/posts&quot;) } type Post { id: Int! title: String! body: String! }   GraphQL Query:  query getUsersWithLatestPosts { # Retrieve all users users { id name username email # Access user's posts through the nested field posts { id title body } } }   This query retrieves details of multiple users and their most recent posts based on the provided user IDs. Tailcall recognizes that fetching user details and their individual posts are independent tasks. As a result, it can execute these requests concurrently for each user.  ","version":"Next","tagName":"h3"},{"title":"Example 3: Fetching Posts with Users‚Äã","type":1,"pageTitle":"Sequencing & Parallelism","url":"/docs/graphql-data-access-parallel-vs-sequence/#example-3-fetching-posts-with-users","content":" Imagine you're building a social media platform and want to display a list of posts with each post's author. Traditionally, you might write a query that retrieves all posts and then, for each post, make a separate request to fetch its corresponding user. This approach leads to the N+1 problem, where N represents the number of posts, and 1 represents the additional request per post to retrieve its user.  Schema:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) } type User { id: Int! name: String! }   GraphQL Query:  query getPostsWithUsers { posts { id userId title body user { id name } } }   Tailcall analyzes the schema and recognizes that fetching user details for each post is independent. It can potentially execute these requests to /users/{{.value.userId}} concurrently, fetching user data for multiple posts simultaneously.  In summary, Tailcall automates the management of sequence and parallelism in API calls. It analyzes the defined schema to optimize execution, freeing developers from manual intervention. ","version":"Next","tagName":"h3"},{"title":"Field Level GraphQL Authentication","type":0,"sectionRef":"#","url":"/docs/field-level-access-control-graphql-authentication/","content":"","keywords":"","version":"Next"},{"title":"What is Authentication?‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#what-is-authentication","content":" Authentication is the process of verifying a user's identity before granting access to data. In most modern applications, some information, such as a list of products in an e-commerce application, is accessible to all users without requiring identification. However, personal data, like a user's order history, is accessible to the user who owns that information. Verifying a user's identity to access such personal data is known as authentication.  The primary reasons for implementing authentication in an application include:  Protecting User-Specific Data Ensuring that data belonging to a user is not accessible by others.Security The ability to block users based on certain criteria necessitates identifying them.Customized User Experiences Delivering personalized experiences based on a user's identity.  Authentication can be implemented using credential validation mechanisms, such as:  Basic AuthJWTOAuthAPI Key  ","version":"Next","tagName":"h2"},{"title":"Entity Level Authentication in GraphqQL‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#entity-level-authentication-in-graphqql","content":" Entity level authentication in GraphQL refers to applying authentication logic to specific entities or types within your GraphQL schema, rather than at the API entry point or resolver level for individual queries or mutations. This approach allows you to control access to particular data types or fields based on the user's authentication status, enabling a more granular and flexible security model.  Advantages of this approach:  Flexibility: Tailors security measures to precisely fit the needs of your application, enhancing the protection of sensitive data.Scalability: Facilitates extending security policies to new entities and fields as your schema expands.Customization: Enables implementing different authentication mechanisms for distinct entities based on their security requirements.  ","version":"Next","tagName":"h3"},{"title":"GraphQL Authentication‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#graphql-authentication","content":" Tailcall provides a straightforward way to implement entity level authentication in your GraphQL schema. By leveraging custom directives, you can define which entities or fields require authentication to access their data. Tailcall supports multiple authentication providers, such as Basic Auth and JWT, allowing you to choose the authentication mechanism that best suits your application's requirements. to know more about how to use it, read the following articles:  Basic AuthJWT  ","version":"Next","tagName":"h2"},{"title":"GraphQL Configuration‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#graphql-configuration","content":" Enabling support for authentication in Tailcall could be done in two steps:  With the help of @link directive connect multiple authentication files as you need for different provides. To connect it use either Htpasswd or Jwks link typeMark that some type of field requires authentication to be fetched with the help of @protected directive  Your config could look like this now:  schema @server(port: 8000) @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) @link(id: &quot;auth-basic&quot;, type: Htpasswd, src: &quot;htpasswd&quot;) @link(id: &quot;auth-jwt&quot;, type: Jwks, src: &quot;jwks.json&quot;) { query: Query mutation: Mutation } type Query { posts: [Post] @http(path: &quot;/posts&quot;) user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type Mutation { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type User @protected { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! @protected user: User @http(path: &quot;/users/{{.value.userId}}&quot;) }   In that case the whole User type and Post.body are marked as protected and therefore requiring authentication to resolve its content. That means following points:  any query for Post.body will require authenticationany query for any field of User will require authenticationany field that resolves to User type will require authentication  For more info about possible configuration for available providers read articles for Basic Auth and JWT  ","version":"Next","tagName":"h2"},{"title":"Making test requests‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#making-test-requests","content":" Now let's try to access some data from the example above. Start the graphql server with provided config and use graphQL playground that should be opened automatically in your browser.  If you execute the query that don't have any @protected fields like  { posts { title } }   Then the data for this will be resolved as usual without providing any additional info. showing the list of posts with their titles:But if you change the query to access protected data, then if you don't provide any authentication data, i.e. for query:  { posts { body } }   You will get an authentication failure error stating that authentication parameters were not provided. e.g.:  { &quot;data&quot;: null, &quot;errors&quot;: [ { &quot;message&quot;: &quot;Authentication Failure: Missing Authorization Header.&quot;, &quot;locations&quot;: [ { &quot;line&quot;: 3, &quot;column&quot;: 5 } ] } ] }     Now update the request by providing additional Authorization header. You can do in the Playground by navigating to the tab HTTP HEADERS at the bottom by adding following header for Basic Auth:  { &quot;Authorization&quot;: &quot;Basic dGVzdHVzZXIxOnBhc3N3b3JkMTIzs&quot; }   Now after executing the request again you'll get the response for all the requested fields without any error.  ","version":"Next","tagName":"h2"},{"title":"How it works‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#how-it-works","content":" ","version":"Next","tagName":"h2"},{"title":"@protected Type‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#protected-type","content":" If type is marked with @protected then:  attempt to request any field of that type will require authenticationattempt to request any field from other type that resolves to protected type will require authentication and the underlying IO operation won't be executed without it  ","version":"Next","tagName":"h3"},{"title":"Mutation‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#mutation","content":" For mutation entity level authentication works similar to queries. But since mutation involves requests that changes external state you should be careful where do you specify @protected directive because marking some nested field as protected doesn't prevent from executing the request to resolve the parent fields. I.e. following example is problematic:  schema { query: Query mutation: Mutation } type Query { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type Mutation { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;, method: POST) } type User { id: Int! name: String! website: String @protected }   Here you can still execute the mutation without any authentication and fail on attempting to resolve website field.  To resolve this issue, consider marking root fields as protected in case they require authentication, i.e.:  schema { query: Query mutation: Mutation } type Query { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type Mutation { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;, method: POST) @protected } type User { id: Int! name: String! website: String @protected }   ","version":"Next","tagName":"h3"},{"title":"Multiple auth providers‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#multiple-auth-providers","content":" In case you linked multiple authentication files all of them will be used to execute validation process. In that case, by default, Tailcall will validate all of them in parallel and succeed if at least one of them succeed.  ","version":"Next","tagName":"h3"},{"title":"Authentication headers‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#authentication-headers","content":" To validate authentication for user request the specific headers are used (like Authorization header). In case auth is enabled for tailcall those headers will be also added to the allowedHeaders list and therefore they will be forwarded to the upstream requests implicitly.  ","version":"Next","tagName":"h3"},{"title":"Basic Authentication‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#basic-authentication","content":" Basic Authentication is a straightforward authentication scheme that sends base64-encoded usernames and passwords in the HTTP Authorization header with each request. It's simple to implement but requires HTTPS to ensure security due to its lack of encryption.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#prerequisites","content":" To be able to use Basic Authentication support you should have configured htpasswd file that contains users credentials data.  To generate this data you can use Apache tooling itself or available web-tool  important Since this file stores secure information make sure to hash the password you use with secure algorithms  ","version":"Next","tagName":"h3"},{"title":"Basic Auth GraphQL Configuration‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#basic-auth-graphql-configuration","content":" To use Basic Auth you should first include htpasswd file generated from Prerequisites with the help of @link directive.  We can use that file as an example for it that has data for testuser:mypassword credentials in encrypted format:  htpasswd testuser:$2y$10$wJ/mZDURcAOBIrswCAKFsO0Nk7BpHmWl/XuhF7lNm3gBAFH3ofsuu   After adding @link you can use the @protected directive to mark the fields that requiring success authentication to be requested.  The whole example could look like this:  schema @server(port: 8000) @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) @link(id: &quot;auth-basic&quot;, type: Htpasswd, src: &quot;htpasswd&quot;) { query: Query } type Query { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type User @protected { id: Int! name: String! username: String! email: String! phone: String website: String }   ","version":"Next","tagName":"h3"},{"title":"Making test request‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#making-test-request","content":" Now you can run the example file with Tailcall and try to make a query for data with specifying credentials.  To make the request first create base64 encoded string from the testuser:mypassword string and then append the result to the Authorization: Basic header.  A request example with curl:  curl --request POST \\ --url http://localhost:8000/graphql \\ --header 'Authorization: Basic dGVzdHVzZXI6bXlwYXNzd29yZA==' \\ --data '{&quot;query&quot;:&quot;query {\\n\\tuser(id: 1) { name }\\n}&quot;}'   or you can use the GraphQL Playground and add the header in the HTTP Headers section:  { &quot;Authorization&quot;: &quot;Basic dGVzdHVzZXIyOm15cGFzc3dvcmQ=&quot; }   with query:  query { user(id: 1) { name } }   Executing such request should be resolved with the user and its name.  ","version":"Next","tagName":"h3"},{"title":"JWT Authentication‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#jwt-authentication","content":" JWT Authentication uses digitally signed tokens to authenticate and transmit user information in a compact JSON format, allowing stateless and secure communication between clients and servers. It offers greater flexibility and security, supporting expiration times and custom data embedding within the token itself.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#prerequisites-1","content":" To be able to use JWT authentication you should have configured JSON Web Key Sets (JWKS for short) file.  To create this file you can use available web-tools like JWK creator in case you already have RSA key-pair or mkjwk if you don't.  ","version":"Next","tagName":"h3"},{"title":"JWT Auth GraphQL Configuration‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#jwt-auth-graphql-configuration","content":" To use JWT you should first include JWKS file generated from Prerequisites with the help of @link directive.  We can use that file as an example for it:  jwks.json { &quot;keys&quot;: [ { &quot;kty&quot;: &quot;RSA&quot;, &quot;use&quot;: &quot;sig&quot;, &quot;alg&quot;: &quot;RS256&quot;, &quot;kid&quot;: &quot;I48qMJp566SSKQogYXYtHBo9q6ZcEKHixNPeNoxV1c8&quot;, &quot;n&quot;: &quot;ksMb5oMlhJ_HzAebCuBG6-v5Qc4J111ur7Aux6-8SbxzqFONsf2Bw6ATG8pAfNeZ-USA3_T1mGkYTDvfoggXnxsduWV_lePZKKOq_Qp_EDdzic1bVTJQDad3CXldR3wV6UFDtMx6cCLXxPZM5n76e7ybPt0iNgwoGpJE28emMZJXrnEUFzxwFMq61UlzWEumYqW3uOUVp7r5XAF5jQ_1nQAnpHBnRFzdNPVb3E6odMGu3jgp8mkPbPMP16Fund4LVplLz8yrsE9TdVrSdYJThylRWn_BwvJ0DjUcp8ibJya86iClUlixAmBwR9NdStHwQqHwmMXMKkTXo-ytRmSUobzxX9T8ESkij6iBhQpmDMD3FbkK30Y7pUVEBBOyDfNcWOhholjOj9CRrxu9to5rc2wvufe24VlbKb9wngS_uGfK4AYvVyrcjdYMFkdqw-Mft14HwzdO2BTS0TeMDZuLmYhj_bu5_g2Zu6PH5OpIXF6Fi8_679pCG8wWAcFQrFrM0eA70wD_SqD_BXn6pWRpFXlcRy_7PWTZ3QmC7ycQFR6Wc6Px44y1xDUoq3rH0RlZkeicfvP6FRlpjFU7xF6LjAfd9ciYBZfJll6PE7zf-i_ZXEslv-tJ5-30-I4Slwj0tDrZ2Z54OgAg07AIwAiI5o4y-0vmuhUscNpfZsGAGhE&quot;, &quot;e&quot;: &quot;AQAB&quot; } ] }   After adding @link you can use the @protected directive to mark the fields that requiring success authentication to be requested.  The whole example could look like this:  schema @server(port: 8000) @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) @link(id: &quot;auth-jwks&quot;, type: Jwks, src: &quot;jwks.json&quot;) { query: Query } type Query { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type User @protected { id: Int! name: String! username: String! email: String! phone: String website: String }   ","version":"Next","tagName":"h3"},{"title":"Making test request‚Äã","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#making-test-request-1","content":" Now you can run the example file with Tailcall and try to make a query for data with specifying credentials.  To make the request first obtain JWT token compatible with JWKS file you've linked before (if you've used the example jwks.json file from above then you can use the token from the example below).  An request example with curl:  curl --request POST \\ --url http://localhost:8000/graphql \\ --header 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6Ikk0OHFNSnA1NjZTU0tRb2dZWFl0SEJvOXE2WmNFS0hpeE5QZU5veFYxYzgifQ.eyJleHAiOjIwMTkwNTY0NDEuMCwiaXNzIjoibWUiLCJzdWIiOiJ5b3UiLCJhdWQiOlsidGhlbSJdfQ.cU-hJgVGWxK3-IBggYBChhf3FzibBKjuDLtq2urJ99FVXIGZls0VMXjyNW7yHhLLuif_9t2N5UIUIq-hwXVv7rrGRPCGrlqKU0jsUH251Spy7_ppG5_B2LsG3cBJcwkD4AVz8qjT3AaE_vYZ4WnH-CQ-F5Vm7wiYZgbdyU8xgKoH85KAxaCdJJlYOi8mApE9_zcdmTNJrTNd9sp7PX3lXSUu9AWlrZkyO-HhVbXFunVtfduDuTeVXxP8iw1wt6171CFbPmQJU_b3xCornzyFKmhSc36yvlDfoPPclWmWeyOfFEp9lVhQm0WhfDK7GiuRtaOxD-tOvpTjpcoZBeJb7bSg2OsneyeM_33a0WoPmjHw8WIxbroJz_PrfE72_TzbcTSDttKAv_e75PE48Vvx0661miFv4Gq8RBzMl2G3pQMEVCOm83v7BpodfN_YVJcqZJjVHMA70TZQ4K3L4_i9sIK9jJFfwEDVM7nsDnUu96n4vKs1fVvAuieCIPAJrfNOUMy7TwLvhnhUARsKnzmtNNrJuDhhBx-X93AHcG3micXgnqkFdKn6-ZUZ63I2KEdmjwKmLTRrv4n4eZKrRN-OrHPI4gLxJUhmyPAHzZrikMVBcDYfALqyki5SeKkwd4v0JAm87QzR4YwMdKErr0Xa5JrZqHGe2TZgVO4hIc-KrPw' \\ --data '{&quot;query&quot;:&quot;query {\\n\\tuser(id: 1) { name }\\n}&quot;}'   Executing such request should be resolved with the user and its name. ","version":"Next","tagName":"h3"},{"title":"Data Dog Telemetry Integration","type":0,"sectionRef":"#","url":"/docs/graphql-data-dog-telemetry-tailcall/","content":"Data Dog Telemetry Integration This guide is based on the official doc. Go to datadoghq.comLogin to your account (make sure you choose right region for your account on login)Go to Organization Settings -&gt; API Keys and copy the value of existing key or create a new oneIntegration with datadog requires OpenTelemetry Collector to be able to send data to. As an example we can use following config for the collector: receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 exporters: logging: verbosity: detailed datadog: traces: span_name_as_resource_name: true hostname: &quot;otelcol&quot; api: key: ${DATADOG_API_KEY} # make sure to specify right datadog site based on # https://docs.datadoghq.com/getting_started/site/ site: us5.datadoghq.com processors: batch: datadog/processor: probabilistic_sampler: sampling_percentage: 30 service: pipelines: traces: receivers: [otlp] processors: [batch, datadog/processor] exporters: [datadog] metrics: receivers: [otlp] processors: [batch] exporters: [datadog] logs: receivers: [otlp] processors: [batch] exporters: [datadog] Go to your GraphQL configuration and update it to: schema @telemetry( export: {otlp: {url: &quot;http://localhost:4317&quot;}} ) { query: Query } Set the api key you've copied before to the environment variable named DATADOG_API_KEY and start Otel collector and tailcall with updated config Now make some requests to running service and wait a little bit until Datadog proceeds the data. After that you can go to APM -&gt; Traces, locate the span with name request and click on it. You should see something like on screenshot below: To see metrics now go to Metrics -&gt; Explorer and search for metric you want to see. After updating the query you should see something like on example below:","keywords":"","version":"Next"},{"title":"Reading Environment Variables","type":0,"sectionRef":"#","url":"/docs/graphql-environment-variables/","content":"","keywords":"","version":"Next"},{"title":"Need for Environment Variables‚Äã","type":1,"pageTitle":"Reading Environment Variables","url":"/docs/graphql-environment-variables/#need-for-environment-variables","content":" Applications rely on external tools, authentication methods, and configurations. For proper functioning, our code needs to access these values.  Consider a scenario of JWT authentication. When signing tokens for our users, we need:  Expiry time: The duration after which the token expires.Secret key: The key for encrypting the token.Issuer: The token issuer, often the organization's name.  There are two ways to manage this:  Hardcode the values in our code: This approach, while simple, poses a massive security risk by exposing sensitive information and requires code changes and application redeployment for updates. Store the values in environment variables: Storing sensitive values in the OS of the server running your application allows runtime access without code modifications, keeping sensitive information secure and simplifying value changes.  ","version":"Next","tagName":"h2"},{"title":"Environment Variables‚Äã","type":1,"pageTitle":"Reading Environment Variables","url":"/docs/graphql-environment-variables/#environment-variables","content":" With Tailcall, you can seamlessly integrate environment variables into your GraphQL schema. Tailcall supports this through a env Context variable. All directives share this Context, allowing you to resolve values in your schema.  Example schema:  type Query { users: [User]! @http( baseUrl: &quot;https://jsonplaceholder.typicode.com&quot; path: &quot;/users&quot; ) }   Here, we fetch a list of users from the JSONPlaceholder API. The users field will contain the fetched value at runtime. This works fine, but what if we want to change the API endpoint? We would need to update the code and redeploy the application, which is cumbersome.  We can address this issue using environment variables. Replace the API endpoint with an environment variable, allowing us to change the variable's value without altering our codebase.  type Query { users: [User]! @http(baseUrl: &quot;{{env.API_ENDPOINT}}&quot;, path: &quot;/users&quot;) }   Here, you must set API_ENDPOINT as an environment variable on the device running your server. Upon startup, the server retrieves this value and makes it accessible through the env Context variable.  This approach allows us to change the API endpoint without modifying our codebase. For instance, we might use different API endpoints for development (stage-api.example.com) and production (api.example.com) environments.  Remember, environment variables are not limited to the baseUrl or @http directive. You can use them throughout your schema, as a Mustache template handles their evaluation.  Here's another example, using an environment variable in the headers of @grpc:  type Query { users: [User] @grpc( service: &quot;UserService&quot; method: &quot;ListUsers&quot; protoPath: &quot;./proto/user_service.proto&quot; baseURL: &quot;https://grpc-server.example.com&quot; headers: [ {key: &quot;X-API-KEY&quot;, value: &quot;{{.env.API_KEY}}&quot;} ] ) }   ","version":"Next","tagName":"h2"},{"title":"Security Aspects and Best Practices‚Äã","type":1,"pageTitle":"Reading Environment Variables","url":"/docs/graphql-environment-variables/#security-aspects-and-best-practices","content":" Environment variables help reduce security risks, but it's crucial to understand that they do not remove these risks entirely because the values are in plain text. Even if configuration values are not always highly sensitive, there is still a potential for compromising secrets. To ensure your secrets remain secure, consider the following tips:  Use a .env file: It's a common practice to create a .env file in your project's root directory for storing all environment variables. Avoid committing this file to your version control system; instead, add it to .gitignore to prevent public exposure of your secrets. For clarity and collaboration, maintain a .env.example file that enumerates all the necessary environment variables for your application, thereby guiding other developers on what variables they need to set. Within Tailcall (or in other environments), you can make use of this .env file by exporting its key-value pairs to your operating system. For example, if your .env file looks like this: API_ENDPOINT=https://jsonplaceholder.typicode.com Export it to your OS with: export $(cat .env | xargs) On Windows: Get-Content .env | Foreach-Object { [System.Environment]::SetEnvironmentVariable($_.Split(&quot;=&quot;)[0], $_.Split(&quot;=&quot;)[1], &quot;User&quot;) } After this, you can access API_ENDPOINT in your codebase. Use Kubernetes Secrets: When deploying your application with Kubernetes, use its Secrets feature to manage environment variables. This approach ensures your secrets remain private and are not embedded in your codebase, while also making it easier to update values as necessary. Store Secrets Through Cloud Provider GUIs: For deployments using a cloud provider, use their GUI for environment variable management. These interfaces are intuitive and practical for containerized applications that automatically scale.  Following these practices ensures effective and secure management of your environment variables. ","version":"Next","tagName":"h2"},{"title":"Honeycomb Telemetry Integration","type":0,"sectionRef":"#","url":"/docs/graphql-honeycomb-telemetry-tailcall/","content":"Honeycomb Telemetry Integration Go to honeycomb.ioLogin to your accountGo to Account -&gt; Team Settings -&gt; Environments and API Keys -&gt; Configuration and create new or copy existing api keyGo to your GraphQL configuration and update settings: schema @telemetry( export: { otlp: { url: &quot;https://api.honeycomb.io:443&quot; headers: [ { key: &quot;x-honeycomb-team&quot; value: &quot;{{.env.HONEYCOMB_API_KEY}}&quot; } { key: &quot;x-honeycomb-dataset&quot; value: &quot;&lt;your-dataset&gt;&quot; } ] } } ) { query: Query } Set the api key you've copied before to the environment variable named HONEYCOMB_API_KEY and start tailcall with updated config Now make some requests to running service and wait a little bit until honeycomb proceeds the data. After that you can go to Home -&gt; Total traces and click on the trace with name request. Now choose Traces in the bottom and click on the first trace from the list. You should see the picture similar to this: Here you can see data about the request that was made to the GraphQL server and what actions were made to handle this request. To see metrics now go Query and run a query to fetch the data about metrics. You can use following screenshot as an example:","keywords":"","version":"Next"},{"title":"Using HTTP Cache","type":0,"sectionRef":"#","url":"/docs/graphql-http-cache-guide-tailcall/","content":"","keywords":"","version":"Next"},{"title":"Understanding HTTP Caching‚Äã","type":1,"pageTitle":"Using HTTP Cache","url":"/docs/graphql-http-cache-guide-tailcall/#understanding-http-caching","content":" HTTP Caching involves saving copies of HTTP responses to serve identical future requests directly from the cache, bypassing the need for new API calls. This reduces latency, conserves bandwidth, and alleviates the load on upstream services by utilizing a cache keyed by request URLs and headers.  By default, HTTP caching is turned off in Tailcall. Enabling it requires setting the httpCache parameter to integer value which is greater than 0 in the @upstream configuration. Tailcall employs a in-memory Least_Recently_Used (LRU) cache mechanism to manage stored responses, adhering to upstream-provided caching directives like Cache-Control to optimize the caching process and minimize redundant upstream API requests.  ","version":"Next","tagName":"h3"},{"title":"Enabling HTTP Caching‚Äã","type":1,"pageTitle":"Using HTTP Cache","url":"/docs/graphql-http-cache-guide-tailcall/#enabling-http-caching","content":" To activate HTTP caching, adjust the upstream configuration in Tailcall by setting httpCache to appropriate cache size, as shown in the following example:  schema @server(port: 4000) @upstream( baseURL: &quot;https://api.example.com&quot; httpCache: 42 ) { query: Query }   This configuration instructs Tailcall to cache responses from the designated upstream API.  ","version":"Next","tagName":"h3"},{"title":"Cache-Control headers in responses‚Äã","type":1,"pageTitle":"Using HTTP Cache","url":"/docs/graphql-http-cache-guide-tailcall/#cache-control-headers-in-responses","content":" Enabling the cacheControl setting in Tailcall ensures that Cache-Control headers are included in the responses returned to clients. When activated, Tailcall dynamically sets the max-age directive in the Cache-Control header to the minimum max-age value encountered in any of the responses from upstream services. This approach guarantees that the caching duration for the composite response is conservative, aligning with the shortest cache validity period provided by the upstream services. By default, this feature is disabled (false), meaning Tailcall will not modify or add Cache-Control headers unless explicitly instructed to do so. This setting is distinct from the general HTTP cache setting, which controls whether responses are cached internally by Tailcall; cacheControl specifically controls the caching instructions sent to clients.  Here is how you can enable the cacheControl setting within your Tailcall schema to apply these caching instructions:  schema @server(headers: {cacheControl: true}) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"Best Practices for Enhancing REST API Performance on GraphQL‚Äã","type":1,"pageTitle":"Using HTTP Cache","url":"/docs/graphql-http-cache-guide-tailcall/#best-practices-for-enhancing-rest-api-performance-on-graphql","content":" The combination of httpCache and cacheControl provides a comprehensive caching solution. While httpCache focuses on internal caching to reduce the impact of high latency and frequent requests, cacheControl manages client-side caching policies, ensuring an optimal balance between performance, data freshness, and efficient resource use.  These caching primitives are beneficial for REST APIs that are latency-sensitive, have a high rate of request repetition, or come with explicit caching headers indicating cacheable responses. Together, they tackle the common challenges of optimizing REST API performance by minimizing unnecessary network traffic and server load while ensuring response accuracy.  To further enhance the performance of any API with Tailcall, integrating the @cache directive offers protocol agnostic control over caching at the field level within a GraphQL schema. ","version":"Next","tagName":"h3"},{"title":"GraphQL over HTTP/2","type":0,"sectionRef":"#","url":"/docs/graphql-http2-guide-tailcall/","content":"","keywords":"","version":"Next"},{"title":"SSL‚Äã","type":1,"pageTitle":"GraphQL over HTTP/2","url":"/docs/graphql-http2-guide-tailcall/#ssl","content":" For Tailcall to serve GraphQL over HTTP/2 we need to first enable SSL for which we need to generate a certificate and a key. To generate the required certificates (cert.pem and key.pem) OpenSSL is a widely used option. Here are the steps to get started with SSL:  Install OpenSSL: Download and install OpenSSL from its official website if it's not already installed on your system. Generate Private Key openssl genrsa -out key.pem 2048 This creates a 2048-bit RSA private key, storing it in a file named key.pem. Generate Certificate Signing Request (CSR) openssl req -new -key key.pem -out csr.pem You will be prompted to provide information for the certificate, such as the Common Name (CN), organization details, and locality. This information is embedded into the CSR, saved in a file named csr.pem. This file can be used to request a certificate from a Certificate Authority (CA) or generate a self-signed certificate. Generate Self-Signed Certificate openssl x509 -req -days 365 -in csr.pem -signkey key.pem -out cert.pem This generates a self-signed certificate valid for 365 days using the CSR from step 3 and the private key from step 2. The validity period can be adjusted by changing the number of days (-days). A &quot;Signature ok&quot; prompt confirms the successful creation. Cleanup Intermediate Files rm csr.pem After using the CSR to generate the self-signed certificate (cert.pem), the CSR file (csr.pem) becomes redundant. This step removes intermediate files created during the certificate generation process.  tip Use self-signed certificates for HTTP/2 configurations in development environments. While they enable convenient HTTPS testing locally, in production, always opt for certificates issued by trusted Certificate Authorities.  ","version":"Next","tagName":"h2"},{"title":"Configuration‚Äã","type":1,"pageTitle":"GraphQL over HTTP/2","url":"/docs/graphql-http2-guide-tailcall/#configuration","content":" Once the certificate and key are generated we can link them with our main configuration using the @link directive, to enable HTTPS.  schema @link(type: &quot;Cert&quot;, src: &quot;./cert.pem&quot;) @link(type: &quot;Key&quot;, src: &quot;./key.pem&quot;) { query: Query mutation: Mutation } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type User { id: Int! name: String! }   Once HTTPS is enabled we set the version to HTTP2 for the server:  schema @link(type: &quot;Cert&quot;, src: &quot;./cert.pem&quot;) @link(type: &quot;Key&quot;, src: &quot;./key.pem&quot;) @server(version: HTTP2) { query: Query mutation: Mutation } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type User { id: Int! name: String! }   That's pretty much all that's required. Now you can go ahead and launch your server as usual.  INFO File read: ./jsonplaceholder.graphql ... ok INFO N + 1 detected: 0 INFO üöÄ Tailcall launched at [0.0.0.0:8000] over HTTP/2.0 INFO üåç Playground: https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql  ","version":"Next","tagName":"h2"},{"title":"Customizing using Javascript","type":0,"sectionRef":"#","url":"/docs/graphql-javascript-customization/","content":"","keywords":"","version":"Next"},{"title":"Getting Started‚Äã","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#getting-started","content":" To leverage this customization, JavaScript functions must be created in a JavaScript file and linked with the main configuration file using the @link directive. There are two primary ways to achieve this:  Define an onRequest property with the JS function name in the http directive.Define it in the upstream directive, which acts as a global middleware for all requests.  tip If you specify a onRequest handler for both http and upstream the http one will always take precedence over the global onRequest handler.  The function serves as middleware, allowing for the interception and modification of the request, as well as the production of artificial responses. Here is a simple example of a worker.js file with a function named foo, which takes a request object as an argument, logs the request, and returns the original request without any modifications.  function foo({request}) { console.log(`${request.method} ${request.uri.path}`) return {request} }   Once you have a worker file ready, link that file to the GraphQL configuration using the @link directive and define the onRequest property.  schema @link(type: Script, src: &quot;./worker.js&quot;) @upstream(onRequest: &quot;foo&quot;) { query: Query }   Now, you can start the server using the usual start command. Requests made to the GraphQL server will now be intercepted by the worker and logged to the console.  ","version":"Next","tagName":"h2"},{"title":"Modify Request‚Äã","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#modify-request","content":" You can modify the request by returning a request object from the onRequest function. Below is an example where we are modifying the request to add a custom header.  function onRequest({request}) { request.headers[&quot;x-custom-header&quot;] = &quot;Hello, Tailcall!&quot; return {request} }   ","version":"Next","tagName":"h2"},{"title":"Create Response‚Äã","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#create-response","content":" You can respond with custom responses by returning a response object from the onRequest function. Below is an example where we are responding with a custom response for all requests that start with https://api.example.com.  function onRequest({request}) { if (request.uri.path.startsWith(&quot;https://api.example.com&quot;)) { return { response: { status: 200, headers: { &quot;content-type&quot;: &quot;application/json&quot; }, body: JSON.stringify({message: &quot;Hello, Tailcall!&quot;}) } } } else { return {request} }   ","version":"Next","tagName":"h2"},{"title":"Response Redirect‚Äã","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#response-redirect","content":" Sometimes you might want to redirect the request to a different URL. You can do this by returning a response object with a status of 301 or 302 and a Location header. The following example redirects all requests to https://example.com to https://tailcall.com.  function onRequest({request}) { if (request.uri.path.startsWith(&quot;https://example.com&quot;)) { return { response: { status: 301, headers: { Location: &quot;https://tailcall.com&quot;, }, }, } } else { return {request} } }   important The new request that's created as a result of the redirect will not be intercepted by the worker.  ","version":"Next","tagName":"h2"},{"title":"Schema‚Äã","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#schema","content":" The onRequest function takes a single argument that contains the request object. The return value of the onRequest function can be a request object, or a response object. It can not be null or undefined.  ","version":"Next","tagName":"h2"},{"title":"Request‚Äã","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#request","content":" The request object has the following shape:  type Request = { method: string uri: { path: string query?: {[key: string]: string} scheme: &quot;Http&quot; | &quot;Https&quot; host?: string port?: number } headers: {[key: string]: string} body?: string }   By default the headers field will be empty in most cases, unless headers are whitelisted via the allowedHeaders setting in @upstream.  The http filter doesn't have access to the request's body, hence you can't directly modify the body of an outgoing request. This is more of a design choice than a limitation we have made to ensure that developers don't misuse this API to write all kind of business logic in Tailcall.  tip As an escape hatch you can pass the request body as a query param instead of an actual request body and read in the JS.  The modified request that's returned from the above onRequest function can optionally provide the body. This body is used by Tailcall as the request body while making the upstream request.  ","version":"Next","tagName":"h3"},{"title":"Response‚Äã","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#response","content":" The response object has the following shape:  type Response = { status: number headers: {[key: string]: string} body?: string }  ","version":"Next","tagName":"h3"},{"title":"Logging Levels Configuration","type":0,"sectionRef":"#","url":"/docs/graphql-logging-levels-tailcall/","content":"","keywords":"","version":"Next"},{"title":"error‚Äã","type":1,"pageTitle":"Logging Levels Configuration","url":"/docs/graphql-logging-levels-tailcall/#error","content":" This is the highest severity level. It indicates a critical issue that may lead to the failure of the program or a part of it.  TAILCALL_LOG_LEVEL=error tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=error tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"warn‚Äã","type":1,"pageTitle":"Logging Levels Configuration","url":"/docs/graphql-logging-levels-tailcall/#warn","content":" This log level signifies potential issues or warnings that do not necessarily result in immediate failure but may require attention.  TAILCALL_LOG_LEVEL=warn tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=warn tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"info‚Äã","type":1,"pageTitle":"Logging Levels Configuration","url":"/docs/graphql-logging-levels-tailcall/#info","content":" This level offers general information about the program's execution, providing insights into its state and activities.  TAILCALL_LOG_LEVEL=info tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=info tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"debug‚Äã","type":1,"pageTitle":"Logging Levels Configuration","url":"/docs/graphql-logging-levels-tailcall/#debug","content":" The debug log level is useful for developers during the debugging process, providing detailed information about the program's internal workings.  TAILCALL_LOG_LEVEL=debug tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=debug tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"trace‚Äã","type":1,"pageTitle":"Logging Levels Configuration","url":"/docs/graphql-logging-levels-tailcall/#trace","content":" The trace log level is the most detailed logging level, used for fine-grained debugging. This level provides exhaustive details about the program's execution flow.  TAILCALL_LOG_LEVEL=trace tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=trace tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"off‚Äã","type":1,"pageTitle":"Logging Levels Configuration","url":"/docs/graphql-logging-levels-tailcall/#off","content":" This level serves as a special indicator for generating no logs, allowing the option to disable logging entirely.  TAILCALL_LOG_LEVEL=off tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=off tailcall &lt;COMMAND&gt;   info The default log level is info.  Log levels are hierarchical, meaning if you set the log level to a specific level, it includes all the levels above it. For example, setting the log level to info will include logs at the info, warn, and error levels, but exclude debug and trace logs.    info You can specify log levels in either uppercase or lowercase; both yield the same result. For example, TAILCALL_LOG_LEVEL=DEBUG and TAILCALL_LOG_LEVEL=debug are same. ","version":"Next","tagName":"h3"},{"title":"New Relic Telemetry Integration","type":0,"sectionRef":"#","url":"/docs/graphql-newrelic-guide-telemetry/","content":"New Relic Telemetry Integration The guide is based on official doc Go to newrelic.comLogin to your accountGo to &lt;your user name&gt; -&gt; Api Keys and copy license value for key with access to write dataGo to GraphQL configuration and update it with: schema @telemetry( export: { otlp: { url: &quot;https://otlp.nr-data.net:4317&quot; headers: [ { key: &quot;api-key&quot; value: &quot;{{.env.NEWRELIC_API_KEY}}&quot; } ] } } ) { query: Query } Set the api key you've copied before to the environment variable named NEWRELIC_API_KEY and start tailcall with updated config Now make some requests to running service and wait a little bit until New Relic proceeds the data. After that you can go to Traces locate request trace, click on it, then pick one of the available traces and click on it. You should see something like the screenshot below: To see metrics now go to APM &amp; Services -&gt; Metrics Explorer and choose the metrics you want to see like on example below.","keywords":"","version":"Next"},{"title":"GraphQL Playground","type":0,"sectionRef":"#","url":"/docs/graphql-playground-guide/","content":"","keywords":"","version":"Next"},{"title":"Performance and Security‚Äã","type":1,"pageTitle":"GraphQL Playground","url":"/docs/graphql-playground-guide/#performance-and-security","content":" Performance Impact: The showcase feature prioritizes flexibility and ease of testing over speed, leading to slower response times due to the overhead of dynamically applied configurations.Security Risk: There's a potential security risk as it may allow unauthorized access to files and environment variables.  important Due to these concerns, this mode is not recommended for production environments. ","version":"Next","tagName":"h2"},{"title":"Step-by-Step Tutorial: Building GraphQL over gRPC","type":0,"sectionRef":"#","url":"/docs/graphql-grpc-tailcall/","content":"","keywords":"","version":"Next"},{"title":"What is gRPC?‚Äã","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#what-is-grpc","content":" This guide assumes a basic familiarity with gRPC. It is a high-performance framework created by Google for remote procedure calls (RPCs). Its key features include:  HTTP/2 Transport: Ensures efficient and fast data transfer.Protocol Buffers (Protobuf): Serves as a powerful interface description language.Efficiency: Offers binary serialization, reduces latency, and supports data streaming.  This combination of features makes gRPC ideal for microservices and distributed systems. If you need a more detailed understanding or are new to gRPC, we recommend visiting the official gRPC website for comprehensive documentation and resources.  Now, let's explore how gRPC can be integrated into our proxy gateway to enhance communication and data exchange in distributed systems.  ","version":"Next","tagName":"h2"},{"title":"gRPC upstream‚Äã","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#grpc-upstream","content":" We need some gRPC service available to be able to execute requests from the Tailcall gateway. For pure example purposes, we will build some simple gRPC services.  ","version":"Next","tagName":"h2"},{"title":"Protobuf definition‚Äã","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#protobuf-definition","content":" First, we need to create an example protobuf file that will define the structure of the data we want to transmit using gRPC. Here is the definition of NewsService that implements CRUD operations on news data that we'll put into the news.proto file.  syntax = &quot;proto3&quot;; import &quot;google/protobuf/empty.proto&quot;; package news; // Define message type for News with all its fields message News { int32 id = 1; string title = 2; string body = 3; string postImage = 4; } // Message with the id of a single news message NewsId { int32 id = 1; } // List of IDs of news to get multiple responses message MultipleNewsId { repeated NewsId ids = 1; } // List of all news message NewsList { repeated News news = 1; } // NewsService defines read and write operations for news items service NewsService { // GetAllNews retrieves all news items without any arguments rpc GetAllNews (google.protobuf.Empty) returns (NewsList) {} // GetNews fetches a single news item by its ID rpc GetNews (NewsId) returns (News) {} // GetMultipleNews retrieves multiple news items based on their IDs rpc GetMultipleNews (MultipleNewsId) returns (NewsList) {} }   ","version":"Next","tagName":"h3"},{"title":"Implement gRPC service‚Äã","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#implement-grpc-service","content":" Now having the protobuf file you can write a server that implements NewsService at any language you want that supports gRPC. Tailcall organization has a sample node.js service inside this repo that you can pull to your local machine. To spin up the sample service run inside the repo and wait for logs about the service running.  npm i npm start   ","version":"Next","tagName":"h3"},{"title":"GraphQL Configuration for GRPC‚Äã","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#graphql-configuration-for-grpc","content":" Now when we have a running gRPC service we're going to write Tailcall's config to make the integration. To do this we need to specify GraphQL types corresponding to gRPC types we have defined in the protobuf file. Let's create a new file grpc.graphql file with the following content:  # The GraphQL representation for News message type type News { id: Int title: String body: String postImage: String } # Input type that is used to fetch news data by its id input NewsInput { id: Int } # Resolves multiple news entries type NewsData { news: [News]! }   Now when we have corresponding types in schema we want to define GraphQL Query that specifies the operation we can execute onto news. We can extend our config with the next Query:  type Query { # Get all news i.e. NewsService.GetAllNews news: NewsData! # Get single news by id i.e. NewsService.GetNews newsById(news: NewsInput!): News! }   Also, let's specify options for Tailcall's ingress and egress at the beginning of the config using @server and @upstream directives.  schema @server(port: 8000) @upstream( baseURL: &quot;http://localhost:50051&quot; httpCache: 42 ) { query: Query }   To specify the protobuf file to read types from, use the @link directive with the type Protobuf on the schema. id is an important part of the definition that will be used by the @grpc directive later  schema @link(id: &quot;news&quot;, src: &quot;./news.proto&quot;, type: Protobuf)   Now you can connect GraphQL types to gRPC types. To do this you may want to explore more about @grpc directive. Its usage is pretty straightforward and requires you to specify the path to a method that should be used to make a call. The method name will start with the package name, followed by the service name and the method name, all separated by the . symbol.  If you need to provide any input to the gRPC method call you can specify it with the body option that allows you to specify a Mustache template and therefore it could use any input data like args and value to construct the body request. The body value is specified in the JSON format if you need to create the input manually and cannot use args input.  type Query { news: NewsData! @grpc(method: &quot;news.news.NewsService.GetAllNews&quot;) newsById(news: NewsInput!): News! @grpc( service: &quot;news.news.NewsService.GetNews&quot; body: &quot;{..args.news}}&quot; ) }   Wrapping up the whole result config that may look like this:  # file: app.graphql schema @server(port: 8000) @upstream( baseURL: &quot;http://localhost:50051&quot; httpCache: 42 ) @link(id: &quot;news&quot;, src: &quot;./news.proto&quot;, type: Protobuf) { query: Query } type Query { news: NewsData! @grpc(method: &quot;news.news.NewsService.GetAllNews&quot;) newsById(news: NewsInput!): News! @grpc( method: &quot;news.news.NewsService.GetNews&quot; body: &quot;{{.args.news}}&quot; ) } type News { id: Int title: String body: String postImage: String } input NewsInput { id: Int } type NewsData { news: [News]! }   Start the server by pointing it to the config.  tailcall start ./app.graphql   And now you can go to the page http://127.0.0.1:8000/graphql and execute some GraphQL queries e.g.:  { news { news { id title body } } }   Or  { newsById(news: {id: 2}) { id title body } }   ","version":"Next","tagName":"h2"},{"title":"Batching‚Äã","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#batching","content":" Another important feature of the @grpc directive is that it allows you to implement request batching for remote data almost effortlessly as soon as you have gRPC methods that resolve multiple responses for multiple inputs in a single request.  In our protobuf example file, we have a method called GetMultipleNews that we can use. To enable batching we need to enable @upstream.batch option first and specify batchKey option for the @grpc directive.  schema @server(port: 8000) @upstream( baseURL: &quot;http://localhost:50051&quot; httpCache: 42 batch: {delay: 10} ) @link(id: &quot;news&quot;, src: &quot;./news.proto&quot;, type: Protobuf) { query: Query } type Query { newsById(news: NewsInput!): News! @grpc( method: &quot;news.NewsService.GetNews&quot; body: &quot;{{.args.news}}&quot; batchKey: [&quot;news&quot;, &quot;id&quot;] ) }   Restart the GraphQL server and make the query with multiple news separately, e.g.:  { n1: newsById(news: {id: 1}) { id title body } n2: newsById(news: {id: 2}) { id title body } }   Those 2 requests will be executed inside a single request to the gRPC method GetMultipleNews  ","version":"Next","tagName":"h2"},{"title":"Reflection‚Äã","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#reflection","content":" gRPC reflection is a potent feature enabling clients to dynamically discover services and their methods at runtime. Tailcall enhances this capability by obviating the need for developers to link each proto file individually. This feature proves particularly valuable in environments where proto files are continuously evolving or when services dynamically expose varying methods. Here are the steps to follow:  Add the gRPC endpoint as a [link] with type set to Grpc. This enables the GraphQL server to understand that the specified source is a gRPC endpoint that supports reflection. schema @link( src: &quot;https://my-grpc-service.com:50051&quot; type: Grpc ) { query: Query } Next, as before we will just add the methods with a fully qualified name: type Query { news: [News] @grpc(method: &quot;news.NewsService.GetAllNews&quot;) } type News { id: Int title: String body: String postImage: String }   ","version":"Next","tagName":"h2"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#conclusion","content":" Well done on integrating a gRPC service with the Tailcall gateway! This tutorial has demonstrated the straightforward and efficient process, showcasing Tailcall's compatibility with advanced communication protocols like gRPC.  You can find this working example and test it by yourself by the next links:  node-grpc - example implementation for gRPC service in node.jsgRPC example config - Tailcall's config to integrate with gRPC service above  ","version":"Next","tagName":"h2"},{"title":"Key Takeaways‚Äã","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#key-takeaways","content":" Simplicity of Integration: The integration of gRPC with Tailcall seamlessly enhances the overall capability of your system to handle high-performance and efficient data composition.Scalability and Performance: By leveraging the power of gRPC along with Tailcall, we've laid a foundation for building scalable and high-performing distributed systems.  ","version":"Next","tagName":"h3"},{"title":"Next Steps‚Äã","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#next-steps","content":" With the basics in place, we encourage you to explore further:  Dive Deeper: Tailcall gateway offers a lot of other features and configurations that you can utilize. Dive deeper into our documentation to explore more advanced settings and customization options.Explore Other Guides: Our documentation includes a variety of guides and tutorials that can help you leverage the full potential of Tailcall in different scenarios. Whether it's adding security layers, load balancing, or detailed logging, there's a lot more to explore. ","version":"Next","tagName":"h3"},{"title":"GraphQL Resolver Context","type":0,"sectionRef":"#","url":"/docs/graphql-resolver-context-tailcall/","content":"","keywords":"","version":"Next"},{"title":"Schema Definition‚Äã","type":1,"pageTitle":"GraphQL Resolver Context","url":"/docs/graphql-resolver-context-tailcall/#schema-definition","content":" type Context = { args: Map&lt;string, JSON&gt; value: JSON env: Map&lt;string, string&gt; vars: Map&lt;string, string&gt; headers: Map&lt;string, string&gt; }   Context operates by storing values as key-value pairs, which can be accessed through mustache template syntax.  ","version":"Next","tagName":"h2"},{"title":"args‚Äã","type":1,"pageTitle":"GraphQL Resolver Context","url":"/docs/graphql-resolver-context-tailcall/#args","content":" This property facilitates access to query arguments. Consider the example:  type Query { user(id: ID!): User @http(path: &quot;/users/{{.args.id}}&quot;) }   Here, args.id is utilized to retrieve the id argument provided to the user query.  ","version":"Next","tagName":"h3"},{"title":"value‚Äã","type":1,"pageTitle":"GraphQL Resolver Context","url":"/docs/graphql-resolver-context-tailcall/#value","content":" This enables access to the fields of the specified type.  type Post { id: ID! title: String! body: String! comments: [Comment] @http(path: &quot;/posts/{{.value.id}}/comments&quot;) }   In this case, value.id accesses the id field of the Post type.  ","version":"Next","tagName":"h3"},{"title":"env‚Äã","type":1,"pageTitle":"GraphQL Resolver Context","url":"/docs/graphql-resolver-context-tailcall/#env","content":" Environment variables, set at server startup, allow directives to dynamically adapt behavior based on external configurations without altering the server configuration itself.  Example:  type Query { users: [User]! @http(baseUrl: &quot;{{.env.API_ENDPOINT}}&quot;, path: &quot;/users&quot;) }   env.API_ENDPOINT references an environment variable named API_ENDPOINT, which specifies the base URL for HTTP requests.  ","version":"Next","tagName":"h3"},{"title":"vars‚Äã","type":1,"pageTitle":"GraphQL Resolver Context","url":"/docs/graphql-resolver-context-tailcall/#vars","content":" vars offers a mechanism for defining reusable variables within the configuration. Unlike env, these are embedded and can be universally applied across configurations.  schema @server( vars: {key: &quot;apiKey&quot;, value: &quot;{{.env.AUTH_TOKEN}}&quot;} ) { query: Query } type Query { user(id: ID!): [User] @http( url: &quot;/users&quot; headers: [ { key: &quot;Authorization&quot; value: &quot;Bearer {{.vars.apiKey}}&quot; } ] ) }   Here, the variable apiKey is set using an environment variable and subsequently utilized in the Authorization header for HTTP requests.  ","version":"Next","tagName":"h3"},{"title":"headers‚Äã","type":1,"pageTitle":"GraphQL Resolver Context","url":"/docs/graphql-resolver-context-tailcall/#headers","content":" Headers originate from the request made to the GraphQL server.  type Query { commentsForUser: [Comment] @http(path: &quot;/users/{{.headers.x-user-id}}/comments&quot;) }   In this example, headers.x-user-id extracts the value of the x-user-id header present in the request, dynamically constructing the request path. ","version":"Next","tagName":"h3"},{"title":"Exposing GraphQL as REST APIs","type":0,"sectionRef":"#","url":"/docs/graphql-rest-integration/","content":"","keywords":"","version":"Next"},{"title":"How it works‚Äã","type":1,"pageTitle":"Exposing GraphQL as REST APIs","url":"/docs/graphql-rest-integration/#how-it-works","content":" This guide show you how to expose REST endpoints for your GraphQL operations by using the @rest directive like follows:  There are three main steps to this process:  Define your Tailcall GraphQL configuration file.Define an operation using @rest directive in a separate file.Link the operation to the main config file.  ","version":"Next","tagName":"h2"},{"title":"Example‚Äã","type":1,"pageTitle":"Exposing GraphQL as REST APIs","url":"/docs/graphql-rest-integration/#example","content":" ","version":"Next","tagName":"h2"},{"title":"Step 1: Define your GraphQL configuration‚Äã","type":1,"pageTitle":"Exposing GraphQL as REST APIs","url":"/docs/graphql-rest-integration/#step-1-define-your-graphql-configuration","content":" schema @upstream( baseURL: &quot;https://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { post(id: Int!): Post @http(path: &quot;/posts/{{.args.id}}&quot;) } type Post { userId: Int! id: Int title: String body: String user: User @http(path: &quot;/users/{{.value.userId}}&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String }   for more information on how to define your Tailcall GraphQL configuration file, please refer to the Tailcall GraphQL Configuration.  ","version":"Next","tagName":"h3"},{"title":"Step 2: Define an operation using @rest directive‚Äã","type":1,"pageTitle":"Exposing GraphQL as REST APIs","url":"/docs/graphql-rest-integration/#step-2-define-an-operation-using-rest-directive","content":" We will define an operation and use the @rest directive to define a REST endpoint for the operation. We will create a new file and add the following content to it. Save the file with the filename: user-operation.graphql. You can name the file anything you want, but make sure to link it to the main config file in the next step.  query ($id: Int!) @rest(method: GET, path: &quot;/post/$id&quot;) { post(id: $id) { id title body user { id name } } }   to know more about the @rest directive, please refer to the Tailcall GraphQL Directives.  ","version":"Next","tagName":"h3"},{"title":"Step 3: Link the operation to the main config file‚Äã","type":1,"pageTitle":"Exposing GraphQL as REST APIs","url":"/docs/graphql-rest-integration/#step-3-link-the-operation-to-the-main-config-file","content":" checkout the @link directive in the config snippet below to link the operation file. This step is crucial to make the REST endpoint available.  schema @upstream(baseURL: &quot;https://jsonplaceholder.typicode.com&quot;) @link(type: Operation, src: &quot;user-operation.graphql&quot;) { query: Query }   To know more about the @link directive, please refer to the Tailcall GraphQL Directives.  Response‚Äã    In summary, by utilizing the @rest directive, we've seamlessly exposed RESTful services over Tailcall's GraphQL, enhancing the traditional posts API to offer richer functionality without additional code. This approach combines the simplicity and ubiquity of REST with the modularity and flexibility of GraphQL, allowing for easy consumption from any HTTP client while leveraging GraphQL's powerful data querying capabilities. ","version":"Next","tagName":"h3"},{"title":"Solving GraphQL N+1 Problem with Tailcall","type":0,"sectionRef":"#","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/","content":"","keywords":"","version":"Next"},{"title":"What is the N+1 Problem?‚Äã","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#what-is-the-n1-problem","content":" In simple terms, the N+1 problem occurs when your server fetches data in an inefficient manner that is - instead of making a single request to retrieve necessary data set, it makes multiple, separate requests.  For instance, if you're fetching a list of posts and their authors, an inefficient server might first fetch the posts (1 request). Then, for each post, it makes request to fetch their author (N requests). This results in N+1 total requests.  This approach can quickly become problematic as your nested data grows. It leads to a large number of unnecessary requests, slowing down your server and wasting resources.  ","version":"Next","tagName":"h2"},{"title":"Why is N+1 a Problem for GraphQL?‚Äã","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#why-is-n1-a-problem-for-graphql","content":" The N+1 problem in GraphQL queries can lead to inefficiencies in data fetching due to poorly optimized resolvers. Let's delve into this issue with a simplified explanation:  Resolver Efficiency: In GraphQL, each nested field within a single query might require its own request. For instance, if you're dealing with a list of N items, this results in N additional requests, culminating in a total of N+1 requests. Complexity in Detection: Identifying and resolving the N+1 problem can be challenging for developers, especially by merely examining GraphQL queries, schema or the server side resolver logic. Optimization Necessity: Addressing this issue often requires employing advanced techniques such as batching request or utilizing open source tools like DataLoader for batch loading to minimize the number of requests triggered by resolvers on your GraphQL server. While effective, these solutions can introduce additional complexity into the development process.    ","version":"Next","tagName":"h2"},{"title":"N+1 in REST APIs‚Äã","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#n1-in-rest-apis","content":" Imagine we need to fetch data from the jsonplaceholder.typicode.com, requiring both posts and their authors' details.  First, we request all posts:  ‚ùØ curl https://jsonplaceholder.typicode.com/posts [ { &quot;userId&quot;: 1, &quot;id&quot;: 1, &quot;title&quot;: &quot;Creating Solutions for Challenges&quot;, &quot;body&quot;: &quot;We anticipate and understand challenges, creating solutions while considering exceptions and criticisms.&quot; }, { &quot;userId&quot;: 1, &quot;id&quot;: 2, &quot;title&quot;: &quot;Understanding Identity&quot;, &quot;body&quot;: &quot;Life's essence, measured through time, presents pains and joys. We find solace in the mundane, seeking meaning beyond the visible.&quot; } ]   This command retrieves posts from the API, with each post containing a userId field indicating its author.  Next, we fetch details for each post's author, such as:  ‚ùØ curl https://jsonplaceholder.typicode.com/users/1 { &quot;id&quot;: 1, &quot;name&quot;: &quot;Leanne Graham&quot;, &quot;username&quot;: &quot;Bret&quot;, &quot;email&quot;: &quot;Sincere@april.biz&quot;, &quot;address&quot;: { &quot;street&quot;: &quot;Kulas Light&quot;, &quot;suite&quot;: &quot;Apt. 556&quot;, &quot;city&quot;: &quot;Gwenborough&quot;, &quot;zipcode&quot;: &quot;92998-3874&quot;, &quot;geo&quot;: { &quot;lat&quot;: &quot;-37.3159&quot;, &quot;lng&quot;: &quot;81.1496&quot; } }, &quot;phone&quot;: &quot;1-770-736-8031 x56442&quot;, &quot;website&quot;: &quot;hildegard.org&quot;, &quot;company&quot;: { &quot;name&quot;: &quot;Romaguera-Crona&quot;, &quot;catchPhrase&quot;: &quot;Multi-layered client-server neural-net&quot;, &quot;bs&quot;: &quot;harness real-time e-markets&quot; } }   For 100 posts, this results in 100 additional requests for author details, totaling 101 requests. This is the infamous N+1 problem:  1 request for /posts100 or N requests for /users/:id for each user  info This issue can escalate in real-world scenarios, leading to straining resources, increasing server costs, slowing response times, and potentially causing server downtime even at a moderate scale.  Hope this gives you a high-level overview of what the N+1 problem is in the API context. It's a common problem not specific to just APIs or GraphQL, you will see this problem very commonly in database queries also. However addressing the N+1 problem during application design and development is crucial and we will see how this is tackled in Tailcall.  ","version":"Next","tagName":"h2"},{"title":"N+1 in GraphQL using Tailcall‚Äã","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#n1-in-graphql-using-tailcall","content":" Before diving into solutions, let's observe the N+1 problem in the following GraphQL configuration:  tip If you are new here you might want to check out our Getting Started guide.  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) } type User { id: Int! name: String! username: String! email: String! }   This configuration sets up a GraphQL schema for a server utilizing jsonplaceholder.typicode.com as its data source. It allows direct querying of posts and, for each post, retrieves the associated author information. Similar to our curl requests above, when we query for posts and their authors using graphql query on client side given below we end up issuing multiple user calls upstream:  query { posts { id title user { id name email } } }   Let's examine the CLI output for this configuration with Tailcall's start command:  ‚ùØ tailcall start ./examples/jsonplaceholder.graphql INFO File read: ./examples/jsonplaceholder.graphql ... ok INFO N+1 detected: 1 INFO üöÄ Tailcall launched at [0.0.0.0:8000] over HTTP/1.1 INFO üåç Playground: https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql INFO GET http://jsonplaceholder.typicode.com/posts HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/8 HTTP/1.1 ... INFO GET http://jsonplaceholder.typicode.com/users/8 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/10 HTTP/1.1   Tailcall logs a sequence of requests made to fetch posts and then their individual authors, highlighting the N+1 problem in real-time. Since there are 100 posts, so 100 requests are made to fetch the authors.  ","version":"Next","tagName":"h2"},{"title":"Deduplication using DataLoaders‚Äã","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#deduplication-using-dataloaders","content":" If you run the query, at first you will observe a lot of duplicate requests are being made for getting the same author details.    This happens because of the 100 posts, a lot them are authored by the same user and by default Tailcall will make a request for every user when requested. You can fix this by setting dedupe to true in server.  schema @server( dedupe: true port: 8000) @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query } type Query { # ... } type Post { # ... } type User { # ... }   When you enable dedupe, for each downstream request, Tailcall will automatically using a dataloader deduplicate all upstream requests and instead of making 100 it will only make 10 requests for unique users:  ‚ùØ tailcall start ./examples/jsonplaceholder.graphql INFO File read: ./examples/jsonplaceholder.graphql ... ok INFO N+1 detected: 1 INFO üöÄ Tailcall launched at [0.0.0.0:8000] over HTTP/1.1 INFO üåç Playground: https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql INFO GET http://jsonplaceholder.typicode.com/posts HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/1 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/2 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/3 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/4 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/5 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/6 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/7 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/8 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/9 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/10 HTTP/1.1   This is a massive 10x improvement over the previous implementation. However, it might not always be the case. For eg: If all the posts are created by different users you might still end up making 100 requests upstream.    tip Dedupe has a slight performance overhead so if your use case doesn't have any N+1 issues, it might be worth keeping this setting disabled.  ","version":"Next","tagName":"h2"},{"title":"Detect N+1 using Tailcall‚Äã","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#detect-n1-using-tailcall","content":" Before we get into the actual solution, if you observe closely the above logs Tailcall identified that there was one N+1 issue, even before the requests were made:  ‚ùØ tailcall start ./examples/jsonplaceholder.graphql INFO File read: ./examples/jsonplaceholder.graphql ... ok INFO N+1 detected: 1 INFO üöÄ Tailcall launched at [0.0.0.0:8000] over HTTP/1.1 INFO üåç Playground: https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql INFO GET http://jsonplaceholder.typicode.com/posts HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/8 HTTP/1.1 ... INFO GET http://jsonplaceholder.typicode.com/users/10 HTTP/1.1   To get a deeper understanding of what this N+1 issue is, we can use the --n-plus-one-queries parameter with the check command:  ‚ùØ tailcall check ./jsonplaceholder.graphql --n-plus-one-queries INFO File read: ./examples/jsonplaceholder.graphql ... ok INFO Config ./examples/jsonplaceholder.graphql ... ok INFO N+1 detected: 1 query { posts { user } }   Incredible, isn't it? Tailcall has discovered that querying for posts followed by their users would result in N+1 upstream calls. This represents a significant productivity gain, as you can now identify all such N+1 issues upfront without resorting to complex profiling, tracing, or other runtime techniques. The check command also identifies the minimal query that could lead to these N+1 problems by performing semantic analysis of your configuration. With these powerful tools handy you can go about making extremely efficient GraphQL backends as we will see next:  ","version":"Next","tagName":"h2"},{"title":"Using Batch APIs‚Äã","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#using-batch-apis","content":"   An effective technique to mitigate the N+1 problem is deduplicating similar requests, significantly reducing the number of server calls. We achieved it previously using the dedupe setting. With Tailcall we can go one step further by giving hints about &quot;batch APIs&quot;.  Batch APIs: Are special APIs that allow us to query multiple things at once. In our case we can pass multiple user Ids as query params, to the /users API to resolve many users at once:  tip Try to hit /users?id=1&amp;id=2  TailCall provides the capability to leverage Batch APIs. To utilize this feature, edit the @http directive on Post.user field in your GraphQL schema as follows:  type Post { id: Int! userId: Int! title: String! body: String! user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{.value.userId}}&quot;}] batchKey: [&quot;id&quot;] ) }   The described changes introduce two significant tweaks to the @http directive:  Addition of a query parameter: type Post { # ... user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{.value.userId}}&quot;}] batchKey: [&quot;id&quot;] ) } This configuration generates a URL with the userId from the Post in the query params. For a batch of users, the CLI compiles a single URL, such as /users?id=1&amp;id=2&amp;id=3...id=10, consolidating the 10 requests into one. Addition of a batchKey: type Post { # ... user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{.value.userId}}&quot;}] batchKey: [&quot;id&quot;] ) } This parameter instructs the system to use the user's id, in the User type, as the unique identifier. This helps in differentiating between users received from the batch API.  Let's see what the server logs when you now start Tailcall with the updated configuration:  schema @server(port: 8000) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{.value.userId}}&quot;}] batchKey: [&quot;id&quot;] ) } type User { id: Int! name: String! username: String! email: String! }   Let's start the server as usual and focus on the detected N+1 issues:  ‚ùØ tailcall start ./examples/jsonplaceholder.graphql INFO File read: ./examples/jsonplaceholder.graphql ... ok INFO N+1 detected: 0 INFO üöÄ Tailcall launched at [0.0.0.0:8000] over HTTP/1.1 INFO üåç Playground: https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql INFO GET http://jsonplaceholder.typicode.com/posts HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users?id=1&amp;id=10&amp;id=2&amp;id=3&amp;id=4&amp;id=5&amp;id=6&amp;id=7&amp;id=8&amp;id=9 HTTP/1.1   As you can see there are ZERO N+1 detected this time! It basically means that irrespective of how large the list of posts is there is a finite number of requests that will be issued in this case that's always going to be TWO. And this is how Tailcall users tackle the N+1 problem in GraphQL.  ","version":"Next","tagName":"h2"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#conclusion","content":" To summarize, we learnt that N+1 is a general problem and not specific to GraphQL. It's a hard problem to identify, and developers often resort to runtime analysis to find such scenarios. N+1 can really strain your infrastructure, leading to serious downtime in certain cases.    We also learnt that in Tailcall, the CLI can introspect your configuration and identify all the potential N+1 issues upfront. Using dedupe, you can improve the N+1 problem significantly, however, it's not a complete solution. To completely eliminate the N+1 problem, you can configure Tailcall to leverage Batch APIs. Hopefully, this guide underscores the effectiveness of Tailcall in addressing the N+1 problem.   ","version":"Next","tagName":"h2"},{"title":"GraphQL Telemetry","type":0,"sectionRef":"#","url":"/docs/graphql-telemetry-guide/","content":"","keywords":"","version":"Next"},{"title":"What is Observability‚Äã","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#what-is-observability","content":" Observability is essential for maintaining the health and performance of your applications. It provides insights into your software's operation in real-time by analyzing telemetry data ‚Äî logs, metrics, and traces. This data helps in troubleshooting, optimizing, and ensuring your application works as expected.  Logs offer a record of events that have happened within your application, useful for understanding actions taken or errors that have occurred.Metrics are numerical data that measure different aspects of your system's performance, such as request rates or memory usage.Traces show the journey of requests through your system, highlighting how different parts of your application interact and perform.  Tailcall provides observability support by integrating OpenTelemetry specification into it with help of provided SDKs and data formats.  OpenTelemetry is a toolkit for collecting telemetry data in a consistent manner across different languages and platforms. It frees you from being locked into a single observability platform, allowing you to send your data to different tools for analysis, such as New Relic or Honeycomb.  ","version":"Next","tagName":"h2"},{"title":"Comparison with Apollo Studio‚Äã","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#comparison-with-apollo-studio","content":" While Apollo studio telemetry also provides analytics tools for your schema but when choosing between it and OpenTelemetry integration consider next points:  OpenTelemetry is more generalized observability framework that could be used for cross-service analytics while Apollo Studio can provide insights related purely to graphQLOpenTelemetry is vendor-agnostic and therefore you could actually use different observability platforms depending on your needs and don't rely on single tool like Apollo StudioOpenTelemetry integration in Tailcall can provide more analytical data that is out of scope of graphQL analytics provided by Apollo Studio  ","version":"Next","tagName":"h2"},{"title":"Prerequisites‚Äã","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#prerequisites","content":" Consider we have the following GraphQL configuration that connects with jsonplaceholder.com to fetch the data about user and posts  schema @server(port: 8000, hostname: &quot;0.0.0.0&quot;) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) @cache(maxAge: 3000) user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) }   We will update that config with telemetry integration in following sections.  ","version":"Next","tagName":"h2"},{"title":"GraphQL Configuration for Telemetry‚Äã","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#graphql-configuration-for-telemetry","content":" By default, telemetry data is not generated by Tailcall since it requires some setup to know where to send this data and also that affects performance of server that could be undesirable in some cases.  Telemetry configuration is provided by @telemetry directive to setup how and where the telemetry data is send.  To enable it we can update our config with something like config below:  schema @telemetry( export: { otlp: {url: &quot;http://your-otlp-compatible-backend.com&quot;} } ) { query: Query }   Here, export specifies the format of generated data and endpoint to which to send that data. Continue reading to know more about different options for it.  ","version":"Next","tagName":"h2"},{"title":"Export to OTLP‚Äã","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#export-to-otlp","content":" OTLP is a vendor agnostic protocol that is supported by growing number of observability backends.  OpenTelemetry Collector‚Äã  OpenTelemetry Collector is a vendor-agnostic way to receive, process and export telemetry data in OTLP format.  Although, tailcall can send the data directly to the backends that supports OTLP format using Otel Collector could be valuable choice since it's more robust solution well-suited for a high-scale, more flexible settings and ability to export in different formats other than OTLP.  In summary, if you're gonna to use OTLP compatible platform or prometheus and your load is not that massive you could send the data directly to platforms. From the other side, if you need to export to different formats (like Jaeger or Datadog) or your application involves high load consider using Otel Collector as an export target.  ","version":"Next","tagName":"h3"},{"title":"Export to prometheus‚Äã","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#export-to-prometheus","content":" Prometheus is a metric monitoring solution. Please note that prometheus works purely with metrics and other telemetry data like traces and logs won't be sent to it.  Prometheus integration works by adding a special route for the GraphQL server's router that outputs generated metrics in prometheus format consumable by prometheus scraper.  ","version":"Next","tagName":"h3"},{"title":"Data generated‚Äã","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#data-generated","content":" You can find a reference of type of info generated by Tailcall in the @telemetry reference or consult examples in the next section, in order to gain some understanding.  ","version":"Next","tagName":"h2"},{"title":"Relation with other services‚Äã","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#relation-with-other-services","content":" Tailcall fully supports Context Propagation functionality and therefore you can analyze distributed traces across all of your services that are provides telemetry data.  That may look like this:    Where Tailcall is a part of whole distributed trace  ","version":"Next","tagName":"h3"},{"title":"Customize generated data‚Äã","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#customize-generated-data","content":" In some cases you may want to customize the data that were added to telemetry payload to have more control over analyzing process. Tailcall supports that customization for specific use cases described below. For eg. the metric http.server.request.count can be customized with the requestHeaders property to allow splitting the overall count by specific headers.  important The value of specified headers will be sent to telemetry backend as is, so use it with care to prevent of leaking any sensitive data to third-party services you don't have control over. ","version":"Next","tagName":"h3"},{"title":"GraphQL Server Watch Mode","type":0,"sectionRef":"#","url":"/docs/graphql-watch-mode-tailcall/","content":"","keywords":"","version":"Next"},{"title":"Use case‚Äã","type":1,"pageTitle":"GraphQL Server Watch Mode","url":"/docs/graphql-watch-mode-tailcall/#use-case","content":" Running a server in watch mode offers a lot of key benefits:  Real-time Feedback: Watch mode ensures that your server remains up-to-date with your code changes, instantly reflecting those changes and providing you with real-time feedback during development.Efficiency: Manually restarting the server each time you change code can be tedious and time-consuming. Watch mode automates this process, enhancing development efficiency.Debugging: It enables you to identify and resolve issues as they occur, reducing debugging time. With your server automatically restarting upon code changes, you detect errors earlier.  ","version":"Next","tagName":"h2"},{"title":"Using entr‚Äã","type":1,"pageTitle":"GraphQL Server Watch Mode","url":"/docs/graphql-watch-mode-tailcall/#using-entr","content":" It's a powerful file-watching utility that makes running a server in watch mode a breeze. Let's go through the steps for the installation process for different operating system :  ","version":"Next","tagName":"h2"},{"title":"Installation‚Äã","type":1,"pageTitle":"GraphQL Server Watch Mode","url":"/docs/graphql-watch-mode-tailcall/#installation","content":" Homebrew‚Äã  Open the Terminal, which you can find in the &quot;Utilities&quot; folder within the &quot;Applications&quot; folder. Install Homebrew if you haven't already. Run the following command in your Terminal: /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot; After installing Homebrew, proceed to install entr by executing the following command: brew install entr To verify the installation, run: entr --version   Upon successful installation, it will display the latest version of entr.  Windows Subsystem‚Äã  Install Windows Subsystem for Linux (WSL) on your Windows machine by following Microsoft's official documentation. After setting up WSL, open the Linux terminal by running: wsl -d &lt;DistributionName&gt; Replace &lt;DistributionName&gt; with the name of the Linux distribution that you have installed. Install entr within the Linux terminal using the package manager of your chosen Linux distribution. For example, on Ubuntu, you can use: sudo apt update sudo apt install entr Verify the installation by running: entr --version   A successful installation will display the latest version of entr.  apt-get‚Äã  On Linux, you can install entr using your distribution's package manager. For example, on Ubuntu, use: sudo apt update sudo apt install entr To verify the installation, run: entr --version   If you install it, it will show the latest version of the entr  ","version":"Next","tagName":"h3"},{"title":"Watch Mode‚Äã","type":1,"pageTitle":"GraphQL Server Watch Mode","url":"/docs/graphql-watch-mode-tailcall/#watch-mode","content":" To run your server in watch mode with entr, use the ls command to list the files you want to track. The general syntax is as follows:  ls *.graphql | entr -r tailcall start ./jsonplaceholder.graphql   This command uses entr to continuously track the jsonplaceholder.graphql file and when it changes, It runs the tailcall start command with the file as an argument  Detailing the above command as follows:  ls *.graphql : This part of the code lists the file or files you want to track for changes. In this case, it lists the file named &quot;jsonplaceholder.graphql&quot; within the &quot;examples&quot; directory. | : The pipe symbol ('|') takes the output of the preceding command (the file listing) and feeds it as input to the following command (entr). entr -r tc start ./jsonplaceholder.graphql : Whenever the file &quot;jsonplaceholder.graphql&quot; changes, this command executes.  entr is a command-line tool for running arbitrary commands whenever files change. It tracks the files specified in the previous command (ls ./jsonplaceholder.graphql) r : This flag instructs entr to persist in running the command through errors, ensuring continuous operation. tc start ./jsonplaceholder.graphql : This command runs upon detecting changes, executing tc start with the file path./jsonplaceholder.graphql as an argument  ","version":"Next","tagName":"h3"},{"title":"Some Best Practices‚Äã","type":1,"pageTitle":"GraphQL Server Watch Mode","url":"/docs/graphql-watch-mode-tailcall/#some-best-practices","content":" To make the most of running a server in watch mode with entr, consider the following best practices:  Selective File Watching: Be selective about which files you track with entr. Watching unnecessary files can lead to increased CPU and memory usage. Focus on the essential files related to your project. Organize Your Project: Maintain a well-organized project structure to make it easier to identify which files need tracking. Clear Output: Clear the terminal output before running entr to have a clean workspace. Version Control: Ensure that your project is under version control (e.g., Git) to track changes and revert if necessary. Update entr: Ensure entr is always updated to the latest version for bug fixes and enhancements.  By following these best practices and using entr effectively, you can greatly improve your development workflow. Experiment with entr, adapt it to your project's specific requirements, and enjoy a smoother and more efficient development process. Happy coding! ","version":"Next","tagName":"h2"},{"title":"Simplifying GraphQL Scalars","type":0,"sectionRef":"#","url":"/docs/graphql-scalars-guide/","content":"","keywords":"","version":"Next"},{"title":"Default Scalars‚Äã","type":1,"pageTitle":"Simplifying GraphQL Scalars","url":"/docs/graphql-scalars-guide/#default-scalars","content":" Here is a list of default scalars that are built into the GraphQL Spec:  Scalar\tDescription\tSpecificationInt\tA type representing non-fractional signed whole numbers. Values can range up to (2^31 - 1).\tGraphQL Specification for Int Float\tA type for signed double-precision floating-point numbers.\tGraphQL Specification for Float String\tA sequence of UTF-8 characters, representing textual data.\tGraphQL Specification for String Boolean\tA boolean type that represents true or false.\tGraphQL Specification for Boolean ID\tA unique identifier, typically used to refetch an object or as a cache key.\tGraphQL Specification for ID  ","version":"Next","tagName":"h2"},{"title":"GraphQL Scalars‚Äã","type":1,"pageTitle":"Simplifying GraphQL Scalars","url":"/docs/graphql-scalars-guide/#graphql-scalars","content":" These are the current set of custom scalars supported by Tailcall:  Scalar\tDescription\tSpecificationEmail\tA string that conforms to the email format as defined in the HTML specification, utilizing the Unicode character set.\tHTML Specification for Valid Email Addresses PhoneNumber\tA string format adhering to the E.164 international standard, which outlines the numbering plan for the worldwide public switched telephone network (PSTN) and certain data networks.\tE.164 International Numbering Plan Date\tA string that represents dates and times in the Internet protocols, following the ISO 8601 standard via the Gregorian calendar.\tRFC 3339 Date and Time Internet Formats Url\tA standardized format for Uniform Resource Identifiers (URI) that includes both the generic URI syntax and guidelines for resolving URI references, which may be in relative form.\tRFC 3986 Uniform Resource Identifier JSON\tA lightweight data interchange format based on the ECMAScript Programming Language Standard, designed for human-readable data representation.\tRFC 7159 The JavaScript Object Notation (JSON) Data Interchange Format Empty\tA type that represents no value or is used as a placeholder in contexts where no other data is expected or returned. It's equivalent to unit or void in other programming languages.\t  If none of the scalars make sense for your use case, consider opening an issue on the Tailcall github repository.  ","version":"Next","tagName":"h2"},{"title":"Custom Scalars‚Äã","type":1,"pageTitle":"Simplifying GraphQL Scalars","url":"/docs/graphql-scalars-guide/#custom-scalars","content":" Apart from the pre-defined list of scalars, you can define your own custom scalars in your GraphQL schema like in the example below.  scalar AnyScalar schema @server(port: 8000, hostname: &quot;localhost&quot;) { query: Query } type Query { any(value: AnyScalar!): AnyScalar! @expr(body: &quot;{{.args.value}}&quot;) }   important Be aware that custom scalars don't have any validation and can be mapped to any data structure when using it.  ","version":"Next","tagName":"h2"},{"title":"Example Usage‚Äã","type":1,"pageTitle":"Simplifying GraphQL Scalars","url":"/docs/graphql-scalars-guide/#example-usage","content":" Let's try using these custom scalars in our GraphQL schema.  schema @server(port: 8000, hostname: &quot;localhost&quot;) { query: Query } type Query { email(value: Email!): Email! @expr(body: &quot;{{.args.value}}&quot;) }   ","version":"Next","tagName":"h2"},{"title":"Valid Query Example‚Äã","type":1,"pageTitle":"Simplifying GraphQL Scalars","url":"/docs/graphql-scalars-guide/#valid-query-example","content":" Here is an example of a valid query that passes the custom scalar validations:  ","version":"Next","tagName":"h3"},{"title":"Invalid Query Example‚Äã","type":1,"pageTitle":"Simplifying GraphQL Scalars","url":"/docs/graphql-scalars-guide/#invalid-query-example","content":" And here is an example of an invalid query that fails the custom scalar validations as expected: ","version":"Next","tagName":"h3"},{"title":"Integrating Tailcall with Apollo Studio","type":0,"sectionRef":"#","url":"/docs/integrate-apollo-studio-graphql-tailcall/","content":"","keywords":"","version":"Next"},{"title":"Creating a monolith graph‚Äã","type":1,"pageTitle":"Integrating Tailcall with Apollo Studio","url":"/docs/integrate-apollo-studio-graphql-tailcall/#creating-a-monolith-graph","content":" Before you configure tailcall, you will need to create a Monolith graph on Apollo Studio. Go to your organization's home page and click on Create your first graph, if this is your first graph or Create New Graph if you have existing graphs. Change the Graph title, Graph ID and other fields as desired and make sure to change Graph Architecture to Monolith, assuming tailcall is booted in monolith mode. Once you are done, click on Next. You'll see the following screen. Copy the fields APOLLO_KEY and APOLLO_GRAPH_REF as they are required by tailcall to be able to send the usage metrics. Next we need to connect Apollo with our running instance of Tailcall. There are two ways to let Apollo know about your GraphQL schema: Navigate to Local Introspection. If you have a deployed instance of your GraphQL server you can put the URL pointing to that in Endpoint URL and click on Introspect and Upload. If not, start a local instance of tailcall and put the local url here, similar to how is shown in the image below. You can start a local instance of Tailcall by running tailcall start (click here to know more). Or, Navigate to Local Schema and insert your schema generated by tailcall and click Upload. You can get the schema by running tailcall check (click here to know more).  You have now created a Monolith graph in Apollo Studio. The next step is to configure tailcall to use the APOLLO_API_KEY and APOLLO_GRAPH_REF. Follow detailed instructions here.  ","version":"Next","tagName":"h2"},{"title":"Checking the metrics in Apollo Studio‚Äã","type":1,"pageTitle":"Integrating Tailcall with Apollo Studio","url":"/docs/integrate-apollo-studio-graphql-tailcall/#checking-the-metrics-in-apollo-studio","content":" To see the metrics for you queries follow these instructions:  Start tailcall with the appropriate configuration for Apollo (click here to know more). Below is an example of what a config may look like: schema @server(port: 8000) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) @telemetry( export: { apollo: { apiKey: &quot;&lt;APOLLO_API_KEY from Apollo Website&gt;&quot; graphRef: &quot;&lt;APOLLO_GRAPH_REF from Apollo Website&gt;&quot; } } ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! } Visit http://localhost:8000/graphql and create a query with an appropriate name (below is an example query named MyQuery) and run it multiple times to send the metrics to Apollo Studio. tip Naming the query is not required to be able to send the metrics, but it helps to organize the metrics with appropriate names when viewed in Apollo Studio. query MyQuery { posts { id title } } To see the metrics click on the VARIANT NAME of your graph. In the example below, the variant name is current. You will see the following page. From here click on insights icon as highlighted on the left side of the image. You will now be able to see all the information related to your queries here  important If you don't see the name of your query here, try running the query multiple times and waiting for some time. Since the metric isn't sent to Apollo Studio for each query, instead they are batched together and sent at once for efficiency reasons. ","version":"Next","tagName":"h2"},{"title":"Deploy Tailcall on AWS Lambda","type":0,"sectionRef":"#","url":"/docs/tailcall-on-aws/","content":"","keywords":"","version":"Next"},{"title":"Generate Access Keys for AWS‚Äã","type":1,"pageTitle":"Deploy Tailcall on AWS Lambda","url":"/docs/tailcall-on-aws/#generate-access-keys-for-aws","content":" Follow the steps below to generate the Access Keys:  Go to AWS Management Console and click the drop down menu in the top right corner and Click on Security credentials. Scroll down to the Access Keys section and click on Create access key. You will get the following warning since we are trying to create access keys for the root user. For this guide, we will continue with creating the access keys. If you do not want to continue with the root user, you can learn more about the AWS security credentials here and managing access keys here. Once you click on Create access key, you will get the Access key ID and Secret access key. Make sure to download the CSV file and store it securely.  ","version":"Next","tagName":"h2"},{"title":"Terraform setup‚Äã","type":1,"pageTitle":"Deploy Tailcall on AWS Lambda","url":"/docs/tailcall-on-aws/#terraform-setup","content":" Now that you have the AWS Access Key ID and Secret Access Key, you will need to generate API token for terraform and setup a terraform organization and workspace. If you don't have a Terraform Cloud account, you can create one here.  ","version":"Next","tagName":"h2"},{"title":"Terraform API Token‚Äã","type":1,"pageTitle":"Deploy Tailcall on AWS Lambda","url":"/docs/tailcall-on-aws/#terraform-api-token","content":" Follow these steps to generate the Terraform API token:  Go to the Tokens section in Settings and click on Create an API token. Give a description for the token and change the expiration if required. Click on Generate token. Copy the generated token and store it securely.  ","version":"Next","tagName":"h3"},{"title":"Terraform Organization and Workspace‚Äã","type":1,"pageTitle":"Deploy Tailcall on AWS Lambda","url":"/docs/tailcall-on-aws/#terraform-organization-and-workspace","content":" To create an organization, go to the Organizations section in Settings and click on Create organization. Fill in the organization name and email and click on Create organization. Now that you have created an organization, you will be presented with the following page for creating a workspace. Click on CLI-Driven Workflow, since the github action which we will be using for deployment, tailcallhq/gh-action, uses the terraform CLI. Fill in the workspace name. By default the project will be set to Default Project, if you have any project in terraform cloud, you can select that project, otherwise continue with the Default Project and click on Create.  You now have everything required for a successful deployment of your tailcall server on AWS Lambda.  ","version":"Next","tagName":"h3"},{"title":"Setting up the project repo‚Äã","type":1,"pageTitle":"Deploy Tailcall on AWS Lambda","url":"/docs/tailcall-on-aws/#setting-up-the-project-repo","content":" Now you need to create a new repository on Github and use the Github action tailcallhq/gh-action to deploy it. The easiest way to get started is to create a new repository using this template repo https://github.com/tailcallhq/deploy-tailcall.  Go to the repo and click on Use this template and create a new repository. Give your repository a name and click on Create repository. Now that you have created a repository, you will need to add the AWS access keys and Terraform API token to the repository secrets. To do that, click on Settings. Click on Secrets and variables in the left side bar to expand the section and click on Actions. Click on New repository secret to add a new secret. Add the secret name as AWS_ACCESS_KEY_ID or any name you prefer and paste the AWS access key ID that you generated earlier in the value field. Click on Add secret to save the secret. Similarly add the AWS secret access key and the Terraform API token as secrets to the repository.  You are now ready to deploy your tailcall server on AWS Lambda using terraform.  ","version":"Next","tagName":"h2"},{"title":"Deploy on AWS Lambda using terraform‚Äã","type":1,"pageTitle":"Deploy Tailcall on AWS Lambda","url":"/docs/tailcall-on-aws/#deploy-on-aws-lambda-using-terraform","content":" In this example, we will deploy a simple graphQL server using tailcall, on AWS Lambda using terraform, which will convert the JSONPlaceholder REST API to a GraphQL API.  Below is the config present in the template repo, that will be used for this deployment. You can learn more about this here.  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) }   To deploy the server, just update the provider to aws in the deploy-tailcall job in the .github/workflows/main.yml file, similar to the example below. Also, update the terraform-workspace and terraform-org as well as the other inputs based on your requirements.  on: [push] jobs: deploy_tailcall: runs-on: ubuntu-latest name: Deploy Tailcall steps: - name: Checkout repository uses: actions/checkout@v2 - name: Deploy Tailcall id: deploy-tailcall uses: tailcallhq/gh-action@v0.2 with: provider: &quot;aws&quot; aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} aws-region: &quot;us-east-1&quot; aws-iam-role: &quot;iam_for_tailcall&quot; terraform-api-token: ${{ secrets.TERRAFORM_API_TOKEN }} terraform-org: &quot;tailcall-demo&quot; terraform-workspace: &quot;tailcall&quot; tailcall-config: &quot;config.graphql&quot;   After updating the main.yml file, commit the changes and push them to the repository. This will trigger the deployment of the tailcall server on AWS Lambda. ","version":"Next","tagName":"h2"},{"title":"GraphQL Configuration Formats","type":0,"sectionRef":"#","url":"/docs/tailcall-graphql-configuration-format-conversion/","content":"","keywords":"","version":"Next"},{"title":"Converting Formats‚Äã","type":1,"pageTitle":"GraphQL Configuration Formats","url":"/docs/tailcall-graphql-configuration-format-conversion/#converting-formats","content":" To convert files between different formats, use the following command:  tailcall check format_type &lt; input_files &gt; --format   Let's try to convert a Tailcall graphql file to json and then back to graphql  To convert graphql to json  tailcall check examples/jsonplaceholder.graphql --format json &gt; &quot;examples/jsonplaceholder.json&quot;   Now to convert back to graphql  tailcall check examples/jsonplaceholder.json --format graphql &gt; &quot;examples/jsonplaceholder2.graphql&quot;   To learn more about writing configuration to leverage the full power of Tailcall, explore the Directives documentation.  ","version":"Next","tagName":"h2"},{"title":"Format Conversions‚Äã","type":1,"pageTitle":"GraphQL Configuration Formats","url":"/docs/tailcall-graphql-configuration-format-conversion/#format-conversions","content":" graphqlymljson schema @server(port: 8000, hostname: &quot;0.0.0.0&quot;) @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;, httpCache: 42, batch: {delay: 100}) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) users: [User] @http(path: &quot;/users&quot;) user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @call(query: &quot;user&quot;, args: {id: &quot;{{.value.userId}}&quot;}) }   ","version":"Next","tagName":"h2"},{"title":"Editor Support‚Äã","type":1,"pageTitle":"GraphQL Configuration Formats","url":"/docs/tailcall-graphql-configuration-format-conversion/#editor-support","content":" To leverage autocomplete and validation for GraphQL configurations, the init command can be used to automatically create .tailcallrc.graphql for GraphQL configurations and .tailcallrc.schema.json for JSON and YAML configurations. These files enhance editor support by providing schema definitions, facilitating faster and error-free configuration.  ","version":"Next","tagName":"h2"},{"title":"GraphQL‚Äã","type":1,"pageTitle":"GraphQL Configuration Formats","url":"/docs/tailcall-graphql-configuration-format-conversion/#graphql","content":" When you run tailcall init, it creates a .tailcallrc.graphql file containing your GraphQL schema definitions and a .graphqlrc.yml file configured to use this schema. The .graphqlrc.yml file is set up as follows:  schema: - &quot;./.tailcallrc.graphql&quot; - &quot;./app.graphql&quot;   This file contains the path to the .tailcallrc.graphql file and the path to the main GraphQL configuration file which is app.graphql. This setup allows GraphQL IDE plugins and Language Server Protocols (LSP) to automatically pick up the schema for autocomplete and validation, enhancing your development experience with real-time feedback and suggestions.  ","version":"Next","tagName":"h3"},{"title":"JSON & YAML‚Äã","type":1,"pageTitle":"GraphQL Configuration Formats","url":"/docs/tailcall-graphql-configuration-format-conversion/#json--yaml","content":" For JSON or YAML configurations, tailcall init also creates a .tailcallrc.schema.json file. To enable validation and autocomplete in your JSON files, reference the .tailcallrc.schema.json in the $schema attribute at the beginning of your JSON file:  { &quot;$schema&quot;: &quot;./.tailcallrc.schema.json&quot; }   This reference enables your IDE to validate and autocomplete using the JSON schema, offering a streamlined configuration process with instant error and typo detection. ","version":"Next","tagName":"h3"},{"title":"CTOs Guide to GraphQL","type":0,"sectionRef":"#","url":"/graphql/cto-guide/","content":"CTOs Guide to GraphQL Good APIs craft a broad spectrum of functionalities. Yet, the broader their scope, the more they diverge from being the perfect fit for any specific use case. This fundamental discrepancy ‚Äî the impedance mismatch between the general capabilities of an API and the precise needs of a particular scenario ‚Äî amplifies the necessity for an orchestration layer. Such a layer adeptly bridges this gap, tailor-fitting generic APIs to meet exact requirements with finesse. Tailcall stands at the forefront of this innovation, seamlessly transforming the way APIs are integrated and interacted with. Tailcall introduces a set of primitives, enabling developers to express and fine-tune how APIs are orchestrated without writing any code. This approach facilitates specifying different caching and batching strategies to enhance the overall system's efficiency. It also enables precise governance and access control mechanisms on actual domain entities and their relationships. Tailcall serves as a central hub for team collaboration, offering a unified point for managing all APIs, documentation, and more. Once configured, it positions itself between the clients and microservices, adeptly managing all requests and orchestrating them as needed. Manually crafting BFF (Backend for Frontend) layers has become outdated. With Tailcall, API orchestration evolves into a streamlined and highly optimized process. It functions as an essential intermediary, intelligently directing requests and assembling responses from each microservice. This approach diminishes the development burden associated with traditional BFF layers but also bolsters performance, reliability, and scalability throughout the application infrastructure.","keywords":"","version":"Next"},{"title":"Command Line Reference","type":0,"sectionRef":"#","url":"/docs/tailcall-graphql-cli/","content":"","keywords":"","version":"Next"},{"title":"check‚Äã","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#check","content":" The check command validates a composition spec. Notably, this command can detect potential N+1 issues. To use the check command, follow this format:  tailcall check [OPTIONS] &lt;FILE_PATHS&gt;...   The check command offers options that control settings such as the display of the generated schema, n + 1 issues etc.  ","version":"Next","tagName":"h2"},{"title":"--n-plus-one-queries‚Äã","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#--n-plus-one-queries","content":" This flag triggers the detection of N+1 issues.  Type: BooleanDefault: false  tailcall check --n-plus-one-queries &lt;FILE_PATHS&gt; ...   ","version":"Next","tagName":"h3"},{"title":"--schema‚Äã","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#--schema","content":" This option enables the display of the schema of the composition spec.  Type: BooleanDefault: false  tailcall check --schema &lt;file1&gt; &lt;file2&gt; ... &lt;fileN&gt;   The check command allows for files. Specify each file path, separated by a space, after the options.  Example:  tailcall check --schema ./path/to/file1.graphql ./path/to/file2.graphql   ","version":"Next","tagName":"h3"},{"title":"--format‚Äã","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#--format","content":" This is an optional command which allows changing the format of the input file. It accepts gql or graphql,yml or yaml, json .  tailcall check ./path/to/file1.graphql ./path/to/file2.graphql --format json   ","version":"Next","tagName":"h3"},{"title":"start‚Äã","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#start","content":" The start command launches the GraphQL Server for the specific configuration.  To start the server, use the following command:  tailcall start &lt;file1&gt; &lt;file2&gt; ... &lt;fileN&gt; &lt;http_path1&gt; &lt;http_path2&gt; .. &lt;http_pathN&gt;   The start command allows for files and supports loading configurations over HTTP. You can mix file system paths with HTTP paths. Specify each path, separated by a space, after the options.  Example:  tailcall start ./path/to/file1.graphql ./path/to/file2.graphql http://example.com/file2.graphql   ","version":"Next","tagName":"h2"},{"title":"init‚Äã","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#init","content":" The init command bootstraps a new TailCall project. It creates the necessary GraphQL schema files in the provided file path.  tailcall init &lt;file_path&gt;   This command prompts for file creation and configuration, creating the following files:  File Name\tDescription.tailcallrc.schema.json\tProvides autocomplete in your editor when the configuration is written in json or yml format. .graphqlrc.yml\tAn IDE configuration that references your GraphQL configuration (if it's in .graphql format) and the following .tailcallrc.graphql. .tailcallrc.graphql\tContains Tailcall specific auto-completions for .graphql format.  ","version":"Next","tagName":"h2"},{"title":"gen‚Äã","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#gen","content":" The gen command in the TailCall CLI is designed to generate GraphQL configurations from various sources, such as protobuf files and REST endpoints.  To generate a TailCall GraphQL configuration, provide a configuration file to the gen command. This configuration file should be in JSON or YAML format, as illustrated in the example below:  JSONYML { &quot;inputs&quot;: [ { &quot;curl&quot;: { &quot;src&quot;: &quot;https://jsonplaceholder.typicode.com/posts/1&quot;, &quot;fieldName&quot;: &quot;post&quot;, &quot;headers&quot;: { &quot;Content-Type&quot;: &quot;application/json&quot;, &quot;Accept&quot;: &quot;application/json&quot;, &quot;Authorization&quot;: &quot;Bearer {{.env.AUTH_TOKEN}}&quot; } } }, { &quot;proto&quot;: { &quot;src&quot;: &quot;./news.proto&quot; } } ], &quot;output&quot;: { &quot;path&quot;: &quot;./output.graphql&quot;, &quot;format&quot;: &quot;graphQL&quot; }, &quot;schema&quot;: { &quot;query&quot;: &quot;Query&quot; }, &quot;preset&quot;: { &quot;mergeType&quot;: 1, &quot;consolidateURL&quot;: 0.5 } }   ","version":"Next","tagName":"h2"},{"title":"Inputs‚Äã","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#inputs","content":" The inputs section specifies the sources from which the GraphQL configuration should be generated. Each source can be either a REST endpoint or a protobuf file.  REST: When defining REST endpoints, the configuration should include the following properties. src (Required): The URL of the REST endpoint. In this example, it points to a specific post on jsonplaceholder.typicode.com. fieldName (Required): A unique name that should be used as the field name, which is then used in the operation type. In the example below, it's set to post. headers (Optional): Users can specify the required headers to make the HTTP request in the headers section. info Ensure that secrets are not stored directly in the configuration file. Instead, use templates to securely reference secrets from environment variables. For example, see the following configuration where AUTH_TOKEN is referenced from the environment like {{.env.AUTH_TOKEN}}. JSONYML { &quot;curl&quot;: { &quot;src&quot;: &quot;https://jsonplaceholder.typicode.com/posts/1&quot;, &quot;fieldName&quot;: &quot;post&quot;, &quot;headers&quot;: { &quot;Authorization&quot;: &quot;Bearer {{.env.AUTH_TOKEN}}&quot; } } } For the above input configuration, the following field will be generated in the operation type: type Query { # field name is taken from the above JSON config post(p1: Int!): Post @http(path: &quot;/posts/{{arg.p1}}&quot;) } important Ensure that each field name is unique across the entire configuration to prevent overwriting previous definitions. Proto: For protobuf files, specify the path to the proto file (src). JSONYML { &quot;proto&quot;: { &quot;src&quot;: &quot;./path/to/file.proto&quot; } }   ","version":"Next","tagName":"h3"},{"title":"Output‚Äã","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#output","content":" The output section specifies the path and format for the generated GraphQL configuration.  path: The file path where the output will be saved.format: The format of the output file. Supported formats are json, yml, and graphQL.  tip You can also change the format of the configuration later using the check command.  ","version":"Next","tagName":"h3"},{"title":"Preset‚Äã","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#preset","content":" The config generator provides a set of tuning parameters that can make the generated configurations more readable by reducing duplication. This can be configured using the preset section.  JSONYML Presets with default values { &quot;preset&quot;: { &quot;mergeType&quot;: 1, &quot;consolidateURL&quot;: 0.5, }, }   mergeType: This setting merges types in the configuration that satisfy the threshold criteria. It takes a threshold value between 0.0 and 1.0 to determine if two types should be merged or not. The default is 1.0. For example, the following types T1 and T2 are exactly similar, and with a threshold value of 1.0, they can be merged into a single type called M1: Merging type T1 and T2 into M1 # BEFORE type T1 { id: ID firstName: String lastName: String } type T2 { id: ID firstName: String lastName: String } # AFTER: T1 and T2 are merged into M1. type M1 { id: ID firstName: String lastName: String } consolidateURL: The setting identifies the most common base URL among multiple REST endpoints and uses this URL in the upstream directive. It takes a threshold value between 0.0 and 1.0 to determine the most common endpoint. The default is 0.5. For example, if the Query type has three base URLs, using the consolidateURL setting with a 0.5 threshold will pick the base URL that is used in more than 50% of the http directives, http://jsonplaceholder.typicode.com, and add it to the upstream, cleaning the base URLs from the Query type. schema @server(hostname: &quot;0.0.0.0&quot;, port: 8000) @upstream(httpCache: 42) { query: Query } type Query { post(id: Int!): Post @http( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; path: &quot;/posts/{{.args.id}}&quot; ) posts: [Post] @http( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; path: &quot;/posts&quot; ) user(id: Int!): User @http( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; path: &quot;/users/{{.args.id}}&quot; ) users: [User] @http( baseURL: &quot;http://jsonplaceholder-1.typicode.com&quot; path: &quot;/users&quot; ) } After enabling the consolidateURL setting: schema @server(hostname: &quot;0.0.0.0&quot;, port: 8000) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; httpCache: 42 ) { query: Query } type Query { post(id: Int!): Post @http(path: &quot;/posts/{{.args.id}}&quot;) posts: [Post] @http(path: &quot;/posts&quot;) user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) users: [User] @http( baseURL: &quot;http://jsonplaceholder-1.typicode.com&quot; path: &quot;/users&quot; ) }  ","version":"Next","tagName":"h3"},{"title":"GraphQL Mutations: Techniques and Best Practices","type":0,"sectionRef":"#","url":"/graphql/graphql-mutations/","content":"","keywords":"","version":"Next"},{"title":"Introduction‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#introduction","content":" GraphQL has revolutionized the way we interact with APIs by offering a flexible and efficient approach to querying and manipulating data. Among its powerful features, mutations stand out as the key mechanism for creating, updating, and deleting data. In this article, we delve into the intricacies of GraphQL mutations, providing a detailed guide to mastering this essential component.  ","version":"Next","tagName":"h2"},{"title":"Understanding GraphQL Mutations‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#understanding-graphql-mutations","content":" ","version":"Next","tagName":"h2"},{"title":"What are GraphQL Mutations?‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#what-are-graphql-mutations","content":" GraphQL mutations are the counterpart to queries, designed specifically for writing data rather than reading it. While queries fetch data, mutations allow you to modify server-side data. Think of queries as a way to ask questions and get answers, while mutations are more like giving commands to change things.  ","version":"Next","tagName":"h3"},{"title":"Why Use Mutations?‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#why-use-mutations","content":" Mutations are essential because they enable dynamic interactions with your data. Instead of just looking at information, you can add new entries, update existing ones, or even remove data that's no longer needed. This ability to change data makes your application more interactive and responsive.  ","version":"Next","tagName":"h3"},{"title":"Mutation Structure‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#mutation-structure","content":" ","version":"Next","tagName":"h2"},{"title":"Mutation Type‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#mutation-type","content":" A GraphQL mutation typically involves several key components. First, you have the Mutation Type, which defines the action to be performed, such as creating, updating, or deleting data.  ","version":"Next","tagName":"h3"},{"title":"Input Arguments‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#input-arguments","content":" Next, you have Input Arguments, which specify the data required for the mutation. These are like the ingredients you need to perform the mutation.  ","version":"Next","tagName":"h3"},{"title":"Return Fields‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#return-fields","content":" Finally, you have Return Fields, which indicate the data returned after the mutation is executed. This is what you get back after the mutation has done its job.  Here‚Äôs a basic example of a mutation to create a new user:  mutation { createUser( input: {name: &quot;John Doe&quot;, email: &quot;john.doe@example.com&quot;} ) { id name email } }   ","version":"Next","tagName":"h3"},{"title":"Defining Mutations in the Schema‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#defining-mutations-in-the-schema","content":" To implement mutations, you must define them in your GraphQL schema. This involves specifying the mutation type and the fields it supports. Here‚Äôs an example schema definition:  type Mutation { createUser(input: CreateUserInput!): User updateUser(id: ID!, input: UpdateUserInput!): User deleteUser(id: ID!): User } input CreateUserInput { name: String! email: String! } input UpdateUserInput { name: String email: String }   ","version":"Next","tagName":"h2"},{"title":"Executing Mutations‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#executing-mutations","content":" Executing mutations in GraphQL involves sending a mutation request with the necessary input data. The response typically includes the newly modified data, confirming the mutation's success.  ","version":"Next","tagName":"h2"},{"title":"Example: Creating a User‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#example-creating-a-user","content":" Here's how you can create a new user named Jane Doe:  mutation { createUser( input: {name: &quot;Jane Doe&quot;, email: &quot;jane.doe@example.com&quot;} ) { id name email } }   The response might look like this:  { &quot;data&quot;: { &quot;createUser&quot;: { &quot;id&quot;: &quot;1&quot;, &quot;name&quot;: &quot;Jane Doe&quot;, &quot;email&quot;: &quot;jane.doe@example.com&quot; } } }   ","version":"Next","tagName":"h3"},{"title":"Handling Errors in Mutations‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#handling-errors-in-mutations","content":" Error handling is crucial for robust GraphQL APIs. Mutations should provide meaningful error messages and handle various scenarios gracefully.  ","version":"Next","tagName":"h2"},{"title":"Example: Handling Validation Errors‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#example-handling-validation-errors","content":" If you try to create a user without a name or with an invalid email, you'll get a validation error:  mutation { createUser(input: {name: &quot;&quot;, email: &quot;invalid-email&quot;}) { id name email } }   The response will be:  { &quot;errors&quot;: [ { &quot;message&quot;: &quot;Validation error: Name is required, Email is invalid&quot;, &quot;locations&quot;: [ { &quot;line&quot;: 2, &quot;column&quot;: 3 } ], &quot;path&quot;: [&quot;createUser&quot;] } ], &quot;data&quot;: { &quot;createUser&quot;: null } }   ","version":"Next","tagName":"h3"},{"title":"Advanced Mutation Techniques‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#advanced-mutation-techniques","content":" ","version":"Next","tagName":"h2"},{"title":"Nested Mutations‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#nested-mutations","content":" Nested mutations allow you to perform multiple related operations in a single mutation. This can be particularly useful for complex data relationships. For example, you can create a user and their associated posts in one go:  mutation { createUser( input: { name: &quot;Alice&quot; email: &quot;alice@example.com&quot; posts: [{title: &quot;First Post&quot;}, {title: &quot;Second Post&quot;}] } ) { id name email posts { id title } } }   caution Performing Nested Mutations is possible but caution is advised as by default, GraphQL mutations are not transactional. This means that if one part of the mutation fails, the other parts will still be executed. You may need to implement custom logic to handle this.  ","version":"Next","tagName":"h3"},{"title":"Optimizing Mutations for Performance‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#optimizing-mutations-for-performance","content":" Efficiently designed mutations are essential for maintaining performance and scalability in your GraphQL API. Consider the following techniques:  ","version":"Next","tagName":"h2"},{"title":"Optimistic UI Updates‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#optimistic-ui-updates","content":" Enhance user experience by updating the UI optimistically before the mutation response is received. This makes the app feel faster and more responsive.  ","version":"Next","tagName":"h3"},{"title":"Input Validation‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#input-validation","content":" Perform thorough validation on the client-side to minimize server-side processing. This helps ensure that only valid data reaches your server, reducing the risk of errors and improving performance.  ","version":"Next","tagName":"h3"},{"title":"Example Diagram: Mutation Lifecycle‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#example-diagram-mutation-lifecycle","content":" Here‚Äôs a simple diagram to illustrate the lifecycle of a mutation:    ","version":"Next","tagName":"h2"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#conclusion","content":" Mastering GraphQL mutations is fundamental for any developer working with GraphQL APIs. By understanding their structure, implementing them effectively, and optimizing for performance, you can leverage the full potential of GraphQL for dynamic and efficient data manipulation.    ","version":"Next","tagName":"h2"},{"title":"FAQs‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#faqs","content":" ","version":"Next","tagName":"h2"},{"title":"What is a GraphQL mutation?‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#what-is-a-graphql-mutation","content":" A GraphQL mutation is an operation that allows clients to modify server-side data, including creating, updating, and deleting records.  ","version":"Next","tagName":"h3"},{"title":"How do I handle errors in GraphQL mutations?‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#how-do-i-handle-errors-in-graphql-mutations","content":" GraphQL responses include both data and errors. Clients can handle partial successes by checking the presence of errors in the response and taking appropriate actions.  ","version":"Next","tagName":"h3"},{"title":"What is the difference between queries and mutations in GraphQL?‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#what-is-the-difference-between-queries-and-mutations-in-graphql","content":" Queries are used to fetch data, while mutations are used to modify data. Queries are typically idempotent, while mutations change the state of the server.  ","version":"Next","tagName":"h3"},{"title":"How do I secure GraphQL mutations?‚Äã","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#how-do-i-secure-graphql-mutations","content":" Secure GraphQL mutations by implementing authentication to verify user identity and authorization to ensure users have the correct permissions to perform the mutation. ","version":"Next","tagName":"h3"},{"title":"The Comprehensive Guide to GraphQL","type":0,"sectionRef":"#","url":"/graphql/","content":"","keywords":"","version":"Next"},{"title":"Introduction to GraphQL‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#introduction-to-graphql","content":" GraphQL, developed by Facebook in 2012 and open-sourced in 2015, is a query language for your API, and a server-side runtime for executing queries. It was originally developed to simplify endpoint management for REST-based APIs. Instead of maintaining multiple endpoints with small amounts of disjointed data, GraphQL provides a single endpoint that inputs complex queries and outputs only as much information as is needed for the query. This flexibility empowers developers to design more efficient and adaptable APIs, making GraphQL increasingly popular in modern web development.  At its core, GraphQL enables declarative data fetching, where clients specify the exact structure of the data they require, and the server responds with precisely that data. This contrasts with REST APIs, where endpoints are predefined, and clients receive fixed responses regardless of their specific data needs.  To know more in detail about GraphQL, you can refer What is GraphQL.  ","version":"Next","tagName":"h2"},{"title":"Fundamental Concepts of GraphQL Server‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#fundamental-concepts-of-graphql-server","content":" GraphQL is built upon several core concepts that form the foundation of its query language and API design. Understanding these concepts is essential for effectively utilizing GraphQL in your projects.  ","version":"Next","tagName":"h2"},{"title":"1. Schema‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#1-schema","content":" At the heart of every GraphQL API is the schema which is a set of types which completely describe the set of possible data you can query on that server. Then, when queries come in, they are validated and executed against that schema.  GraphQL schemas are typically defined using the GraphQL Schema Definition Language (SDL), a simple syntax for describing types. Each type in the schema represents a distinct object in the API. Types can have fields that correspond to the properties of the object, as well as relationships to other types.  Here's a code snippet illustrating how a GraphQL schema might be defined using the GraphQL Schema Definition Language (SDL):  schema { query: Query } type Post { id: ID! title: String! content: String! userId: ID! } type Query { post(id: ID!): Post }   In this schema:  We define an object type: Post.Each Post object has fields for id, title, content, and a userId.We also define a root Query type, which contains entry points for querying individual users and posts by their IDs. We will dig deep into this in Next Section  This schema serves as a contract between the client and the server, defining the structure of the data available through the API and specifying how clients can interact with it. It forms the foundation for building and querying data in a GraphQL API. You can learn more about GraphQL Schema in detail.  ","version":"Next","tagName":"h3"},{"title":"2. Query‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#2-query","content":" Most types in your schema will just be normal object types, but there are two types that are special within a schema Query and Mutation.  Every GraphQL server has a query type and may or may not have a mutation type. These types are the same as a regular object type, but they are special because they define the entry point of every GraphQL query. So if you see a query that looks like:  query { user(id: &quot;123&quot;) { name } }   That means that the GraphQL service needs to have a Query type with user field:  type Query { user(id: ID!): User }   ","version":"Next","tagName":"h3"},{"title":"3. Mutation‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#3-mutation","content":" Mutation work in a similar way as Query - you define fields on the Mutation type, and those are available as the root mutation fields you can call in your query.  It‚Äôs important to remember that other than the special status of being the ‚Äúentry point‚Äù into the schema, the Query and Mutation types are the same as any other GraphQL object type, and their fields work exactly the same way. While queries are used for reading data from a GraphQL API, mutations are used for modifying or updating data. Mutations allow clients to perform actions such as creating, updating, or deleting objects in the API's data store.  Here's a code snippet illustrating how mutations might be defined in GraphQL:  type Mutation { createUser(input: CreateUserInput!): User! }   To query above mutation, you would use a query like this:  mutation { createUser( input: {name: &quot;Alice&quot;, email: &quot;dummy@gmail.com&quot;} ) { id name email } }   ","version":"Next","tagName":"h3"},{"title":"4. Subscriptions‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#4-subscriptions","content":" Subscriptions enable real-time communication between clients and servers in GraphQL APIs. Unlike queries and mutations, which are request-response interactions, subscriptions establish a persistent connection between the client and the server, allowing the server to push updates to the client as they occur.  Subscriptions are defined in the GraphQL schema alongside queries and mutations, specifying the events or data changes that clients can subscribe to. Clients initiate a subscription by sending a subscription query to the server, which then notifies the client whenever the subscribed event occurs.  Here's a code snippet illustrating how subscriptions might be defined in GraphQL:  type Subscription { newMessage: Message! } type Message { id: ID! content: String! createdAt: String! } input SendMessageInput { content: String! } type Mutation { sendMessage(input: SendMessageInput!): Message! }   In this schema:  We define a Subscription type, which contains an entry point newMessage representing the event that clients can subscribe to receive updates about new messages.The newMessage subscription returns a Message object whenever a new message is created.We define a Message type with fields for id, content, and createdAt, representing a message object.We also define an input object type SendMessageInput with a field for content, which represents the input data for creating a new message.Finally, we have a Mutation type with an operation sendMessage that takes an input object of type SendMessageInput and returns the created Message object.  Clients can subscribe to the newMessage event to receive real-time updates whenever a new message is created. When a new message is created, the server pushes the updated message data to all subscribed clients in real-time.  In summary, the fundamental concepts of GraphQL‚Äîschema, queries, mutations, and subscriptions‚Äîprovide a powerful framework for building flexible and efficient APIs that meet the diverse needs of modern applications.  This GraphQL configuration is enough for starting a GraphQL server using Tailcall. You can start the server using the start command.  ","version":"Next","tagName":"h3"},{"title":"Advantages of Using GraphQL‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#advantages-of-using-graphql","content":" While REST (Representational State Transfer) has long been a dominant paradigm for building web APIs, GraphQL offers several key advantages that revolutionize API design and development:  ","version":"Next","tagName":"h2"},{"title":"1. Efficient Data Fetching‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#1-efficient-data-fetching","content":" One of the primary advantages of GraphQL is its ability to efficiently fetch data from the server. With GraphQL, clients can request only the specific fields they need, avoiding the problem of over-fetching data that often occurs with REST APIs. This minimizes the amount of data transferred over the network, leading to faster response times and improved performance for client applications.  Additionally, GraphQL enables clients to retrieve related pieces of data in a single request by specifying nested query structures. This eliminates the need for multiple round-trip requests to fetch data from different endpoints, further optimizing data fetching efficiency.  ","version":"Next","tagName":"h3"},{"title":"2. Strongly-Typed Schema‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#2-strongly-typed-schema","content":" GraphQL employs a strongly-typed schema to define the structure of the API and the types of data it supports. This schema serves as a contract between the client and the server, providing clear documentation of the available data and operations.  By defining a schema upfront, GraphQL enables type checking and validation of queries at compile-time, catching errors early in the development process. This helps prevent runtime errors and improves the reliability of client-server interactions.  Additionally, the schema serves as a central source of truth for the API, making it easier for frontend and backend developers to collaborate. Changes to the schema can be communicated effectively, and tools can be built around the schema to provide features like autocomplete and code generation.  ","version":"Next","tagName":"h3"},{"title":"3. Reduced Network Requests‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#3-reduced-network-requests","content":" GraphQL reduces the number of network requests required to fetch data by allowing clients to specify complex queries in a single request. Unlike REST APIs, which often require multiple requests to retrieve related data from different endpoints, GraphQL enables clients to fetch all the necessary data in a single round trip.  This reduction in network requests can have significant performance benefits, particularly for mobile and web applications operating over limited bandwidth or high-latency networks. By minimizing the overhead associated with network communication, GraphQL helps improve the responsiveness and efficiency of client applications.  In summary, GraphQL represents a paradigm shift in API design, offering developers greater flexibility, efficiency, and control over data fetching compared to traditional RESTful architectures. By leveraging the advantages of GraphQL‚Äîefficient data fetching, strongly-typed schema, and reduced network requests‚Äîdevelopers can create more scalable, flexible, and performant systems that meet the needs of modern applications and users.  ","version":"Next","tagName":"h3"},{"title":"Getting Started with GraphQL‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#getting-started-with-graphql","content":" Before diving into GraphQL development, it's essential to understand the basic steps involved in setting up a GraphQL server, defining a schema, and creating resolvers.  ","version":"Next","tagName":"h2"},{"title":"1. Setting up a GraphQL Server‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#1-setting-up-a-graphql-server","content":" Setting up a GraphQL server involves configuring a server environment capable of processing GraphQL requests and responses. You can set up a GraphQL Server using Tailcall by following the steps below:  Install Tailcall's GraphQL CLI by running the following command:  npm install -g @tailcallhq/tailcall   Set up a new GraphQL project by running the following command on a new project directory:  tailcall init   Using Tailcall's GraphQL CLI, you can quickly set up a GraphQL server with minimal configuration. The CLI provides a streamlined development environment for building GraphQL APIs.  ","version":"Next","tagName":"h3"},{"title":"2. Defining a Schema‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#2-defining-a-schema","content":" The schema is a critical component of any GraphQL API, as it defines the types of data that clients can query and manipulate. GraphQL schemas are typically written using the GraphQL Schema Definition Language (SDL), a simple syntax for describing types, fields, and relationships.  To define a schema, you'll need to specify the types of data available in your API, including objects, along with their associated fields and relationships. You'll also define query, mutation, and subscription types to specify the operations that clients can perform. for example:  schema { query: Query } type Post { id: ID! title: String! content: String! } type Query { post(id: ID!): Post }   ","version":"Next","tagName":"h3"},{"title":"3. Attaching Resolvers‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#3-attaching-resolvers","content":" Resolvers are responsible for fetching the data requested by clients and returning it in the appropriate format. Each field in your schema corresponds to a resolver function, which retrieves the data from your data sources, such as databases, APIs, or in-memory caches.  When a client sends a GraphQL query, the server resolves each field in the query by executing the corresponding resolver function. Resolvers may perform database queries, call external APIs, or perform other tasks to retrieve the requested data. Once the data is fetched, the resolvers return it to the client in the format specified by the GraphQL schema.  By setting up a GraphQL server, defining a schema, and attaching resolvers, you can begin building powerful and flexible APIs that provide clients with the precise data they need. This foundational knowledge forms the basis for more advanced GraphQL development, including integrating GraphQL with existing APIs, handling complex data relationships, and optimizing API performance.  Lets attach resolvers to the schema we defined in the previous section using Tailcall's GraphQL Configuration: We will add the resolvers with @http directive:  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type Post { id: ID! title: String! content: String! } type Query { post(id: ID!): Post @http(path: &quot;/posts/{{.args.id}}&quot;) }   In this example: We have used the @http directive to attach resolvers to the post field in the Query. and @upstream directive to define the base URL for the upstream server.  This configuration is enough for starting a GraphQL server using Tailcall. You can start the server using the start command.  For starting the server, you can use the following command:  tailcall start path/to/your-graphql-configuration   ","version":"Next","tagName":"h3"},{"title":"4. Handling Data Relationships‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#4-handling-data-relationships","content":" One of the strengths of GraphQL is its ability to handle data relationships with ease. When designing your GraphQL schema, consider how different types of data relate to each other and how clients may want to query or manipulate these relationships.  Use GraphQL's powerful type system to define clear relationships between your data types, including one-to-one, one-to-many, and many-to-many relationships. This allows clients to fetch related data in a single query, reducing the need for multiple round-trip requests.  Here's a code snippet illustrating how to handle data relationships in GraphQL:  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type User { id: ID! name: String! email: String! } type Post { id: ID! title: String! content: String! userId: ID! author: User! @http(path: &quot;/users/{{.value.userId}}&quot;) } type Query { post(id: ID!): Post! @http(path: &quot;/posts/{{.args.id}}&quot;) }   In this example:  We define a User type representing a user object with fields for id, name, and email.We define a Post type representing a post object with fields for id, title, content, and userId.We establish a relationship between Post and User by adding an author field to the Post type. The author field fetches the user data corresponding to the userId of the post.We attach resolvers to the author field using the @http directive to fetch user data from the upstream server.  ","version":"Next","tagName":"h3"},{"title":"Tools and Libraries for GraphQL‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#tools-and-libraries-for-graphql","content":" Utilizing the right tools and libraries can significantly streamline the development, testing, and maintenance of your GraphQL API. Here are some essential tools and resources:  ","version":"Next","tagName":"h2"},{"title":"1. Popular GraphQL Clients‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#1-popular-graphql-clients","content":" Apollo Client: A comprehensive GraphQL client for JavaScript applications, offering features such as query caching, local state management, and error handling. Apollo Client supports various frontend frameworks, including React, Angular, and Vue.js.  Relay: Developed by Facebook, Relay is a powerful GraphQL client optimized for React applications. It provides features like declarative data fetching, pagination, and efficient updates through GraphQL mutations.  URQL (formerly known as &quot;Urql&quot;): A lightweight and flexible GraphQL client for React and other JavaScript frameworks. URQL focuses on simplicity, performance, and customization, offering hooks-based APIs for querying and caching GraphQL data.  ","version":"Next","tagName":"h3"},{"title":"2. Testing and Debugging Tools‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#2-testing-and-debugging-tools","content":" GraphQL Playground: An interactive GraphQL IDE that allows you to explore, test, and debug GraphQL APIs using a web-based interface. GraphQL Playground supports features like syntax highlighting, query autocompletion, and response visualization, making it invaluable for API development and testing.  GraphiQL: Similar to GraphQL Playground, GraphiQL is a web-based IDE for testing and debugging GraphQL APIs. It provides a user-friendly interface for composing and executing GraphQL queries, with built-in documentation and query history functionality.  Apollo Studio Explorer: Part of the Apollo Studio platform, Apollo Studio Explorer offers a visual GraphQL editor and testing environment for exploring GraphQL schemas, executing queries, and analyzing query performance. It integrates seamlessly with Apollo Client and provides insights into schema usage and query execution metrics.  Tailcall Playground: Tailcall Playground is a web-based IDE for testing and debugging GraphQL servers,and analyze the behavior of your GraphQL server.  ","version":"Next","tagName":"h3"},{"title":"3. Community Resources and Support‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#3-community-resources-and-support","content":" GraphQL Documentation: Comprehensive documentation resources are available for GraphQL, covering topics such as schema definition, query syntax, and best practices for API design. The official GraphQL website (graphql.org) provides detailed guides, tutorials, and reference documentation for learning and mastering GraphQL.  GitHub Repositories: Explore open-source GraphQL projects and libraries on GitHub to discover reusable components, utilities, and tools for building and extending GraphQL APIs. Many popular GraphQL clients, server frameworks, and development tools are hosted on GitHub, offering opportunities for collaboration and contribution.  Online Communities: Engage with the GraphQL community through online forums, discussion groups, and social media channels. Platforms like Reddit (r/graphql), Stack Overflow, and Discord host active communities of GraphQL enthusiasts and practitioners, where you can ask questions, share knowledge, and seek advice on GraphQL-related topics.  By leveraging these tools and resources, you can enhance your GraphQL development workflow, streamline API testing and debugging, and tap into the collective expertise of the GraphQL community for support and guidance.  ","version":"Next","tagName":"h3"},{"title":"Real-world Examples of GraphQL Implementation‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#real-world-examples-of-graphql-implementation","content":" Real-world examples of GraphQL implementation offer valuable insights into the practical applications, benefits, and challenges of adopting GraphQL in different industries and use cases. Here are some case studies and lessons learned from successful GraphQL adoption:  ","version":"Next","tagName":"h2"},{"title":"1. Case Studies of Successful GraphQL Adoption‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#1-case-studies-of-successful-graphql-adoption","content":" GitHub: GitHub adopted GraphQL to address the inefficiencies and complexities of its RESTful API, which led to over-fetching, under-fetching, and versioning challenges. By transitioning to GraphQL, GitHub improved data fetching efficiency, reduced network requests, and provided a more flexible and intuitive API for developers. GraphQL enabled GitHub to deliver personalized data, optimize performance, and streamline client-server communication.  Shopify: Shopify leveraged GraphQL to power its next-generation commerce platform, enabling merchants to build customized storefronts and applications. GraphQL empowered Shopify developers to fetch precisely the data they needed, avoiding over-fetching and reducing latency. Shopify's adoption of GraphQL resulted in improved developer productivity, faster feature development, and enhanced API performance for merchants and partners.  ","version":"Next","tagName":"h3"},{"title":"2. Lessons Learned from Industry Use Cases‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#2-lessons-learned-from-industry-use-cases","content":" Performance Optimization: Many companies, including Facebook, Twitter, and Airbnb, have shared insights into optimizing GraphQL performance at scale. Key strategies include batching requests, implementing caching mechanisms, optimizing resolver functions, and monitoring query execution times. By optimizing GraphQL performance, organizations can minimize latency, improve scalability, and enhance user experience.  Data Modeling and Schema Design: Successful GraphQL implementations emphasize the importance of thoughtful data modeling and schema design. Designing a clear and intuitive schema, defining relationships between types, and normalizing data structures are critical for building scalable and maintainable GraphQL APIs. Companies like PayPal and Coursera have documented their approaches to schema design, highlighting best practices for organizing and structuring data in GraphQL schemas.  Developer Experience: Prioritizing developer experience (DX) is essential for driving adoption and success with GraphQL. Providing comprehensive documentation, offering interactive tooling (e.g., GraphQL playgrounds), and fostering a supportive developer community are key factors in promoting GraphQL adoption. Companies like Apollo and Prisma have contributed to the GraphQL ecosystem by developing tools, libraries, and educational resources to empower developers and simplify GraphQL development workflows.  By studying real-world examples of GraphQL implementation and learning from industry use cases, organizations can gain valuable insights into the benefits, challenges, and best practices associated with adopting GraphQL. Whether optimizing performance, designing schemas, or enhancing developer experience, GraphQL offers compelling advantages for building modern, data-driven applications in various domains and industries.  ","version":"Next","tagName":"h3"},{"title":"Future Trends in GraphQL‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#future-trends-in-graphql","content":" As GraphQL continues to evolve and gain traction in the developer community, several emerging trends and advancements are shaping the future of GraphQL adoption and implementation. Here are some key areas to watch:  ","version":"Next","tagName":"h2"},{"title":"1. GraphQL in the Context of Microservices‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#1-graphql-in-the-context-of-microservices","content":" Service Mesh Integration: With the increasing adoption of microservices architectures, GraphQL is poised to play a significant role in service mesh environments. Integrating GraphQL with service mesh technologies such as Istio and Linkerd enables developers to build distributed, resilient, and scalable applications with enhanced API management, observability, and security capabilities.  GraphQL Federation: GraphQL federation, an architectural pattern for composing distributed GraphQL schemas, is gaining momentum as a preferred approach for building scalable and modular microservices architectures. By federating multiple GraphQL APIs into a unified graph, organizations can achieve greater agility, autonomy, and composability across their microservices ecosystem.  ","version":"Next","tagName":"h3"},{"title":"2. Integration with Emerging Technologies‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#2-integration-with-emerging-technologies","content":" Serverless Computing: The integration of GraphQL with serverless computing platforms such as AWS Lambda, Azure Functions, and Google Cloud Functions enables developers to build event-driven, scalable APIs with minimal operational overhead. Serverless GraphQL functions provide dynamic data resolution, auto-scaling, and cost-efficient execution, making them ideal for modern, cloud-native applications.  Edge Computing: GraphQL is increasingly being adopted in edge computing scenarios, where low-latency data access and distributed processing are critical requirements. By deploying GraphQL at the edge using technologies like Cloudflare Workers and AWS CloudFront, organizations can deliver performant, responsive APIs to edge locations worldwide, improving user experience and application performance.  ","version":"Next","tagName":"h3"},{"title":"3. Potential Advancements in the GraphQL Ecosystem‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#3-potential-advancements-in-the-graphql-ecosystem","content":" GraphQL Standardization: As GraphQL adoption continues to grow, efforts to standardize GraphQL specifications, tooling, and best practices are gaining momentum. Organizations such as the GraphQL Foundation and the GraphQL Working Group are leading initiatives to define and maintain GraphQL standards, promote interoperability, and drive innovation in the GraphQL ecosystem.  Schema Stitching and Composition: Advanced schema stitching and composition techniques are emerging to address the challenges of building and managing complex GraphQL schemas. Tools and libraries for schema stitching, such as Apollo Federation and GraphQL Mesh, enable developers to compose distributed schemas, federate data sources, and implement cross-cutting concerns like authentication, authorization, and caching.  Advanced Query Optimization: Ongoing research and development efforts are focused on advancing query optimization techniques for GraphQL APIs. Innovations in query planning, execution, and caching are enhancing the performance, scalability, and efficiency of GraphQL queries, enabling organizations to deliver real-time, data-intensive applications with low latency and high throughput.  As GraphQL continues to mature and expand its capabilities, organizations can expect to see further integration with microservices, emerging technologies, and advancements in the GraphQL ecosystem. By staying informed about these future trends and embracing GraphQL as a strategic technology, organizations can unlock new opportunities for innovation, agility, and growth in the rapidly evolving landscape of modern software development.  ","version":"Next","tagName":"h3"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#conclusion","content":" In conclusion, GraphQL has emerged as a powerful query language and runtime for building efficient, flexible, and scalable APIs. Throughout this guide, we've explored the fundamental concepts, advantages, implementation strategies, optimization techniques, and future trends of GraphQL. Here's a summary of the key takeaways:  ","version":"Next","tagName":"h2"},{"title":"Key Takeaways‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#key-takeaways","content":" GraphQL offers several advantages over traditional REST APIs, including efficient data fetching, a strongly-typed schema, and reduced network requests. By enabling clients to request precisely the data they need, GraphQL optimizes data transfer and improves application performance.Understanding the fundamental concepts of GraphQL, such as schema, queries, mutations, and subscriptions, is essential for effectively designing, implementing, and consuming GraphQL APIs. With a clear understanding of these concepts, developers can leverage the full potential of GraphQL to build sophisticated and intuitive APIs.Implementing GraphQL in your API involves setting up a GraphQL server, defining a schema, and attaching resolvers to fetch and manipulate data. By structuring queries and mutations, developers can design APIs that are easy to understand, maintain, and evolve over time.  ","version":"Next","tagName":"h3"},{"title":"Recap of Fundamental Concepts‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#recap-of-fundamental-concepts","content":" Schema: Defines the types of data available in the API and the relationships between them.Queries: Retrieve data from the API.Mutations: Modify data in the API.Subscriptions: Listen for real-time updates from the API.  By embracing GraphQL and leveraging its capabilities to build modern, data-driven APIs, developers can unlock new opportunities for innovation, collaboration, and growth. Whether you're a beginner exploring the basics of GraphQL or an experienced developer optimizing complex APIs, the comprehensive guide to GraphQL provides valuable insights and guidance to support your journey in mastering this powerful technology.  Thank you for joining us on this exploration of GraphQL. We hope this guide has equipped you with the knowledge and tools needed to build successful GraphQL APIs and navigate the evolving landscape of modern software development.  ","version":"Next","tagName":"h3"},{"title":"Next Steps‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#next-steps","content":" Congratulations on completing this comprehensive guide to GraphQL! As you continue your journey to mastering GraphQL and building powerful APIs, here are some recommended next steps to further enhance your skills and stay updated on GraphQL developments:  ","version":"Next","tagName":"h2"},{"title":"Further Resources for Mastering GraphQL‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#further-resources-for-mastering-graphql","content":" Explore in-depth tutorials, documentation, and guides provided by GraphQL's official website (https://graphql.org/). The website offers a wealth of resources, including tutorials, specifications, and best practices for implementing GraphQL APIs.Dive deeper into GraphQL concepts and techniques with online courses and tutorials available on platforms like Udemy, Coursera, and Pluralsight. These courses cover a wide range of topics, from GraphQL fundamentals to advanced topics like schema stitching and federation.Check out books and ebooks on GraphQL, such as &quot;Learning GraphQL: Declarative Data Fetching for Modern Web Apps&quot; by Eve Porcello and &quot;The GraphQL Guide&quot; by John Resig and Loren Sands-Ramshaw. These resources provide comprehensive coverage of GraphQL concepts, best practices, and real-world examples.  ","version":"Next","tagName":"h2"},{"title":"Community Forums and Events for Staying Updated on GraphQL Developments‚Äã","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#community-forums-and-events-for-staying-updated-on-graphql-developments","content":" Join the GraphQL community on platforms like GitHub, Reddit, and Stack Overflow to connect with other developers, ask questions, and share insights and experiences. These forums are valuable resources for staying updated on the latest trends, tools, and techniques in the GraphQL ecosystem.Attend GraphQL meetups, conferences, and workshops to network with industry experts, learn from experienced developers, and gain hands-on experience with GraphQL. Events like GraphQL Summit, GraphQL Europe, and GraphQL Asia offer opportunities to connect with the broader GraphQL community and stay informed about emerging trends and best practices. ","version":"Next","tagName":"h2"},{"title":"Mastering GraphQL Queries: Comprehensive Guide","type":0,"sectionRef":"#","url":"/graphql/graphql-queries/","content":"","keywords":"","version":"Next"},{"title":"Introduction to GraphQL Queries‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#introduction-to-graphql-queries","content":" In GraphQL, queries are the primary method to fetch data from a server. A GraphQL query allows you to specify exactly what data you need, making data retrieval both precise and efficient.  ","version":"Next","tagName":"h2"},{"title":"What is a GraphQL Query?‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#what-is-a-graphql-query","content":" A GraphQL query is a read operation that allows clients to specify precisely which data they need from the server. Unlike traditional REST APIs, where endpoints define the structure of responses, GraphQL queries let clients dictate the shape and size of the response. This flexibility reduces over-fetching and under-fetching of data, optimizing both server and client performance.  ","version":"Next","tagName":"h2"},{"title":"Basic Structure of a GraphQL Query‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#basic-structure-of-a-graphql-query","content":" GraphQL queries are written in a declarative syntax, resembling the structure of the requested data. Here is an example of a simple query to fetch user information:  { user(id: &quot;1&quot;) { id name email } }   ","version":"Next","tagName":"h2"},{"title":"Components of a Query‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#components-of-a-query","content":" Field: The basic unit of a query. In the example, id, name, and email are fields.Arguments: Parameters passed to fields to specify or filter data. id: &quot;1&quot; is an argument to the user field.Aliases: Alternative names for fields to avoid conflicts and improve readability.  ","version":"Next","tagName":"h3"},{"title":"Advanced Query Features‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#advanced-query-features","content":" ","version":"Next","tagName":"h2"},{"title":"Nested Queries‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#nested-queries","content":" GraphQL queries support nesting, allowing clients to request related data in a single query. This feature is particularly useful for fetching hierarchical data structures.  { user(id: &quot;1&quot;) { id name posts { title content } } }   ","version":"Next","tagName":"h3"},{"title":"Fragments‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#fragments","content":" Fragments allow the reuse of common field selections across multiple queries, mutations, or subscriptions. They help in maintaining a DRY (Don't Repeat Yourself) approach in GraphQL queries.  fragment userFields on User { id name email } { user(id: &quot;1&quot;) { ...userFields } }   ","version":"Next","tagName":"h3"},{"title":"Variables‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#variables","content":" Variables enable dynamic queries, where the arguments can be passed externally, making the queries more flexible and reusable.  query getUser($userId: ID!) { user(id: $userId) { id name email } }   { &quot;userId&quot;: &quot;1&quot; }   ","version":"Next","tagName":"h3"},{"title":"Directives‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#directives","content":" Directives are used to modify the behavior of queries at runtime. Common directives include @include and @skip for conditional field inclusion.  { user(id: &quot;1&quot;) { id name email @include(if: $includeEmail) } }   ","version":"Next","tagName":"h3"},{"title":"Error Handling in Queries‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#error-handling-in-queries","content":" GraphQL provides a standardized way to handle errors. The response includes both data and errors, allowing clients to handle partial success scenarios gracefully.  { &quot;data&quot;: { &quot;user&quot;: null }, &quot;errors&quot;: [ { &quot;message&quot;: &quot;User not found&quot;, &quot;locations&quot;: [ { &quot;line&quot;: 2, &quot;column&quot;: 3 } ], &quot;path&quot;: [&quot;user&quot;] } ] }   ","version":"Next","tagName":"h2"},{"title":"Best Practices for Writing GraphQL Queries‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#best-practices-for-writing-graphql-queries","content":" Fetch Only Necessary Data: Always request the minimum required fields to reduce the payload and improve performance.Use Aliases and Fragments: To avoid naming conflicts and promote reuse of common field selections.Implement Pagination: For queries that return large lists, use pagination techniques like first, last, before, and after.Handle Errors Gracefully: Ensure your client can handle partial successes and provide useful feedback to users.  ","version":"Next","tagName":"h2"},{"title":"Example Diagram: GraphQL Query Structure‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#example-diagram-graphql-query-structure","content":"   ","version":"Next","tagName":"h2"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#conclusion","content":" You now have the skills to write simple and nested GraphQL queries, pass arguments, use variables for dynamic queries, paginate results, and filter queries. Mastering these concepts will enable you to fetch data efficiently and effectively using GraphQL.    ","version":"Next","tagName":"h2"},{"title":"Frequently Asked Questions (FAQs)‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#frequently-asked-questions-faqs","content":" ","version":"Next","tagName":"h2"},{"title":"How do I handle errors in GraphQL queries?‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#how-do-i-handle-errors-in-graphql-queries","content":" GraphQL responses include both data and errors. Clients can handle partial successes by checking the presence of errors in the response and taking appropriate actions.  ","version":"Next","tagName":"h3"},{"title":"What are GraphQL fragments?‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#what-are-graphql-fragments","content":" Fragments are reusable units of query logic that help maintain a DRY approach in your GraphQL queries. They allow you to define common field selections and use them across multiple queries, mutations, or subscriptions.  ","version":"Next","tagName":"h3"},{"title":"Can I use GraphQL with existing REST APIs?‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#can-i-use-graphql-with-existing-rest-apis","content":" Yes, you can use GraphQL as a layer on top of existing REST APIs to provide a more flexible and efficient way to query your data. For quickly creating a GraphQL server that converts REST APIs to GraphQL, check out Getting Started with Tailcall.  ","version":"Next","tagName":"h3"},{"title":"What are GraphQL directives?‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#what-are-graphql-directives","content":" Directives are used to modify the behavior of queries at runtime. Common directives like @include and @skip allow you to conditionally include or exclude fields from the query based on dynamic conditions.  ","version":"Next","tagName":"h3"},{"title":"How does GraphQL handle nested queries?‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#how-does-graphql-handle-nested-queries","content":" GraphQL allows you to fetch related data in a single request using nested queries. This is particularly useful for hierarchical data structures where you need to retrieve parent and child data together.  ","version":"Next","tagName":"h3"},{"title":"What is GraphiQL?‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#what-is-graphiql","content":" GraphiQL is an open-source in-browser IDE for exploring GraphQL APIs. You can use GraphiQL to interact with GraphQL servers and visualize query results.  ","version":"Next","tagName":"h3"},{"title":"What is the benefit of using aliases in GraphQL?‚Äã","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#what-is-the-benefit-of-using-aliases-in-graphql","content":" Aliases allow you to rename fields in the response, avoiding conflicts and improving readability. This is useful when querying the same field multiple times with different arguments. ","version":"Next","tagName":"h3"},{"title":"Using GraphQL Variables for Type-Safe Queries","type":0,"sectionRef":"#","url":"/graphql/graphql-variables/","content":"","keywords":"","version":"Next"},{"title":"What Are GraphQL Variables?‚Äã","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#what-are-graphql-variables","content":" GraphQL variables are similar to variables in any other programming language. They store values that you can access using their names. These variables are used to pass data from your application to your GraphQL queries and mutations. For instance, take a look at this example where a GraphQL query uses a variable to fetch data:  query GetUserByName($name: String!) { user(name: $name) { name email age } }   In this query, the $name variable in the query helps find a user by its name. You can easily spot GraphQL variables because they always start with a dollar sign ($). Here‚Äôs how a response might look:  { &quot;data&quot;: { &quot;user&quot;: { &quot;name&quot;: &quot;John&quot;, &quot;email&quot;: &quot;john@example.com&quot;, &quot;age&quot;: 10 } } }   ","version":"Next","tagName":"h2"},{"title":"Defining and Using Variables in GraphQL Queries‚Äã","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#defining-and-using-variables-in-graphql-queries","content":" GraphQL variables are defined separately from the query string itself. When you run the query, these variables are inserted into it, and the API responds with matching results. Here‚Äôs how you define a query and its variables in a JSON object for HTTP requests:  { &quot;query&quot;: &quot;query GetUserByName($name: String!) { user(name: $name) { name email age } }&quot;, &quot;variables&quot;: { &quot;name&quot;: &quot;John&quot; } }   Separating the query from the variables makes it easy to write reusable queries. When making requests, you send the query and variables as separate objects.  ","version":"Next","tagName":"h2"},{"title":"Default Values for GraphQL Variables‚Äã","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#default-values-for-graphql-variables","content":" You can set default values for variables, which allows queries to run even without input. Here‚Äôs how you do it:  query GetUserByName($name: String = &quot;Jack&quot;) { user(name: $name) { name email age } }   In this example, if no value is provided for $name, the query uses &quot;Jack&quot; as the default.  ","version":"Next","tagName":"h2"},{"title":"Using Variables in GraphQL Mutations‚Äã","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#using-variables-in-graphql-mutations","content":" GraphQL mutations can create, update, or delete data on the server. Variables work the same way in mutations as they do in queries.  ","version":"Next","tagName":"h2"},{"title":"Example:‚Äã","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#example","content":" mutation UpdateUserName($id: ID!, $new_name: String!) { updateUserName(id: $id, name: $new_name) { id name email age } }   ","version":"Next","tagName":"h3"},{"title":"Passing Variables:‚Äã","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#passing-variables","content":" { &quot;id&quot;: &quot;1&quot;, &quot;new_name&quot;: &quot;Johnny&quot; }   ","version":"Next","tagName":"h3"},{"title":"Using JavaScript to Make a GraphQL Request:‚Äã","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#using-javascript-to-make-a-graphql-request","content":" const query = ` query GetUserByName($name: String!) { user(name: $name) { name email age } } ` const variables = {name: &quot;John&quot;} fetch(&quot;https://YOUR_GRAPHQL_SERVER_URL&quot;, { method: &quot;POST&quot;, headers: { &quot;Content-Type&quot;: &quot;application/json&quot;, }, body: JSON.stringify({query, variables}), }) .then((response) =&gt; response.json()) .then((data) =&gt; console.log(data))   Replace YOUR_GRAPHQL_SERVER_URL with your GraphQL Server url.  ","version":"Next","tagName":"h3"},{"title":"GraphQL Variable Types and Type Safety‚Äã","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#graphql-variable-types-and-type-safety","content":" GraphQL variables come with types to ensure type safety. For example, String! indicates that the variable must be a string GraphQL type and is required. If you pass a different type, an error occurs, and the query won‚Äôt run. This type safety prevents unexpected inputs and results, ensuring your application runs smoothly.  GraphQL has several built-in types: String, Int, Float, Boolean, and ID. These types form the foundation for input object types. You can also define custom input types to model your data.  ","version":"Next","tagName":"h2"},{"title":"Building Apps with GraphQL‚Äã","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#building-apps-with-graphql","content":" TailCall‚Äôs CLI tool can generate GraphQL configurations from various sources, such as protobuf files and REST endpoints. This tool simplifies the process of creating GraphQL configurations, enabling you to build powerful applications with ease. To know more about the gen command in the TailCall CLI, check out the documentation.  ","version":"Next","tagName":"h2"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#conclusion","content":" GraphQL variables and type safety ensure consistent data across your applications. By leveraging these features, you can build flexible, reliable, and scalable applications. TailCall‚Äôs CLI tool simplifies the process of generating GraphQL configurations, enabling you to create powerful applications with ease. To learn more about building apps with GraphQL, explore the TailCall documentation. ","version":"Next","tagName":"h2"},{"title":"GraphQL vs REST: A Detailed Comparison for Modern API Design","type":0,"sectionRef":"#","url":"/graphql/graphql-vs-rest-api-comparison/","content":"","keywords":"","version":"Next"},{"title":"What is REST?‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#what-is-rest","content":" REST (Representational State Transfer) is an architectural style for designing networked applications. It uses HTTP requests to perform CRUD (Create, Read, Update, Delete) operations. Each resource in a RESTful system is identified by a unique URI and can be manipulated using standard HTTP methods: GET, POST, PUT, DELETE.  ","version":"Next","tagName":"h2"},{"title":"Key Characteristics of REST:‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#key-characteristics-of-rest","content":" Stateless: Each request from a client to server must contain all the information needed to understand and process the request.Cacheable: Responses must explicitly define themselves as cacheable or not to prevent clients from reusing stale or inappropriate data.Layered System: A client cannot ordinarily tell whether it is connected directly to the end server or an intermediary along the way.This image highlights multiple requests to different endpoints, showcasing the common problem of overfetching unnecessary data in API design.  ","version":"Next","tagName":"h3"},{"title":"What is GraphQL?‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#what-is-graphql","content":" GraphQL is a query language for APIs and a runtime for executing those queries. It allows clients to request exactly the data they need, avoiding over-fetching and under-fetching issues common with REST. Developed by Facebook in 2012 and open-sourced in 2015, GraphQL provides a more flexible and efficient approach to API design.  ","version":"Next","tagName":"h2"},{"title":"Key Characteristics of GraphQL:‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#key-characteristics-of-graphql","content":" Strongly Typed: GraphQL APIs are defined by a schema using the GraphQL Schema Definition Language (SDL).Single Endpoint: Unlike REST, which has multiple endpoints, GraphQL operates on a single endpoint.Declarative Data Fetching: Clients specify the shape and structure of the required data in a single query.  GraphQL Efficiency: This image shows how clients specify data needs, ensuring the server response matches the query structure precisely.  ","version":"Next","tagName":"h3"},{"title":"Similarities Between GraphQL and REST‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#similarities-between-graphql-and-rest","content":" Both GraphQL and REST facilitate data exchange between client and server in a client-server model, using HTTP as the underlying communication protocol. Here are some similarities:  Resource-Based Design: Both treat data as resources with unique identifiers. In REST, these are represented by URIs, while in GraphQL, they are defined in the schema and identified by the entities.Stateless: Both are stateless architectures, where each request is independent.Support for JSON: Both can use JSON for data format, although REST can also support XML and other formats.  ","version":"Next","tagName":"h2"},{"title":"Differences Between GraphQL and REST‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#differences-between-graphql-and-rest","content":" ","version":"Next","tagName":"h2"},{"title":"Data Fetching‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#data-fetching","content":" REST: Multiple endpoints for different resources, leading to potential over-fetching and under-fetching.GraphQL: Single query to fetch exactly what is needed, reducing the number of requests and amount of data transferred.  ","version":"Next","tagName":"h3"},{"title":"Flexibility‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#flexibility","content":" REST: Fixed data structure defined by the server.GraphQL: Flexible data structure defined by the client.  ","version":"Next","tagName":"h3"},{"title":"Error Handling‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#error-handling","content":" REST: Error handling needs to be implemented by developers.GraphQL: Inbuilt error handling and detailed error messages due to its strong type system.  ","version":"Next","tagName":"h3"},{"title":"Versioning‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#versioning","content":" REST: Often uses versioned endpoints to handle changes, which can be cumbersome.GraphQL: No need for versioning; deprecated fields are marked and can be handled gracefully.  ","version":"Next","tagName":"h3"},{"title":"Performance‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#performance","content":" REST: Can suffer from performance issues due to over-fetching and multiple round-trips.GraphQL: Typically more efficient as it reduces the amount of data transferred and number of requests.  ","version":"Next","tagName":"h3"},{"title":"When to Use GraphQL vs. REST‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#when-to-use-graphql-vs-rest","content":" ","version":"Next","tagName":"h2"},{"title":"Use GraphQL if:‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#use-graphql-if","content":" You need to reduce the number of API calls.Your application requires complex querying capabilities.You want to minimize over-fetching and under-fetching.You have multiple data sources to integrate.  ","version":"Next","tagName":"h3"},{"title":"Use REST if:‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#use-rest-if","content":" You are building simple APIs with well-defined endpoints.Your application has low complexity and data interrelations.You prefer the simplicity and familiarity of REST.  ","version":"Next","tagName":"h3"},{"title":"Implementing Both GraphQL and REST in a Single Application‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#implementing-both-graphql-and-rest-in-a-single-application","content":" It‚Äôs possible to use both GraphQL and REST within the same application, leveraging their respective strengths. Here‚Äôs how you can achieve this:  Analyze Existing RESTful API: Understand the current data model and endpoint structure.Define GraphQL Schema: Write a schema that represents the data model and required operations.Create Resolvers: Develop resolver functions to fetch data from REST endpoints or other data sources. In Tailcall resolvers can be defined using the @http, @grpc, @graphql and @expr directive. Check out the Tailcall GraphQL Directives for more information.Integrate: Set up a GraphQL server alongside your RESTful services, allowing clients to query data through both APIs.  ","version":"Next","tagName":"h2"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"GraphQL vs REST: A Detailed Comparison for Modern API Design","url":"/graphql/graphql-vs-rest-api-comparison/#conclusion","content":" Both GraphQL and REST have their advantages and use cases. While REST is great for simpler applications with clearly defined endpoints, GraphQL offers a more flexible and efficient solution for complex and data-intensive applications. By understanding their differences and leveraging their strengths, you can design robust APIs that meet the needs of modern applications.  For quickly creating a GraphQL server that converts REST APIs to GraphQL, check out Getting Started with Tailcall. ","version":"Next","tagName":"h2"},{"title":"What is GraphQL?: A Simple Introduction","type":0,"sectionRef":"#","url":"/graphql/what-is-graphql/","content":"","keywords":"","version":"Next"},{"title":"GraphQL over HTTP‚Äã","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#graphql-over-http","content":" ","version":"Next","tagName":"h2"},{"title":"Client Side‚Äã","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#client-side","content":" GraphQL is a query language for your APIs. It gives clients the capability to ask for exactly what they need without worrying about where to get it from.  Instead of making traditional GET, POST, PUT, and DELETE requests to different endpoints, GraphQL needs only one endpoint to interact, typically using the POST method. The client sends queries in the body of the POST request. The request will look something like this:The query is sent as a string inside a JSON object.  ","version":"Next","tagName":"h3"},{"title":"Server Side‚Äã","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#server-side","content":" On the server side, It is a runtime that understands these &quot;queries,&quot; fetches data from various data sources, bundles it in the shape that the client requested, and sends it back in an HTTP response.The response object is inside the data key of the JSON object.  The GraphQL server is responsible for exposing the schema, which is a strongly typed contract between the client and the server. It defines what queries clients can make, what types of data can be fetched, and what mutations can be performed.  For GraphQL, the origin of the data is irrelevant‚Äîit could come from a database, a microservice, or even a RESTful API. In essence, GraphQL is not concerned with the source of the data.  Check out the diagram below to get a better understanding of how GraphQL is used in your stack.  ","version":"Next","tagName":"h3"},{"title":"Client-Server Interaction:‚Äã","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#client-server-interaction","content":" The client sends a query to the server. Note that the query is not in JSON format, but it looks like the shape of the JSON data the client needs. So when the POST request is made, the query is sent as a string inside a JSON object.The server receives the JSON object, extracts the query string from it, parses the query to check for proper syntax, and validates it against the Schema (the contract between the client and the server).Based on the query, the server fetches the data from the data sources and bundles it in the JSON object in the shape that the client requested.  ","version":"Next","tagName":"h3"},{"title":"GraphQL Adoption‚Äã","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#graphql-adoption","content":" Due to this flexibility, the adoption of GraphQL has been increasing rapidly. There are many implementations available in various languages like JavaScript, Python, Ruby, Java, Rust, and more.  Starting off as a &quot;hobbyist&quot; stack, It has now been adopted by many big companies like Netflix, GitHub, Twitter, Pinterest, Shopify, and more.  ","version":"Next","tagName":"h2"},{"title":"Frequently Asked Questions‚Äã","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#frequently-asked-questions","content":" ","version":"Next","tagName":"h2"},{"title":"Is GraphQL frontend or backend?‚Äã","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#is-graphql-frontend-or-backend","content":" GraphQL has two parts: the client-side and the server-side. On the client side, It is a query language that allows you to ask for the data you need. On the server side, It is a runtime for executing those queries using a type system you define for your data.  ","version":"Next","tagName":"h3"},{"title":"Is GraphQL an API Gateway?‚Äã","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#is-graphql-an-api-gateway","content":" GraphQL is not an API Gateway. However, it can be used as a layer between your client and your existing APIs to provide a more flexible and efficient way to interact with your data.  ","version":"Next","tagName":"h3"},{"title":"Is GraphQL a Database?‚Äã","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#is-graphql-a-database","content":" GraphQL is not a database. It is a query language for your API and a server-side runtime for executing queries using a type system you define for your data. It can be used to query data from databases, REST/gRPC APIs, and other data sources.  ","version":"Next","tagName":"h3"},{"title":"Is GraphQL better than REST?‚Äã","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#is-graphql-better-than-rest","content":" It depends on your use case. Since there is more efficiency associated with working with GraphQL, development is much faster with it than with REST.  ","version":"Next","tagName":"h3"},{"title":"How can I convert my REST APIs to GraphQL?‚Äã","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#how-can-i-convert-my-rest-apis-to-graphql","content":" You can use tools like Tailcall, which is the simplest way to convert your REST APIs to GraphQL APIs. You can find more details here. ","version":"Next","tagName":"h3"},{"title":"Problem Statement","type":0,"sectionRef":"#","url":"/graphql/problem-statement/","content":"","keywords":"","version":"Next"},{"title":"Problem Space‚Äã","type":1,"pageTitle":"Problem Statement","url":"/graphql/problem-statement/#problem-space","content":" Two of the major paradigm shifts happening in the technology industry over the past few years are:  Complex User Interfaces: Responsive websites that worked on desktop and mobile are dead. To build a successful B2C business, you need to build for all three platforms viz. Android, iOS, and Web (Desktop/PWA). The applications need to look slick, rich in information, and have snappy response times.Microservice Proliferation: Many companies these days bootstrap themselves on microservices instead of monoliths. This is because the tooling has gotten a lot better, and reusable components are available either in open-source or as a fully managed SAAS solution. This allows developers to focus on their core business logic and move fast.  ","version":"Next","tagName":"h2"},{"title":"Microservice Architecture‚Äã","type":1,"pageTitle":"Problem Statement","url":"/graphql/problem-statement/#microservice-architecture","content":" This is what a typical microservices architecture looks like today:  The clients (Mobile/Web) make requests to the microservices through an API gateway. An API gateway is a server that acts as a single point of entry for any type of request, responsible for routing requests to the appropriate backend service and forwarding the response to the client. An API gateway can also perform common tasks such as authentication, rate limiting, and caching, making it a useful component in a microservices architecture: each service exposes an API to the gateway, and the gateway acts as the &quot;front desk&quot; for clients to access the services.  ","version":"Next","tagName":"h2"},{"title":"API Orchestration‚Äã","type":1,"pageTitle":"Problem Statement","url":"/graphql/problem-statement/#api-orchestration","content":" API orchestration refers to the process of combining one or more APIs to create a new API. This can be done by creating a new API that either acts as a facade for the underlying APIs, or splits up incoming requests, delegates to the underlying APIs, and combines the results back together. Consider a scenario where a social media client application wants to display a timeline of posts with the author's profile information next to each one. In this case, the client can send two separate requests to two different APIs and combine them as follows: First to /posts to retrieve recent posts, with the following response:  type Post { id: ID! title: String! body: String! userId: ID! # Reference to the user by its id. }   Second, with the userId from the above post response, make a request to /users to retrieve the user's profile information, with the following response:  type User { id: ID! name: String! email: String! }   The client can then combine the results from these two APIs to create a single response that contains all the required information. This new response can be considered as the output of the composed API.  type Post { id: ID! title: String! body: String! user: User # Reference to the complete user object }   Orchestration is not limited to stitching APIs, here are some other use cases where having an API Orchestrator is of significant value:  Access Control: Instead of building an ‚Äúadmin‚Äù API and a ‚Äúcustomer‚Äù API, you could create a set of basic CRUD endpoints and build access control on top of the orchestrator. Localization: Adding support for language translations can be moved to an orchestration layer instead of embedding into the application layer. Batching: An orchestrator can intelligently leverage batch APIs automatically without the consumer making any change, thus drastically reducing load. Obfuscation: An orchestrator can precisely control which field needs to be obfuscated, how, and when. Protocol Translation: An orchestrator can very efficiently convert between protocols. Validations: An orchestrator could filter out invalid requests up front, reducing unnecessary work on the underlying services. Type Safe SDK: Orchestration engines can generate type safe client SDKs to consume APIs. Discoverability: Orchestrators can provide detailed &amp; up-to-date documentation of the APIs that are exposed. Collaboration: Allows consumers and producers of APIs to move at different speeds via &quot;mocking&quot;. Optimize APIs based on usage patterns. Breaking Changes: Identify breaking changes, performance degradations and other potential issues even before deployment. Business Logic: Logic controlling the flow of requests based on business conditions is best suited to execution within the gateway or orchestration layer. Distributed Management: Instead of giving control of all APIs to one team, each team can manage their part of the API and seamlessly compose with the existing API network.  important API Orchestration is distinct from Microservice Orchestration, the latter relates to managing multiple micro-services working together to perform a larger task or workflow.  ","version":"Next","tagName":"h2"},{"title":"Composition on Clients‚Äã","type":1,"pageTitle":"Problem Statement","url":"/graphql/problem-statement/#composition-on-clients","content":" Composition on the client side remains unstandardized. Common problems include over-fetching and under-fetching. Over-fetching is where the server responds to a client request with more data than is required to render the screen. Under fetching is where the client needs to make multiple, often chained, API requests to get relevant data for a particular screen because the server couldn't provide all the required data in a single request. These two problems in conjunction with modest hardware and an unreliable network connection can make the overall solution unreliable, slow, and frustrating.  tip When composing on the client side, modest hardware and unfavorable network conditions often result in poor user-experience.  Increased Complexity:To build a rich user interface, API composition is necessary. One of the main challenges with API composition on the client side is that it can lead to increased complexity in the client application: the client needs to handle sending requests to multiple APIs and combining the results, adding to the overall size and complexity of the client code. Reduced Performance:Another challenge with API composition on the client side is that it can result in reduced performance and increased latency:the client often needs to make multiple requests to different APIs, taking more time and resulting in a slower response from the composed API. Increased Risk:In addition, API composition on the client side can also lead to increased security risks:the client needs to handle sensitive information such as API keys and authentication credentials for multiple APIs. These critical security tokens can be vulnerable to attacks if not properly secured, and many clients lack access to powerful CPUs and reliable network connections.  ","version":"Next","tagName":"h2"},{"title":"Backend For Frontend (BFF)‚Äã","type":1,"pageTitle":"Problem Statement","url":"/graphql/problem-statement/#backend-for-frontend-bff","content":" A BFF layer can help to solve the challenges of API composition mentioned above by providing a separate backend service that is optimized for each specific frontend client. This can enable the BFF to perform API composition on behalf of the client, which can help to improve the performance and reliability of the composed API. The BFF layer typically sits as a separate component in the overall architecture, between the frontend client and the microservices. It can communicate with both the frontend client and the microservices using well-defined interfaces and protocols, such as REST or gRPC.  tip BFFs can dramatically improve the reliability and performance of the system, thereby having a direct positive impact on user-experience.  The BFF can take advantage of a powerful CPU and access to a fast network to improve the performance and reliability of the composed API. It can also provide added flexibility and control over the composition process. This can make it a useful tool for developers who want to create new APIs by combining the functionality of multiple underlying APIs. However, there are a few challenges with a BFF layer:  Highly Specialized:BFF layers are highly specialized solutions that require a significant amount of hand-written code. Unlike an API gateway, there is no standard BFF solution that can be deployed out-of-the-box, and each BFF implementation must be custom-tailored to the specific requirements of the frontend client. This lack of standardization and reusability can make the BFF solution more complex and difficult to maintain. Fragile:Fragile and susceptible to failure, the BFF solution is dependent on the developers to follow best practices and handle all error scenarios. If these steps are not taken, the solution can be prone to bugs and performance issues. Additionally, the BFF solution must be thoroughly tested, including performance testing, unit testing, and integration testing, to ensure that it is reliable and performs well in production. This can require significant effort and expertise, and if these steps are not properly followed, the resulting BFF solution will likely be fragile and prone to failure. Since the BFF layer is the client's sole entry point to your backend, it becoming unavailable translates into a complete service outage for the user - it is therefore essential this layer be robust and resilient to exceptions. Speculative Performance:Because BFF layers are typically custom-written for each use case, it can be difficult to predict the performance impact of a small code change. Issues such as unoptimized algorithms, inefficient caching, and unnecessary downstream requests can go unnoticed and only be discovered very late in the development cycle. Typically this means companies must perform thorough benchmarking and load testing before anything goes to production, resulting in a high time to market even for minor changes. Monolithic:This layer frequently becomes quite comprehensive, intertwining with numerous backend services. It's not unusual for it to include a significant amount of complex, manually written code that can be challenging to manage. These issues can make it more difficult for new engineers to get up to speed, and can increase the time and cost associated with updating libraries or making architectural enhancements. Even small changes might necessitate large scale deployments across your infrastructure. Canary Support (Lack thereof):Every change that happens in the backend requires the deployment of the BFF layer. Any feature that is built on the client also requires changes on the BFF layer. Such frequent changes can not be exposed to 100% of users because the reliability and performance of this system are unknown. A common way to solve this problem is to use Blue-Green deployments. This requires additional infrastructure and complex routing mechanisms. First-class support to do canary releases is very important and should be part of a modern BFF layer, however, most companies rely on DevOps for its support. Coupled Releases:Since the BFF layer acts as a bridge between clients and services it serves as the middle link in the dependency chain: the client depends on the BFF, which in turn depends on the services. When it's time to deploy new features, first you must deploy the new services (which must support the existing and new BFF), then the new BFF layer is deployed (which must support existing and new clients), and finally the client can be deployed. If, due to a bug in a microservice, you need to revert the services, then you'd also need to replace the BFF layer with one that supports the new client calls even though the services have (temporarily) lost support for these calls. This coupling makes for expensive operational management. Composability:Traditional APIs, such as REST, work well when interacting directly with a single data source. REST benefits from a mature infrastructure that handles various cross-cutting concerns, such as routing, load balancing, caching, rate limiting, authentication, and authorization. However, the semantics of these capabilities start to break down when we consider API composition. For example, imagine an API composed of two other APIs, where one is highly cacheable and the other is not well defined. The same issues arise with authorization, authentication, and rate limiting. This inherent lack of composability makes REST challenging to use in scenarios requiring API composition.  note Presentation Layer, Facade, Middleware, Frontend Layer, Orchestration Layer, API Adapter ‚Äî these are all terms that are sometimes used to refer to the BFF layer ","version":"Next","tagName":"h2"},{"title":"Understanding GraphQL Schemas and Types","type":0,"sectionRef":"#","url":"/graphql/schemas-and-types/","content":"","keywords":"","version":"Next"},{"title":"What is GraphQL Schema?‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#what-is-graphql-schema","content":" In GraphQL, schemas act as a bridge between the client and the owner of the data, i.e., the Data Source. A schema defines a contract between the client and the server, providing a clear understanding of the data that can be queried. Upon receiving a query, the server validates the query against the GraphQL schema, then executes it and sends back the response in the requested shape.  In simple terms, a schema is a comprehensive description of the data that clients can query. It outlines the types of objects, the relationships between them, and the operations available for querying and mutating data. It is defined using the GraphQL Schema Definition Language (SDL), a human-readable syntax that describes the capabilities of the API.  ","version":"Next","tagName":"h2"},{"title":"The Importance of Schemas in GraphQL‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#the-importance-of-schemas-in-graphql","content":" Schemas in GraphQL are vital because they:  Specify the available data types.Define relationships between different data entities.Enforce data validation rules.Provide a clear contract between the server and the client.  ","version":"Next","tagName":"h2"},{"title":"GraphQL Type System‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#graphql-type-system","content":" As discussed above, GraphQL defines various types that we can utilize to build our schema. Here are the different available types.  Scalar TypeObject TypeInput TypesEnum TypeInterface and Union TypesLists and Non-Null  ","version":"Next","tagName":"h2"},{"title":"Defining Types in GraphQL‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#defining-types-in-graphql","content":" ","version":"Next","tagName":"h2"},{"title":"Scalar Types‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#scalar-types","content":" Scalar types are primitive data types that resolve to a single value. Common scalar types in GraphQL include Int, Float, String, Boolean, and ID.  type Post { id: ID! title: String! content: String! }   ","version":"Next","tagName":"h3"},{"title":"Object Types‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#object-types","content":" Object types represent a collection of fields, each with a specific type. For example, a User object type might have fields like id, name, and email and their corresponding types.  type User { id: ID! name: String! email: String! }   ","version":"Next","tagName":"h3"},{"title":"Input Types‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#input-types","content":" Input types are used for complex mutations, allowing clients to pass structured objects as arguments.  input PostInput { title: String! content: String! authorId: ID! }   ","version":"Next","tagName":"h3"},{"title":"Enum Types‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#enum-types","content":" Enumeration types restrict a field to a set of predefined values, enhancing type safety and validation.  enum Role { ADMIN EDITOR USER }   ","version":"Next","tagName":"h3"},{"title":"Interface and Union Types‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#interface-and-union-types","content":" Interfaces and unions enable polymorphic queries by allowing fields to return different types under a common interface or union.  interface Node { id: ID! } type User implements Node { id: ID! name: String! } type Post implements Node { id: ID! title: String! }   ","version":"Next","tagName":"h3"},{"title":"Lists and Non-Null Types‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#lists-and-non-null-types","content":" In defining your schema, you will utilize object, scalar, input, and enum types. GraphQL also offers modifiers that enable quick validations within type definitions and arguments of queries and mutations. The available modifiers include:  Exclamation Mark (!) for Non-NullSquare Brackets ([]) for List  ","version":"Next","tagName":"h3"},{"title":"Relationships Between Types‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#relationships-between-types","content":" GraphQL schema can represent relationships between types using references. For instance, a User can have multiple posts, and each Post can reference its author.  type User { id: ID! name: String! posts: [Post!]! } type Post { id: ID! title: String! content: String! author: User! }   ","version":"Next","tagName":"h2"},{"title":"Schema, Query and Mutation Types‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#schema-query-and-mutation-types","content":" ","version":"Next","tagName":"h2"},{"title":"Schema Type‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#schema-type","content":" Schema type is a special Object type which is the entry point for all GraphQL operations. It defines the queries, mutations, and subscriptions available in the schema.  schema { query: Query mutation: Mutation subscription: Subscription }   ","version":"Next","tagName":"h3"},{"title":"Query Type‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#query-type","content":" The query type defines the entry point for read operations in a GraphQL schema. It specifies what data clients can fetch.  type Query { users: [User!]! user(id: ID!): User posts: [Post!]! post(id: ID!): Post }   ","version":"Next","tagName":"h3"},{"title":"Mutation Type‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#mutation-type","content":" The mutation type defines the entry point for write operations, allowing clients to modify data.  type Mutation { createUser(name: String!, email: String!): User! createPost(input: PostInput!): Post! }   ","version":"Next","tagName":"h3"},{"title":"Subscriptions in GraphQL‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#subscriptions-in-graphql","content":" Subscriptions allow clients to receive real-time updates when data changes. They are defined similarly to queries and mutations.  type Subscription { postAdded: Post! }   ","version":"Next","tagName":"h2"},{"title":"Best Practices for Designing GraphQL Schemas‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#best-practices-for-designing-graphql-schemas","content":" Use Descriptive Naming Conventions: Ensure that type and field names are intuitive and descriptive.Leverage Scalar and Enum Types: Use scalar and enum types to enforce data validation.Design for Performance: Minimize nested queries and optimize resolver functions.Modularize Schemas: Break down large schemas into smaller, reusable modules.Documentation: Annotate schemas with comments for better maintainability and clarity.  ","version":"Next","tagName":"h2"},{"title":"Example Diagram: GraphQL Schema Structure‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#example-diagram-graphql-schema-structure","content":"   ","version":"Next","tagName":"h2"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#conclusion","content":" A robust and well-defined GraphQL schema is essential for building scalable and efficient APIs. By understanding the core concepts and best practices for defining schemas and types, developers can create powerful and flexible GraphQL servers that meet the needs of their clients. ","version":"Next","tagName":"h2"},{"title":"GraphQL Configuration","type":0,"sectionRef":"#","url":"/docs/tailcall-dsl-graphql-custom-directives/","content":"","keywords":"","version":"Next"},{"title":"@addField Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#addfield-directive","content":" The @addField directive simplifies data structures and queries by adding a field that inline or flattens a nested field or node within your schema. It modifies the schema and the data transformation process, making nested data more accessible and straightforward to present.  For instance, consider a schema:  schema { query: Query } type User @addField(name: &quot;street&quot;, path: [&quot;address&quot;, &quot;street&quot;]) { id: Int! name: String! username: String! email: String! phone: String website: String address: Address @modify(omit: true) } type Address { street: String! city: String! state: String! } type Query { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) }   Suppose we focus on the street field in Address.  In this case, applying the @addField directive to the User type creates a street field within the User type. It uses a path argument to specify the sequence of fields from a declared field (address), leading to the Address field to add. We also can apply @modify(omit: true) to remove the address field from the schema, as the street field from Address is now directly accessible on the User type.  Post application, the schema becomes:  schema { query: Query } type User { id: Int! name: String! username: String! email: String! phone: String website: String street: String } type Query { user(id: Int): Post! }   In the above example, since we added a @modify(omit: true) on the address field, the schema no longer includes the Address type.  The @addField directive also take cares of nullablity of the fields. If any of the fields in the path is nullable, the resulting type will be nullable.  @addField also supports indexing, allowing for the specification of an array index for inline inclusion. For instance, if a field posts is of type [Post], and the goal is to access the title of the first post, specify the path as [&quot;posts&quot;,&quot;0&quot;,&quot;title&quot;].  type User @addField( name: &quot;firstPostTitle&quot; path: [&quot;posts&quot;, &quot;0&quot;, &quot;title&quot;] ) { id: Int! name: String! username: String! email: String! phone: String website: String posts: Post @http(path: &quot;/users/{{.value.id}}/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! }   In conclusion, the @addField directive helps tidy up your schema and streamline data fetching by reducing query depth, promoting better performance and simplicity.  ","version":"Next","tagName":"h2"},{"title":"@cache Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#cache-directive","content":" The @cache directive provides a protocol agnostic mechanism for caching the results of fields within a GraphQL schema. Like any other cache implementation, this feature is useful for optimizing performance by reducing the need to fetch data that doesn't change frequently.  ","version":"Next","tagName":"h2"},{"title":"maxAge‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#maxage","content":" @cache(maxAge: Int)   This parameter is a non-zero unsigned integer specifying the duration, in milliseconds, that retains the cached value.  ","version":"Next","tagName":"h3"},{"title":"Usage‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#usage","content":" Consider the following GraphQL schema example:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int title: String userId: Int @cache(maxAge: 100) user: User @http(path: &quot;/user/{{.value.userId}}&quot;) @cache(maxAge: 200) } type User { id: Int name: String email: String }   In this configuration, the system caches the result of the user field due to its association with an HTTP resolver. But it does not cache the values of userId and title because they lack individual resolvers; the resolver for the posts field retrieves their values, employing the @http(path: &quot;/posts&quot;) directive.  Applying the @cache directive at the type level affects all fields within that type. For example:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post @cache(maxAge: 100) { id: Int title: String userId: Int user: User @http(path: &quot;/user/{{.value.userId}}&quot;) } type User { id: Int name: String email: String }   You can simplify this configuration to show that applying the @cache directive to a type means every field within that type inherits it:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int @cache(maxAge: 100) title: String @cache(maxAge: 100) userId: Int @cache(maxAge: 100) user: User @http(path: &quot;/user/{{.value.userId}}&quot;) @cache(maxAge: 100) } type User { id: Int name: String email: String }   Since the @cache directive does not affect fields without resolvers, the effective configuration can be further reduced as follows:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int title: String userId: Int user: User @http(path: &quot;/user/{{.value.userId}}&quot;) @cache(maxAge: 100) } type User { id: Int name: String email: String }   When applying the @cache directive both at the type level and on individual fields within that type, the field-level directive takes precedence:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post @cache(maxAge: 200) { id: Int title: String userId: Int user: User @http(path: &quot;/user/{{.value.userId}}&quot;) @cache(maxAge: 100) } type User { id: Int name: String email: String }   Thus, in the configuration above, while all fields inherit the @cache(maxAge: 200) directive at the type level, the user field's explicit @cache(maxAge: 100) directive takes precedence.  ","version":"Next","tagName":"h3"},{"title":"Cache Key‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#cache-key","content":" The caching mechanism generates a hash based on information related to the applied query to serve as the cache key for the corresponding value.  For instance, the system caches the user field in the following configuration, using the hash of the interpolated string &quot;/user/{{.value.userId}}&quot; as the cache key. For example, if Post.userId equals 1, the system generates the cache key by hashing the string &quot;/users/1&quot;.  ","version":"Next","tagName":"h3"},{"title":"@call Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#call-directive","content":" The @call directive in GraphQL signifies a shift towards more efficient configuration management by introducing a methodology akin to function invocations in conventional programming. This directive is pivotal for developers navigating the intricacies of elaborate GraphQL schemas, where minimizing redundancy and adhering to the DRY (Don't Repeat Yourself) principle are paramount. Consider the following schema example:  schema @upstream( baseURL: &quot;https://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) } type User { id: Int! name: String! email: String! }   In this schema, at lines 9 and 18, a pattern of configuration duplication emerges when fetching user's data by its id, demonstrating a prime use case for the @call directive. Through refactoring the Post type to incorporate the @call directive, we can eliminate this redundancy.  type Post { id: Int! userId: Int! title: String! body: String! user: User @call( steps: [ {query: &quot;user&quot;, args: {id: &quot;{{.value.userId}}&quot;}} ] ) }   Here, the @call directive invokes the user query from the Query type, leveraging the data-fetching process that's already defined in the root query. The query parameter specifies the target field, while the args parameter delineates the arguments to be passed.  ","version":"Next","tagName":"h2"},{"title":"steps‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#steps","content":" @call directive can compose together other resolvers, allowing to create a chain of resolvers that can be executed in sequence. This is done by using the steps parameter, which is an array of objects that define the operations to be executed.  ","version":"Next","tagName":"h3"},{"title":"query‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#query","content":" Specify the root query field to invoke, alongside the requisite arguments, using the @call directive for a concise and efficient query structure.  type Post { userId: Int! user: User @call( steps: [ {query: &quot;user&quot;, args: {id: &quot;{{.value.userId}}&quot;}} ] ) }   ","version":"Next","tagName":"h3"},{"title":"mutation‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#mutation","content":" Similarly, the @call directive can facilitate calling a mutation from another mutation field, employing the mutation parameter for field specification and the args parameter for argument delineation.  type Mutation { insertPost(input: PostInput, overwrite: Boolean): Post @http( body: &quot;{{.args.input}}&quot; method: &quot;POST&quot; path: &quot;/posts&quot; query: {overwrite: &quot;{{.args.overwrite}}&quot;} ) upsertPost(input: PostInput): Post @call( steps: [ { mutation: &quot;insertPost&quot; args: {input: &quot;{{.args.input}}&quot;, overwrite: true} } ] ) }   ","version":"Next","tagName":"h3"},{"title":"args‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#args","content":" The args parameter in the @call directive facilitates passing arguments to the targeted query or mutation, represented as a key-value mapping where each key corresponds to an argument name and its associated value.  type Post { userId: Int! user: User @call( steps: [ {query: &quot;user&quot;, args: {id: &quot;{{.value.userId}}&quot;}} ] ) }   tip The @call directive is predominantly advantageous in complex, large-scale configurations. For those new to GraphQL or Tailcall, it may be beneficial to explore this directive after familiarizing yourself with the foundational aspects of GraphQL.  ","version":"Next","tagName":"h3"},{"title":"Composition‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#composition","content":" @call directive provides the ability to express a sequence of steps that one might need to compose. These steps are executed such that the result of each step is passed as an argument to the next step. The query and mutation parameters are used to specify the target field, while the args parameter is used to pass arguments to the target field.  Let's explain this with an example:  schema @server { query: Query } type Query { a(input: JSON): JSON @expr(body: {value: &quot;{{.args.input.a}}&quot;}) b(input: JSON): JSON @expr(body: {value: &quot;{{.args.input.b}}&quot;}) c(input: JSON): JSON @expr(body: {value: &quot;{{.args.input.c}}&quot;}) }   Here we have defined there operations viz. a, b &amp; c each of them pluck their respective keys from the given input value. Let's run this query with some test input:  { a(input: {a: 100}) b(input: {b: 200}) c(input: {c: 300}) }   Here is how the response would look like:  { &quot;data&quot;: { &quot;a&quot;: { &quot;value&quot;: 100 }, &quot;b&quot;: { &quot;value&quot;: 200 }, &quot;c&quot;: { &quot;value&quot;: 300 } } }   As you can see the @expr directive plucks the inner value and returns the result. How about we implement an abc operation that could leverage the existing operations and unwrap the following input value:  {&quot;a&quot;: {&quot;b&quot;: {&quot;c&quot;: {&quot;d&quot;: 1000}}}}   Given the above input if we wish to extract the last inner number 1000 then we could define a new operation as follows  schema @server { query: Query } type Query { a(input: JSON): JSON @expr(body: {value: &quot;{{.args.input.a}}&quot;}) b(input: JSON): JSON @expr(body: {value: &quot;{{.args.input.b}}&quot;}) c(input: JSON): JSON @expr(body: {value: &quot;{{.args.input.c}}&quot;}) abc(input: JSON): JSON @call( steps: [ {query: &quot;a&quot;, args: {input: &quot;{{.args.input}}&quot;}} {query: &quot;b&quot;, args: {input: &quot;{{.args.value}}&quot;}} {query: &quot;c&quot;, args: {input: &quot;{{.args.value}}&quot;}} ] ) }   We use the @call directive to compose the operations together. The args specify how we would like to pass the arguments to the operation and the result of that operation is passed to the next step. We can test the new abc operation with the following query:  query { abc(input: {a: {b: {c: 1000}}}) }   The server returns the response that we expected:  { &quot;data&quot;: { &quot;abc&quot;: { &quot;value&quot;: 100 } } }   This way you can compose combine multiple operations can compose them together using the @call directive.  note We use JSON scalar here because we don't care about the type safety of this option. In a real world example you might want to use proper input and output types.  ","version":"Next","tagName":"h3"},{"title":"@expr Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#expr-directive","content":" The @expr directive in GraphQL is a powerful tool for embedding data directly into your schema, offering two primary functionalities:  ","version":"Next","tagName":"h2"},{"title":"Static‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#static","content":" This feature allows for the inclusion of a constant response within the schema definition itself. It is useful for scenarios where the response is unchanging. e.g:  schema { query: Query } type Query { user: User @expr(body: {name: &quot;John&quot;, age: 12}) } type User { name: String age: Int }   The @expr directive also checks the provided value at compile time to ensure it matches the field's schema. If not, the console displays a descriptive error message.  ","version":"Next","tagName":"h3"},{"title":"Dynamic‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#dynamic","content":" Beyond static data embedding, the @expr directive extends its utility to support dynamic data injection through Mustache template syntax. This feature enables the use of placeholders within the constant data, which are then dynamically replaced with actual values at runtime. It supports both scalar values and complex objects, including lists and nested objects, offering flexibility in tailoring responses to specific needs. e.g:  schema { query: Query } type Query { user: User @expr( body: { name: &quot;John&quot; workEmail: &quot;john@xyz.com&quot; personalEmail: &quot;john@xyz.com&quot; } ) } type User { name: String age: Int personalEmail: String workEmail: String emails: Emails @expr( body: { emails: { workEmail: &quot;{{.value.workEmail}}&quot; personalEmail: &quot;{{.value.personalEmail}}&quot; } } ) } type Emails { workEmail: String personalEmail: String }   In this example, the @expr directive dynamically generate an Emails object based on the provided template data. The placeholders within the template ({{.value.workEmail}} and {{.value.personalEmail}}) gets replaced with the actual values specified in the User type, allowing for dynamic content generation while still adhering to the schema's structure.  ","version":"Next","tagName":"h3"},{"title":"@graphQL Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#graphql-directive","content":" The @graphQL directive allows to specify GraphQL API server request to fetch data from.  type Query { users: [User] @graphQL(name: &quot;userList&quot;) }   The @graphQL directive facilitates fetching a list of users from the GraphQL API upstream. The name argument specifies the root field's name on the upstream server. The upcoming request to the GraphQL server determines the User type's inner fields for the request. Depending on the operation type within which one finds the @graphQL directive, the GraphQL configuration determines the query's operation type.  For the next request with the config above:  query { users { id name } }   Tailcall will request the next query for the upstream:  query { userList { id name } }   ","version":"Next","tagName":"h2"},{"title":"baseURL‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#baseurl","content":" This refers to the base URL of the API. If not specified, the default base URL is the one specified in the @upstream directive.  type Query { users: [User] @graphQL( name: &quot;users&quot; baseURL: &quot;https://graphqlzero.almansi.me/api&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"name‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#name","content":" The root field's name on the upstream to request data from. For example:  type Query { users: [User] @graphQL(name: &quot;userList&quot;) }   When Tailcall receives a query for the users field, it will request a query for userList from the upstream.  ","version":"Next","tagName":"h3"},{"title":"args‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#args-1","content":" Named arguments for the requested field. For example:  type Query { user: User @graphQL( name: &quot;user&quot; args: [{key: &quot;id&quot;, value: &quot;{{.value.userId}}&quot;}] ) }   Will request the next query from the upstream for the first user's name:  query { user(id: 1) { name } }   ","version":"Next","tagName":"h3"},{"title":"headers‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#headers","content":" The headers parameter allows customizing the headers of the GraphQL request made by the @graphQL directive. Specifying a key-value map of header names and their values achieves this.  For instance:  type Mutation { users: User @graphQL( name: &quot;users&quot; headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}] ) }   In this example, a request to /users will include the HTTP header X-Server with the value Tailcall.  ","version":"Next","tagName":"h3"},{"title":"batch‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#batch","content":" In case the upstream GraphQL server supports request batching, we can specify the batch argument to batch requests to a single upstream into a single batch request. For example:  schema @upstream( batch: { maxSize: 1000 delay: 10 headers: [&quot;X-Server&quot;, &quot;Authorization&quot;] } ) { query: Query mutation: Mutation } type Query { users: [User] @graphQL(name: &quot;users&quot;, batch: true) posts: [Post] @graphQL(name: &quot;posts&quot;, batch: true) }   Make sure you have also specified batch settings to the @upstream and to the @graphQL directive.  ","version":"Next","tagName":"h3"},{"title":"@grpc Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#grpc-directive","content":" The @grpc directive enables the resolution of GraphQL fields via gRPC services. Below is an illustrative example of how to apply this directive within a GraphQL schema:  schema @link(src: &quot;./users.proto&quot;, type: Protobuf) { query: Query } type Query { users: [User] @grpc(method: &quot;users.UserService.ListUsers&quot;) }   This schema snippet demonstrates the directive's application, where a query for users triggers a gRPC request to the UserService's ListUsers method, thereby fetching the user data.  The .proto file delineates the structure and methods of the gRPC service. A simplified example of such a file is as follows:  syntax = &quot;proto3&quot;; package users; service UserService { rpc ListUsers (UserListRequest) returns (UserListReply) {} rpc GetUser (UserGetRequest) returns (UserGetReply) {} } message UserListRequest { // Definitions of request parameters } message UserListReply { // Structure of the reply } message UserGetRequest { // Definitions of request parameters } message UserGetReply { // Structure of the reply }   important It is mandatory to have a package name in a protobuf file.  Linking this file within a GraphQL schema is facilitated by the @link directive, as shown below:  schema @link(src: &quot;./users.proto&quot;, type: Protobuf) { query: Query }   Tailcall automatically resolves the protobuf file for any methods referenced in the @grpc directive.  ","version":"Next","tagName":"h2"},{"title":"method‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#method","content":" This parameter specifies the gRPC service and method to be invoked, formatted as &lt;package&gt;.&lt;service&gt;.&lt;method&gt;:  type Query { users: [User] @grpc(method: &quot;proto.users.UserService.ListUsers&quot;) }   ","version":"Next","tagName":"h3"},{"title":"baseURL‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#baseurl-1","content":" Defines the base URL for the gRPC API. If not specified, the URL set in the @upstream directive is used by default:  type Query { users: [User] @grpc( baseURL: &quot;https://grpc-server.example.com&quot; method: &quot;proto.users.UserService.ListUsers&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"body‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#body","content":" This parameter outlines the arguments for the gRPC call, allowing for both static and dynamic inputs:  type UserInput { id: ID } type Query { user(id: UserInput!): User @grpc( body: &quot;{{.args.id}}&quot; method: &quot;proto.users.UserService.GetUser&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"headers‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#headers-1","content":" Custom headers for the gRPC request can be defined, facilitating the transmission of authentication tokens or other contextual data:  type Query { users: [User] @grpc( headers: [ {key: &quot;X-CUSTOM-HEADER&quot;, value: &quot;custom-value&quot;} ] method: &quot;proto.users.UserService.ListUsers&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"batchKey‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#batchkey","content":" This argument is employed to optimize batch requests by grouping them based on specified response keys, enhancing performance in scenarios requiring multiple, similar requests:  type Query { users(id: UserInput!): [User] @grpc( batchKey: [&quot;id&quot;] method: &quot;proto.users.UserService.ListUsers&quot; baseURL: &quot;https://grpc-server.example.com&quot; ) }   info Read about n + 1 to learn how to use the batchKey setting.  ","version":"Next","tagName":"h3"},{"title":"@http Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#http-directive","content":" The @http directive indicates a field or node relies on a REST API. For example:  type Query { users: [User] @http(path: &quot;/users&quot;) }   In this example, adding the @http directive to the users field of the Query type indicates reliance on a REST API for the users field. The path argument specifies the REST API's path, which is /users in this scenario.Querying the users field prompts the GraphQL server to issue a GET request to https://jsonplaceholder.typicode.com/users.  ","version":"Next","tagName":"h2"},{"title":"baseURL‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#baseurl-2","content":" Specifies the API's base URL. If unspecified, it defaults to the URL in the @upstream directive.  type Query { users: [User] @http( path: &quot;/users&quot; baseURL: &quot;https://jsonplaceholder.typicode.com&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"path‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#path","content":" Refers to the API endpoint, for example, https://jsonplaceholder.typicode.com/users.  type Query { users: [User] @http(path: &quot;/users&quot;) }   If your API endpoint contains dynamic segments, you can substitute variables using Mustache templates. For example, to fetch a specific user, you can write the path as /users/{{.args.id}}.  type Query { user(id: ID!): User @http(path: &quot;/users/{{.args.id}}&quot;) }   ","version":"Next","tagName":"h3"},{"title":"method‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#method-1","content":" Specifies the HTTP method for the API call. The default method is GET if not specified.  type Mutation { createUser(input: UserInput!): User @http(method: &quot;POST&quot;, path: &quot;/users&quot;) }   ","version":"Next","tagName":"h3"},{"title":"query‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#query-1","content":" Represents the API call's query parameters, either as a static object or with dynamic parameters using Mustache templates. These parameters append to the URL.  type Query { userPosts(id: ID!): [Post] @http( path: &quot;/posts&quot; query: [{key: &quot;userId&quot;, value: &quot;{{.args.id}}&quot;}] ) }   ","version":"Next","tagName":"h3"},{"title":"body‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#body-1","content":" Defines the API call's body, necessary for methods like POST or PUT. Pass it as a static object or use Mustache templates for variable substitution from the GraphQL variables.  type Mutation { createUser(input: UserInput!): User @http( method: &quot;POST&quot; path: &quot;/users&quot; body: &quot;{{.args.input}}&quot; ) }   In the example above, the createUser mutation sends a POST request to /users, with the input object converted to JSON and included in the request body.  ","version":"Next","tagName":"h3"},{"title":"headers‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#headers-2","content":" Customizes the HTTP request headers made by the @http directive. Specify a key-value map of header names and values.  For instance:  type Mutation { createUser(input: UserInput!): User @http( path: &quot;/users&quot; headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}] ) }   In this example, a request to /users will include a HTTP header X-Server with the value Tailcall.  You can make use of mustache templates to provide dynamic values for headers, derived from the arguments or context provided in the request. For example:  type Mutation { users(name: String): User @http( path: &quot;/users&quot; headers: [ {key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;} {key: &quot;User-Name&quot;, value: &quot;{{.args.name}}&quot;} ] ) }   In this scenario, the User-Name header's value will dynamically adjust according to the name argument passed in the request.  ","version":"Next","tagName":"h3"},{"title":"batchKey‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#batchkey-1","content":" Groups data requests into a single call, enhancing efficiency. Refer to our n + 1 guide for more details.  type Post { id: Int! name: String! user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{.value.userId}}&quot;}] batchKey: [&quot;id&quot;] ) }   query: {key: &quot;id&quot;, value: &quot;{{.value.userId}}&quot;}]: Instructs TailCall CLI to generate a URL aligning the user id with userId from the parent Post, compiling a single URL for a batch of posts, such as /users?id=1&amp;id=2&amp;id=3...id=10, consolidating requests into one.  ","version":"Next","tagName":"h3"},{"title":"onRequest‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#onrequest","content":" The onRequest property accepts a string value representing the remote function to be called every time an HTTP request is initiated. Typically the remote function is defined in a linked JavaScript worker file.  note For defining a request middleware globally for all requests, refer to the upstream directive documentation.  type Query { userPosts(id: ID!): [Post] @http( path: &quot;/posts&quot; query: [{key: &quot;userId&quot;, value: &quot;{{.args.id}}&quot;}] onRequest: &quot;someFunctionName&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"@js Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#js-directive","content":" The @js directive allows you to use JavaScript functions to resolve fields in your GraphQL schema. This can be useful for custom data transformations or complex field resolutions.  ","version":"Next","tagName":"h2"},{"title":"Usage‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#usage-1","content":" The @js directive is used to specify a JavaScript function that will resolve the value of a field. The directive takes a single argument, name, which is the name of the JavaScript function to be used.  ","version":"Next","tagName":"h3"},{"title":"Syntax‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#syntax","content":" fieldName: FieldType @js(name: &quot;functionName&quot;)   ","version":"Next","tagName":"h3"},{"title":"Example‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#example","content":" Let's consider a foo.js file which contains a resolve function:  function resolve(val) { let json = JSON.parse(val) return JSON.stringify(json.id) }   Here is an example of how the @js directive is used within a GraphQL schema:  schema @link(type: Script, src: &quot;./scripts/foo.js&quot;) @server(port: 8000) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; httpCache: true ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! idx: Int! @js(name: &quot;resolve&quot;) userId: Int! title: String! body: String! }   ","version":"Next","tagName":"h3"},{"title":"Error Handling‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#error-handling","content":" When using the @js directive, it is important to handle errors within your JavaScript functions. For example, you can use try-catch blocks to catch and handle any errors that occur during the resolution process.  function resolve(val) { try { let json = JSON.parse(val) return JSON.stringify(json.id) } catch (error) { console.error(&quot;Error resolving value:&quot;, error) throw new Error(&quot;Failed to resolve value&quot;) } }   ","version":"Next","tagName":"h3"},{"title":"Performance Considerations‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#performance-considerations","content":" When using the @js directive, keep in mind that JavaScript functions can introduce performance overhead, especially if they perform complex operations or are called frequently. To minimize performance impact, ensure that your functions are optimized and avoid unnecessary computations.  ","version":"Next","tagName":"h3"},{"title":"@link Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#link-directive","content":" The @link directive is used for bringing external resources into your GraphQL schema. It makes it easier to include configurations, .proto files for gRPC services, and other files into your schema. With this directive, external resources are either merged with or used effectively in the importing configuration.  ","version":"Next","tagName":"h2"},{"title":"How it Works‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#how-it-works","content":" The @link directive requires specifying a source src, the resource's type type, and an optional identifier id.  src: The source of the link is defined here. It can be either a URL or a file path. When a file path is given, it's relative to the file's location that is importing the link. type: This specifies the link's type, which determines how the imported resource is integrated into the schema. For a list of supported types, see the Supported Types section. id: This is an optional field that assigns a unique identifier to the link. It's helpful for referring to the link within the schema.  ","version":"Next","tagName":"h3"},{"title":"Example‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#example-1","content":" The following example illustrates how to utilize the @link directive to incorporate a Protocol Buffers (.proto) file for a gRPC service into your GraphQL schema.  schema @server(port: 8000) @upstream( baseURL: &quot;http://news.local&quot; httpCache: 42 batch: {delay: 10} ) @link( id: &quot;news&quot; src: &quot;./src/grpc/news.proto&quot; type: Protobuf ) { query: Query } type Query { news: NewsData! @grpc(method: &quot;news.NewsService.GetAllNews&quot;) } type News { id: Int title: String body: String postImage: String } type NewsData { news: [News]! }   ","version":"Next","tagName":"h3"},{"title":"Supported Types‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#supported-types","content":" The @link directive enriches your configuration by supporting the integration of external resources. Each link type is designed to serve a specific purpose, enhancing the functionality and flexibility of your schema. Below is a detailed overview of each supported link type:  ","version":"Next","tagName":"h3"},{"title":"Config‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#config","content":" The Config link type is essential for importing other configuration files. This feature enables a modular approach to schema management by allowing configurations from the imported file to override overlapping settings in the main schema. This functionality is useful in large projects, where maintaining a single monolithic schema file becomes impractical. By using Config, developers can split their schema configurations into manageable pieces, thus promoting better organization and scalability.  Example use case:  Modularizing schema configurations for different environments (development, staging, production).Reusing common configurations across multiple schema files.  ","version":"Next","tagName":"h3"},{"title":"Protobuf‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#protobuf","content":" The Protobuf link type integrates Protocol Buffers definitions by importing .proto files. This integration is crucial for Tailcall to communicate with gRPC services. By including .proto definitions, the GraphQL server can directly interact with gRPC services, allowing for efficient and type-safe communication.  For detailed integration steps and best practices, refer to the gRPC Integration Guide.  ","version":"Next","tagName":"h3"},{"title":"Script‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#script","content":" The Script link type allows the config to link to an external JavaScript file. This file can contain custom logic that is executed in response to HTTP request-response events. This feature enables developers to implement custom behaviors, such as adding headers to responses or filtering requests based on specific criteria.  Example script for adding a custom header to all outgoing requests:  function onRequest({request}) { // Add a custom header for all outgoing requests request.headers[&quot;X-Custom-Header&quot;] = &quot;Processed&quot; // Return the updated request return {request} }   ","version":"Next","tagName":"h3"},{"title":"Cert‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#cert","content":" The Cert link type is designed for importing SSL/TLS certificates, a crucial component for enabling HTTPS in your GraphQL server. This link type ensures that the server can expose connections over HTTPS.  tip When using the Cert link type, specify the path to the certificate file. Ensure the certificate is up-to-date and issued by a trusted certificate authority (CA) to avoid security warnings or connection issues.  Example use case:  Securing communication between the GraphQL server and clients.Enhancing privacy and security by encrypting data in transit.  ","version":"Next","tagName":"h3"},{"title":"Key‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#key","content":" The Key link type imports the private key associated with your SSL/TLS certificate, enabling HTTPS for your GraphQL server. The private key is a critical security element that decrypts information encrypted by the corresponding public key in the SSL/TLS certificate.  When configuring the Key link type, provide the path to your private key file. Ensure the private key matches the imported certificate specified by the Cert link above, and is protected by appropriate file permissions to maintain security.  ","version":"Next","tagName":"h3"},{"title":"Operation‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#operation","content":" The Operation link type connects your schema to a set of predefined, GraphQL spec-compliant queries and mutations. This functionality allows for the validation and optimization of these operations by the GraphQL server.  Each type serves a specific purpose, enabling the flexible integration of external resources into your GraphQL schema.  ","version":"Next","tagName":"h3"},{"title":"Htpasswd‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#htpasswd","content":" The Htpasswd link type allows the importation of an htpasswd file. This file is utilized to set up Basic authentication.  ","version":"Next","tagName":"h3"},{"title":"Jwks‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#jwks","content":" The Jwks link type enables the importation of a JWKS file. This file facilitates the provision of detailed access control through JWT authentication.  ","version":"Next","tagName":"h3"},{"title":"@modify Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#modify-directive","content":" The @modify directive in GraphQL provides the flexibility to alter the attributes of a field or a node within your GraphQL schema. Here's how you can use this directive:  ","version":"Next","tagName":"h2"},{"title":"name‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#name-1","content":" You can rename a field or a node in your GraphQL schema using the name argument in the @modify directive. This can be helpful when the field name in your underlying data source doesn't match the desired field name in your schema. For instance:  type User { id: Int! @modify(name: &quot;userId&quot;) }   @modify(name: &quot;userId&quot;) informs GraphQL to present the field known as id in the underlying data source as userId in your schema.  ","version":"Next","tagName":"h3"},{"title":"omit‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#omit","content":" You can exclude a field or a node from your GraphQL schema using the omit argument in the @modify directive. This can be useful if you want to keep certain data hidden from the client. For instance:  type User { id: Int! @modify(omit: true) }   @modify(omit: true) instructs GraphQL to exclude the id field from the schema, making it inaccessible to the client.  tip @omit is a standalone directive and is an alias/shorthand for modify(omit: true) checkout documentation  ","version":"Next","tagName":"h3"},{"title":"@omit Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#omit-directive","content":" Within a GraphQL schema, the @omit directive excludes fields or nodes from the generated schema, making them inaccessible through the GraphQL API. This directive is useful for hiding sensitive information or simplifying your API by removing unnecessary fields.  ","version":"Next","tagName":"h2"},{"title":"How it works‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#how-it-works-1","content":" When applied to a field or node, the @omit directive instructs the Tailcall not to include that field or node in the schema. This means that clients cannot query or mutate data in those fields.  ","version":"Next","tagName":"h3"},{"title":"Example‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#example-2","content":" Consider a scenario where you have a User type with an embedded Address type. If you want to exclude the Address type from the schema to simplify the API, you can use the @omit directive:  type Address { city: String street: String } type User { name: String address: Address @omit }   In this example, the address field will not be accessible or visible through the GraphQL API.  ","version":"Next","tagName":"h3"},{"title":"Comparison with modify‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#comparison-with-modify","content":" The @omit directive and @modify(omit: true) essentially serve the same purpose in excluding fields from the schema, but they differ in syntax and flexibility. In fact, one can consider @omit as a shorthand or alias for the more verbose @modify(omit: true).  @omit offers a concise way to directly exclude a field or node without additional arguments. @modify(omit: true), as part of the broader @modify directive, provides more options, such as field renaming through the name argument. This makes it a more flexible choice when you need more than field exclusion.  ","version":"Next","tagName":"h3"},{"title":"@protected Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#protected-directive","content":" The @protected annotation designates a type or field as protected, meaning that a user must be authenticated to access that data.  type Query { protected: String! @protected protectedType: ProtectedType } type ProtectedType @protected { name: String! nested: String! }   important To utilize the @protected directive, you must link at least one authentication provider in the configuration using the @link directive (Htpasswd or Jwks).  ","version":"Next","tagName":"h2"},{"title":"How It Works‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#how-it-works-2","content":" When a field is annotated with @protected, an authentication check is performed upon receiving the request. Depending on the authentication result, either the requested data is provided in the response, or an authentication error is returned.If a type is annotated with @protected, all fields within that type inherit the protection, requiring user authentication for any field that's queried.  ","version":"Next","tagName":"h3"},{"title":"@rest Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#rest-directive","content":" API orchestration is essential, yet not all can adopt GraphQL despite its benefits. The Tailcall DSL feature leverages GraphQL at compile time to generate REST endpoints, aligning with traditional API infrastructure like CDNs and Gateways.  ","version":"Next","tagName":"h2"},{"title":"Usage‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#usage-2","content":" method: Specifies the HTTP method (GET, POST, etc.).path: Sets the endpoint URL, with support for dynamic values from query arguments.query: Defines the query parameters as key-value pairs.  ","version":"Next","tagName":"h3"},{"title":"Example‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#example-3","content":" Define GraphQL types and queries, using the @rest directive to map fields to REST API endpoints.  schema.graphql  schema @upstream(baseURL: &quot;https://jsonplaceholder.typicode.com&quot;) @link(type: Operation, src: &quot;user-operation.graphql&quot;) { query: Query } type Query { user(id: Int!): User @rest(method: &quot;GET&quot;, path: &quot;/users/{{.args.id}}&quot;) } type User { id: Int! name: String! email: String! }   user-operation.graphql  query ($id: Int!) @rest(method: GET, path: &quot;/user/$id&quot;) { user(id: $id) { id name } }     This example demonstrates how to define a simple query to fetch user data from a REST endpoint using the @rest directive. By leveraging @rest, GraphQL can serve as a layer over RESTful services, combining REST's simplicity with GraphQL's flexibility.  ","version":"Next","tagName":"h3"},{"title":"@server Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#server-directive","content":" The @server directive, applied at the schema level, provides a comprehensive set of server configurations. It dictates server behavior and helps tune Tailcall for a range of use-cases.  schema @server(...[ServerSettings]...){ query: Query mutation: Mutation }   In this templated structure, replace ...[ServerSettings]... with specific configurations tailored to your project's needs. Adjust and expand these settings as necessary.  The ServerSettings options and their details appear below.  ","version":"Next","tagName":"h2"},{"title":"workers‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#workers","content":" Setting workers to 32 means that the GraphQL server will use 32 worker threads.  schema @server(workers: 32) { query: Query mutation: Mutation }   This example sets the workers to 32, meaning the GraphQL server will use 32 worker threads.  ","version":"Next","tagName":"h3"},{"title":"port‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#port","content":" Setting the port to 8090 means that Tailcall will be accessible at http://localhost:8000.  schema @server(port: 8090) { query: Query mutation: Mutation }   This example sets the port to 8090, making Tailcall accessible at http://localhost:8090.  tip Always choose non-standard ports, avoiding typical ones like 80 or 8080. Make sure your chosen port is free.  ","version":"Next","tagName":"h3"},{"title":"headers‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#headers-3","content":" Allows intelligent configuration of the final response headers that's produced by Tailcall.  ","version":"Next","tagName":"h3"},{"title":"cacheControl‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#cachecontrol","content":" Activating the cacheControl configuration directs Tailcall to send Cache-Control headers in its responses. The max-age value in the header matches the lowest of the values in the responses that Tailcall receives from its upstream. By default, this is false, which means Tailcall does not set any header.  schema @server(headers: {cacheControl: true}) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"custom‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#custom","content":" The custom is an array of key-value pairs. These headers get added to the response of every request made to the server. This can be useful for adding headers like Access-Control-Allow-Origin to allow cross-origin requests, or some headers like X-Allowed-Roles for use by downstream services.  schema @server( headers: { custom: [ {key: &quot;X-Allowed-Roles&quot;, value: &quot;admin,user&quot;} ] } ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"experimental‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#experimental","content":" When the experimental configuration is enabled, Tailcall can include headers starting with X- in its responses, which are sourced from its upstream. By default, this feature is disabled ([]), meaning Tailcall does not forward any such headers unless explicitly configured to do so.  schema @server( headers: {experimental: [&quot;X-Experimental-Header&quot;]} ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"setCookies‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#setcookies","content":" Enabling the setCookies option instructs Tailcall to include set-cookie headers in its responses, which are obtained from the headers of upstream responses.  schema @server(headers: {setCookies: true}) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"cors‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#cors","content":" The cors configuration allows you to enable CORS on Tailcall. This is useful when you want to access Tailcall in the browser. Here is a simple configuration to get started with cors:  schema @server( headers: { cors: {allowHeaders: [&quot;*&quot;], allowOrigins: [&quot;*&quot;]} } ) { query: Query }   The above setting will enable CORS on the server for all headers, origins &amp; methods. You can further configure the cors settings to make it more secure with the following fields:  allowCredentials: Indicates whether the server allows credentials (e.g., cookies, authorization headers) to be sent in cross-origin requests.allowHeaders: A list of allowed headers in cross-origin requests. This can be used to specify custom headers that are allowed to be included in cross-origin requests.allowMethods: A list of allowed HTTP methods in cross-origin requests. These methods specify the actions that are permitted in cross-origin requests.allowOrigins: A list of origins that are allowed to access the server's resources in cross-origin requests. An origin can be a domain, a subdomain, or even 'null' for local file schemes.allowPrivateNetwork: Indicates whether requests from private network addresses are allowed in cross-origin requests. Private network addresses typically include IP addresses reserved for internal networks.exposeHeaders: A list of headers that the server exposes to the browser in cross-origin responses. Exposing certain headers allows client-side code to access them in the response.maxAge: The maximum time (in seconds) that the client should cache preflight OPTIONS requests to avoid sending excessive requests to the server.vary: A list of header names that indicate the values of which might cause the server's response to vary, potentially affecting caching.  schema @server( port: 8000 hostname: &quot;0.0.0.0&quot; headers: { cors: { allowCredentials: false allowHeaders: [&quot;Authorization&quot;] allowMethods: [POST, GET, OPTIONS] allowOrigins: [&quot;abc.xyz&quot;] allowPrivateNetwork: true exposeHeaders: [&quot;Content-Type&quot;] maxAge: 360 vary: [&quot;Origin&quot;] } } ) { query: Query }   ","version":"Next","tagName":"h3"},{"title":"vars‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#vars","content":" This configuration allows defining local variables for use during the server's operations. These variables are handy for storing constant configurations, secrets, or other shared information that operations might need.  schema @server( vars: {key: &quot;apiKey&quot;, value: &quot;YOUR_API_KEY_HERE&quot;} ) { query: Query mutation: Mutation } type Query { externalData: Data @http( path: &quot;/external-api/data&quot; headers: [ { key: &quot;Authorization&quot; value: &quot;Bearer {{.vars.apiKey}}&quot; } ] ) }   In the provided example, setting a variable named apiKey with a placeholder value of &quot;YOUR_API_KEY_HERE&quot; implies that whenever Tailcall fetches data from the externalData endpoint, it includes the apiKey in the Authorization header of the HTTP request.  tip Local variables, like apiKey, are instrumental in securing access to external services or providing a unified place for configurations. Ensure that sensitive information stored this way is well protected and not exposed unintentionally, if your GraphQL configuration is publicly accessible.  ","version":"Next","tagName":"h3"},{"title":"introspection‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#introspection","content":" This setting controls the server's allowance of introspection queries. Introspection, a core feature of GraphQL, allows clients to directly fetch schema information. This capability proves crucial for tools and client applications in comprehending the available types, fields, and operations. By default, the server enables this setting (true).  schema @server(introspection: false) { query: Query mutation: Mutation }   tip Although introspection is beneficial during development and debugging stages, consider disabling it in production environments. Turning off introspection in live deployments can enhance security by preventing potential attackers from discerning the schema and any associated business logic or data structures.  ","version":"Next","tagName":"h3"},{"title":"queryValidation‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#queryvalidation","content":" The queryValidation configuration determines if the server checks incoming GraphQL queries against the defined schema. Each query check ensures it matches the schema, preventing errors from incorrect or malformed queries. In some situations, you might want to disable it, notably to enhance server performance at the cost of these checks. This defaults to false if not specified.  schema @server(queryValidation: true) { query: Query mutation: Mutation }   The example above sets queryValidation to true, enabling the validation phase for incoming queries.  tip Enable this in the development environment to ensure the queries sent are correct and validated. In the production environment, consider disabling it for improved performance.  ","version":"Next","tagName":"h3"},{"title":"responseValidation‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#responsevalidation","content":" Tailcall can automatically infer the schema of the HTTP endpoints for you. This information can check responses received from the upstream services. Enabling this setting allows you to do that. If not specified, the default setting for responseValidation is false.  schema @server(responseValidation: true) { query: Query mutation: Mutation }   tip Disabling this setting will offer major performance improvements, but at the potential expense of data integrity.  ","version":"Next","tagName":"h3"},{"title":"globalResponseTimeout‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#globalresponsetimeout","content":" The globalResponseTimeout configuration sets the max duration a query can run before the server terminates it. Essentially, it acts as a safeguard against long-running queries that could strain resources or pose security concerns.  If not explicitly defined, there might be a system-specific or default value that applies.  schema @server(globalResponseTimeout: 5000) { query: Query mutation: Mutation }   In this given example, setting the globalResponseTimeout to 5000 milliseconds, or 5 seconds, means any query execution taking longer than this duration will be automatically terminated by  tip Setting an appropriate response timeout in production environments is crucial. This optimizes resource use and serves as a security measure against potential denial-of-service attacks, where adversaries might run complex queries to exhaust server resources.  ","version":"Next","tagName":"h3"},{"title":"version‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#version","content":" The server uses the HTTP version. If not specified, the default value is HTTP1. The available options are HTTP1 and HTTP2.  schema @server(version: HTTP2) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"cert‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#cert-1","content":" The path to certificate(s) for running the server over HTTP2 (HTTPS). If not specified, the default value is null.  schema @server(cert: &quot;./cert.pem&quot;) { query: Query mutation: Mutation }   tip The certificate can be of any extension, but it's highly recommended to use standards (pem, crt, key).  ","version":"Next","tagName":"h3"},{"title":"key‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#key-1","content":" The path to the key for running the server over HTTP2 (HTTPS). If not specified, the default value is null.  schema @server(key: &quot;./key.pem&quot;) { query: Query mutation: Mutation }   tip The key can be of any extension, but it's highly recommended to use standards (pem, crt, key).  ","version":"Next","tagName":"h3"},{"title":"showcase‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#showcase","content":" The @server directive's showcase option allows for hands-on experimentation with server configurations in a controlled environment. This feature simplifies the process of exploring and testing different settings.  schema @server(showcase: true) { query: Query }   ","version":"Next","tagName":"h3"},{"title":"batchRequests‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#batchrequests","content":" Batching in GraphQL combines requests into one, reducing server round trips.  schema @server( port: 8000 batchRequests: true )   tip Batching can improve performance but may introduce latency if one request in the batch takes longer. It also makes network traffic debugging harder.  ","version":"Next","tagName":"h3"},{"title":"dedupe‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#dedupe","content":" A boolean flag, if set to true, will enable deduplication of IO operations to enhance performance. This flag prevents duplicate IO requests from being executed concurrently, reducing resource load. If not specified, this feature defaults to false.  schema @server( port: 8000 dedupe: true )   ","version":"Next","tagName":"h3"},{"title":"@telemetry Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#telemetry-directive","content":" The @telemetry directive facilitates seamless integration with OpenTelemetry, enhancing the observability of your GraphQL services powered by Tailcall. By leveraging this directive, developers gain access to valuable insights into the performance and behavior of their applications.  ","version":"Next","tagName":"h2"},{"title":"Traces‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#traces","content":" Here are the traces that are captured by the @telemetry directive:  Trace Name\tDescriptionrequest\tCaptures the span for processing the HTTP request on the server side, providing foundational observability. graphQL\tOnly for GraphQL ingress. Span for processing GraphQL call REST &lt;http_method&gt; &lt;http_route&gt;\tOnly for REST ingress. Span for processing REST API call &lt;field_name&gt;\tDenotes spans for fields with defined resolvers, offering insights into field names and execution times for resolver logic. &lt;expr_name&gt;\tNested within the &lt;field_name&gt; spans, these granulated spans detail the execution of expressions in resolving a field, highlighting the hierarchical execution pattern of nested expressions. upstream_request\tRequest that were made from tailcall service to upstream  ","version":"Next","tagName":"h3"},{"title":"Metrics‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#metrics","content":" The @telemetry directive also captures the following metrics:  Metric\tDescriptioncache.hit_rate\tReflects the cache hit rate for the cache powered by the @cache directive http.server.request.count\tCounts the number of incoming requests made to specific route. Optionally enriched with selected headers by requestHeaders http.client.request.count\tCounts the number of outgoing requests to specific upstream  ","version":"Next","tagName":"h3"},{"title":"export‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#export","content":" The export field defines how the open-telemetry data should be exported and in which format. The following are the supported formats:  ","version":"Next","tagName":"h3"},{"title":"otlp‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#otlp","content":" Utilizes the OTLP format to export telemetry data to backend systems, supported by most modern tracing and analytics platforms. Here is an example using [honeycomb.io]:  schema @telemetry( export: { otlp: { url: &quot;https://api.honeycomb.io:443&quot; headers: [ { key: &quot;x-honeycomb-team&quot; value: &quot;{{.env.HONEYCOMB_API_KEY}}&quot; } {key: &quot;x-honeycomb-dataset&quot;, value: &quot;tailcall&quot;} ] } } ) { query: Query }   You can configure the OTLP exporter with the following options:  Field\tDescriptionurl\tDefines the URL for the OTLP Collector. headers\tSets additional headers for requests to the OTLP Collector.  ","version":"Next","tagName":"h3"},{"title":"prometheus‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#prometheus","content":" Facilitates metrics export in a Prometheus compatible format, providing a dedicated endpoint for metrics.  schema @telemetry(export: {prometheus: {path: &quot;/metrics&quot;}}) { query: Query }   You can configure the Prometheus exporter with the following options:  Field\tDescriptionpath\tDesignates the endpoint path for Prometheus metrics, defaulting to /metrics. format\tControls the format viz. text or protobuf, for sending data to Prometheus.  ","version":"Next","tagName":"h3"},{"title":"stdout‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#stdout","content":" Outputs all telemetry data to stdout, ideal for testing or local development environments.  schema @telemetry(export: {stdout: {pretty: true}}) { query: Query }   You can configure the stdout exporter with the following options:  Field\tDescriptionpretty\tEnables formatted output of telemetry data for enhanced readability.  ","version":"Next","tagName":"h3"},{"title":"requestHeaders‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#requestheaders","content":" Specifies list of headers of ingress request the value of which will be sent to the telemetry as attributes.  schema @telemetry(requestHeaders: [&quot;X-User-Id&quot;]) { query: Query }   ","version":"Next","tagName":"h3"},{"title":"apollo‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#apollo","content":" Facilitates seamless integration with Apollo Studio, enhancing the observability of GraphQL services. By leveraging this field, developers gain access to valuable insights into the performance and behavior of their GraphQL APIs.  schema @telemetry( export: { otlp: { api_key: &quot;{{.env.APOLLO_API_KEY}}&quot; graph_ref: &quot;graph-id@current&quot; platform: &quot;website.com&quot; version: &quot;1.0.0&quot; } } ) { query: Query }   You can configure the apollo exporter with the following options:  Field\tDescriptionapi_key\tThe API Key generated from Apollo Studio. graph_ref\tThe Graph Ref, which is the graph_id and the variant concatenated using @(i.e. &lt;graph_id&gt;@&lt;variant&gt;) platform\tAn arbitrary value which can contain the name of your website or some other value to identify your deployment uniqely, in case you have multiple deployments. version\tVersion of Apollo which is being used.  By integrating the @telemetry directive into your GraphQL schema, you empower your development teams with critical insights into application performance, enabling proactive optimization and maintenance.  ","version":"Next","tagName":"h3"},{"title":"@upstream Directive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#upstream-directive","content":" The upstream directive enables control over specific aspects of the upstream server connection, including settings such as connection timeouts, keep-alive intervals, and more. The system applies default values if you do not specify them.  schema @upstream(...[UpstreamSetting]...){ query: Query mutation: Mutation }   The document below details the options for UpstreamSetting.  ","version":"Next","tagName":"h2"},{"title":"poolIdleTimeout‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#poolidletimeout","content":" The connection pool waits for this duration in seconds before closing idle connections.  schema @upstream( poolIdleTimeout: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"poolMaxIdlePerHost‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#poolmaxidleperhost","content":" The max number of idle connections each host will maintain.  schema @upstream( poolMaxIdlePerHost: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"keepAliveInterval‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#keepaliveinterval","content":" The time in seconds between each keep-alive message sent to maintain the connection.  schema @upstream( keepAliveInterval: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"keepAliveTimeout‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#keepalivetimeout","content":" The time in seconds that the connection will wait for a keep-alive message before closing.  schema @upstream( keepAliveTimeout: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"keepAliveWhileIdle‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#keepalivewhileidle","content":" A boolean value that determines whether to send keep-alive messages while the connection is idle.  schema @upstream( keepAliveWhileIdle: false baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"proxy‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#proxy","content":" The proxy setting defines an intermediary server that routes upstream requests before they reach their intended endpoint. By specifying a proxy URL, you introduce a layer, enabling custom routing and security policies.  schema @upstream( proxy: {url: &quot;http://localhost:3000&quot;} baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   In the provided example, we've set the proxy's url to &quot;http://localhost:3000&quot;. This configuration ensures that all requests aimed at the designated baseURL first go through this proxy. To illustrate, if the baseURL is &quot;http://jsonplaceholder.typicode.com&quot;, any request targeting it initially goes to &quot;http://localhost:3000&quot; before the proxy redirects it to its final destination.  ","version":"Next","tagName":"h3"},{"title":"connectTimeout‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#connecttimeout","content":" The time in seconds that the connection will wait for a response before timing out.  schema @upstream( connectTimeout: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"timeout‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#timeout","content":" The max time in seconds that the connection will wait for a response.  schema @upstream( timeout: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"tcpKeepAlive‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#tcpkeepalive","content":" The time in seconds between each TCP keep-alive message sent to maintain the connection.  schema @upstream( tcpKeepAlive: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"userAgent‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#useragent","content":" The User-Agent header value for HTTP requests.  schema @upstream( userAgent: &quot;Tailcall/1.0&quot; baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"allowedHeaders‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#allowedheaders","content":" The allowedHeaders configuration defines a set of whitelisted HTTP headers that can be forwarded to upstream services during requests. Without specifying allowedHeaders, the system will not forward any incoming headers to upstream services, offering an extra security layer but potentially limiting necessary data flow. Tailcall compares the provided whitelisted headers in a case-insensitive format.  schema @upstream( allowedHeaders: [&quot;Authorization&quot;, &quot;X-Api-Key&quot;] ) { query: Query mutation: Mutation }   In the example above, the configuration for allowedHeaders permits Authorization and X-Api-Key headers. Thus, requests with these headers will forward them to upstream services; the system ignores all others. This configuration ensures communication of the expected headers to dependent services, emphasizing security and consistency.  ","version":"Next","tagName":"h3"},{"title":"baseURL‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#baseurl-3","content":" This refers to the default base URL for your APIs. If it's not explicitly mentioned in the @upstream directive, then each @http directive must specify its own baseURL. If neither @upstream nor @http provides a baseURL, it results in a compilation error.  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   In this representation, http://jsonplaceholder.typicode.com serves as the baseURL. Thus, all API calls made by @http prepend this URL to their respective paths.  tip Ensure that your base URL remains free from specific path segments. GOOD: @upstream(baseURL: http://jsonplaceholder.typicode.com)BAD: @upstream(baseURL: http://jsonplaceholder.typicode.com/api)  ","version":"Next","tagName":"h3"},{"title":"httpCache‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#httpcache","content":" When httpCache passed with value greater than 0 it directs Tailcall to use HTTP caching mechanisms, following the HTTP Caching RFC to enhance performance by minimizing unnecessary data fetches. If left unspecified, this feature defaults to 0 disabling the caching mechanism.  schema @upstream(httpCache: 42) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"Tips‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#tips","content":" Use batching when other optimization techniques fail to resolve performance issues.Apply batching and thoroughly assess its impact.Understand that batching may make debugging more challenging.  ","version":"Next","tagName":"h3"},{"title":"batch‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#batch-1","content":" An object that specifies the batch settings, including maxSize (the max size of the batch), delay (the delay in milliseconds between each batch), and headers (an array of HTTP headers that the batch will include).  schema @upstream( batch: { maxSize: 1000 delay: 10 headers: [&quot;X-Server&quot;, &quot;Authorization&quot;] } ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"onRequest‚Äã","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#onrequest-1","content":" Similar to the @http property, this accepts a string value representing a middleware function defined in a JavaScript file. It intercepts all outgoing HTTP requests from the server. This interceptor, written in JavaScript, can be used to modify outgoing requests and also generate artificial responses to customize the behavior of the GraphQL server.  schema @upstream(onRequest: 'someFunctionName') @link(type: Script, src: &quot;path_to/worker.js&quot;) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"}],"options":{"highlightResult":true,"id":"default"}}