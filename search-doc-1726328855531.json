{"searchDocs":[{"title":"API Strategy: Driving Innovation and Growth in Modern Business","type":0,"sectionRef":"#","url":"/blog/api-strategy/","content":"","keywords":"","version":null},{"title":"What is an API Strategy?​","type":1,"pageTitle":"API Strategy: Driving Innovation and Growth in Modern Business","url":"/blog/api-strategy/#what-is-an-api-strategy","content":" An API strategy is an outline of the steps needed to design, develop, and manage APIs effectively. It's no longer just about having good APIs; it's about ensuring they are secure, scalable, and reliable. It's about making sure developers are more productive and machine utilization is more efficient. In essence, API strategy is about abstracting cross-cutting concerns from business logic. Abstracting cross-cutting concerns from business logic is a critical aspect of API strategy. Cross-cutting concerns refer to functionalities that are essential to the operation of your API but are not directly related to the business logic. Examples of cross-cutting concerns include:  Security: authentication, authorization, and encryptionMonitoring: logging, analytics, and error trackingScalability: rate limiting, caching, and load balancing  By abstracting these concerns from business logic, you can decouple them from the core functionality of your API, making it easier to maintain, update, and scale your API without affecting the underlying business logic.  For instance, if you're building an e-commerce API, you might abstract security concerns by implementing OAuth 2.0 authentication and authorization. This would allow you to focus on the business logic of processing orders, managing inventory, and handling payments, while ensuring that security is handled separately.  ","version":null,"tagName":"h2"},{"title":"Why Do You Need an API Strategy?​","type":1,"pageTitle":"API Strategy: Driving Innovation and Growth in Modern Business","url":"/blog/api-strategy/#why-do-you-need-an-api-strategy","content":" The importance of an API strategy cannot be overstated. Without one, you risk exposing your business to security vulnerabilities, scalability issues, and reliability problems. A well-defined API strategy helps you address critical concerns such as:  Cross-functional collaborationRate limitingCircuit breakingCachingRoutingCompositionAccess controlAuthenticationVersioningLoggingMonitoringDocumentation  Having a strategy in place ensures that you're not just documenting your APIs, but also managing them effectively, securing them, scaling them, monitoring them, and making sure they're reliable.  ","version":null,"tagName":"h2"},{"title":"The Role of Tools in API Strategy​","type":1,"pageTitle":"API Strategy: Driving Innovation and Growth in Modern Business","url":"/blog/api-strategy/#the-role-of-tools-in-api-strategy","content":" There are many tools available in the market to help with API strategy, such as API gateways and Swagger. An API gateway can help with rate limiting, caching, routing, access control, authentication, authorization, logging, and monitoring. Swagger can assist with documentation. However, are these tools enough? Are they capable of addressing all the challenges that come with API strategy? Let's discuss.  ","version":null,"tagName":"h2"},{"title":"API Composition: A Critical Aspect of API Strategy​","type":1,"pageTitle":"API Strategy: Driving Innovation and Growth in Modern Business","url":"/blog/api-strategy/#api-composition-a-critical-aspect-of-api-strategy","content":" API composition is a critical aspect of API strategy. How do you compose your APIs? Do you use an API gateway or a different tool? How do you prevent the N+1 problem when composing APIs using an API gateway? How do you handle the failure of one of the APIs in the composition? How do you handle caching in the composition? These are just a few of the questions that need to be addressed in your API strategy.  ","version":null,"tagName":"h3"},{"title":"Access Control: A Key Consideration​","type":1,"pageTitle":"API Strategy: Driving Innovation and Growth in Modern Business","url":"/blog/api-strategy/#access-control-a-key-consideration","content":" Access control is another key consideration in API strategy. Can you create an API and use it as both a public API and an admin API, restricting access to fields based on user role? The answer is no, not without a well-defined API strategy.  ","version":null,"tagName":"h3"},{"title":"A Solution to API Strategy Challenges​","type":1,"pageTitle":"API Strategy: Driving Innovation and Growth in Modern Business","url":"/blog/api-strategy/#a-solution-to-api-strategy-challenges","content":" For having a well-defined API strategy, you need a set of tools that can help you with the above points. Such a solution should have first-class support for:  API Composition: Easily compose APIs to create complex workflows and integrations.Access Control: Implement fine-grained access control to restrict access to APIs and resources based on user roles and permissions.Rate Limiting: Enforce rate limits to prevent abuse and ensure fair usage of your APIs.Circuit Breaking: Detect and prevent cascading failures in your API ecosystem.Caching: Improve performance and reduce latency with intelligent caching mechanisms.Routing: Route API requests efficiently and securely to the right backend services.Authentication and Authorization: Implement robust authentication and authorization mechanisms to ensure secure access to your APIs.Versioning: Manage multiple versions of your APIs and ensure backward compatibility.Logging and Monitoring: Gain visibility into API performance and behavior with real-time logging and monitoring.Documentation: Generate accurate and up-to-date documentation for your APIs.  A good solution should also:  Introspect and detect problems: Analyze your configurations to identify potential issues and provide recommendations for improvement.Transfer type safety: Ensure that your API configurations are type-safe and consistent with your code.Provide access control to the sub-API level: Restrict access to specific fields in the APIs based on user roles and permissions.  By using such a solution, you can overcome the challenges of API strategy and create a robust, scalable, and secure API ecosystem that drives innovation and growth in your business.  ","version":null,"tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"API Strategy: Driving Innovation and Growth in Modern Business","url":"/blog/api-strategy/#conclusion","content":" In conclusion, API strategy is no longer a nice-to-have; it's a must-have for businesses that want to stay ahead of the curve. By defining a clear API strategy, businesses can drive innovation, improve efficiency, and create new opportunities for growth. At Tailcall, we're committed to helping businesses achieve their API goals with our GraphQL solution.  Take the First Step Towards a Well-Defined API Strategy  If you're struggling to define your API strategy, take the first step today. Assess your current API landscape, identify areas for improvement, and start building a strategy that works for your business. Remember, A well-defined API strategy is essential for driving innovation and growth in modern business because it enables companies to:  Unlock New Revenue Streams: By providing APIs that offer value to external developers, businesses can create new revenue streams through API-based partnerships and monetization models.Enhance Customer Experience: APIs can provide real-time data and services that enhance customer experience, leading to increased loyalty and retention.Foster Innovation: APIs can enable innovation by providing access to new data, services, and capabilities, allowing businesses to create new products and services that drive growth.Improve Operational Efficiency: A well-defined API strategy can help businesses streamline their operations, reduce costs, and improve efficiency, freeing up resources to focus on innovation and growth.  By having a well-defined API strategy, businesses can create a solid foundation for innovation and growth, enabling them to stay ahead of the competition and achieve their goals.  Ready to Take Your API Strategy to the Next Level?  Contact us today to learn more about how Tailcall can help you overcome API strategy challenges and drive innovation and growth in your business.  Discover future of GraphQL Try Tailcall today Get Started ","version":null,"tagName":"h2"},{"title":"Lessons from the Frontlines: Our GraphQL Adventure at Dream11","type":0,"sectionRef":"#","url":"/blog/dream11-graphql-case-study/","content":"","keywords":"","version":null},{"title":"Case Study: Dream11's GraphQL Journey​","type":1,"pageTitle":"Lessons from the Frontlines: Our GraphQL Adventure at Dream11","url":"/blog/dream11-graphql-case-study/#case-study-dream11s-graphql-journey","content":" ","version":null,"tagName":"h2"},{"title":"The Challenge: Taming the Monolith​","type":1,"pageTitle":"Lessons from the Frontlines: Our GraphQL Adventure at Dream11","url":"/blog/dream11-graphql-case-study/#the-challenge-taming-the-monolith","content":" During our time at Dream11, we embarked on several major re-architecture projects to supercharge our systems' performance and scalability. But perhaps the most exhilarating (and occasionally hair-raising) journey was our transition from a monolithic architecture to microservices.  Now, let us tell you, this wasn't a walk in the park. We faced hurdles at every turn. But we had one golden rule that guided us through the chaos: &quot;The frontend should never be shackled by the backend's structure.&quot; This mantra led us to an exciting solution: using GraphQL as a backend-for-frontend (BFF).  ","version":null,"tagName":"h3"},{"title":"The Magic of Backend-for-Frontends (BFFs)​","type":1,"pageTitle":"Lessons from the Frontlines: Our GraphQL Adventure at Dream11","url":"/blog/dream11-graphql-case-study/#the-magic-of-backend-for-frontends-bffs","content":" Think of BFFs as the ultimate middlemen, sitting between our microservices and frontend applications. They're not just passing messages; they're tailoring responses and error handling for each client application. It's like having a personal assistant for each of your frontend apps! By implementing BFFs, we unlocked a treasure trove of advantages:  No more data bloat: Say goodbye to under-fetching and over-fetching. Our BFFs serve each client exactly what they need, nothing more, nothing less.Divide and conquer: With BFFs handling the heavy lifting of data formatting, our frontend developers could focus on crafting amazing user experiences.Network efficiency: Imagine making one call instead of ten. That's the power of BFFs – they fetch data from multiple sources in one go, keeping our network traffic lean and mean.  ","version":null,"tagName":"h2"},{"title":"Dream11's Microservices Odyssey​","type":1,"pageTitle":"Lessons from the Frontlines: Our GraphQL Adventure at Dream11","url":"/blog/dream11-graphql-case-study/#dream11s-microservices-odyssey","content":" Now, we could have gone for the &quot;big bang&quot; approach, but where's the fun (or safety) in that? Instead, we opted for a more measured journey:  First, we moved all our monolith APIs to a GraphQL-based BFF.We then directed all frontend applications to this new BFF, even adding a lint check to catch any sneaky direct API calls to the monolith.Once we were confident in our new setup, we began the exciting process of moving APIs to microservices, one by one.  Sure, it was a longer path, but it was smoother sailing. We minimized risks, kept our testing manageable, and, most importantly, kept our sanity intact!    ","version":null,"tagName":"h2"},{"title":"Unveiling Dream11's BFF Architecture​","type":1,"pageTitle":"Lessons from the Frontlines: Our GraphQL Adventure at Dream11","url":"/blog/dream11-graphql-case-study/#unveiling-dream11s-bff-architecture","content":" Let me pull back the curtain on our BFF architecture at Dream11. It was a symphony of components working in perfect harmony:  Frontend Applications: The face of our platform, built in React. They took the data from our GraphQL server and transformed it into the engaging user interfaces our players loved.GraphQL Server: The maestro of our operation, built with Apollo Server. It orchestrated data fetching from microservices and delivered it beautifully to our frontend applications.API Gateway: The bouncer of our architecture, powered by Kong. It managed the flow of requests from the GraphQL server to our microservices.Microservices: Our data virtuosos, crafted with Node.js and Express. They fetched data from databases and passed it to the GraphQL server.    Now, you might be scratching your head, wondering, &quot;Why put an API Gateway after the GraphQL server?&quot; Great question! It all comes down to resilience. We needed fine-grained control over rate limiting and circuit breaking for each microservice. GraphQL's single endpoint made this tricky, so we added this extra layer to keep our systems robust and responsive.  This architecture was our trusted companion for years, scaling effortlessly to serve tens of millions of users. But as with any great journey, we eventually hit a new challenge: the performance of our GraphQL server started to feel the strain of our massive success.  Curious about how we turbocharged our GraphQL server? Join us at GraphQL Conference 2024 for the thrilling conclusion! Save Your Spot  ","version":null,"tagName":"h2"},{"title":"The GraphQL Advantage: Dream11's Secret Weapon​","type":1,"pageTitle":"Lessons from the Frontlines: Our GraphQL Adventure at Dream11","url":"/blog/dream11-graphql-case-study/#the-graphql-advantage-dream11s-secret-weapon","content":" Implementing GraphQL for our BFF layer wasn't just a technical decision – it was a game-changer. Here's why we fell in love with GraphQL:  Network efficiency on steroids: We slashed unnecessary network calls, making our app lightning-fast.Bug squashing made easy: Type-safe queries generated at compile time meant fewer surprises in production.Performance boost: We fetched only the data we needed, nothing more, nothing less. Also reduced multiple round trips to the server.Flexibility unleashed: We could structure our data exactly how we wanted, adapting to new requirements with ease.Cross-platform harmony: Consistency across all platforms became a breeze.Developer joy: Our frontend team couldn't stop raving about how easy it was to work with.Time is money: Reduced development time meant we could innovate faster.Happy developers, happy life: The improved developer experience led to more creative solutions and happier teams.  ","version":null,"tagName":"h2"},{"title":"The Next Chapter: From Challenges to Solutions​","type":1,"pageTitle":"Lessons from the Frontlines: Our GraphQL Adventure at Dream11","url":"/blog/dream11-graphql-case-study/#the-next-chapter-from-challenges-to-solutions","content":" The journey we embarked on at Dream11 wasn't just about solving immediate problems – it was about reimagining how we approach backend architecture for massive-scale applications. The challenges we faced, the solutions we crafted, and the lessons we learned have directly shaped the development of Tailcall.  Tailcall emerged from the crucible of these experiences, designed to make the implementation of GraphQL and similar migration journeys significantly easier for other companies. Here's how Tailcall is addressing the pain points we encountered:  Simplified Migration: Tailcall provides tools to streamline the transition from monolithic architectures to microservices, making the journey we undertook at Dream11 more accessible and less risky for other organizations. Performance at Scale: Drawing from our experiences with GraphQL performance challenges, Tailcall incorporates optimizations that allow GraphQL servers to handle massive loads more efficiently. Automated BFF Generation: Recognizing the power of the BFF pattern, Tailcall offers features to automatically generate and manage Backend-for-Frontend layers, reducing development time and potential errors. Enhanced Resilience: Our struggles with rate limiting and circuit breaking at the GraphQL layer have informed Tailcall's design, incorporating these features more seamlessly into the GraphQL ecosystem. Developer Experience: The joys and pains of our development team at Dream11 have directly influenced Tailcall's focus on developer experience, making it easier for teams to work with GraphQL and microservices architectures. Flexible Scaling: Tailcall embodies the lessons learned from scaling Dream11 to millions of users, offering flexible scaling options that grow with your application.  The challenges we faced at Dream11 weren't unique – they're common hurdles for any company dealing with rapid growth and complex data needs. Tailcall is our answer to these industry-wide challenges, encapsulating years of hard-won wisdom into a tool that makes these architectural transitions smoother, faster, and more reliable.  As we continue to evolve Tailcall, we're excited to see how it will empower other companies to undertake their own transformative journeys, armed with the insights and tools born from our experiences. The future of backend architecture is bright, and we're thrilled to be part of shaping it.  Stay tuned, fellow tech enthusiasts. With Tailcall, we're not just solving yesterday's problems – we're building tomorrow's solutions. ","version":null,"tagName":"h2"},{"title":"Exploring GraphiQL: The In-Browser IDE for GraphQL","type":0,"sectionRef":"#","url":"/blog/exploring-graphiql/","content":"","keywords":"","version":null},{"title":"Introduction​","type":1,"pageTitle":"Exploring GraphiQL: The In-Browser IDE for GraphQL","url":"/blog/exploring-graphiql/#introduction","content":" Imagine you’re diving into GraphQL development and find yourself bogged down with setting up an entire environment just to see if an endpoint is functioning. It’s like preparing a full feast just to taste a single dish—server configurations, route setups, test queries, and more before you even get to interact with your data. Sounds overwhelming, right?  Enter GraphiQL, your development superhero. It swoops in to simplify the mess, turning that complicated setup into a breeze. Instead of juggling all those configurations, GraphiQL lets you quickly test and explore your endpoints with ease. It’s like having a magic wand that instantly brings your GraphQL queries to life, making development smoother and way more fun!  ","version":null,"tagName":"h2"},{"title":"Why Use GraphiQL?​","type":1,"pageTitle":"Exploring GraphiQL: The In-Browser IDE for GraphQL","url":"/blog/exploring-graphiql/#why-use-graphiql","content":" If you are here, you either know GraphQL too well and are looking for solutions to some GraphQL idiosyncrasy, or you have stumbled here while trying to learn more about GraphQL. If you are new to the GraphQL world, here’s some resources to help you get started with GraphQL:  Guide To GraphQL Designing GraphQL Schemas Securing GraphQL Apis  GraphiQL lets you test out server endpoints without setting up a whole environment. It shines on documentation websites, saving you from writing a playground from scratch, which can be a real time-saver.    Interactive Interface: Provides a user-friendly interface to interact with your server. Features like auto-complete and syntax-highlighting help you write queries without needing to write the whole thing by hand.Real-time Feedback: Receive immediate responses and see results on the go, making debugging much faster.Built-in Documentation Explorer: No more switching tabs looking for documentation; the built-in explorer lets you see and interact with queries, types, and mutations all in one place.History Tracking: Access previous queries and results, making it easy to repeat, refine, and learn from past requests.Customizable: Tailor the GraphiQL setup to match your style. Adjust colors and options to blend with your website. For more information, see Customization.  ","version":null,"tagName":"h2"},{"title":"Accessing GraphiQL​","type":1,"pageTitle":"Exploring GraphiQL: The In-Browser IDE for GraphQL","url":"/blog/exploring-graphiql/#accessing-graphiql","content":" You can access GraphiQL using either of these methods:  ","version":null,"tagName":"h2"},{"title":"Directly through Tailcall Playground​","type":1,"pageTitle":"Exploring GraphiQL: The In-Browser IDE for GraphQL","url":"/blog/exploring-graphiql/#directly-through-tailcall-playground","content":" If you have a running GraphQL server and want to interact with it graphically, use Tailcall Playground. Open the playground and enter the root endpoint of your server:    Note: Ensure your server's CORS policy allows requests from the Tailcall domain.  Once you enter the endpoint, the schema is automatically loaded, and you are good to go.  ","version":null,"tagName":"h3"},{"title":"By Starting the GraphQL Server with Tailcall​","type":1,"pageTitle":"Exploring GraphiQL: The In-Browser IDE for GraphQL","url":"/blog/exploring-graphiql/#by-starting-the-graphql-server-with-tailcall","content":" Or, if you use Tailcall for your GraphQL server, the playground URL is provided once you start the server:    Simply click on the link, and it will open the Tailcall Playground with the endpoint already set up.  ","version":null,"tagName":"h3"},{"title":"Exploring the GraphiQL Interface​","type":1,"pageTitle":"Exploring GraphiQL: The In-Browser IDE for GraphQL","url":"/blog/exploring-graphiql/#exploring-the-graphiql-interface","content":" ","version":null,"tagName":"h2"},{"title":"Query Editor​","type":1,"pageTitle":"Exploring GraphiQL: The In-Browser IDE for GraphQL","url":"/blog/exploring-graphiql/#query-editor","content":" Packed with handy features like autocomplete, syntax highlighting, error detection, and code folding, this editor keeps your code neat and saves you tons of time.  ","version":null,"tagName":"h3"},{"title":"Variables Editor​","type":1,"pageTitle":"Exploring GraphiQL: The In-Browser IDE for GraphQL","url":"/blog/exploring-graphiql/#variables-editor","content":" Easily edit variables with autocomplete based on the ones declared in your query—no more tedious copy-pasting of long variable names in complex queries.    ","version":null,"tagName":"h3"},{"title":"Response Pane​","type":1,"pageTitle":"Exploring GraphiQL: The In-Browser IDE for GraphQL","url":"/blog/exploring-graphiql/#response-pane","content":" Check out the server's response here. It's super useful for handling lots of nested data, with built-in folding to keep things tidy and avoid getting lost in a sea of JSON.    ","version":null,"tagName":"h3"},{"title":"Setting Headers​","type":1,"pageTitle":"Exploring GraphiQL: The In-Browser IDE for GraphQL","url":"/blog/exploring-graphiql/#setting-headers","content":" Access the Headers Panel right beside the variables panel at the bottom    Add Custom Headers  { &quot;Authorization&quot;: &quot;token myghtoken&quot; }   Run Your Query!  ","version":null,"tagName":"h2"},{"title":"Alternatives​","type":1,"pageTitle":"Exploring GraphiQL: The In-Browser IDE for GraphQL","url":"/blog/exploring-graphiql/#alternatives","content":" In case GraphiQL doesn’t quite work out for you and you want to try another IDE, here are some options:  Introspection with Postman  Querying with Postman    PostmanInsomniaAltair Client  ","version":null,"tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Exploring GraphiQL: The In-Browser IDE for GraphQL","url":"/blog/exploring-graphiql/#conclusion","content":" Wrapping up, we discussed how GraphiQL is an absolute life-saver, especially when you have a server with hundreds of queries returning hundreds of fields of response data. It also makes it super easy to set up a GraphQL playground, like the Tailcall Playground. It’s relieving and exciting to see new open-source projects being launched that make our lives as programmers much easier:  Tailcall absolutely boosts server speed and performanceGraphiQL is a total blessing for testing servers in the development stageVoyager is the ultimate tool to graphically view and edit your complex schemas.  Happy coding, and may your queries always be clean and your responses always be quick, see you in the next one! 🚀 ","version":null,"tagName":"h2"},{"title":"Apollo vs Urql vs Fetch: The Ultimate Showdown","type":0,"sectionRef":"#","url":"/blog/graphql-angular-client/","content":"","keywords":"","version":null},{"title":"🛠️ Project Setup​","type":1,"pageTitle":"Apollo vs Urql vs Fetch: The Ultimate Showdown","url":"/blog/graphql-angular-client/#️-project-setup","content":" First, let's set up our Angular project:  ng new angular-graphql-tailcall-showcase cd angular-graphql-tailcall-showcase   ","version":null,"tagName":"h3"},{"title":"🔧 Tailcall Backend Configuration​","type":1,"pageTitle":"Apollo vs Urql vs Fetch: The Ultimate Showdown","url":"/blog/graphql-angular-client/#-tailcall-backend-configuration","content":" Create a tailcall directory in the project root and add a jsonplaceholder.graphql file:  # File: tailcall/jsonplaceholder.graphql schema @server(port: 8000, hostname: &quot;0.0.0.0&quot;) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; httpCache: 42 ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) }   To start the Tailcall server, run:  tailcall start ./tailcall/jsonplaceholder.graphql   ","version":null,"tagName":"h3"},{"title":"1. Apollo Angular - The Luxury Sports Car of GraphQL Clients​","type":1,"pageTitle":"Apollo vs Urql vs Fetch: The Ultimate Showdown","url":"/blog/graphql-angular-client/#1-apollo-angular---the-luxury-sports-car-of-graphql-clients","content":" First up on our list is Apollo Angular. If GraphQL clients were cars, Apollo would be the Tesla of the bunch - sleek, powerful, and packed with features you didn't even know you needed. Let's pop the hood and see what makes this beauty purr!  Installation and Integration Steps​  Before we can take Apollo for a spin, we need to get it set up in our garage (I mean, project). Here's how:  Install the necessary packages:: npm install apollo-angular @apollo/client graphql Configure Apollo in your app.config.ts: import { APOLLO_OPTIONS, ApolloModule } from 'apollo-angular'; import { HttpLink } from 'apollo-angular/http'; import { InMemoryCache } from '@apollo/client/core'; // In your ApplicationConfig { providers: [ importProvidersFrom(ApolloModule), { provide: APOLLO_OPTIONS, useFactory: (httpLink: HttpLink) =&gt; ({ cache: new InMemoryCache(), link: httpLink.create({ uri: '/graphql', }), }), deps: [HttpLink], }, ], } Code SnippetsNow that we've got our Apollo rocket fueled up, let's see it in action! Here's a component that fetches a list of posts using Apollo in src/app/apollo-angular/post-list.component.ts:  import {Component, OnDestroy} from &quot;@angular/core&quot; import {CommonModule} from &quot;@angular/common&quot; import {Apollo, gql} from &quot;apollo-angular&quot; import {ChangeDetectorRef} from &quot;@angular/core&quot; import { catchError, takeUntil, mergeMap, } from &quot;rxjs/operators&quot; import {Subject, of, throwError} from &quot;rxjs&quot; @Component({ selector: &quot;app-apollo-post-list&quot;, standalone: true, imports: [CommonModule], template: ` &lt;h2&gt;Posts (Apollo Angular)&lt;/h2&gt; &lt;button (click)=&quot;fetchPosts()&quot; [disabled]=&quot;loading&quot;&gt; {{ loading ? &quot;Loading...&quot; : &quot;Load Posts&quot; }} &lt;/button&gt; &lt;button (click)=&quot;triggerNetworkError()&quot;&gt; Trigger Network Error &lt;/button&gt; &lt;button (click)=&quot;triggerGraphQLError()&quot;&gt; Trigger GraphQL Error &lt;/button&gt; &lt;button (click)=&quot;triggerUnexpectedError()&quot;&gt; Trigger Unexpected Error &lt;/button&gt; &lt;ul *ngIf=&quot;!error&quot;&gt; &lt;li *ngFor=&quot;let post of posts&quot;&gt;{{ post.title }}&lt;/li&gt; &lt;/ul&gt; &lt;div *ngIf=&quot;error&quot; class=&quot;error-message&quot;&gt; {{ error }} &lt;/div&gt; `, styles: [ ` .error-message { color: red; margin-top: 10px; } `, ], }) export class ApolloPostListComponent implements OnDestroy { // ... (component properties and constructor) fetchPosts() { this.loading = true this.error = null this.posts = [] let query = gql` query GetPosts($limit: Int) { posts(limit: $limit) { id title ${this.simulateGraphQLError ? &quot;nonExistentField&quot; : &quot;&quot;} } } ` this.apollo .watchQuery({ query: query, variables: { limit: 10, }, }) .valueChanges.pipe( takeUntil(this.unsubscribe$), mergeMap((result) =&gt; { if (this.simulateNetworkError) { return throwError( () =&gt; new Error(&quot;Simulated network error&quot;), ) } if (this.simulateUnexpectedError) { throw new Error(&quot;Simulated unexpected error&quot;) } return of(result) }), catchError((error) =&gt; { this.handleError(error) return of(null) }), ) .subscribe({ next: (result: any) =&gt; { if (result) { this.posts = result.data?.posts || [] } this.loading = false this.cdr.detectChanges() }, error: (error) =&gt; this.handleError(error), complete: () =&gt; { this.loading = false this.cdr.detectChanges() }, }) } // ... (error handling and simulation methods) }   Wow, would you look at that beauty? 😍 This component is like a finely tuned engine, ready to fetch your posts with the precision of a Swiss watch. Let's break down what's happening here:  We're using Apollo's watchQuery method to fetch our posts. It's like having a personal assistant who's always on the lookout for the latest data.We've got some nifty error simulation methods. It's like having a crash test dummy for your data fetching - you can deliberately cause errors to see how your app handles them. Safety first, right?The mergeMap operator is our traffic controller, deciding whether to let the data through or throw an error based on our simulation flags.We're using takeUntil with a Subject to ensure we clean up our subscriptions when the component is destroyed. It's like having an eco-friendly car that doesn't leave any pollution (memory leaks) behind!The template gives us a simple UI to fetch posts and trigger various error scenarios. It's like having a dashboard with different buttons to test your car's performance.  Error Handling​  Speaking of errors, Apollo doesn't just fetch data - it's got your back when things go wrong. Check out this error handling logic:   private handleError(error: any) { this.loading = false; if (error.networkError) { this.error = 'Network error. Please check your internet connection.'; } else if (error.graphQLErrors) { this.error = `GraphQL error: ${error.graphQLErrors .map((e: { message: any }) =&gt; e.message) .join(', ')}`; } else { this.error = 'An unexpected error occurred. Please try again later.'; } console.error('Error fetching posts', error); this.cdr.detectChanges(); }   This error handler is like having a built-in mechanic. Whether it's a network issue (like running out of gas) or a GraphQL error (engine trouble), it's got you covered with user-friendly messages.  Wrapping Up Apollo Angular​  And there you have it, folks! Apollo Angular - the smooth-riding, feature-packed, error-handling marvel of the GraphQL world. It's like driving a luxury car with a supercomputer onboard.  ","version":null,"tagName":"h3"},{"title":"2. Axios - The Versatile Muscle Car of HTTP Clients​","type":1,"pageTitle":"Apollo vs Urql vs Fetch: The Ultimate Showdown","url":"/blog/graphql-angular-client/#2-axios---the-versatile-muscle-car-of-http-clients","content":" If Apollo Angular is the luxury sports car of GraphQL clients, then Axios is like a classic muscle car - powerful, versatile, and ready to handle anything you throw at it. It might not have all the GraphQL-specific bells and whistles, but boy, can it perform!  1. Installation and Integration Steps​  Before we hit the gas, let's get our Axios engine installed and tuned up:  Installations.  First, rev up your terminal and run:  npm install axios   Unlike Apollo, Axios doesn't need any special configuration in your app.config.ts. It's more of a plug-and-play solution. Just import it where you need it, and you're good to go!  Code Snippets  Now, below we implement data fetching using axios in src/app/axios-angular/post-list.component.ts:  import { Component, OnInit, ChangeDetectorRef, } from &quot;@angular/core&quot; import {CommonModule} from &quot;@angular/common&quot; import axios, {AxiosInstance, AxiosError} from &quot;axios&quot; @Component({ selector: &quot;app-axios-post-list&quot;, standalone: true, imports: [CommonModule], template: ` &lt;h2&gt;Posts (Axios Angular)&lt;/h2&gt; &lt;button (click)=&quot;fetchPosts()&quot; [disabled]=&quot;loading&quot;&gt; {{ loading ? &quot;Loading...&quot; : &quot;Load Posts&quot; }} &lt;/button&gt; &lt;button (click)=&quot;triggerNetworkError()&quot;&gt; Trigger Network Error &lt;/button&gt; &lt;button (click)=&quot;triggerGraphQLError()&quot;&gt; Trigger GraphQL Error &lt;/button&gt; &lt;button (click)=&quot;triggerUnexpectedError()&quot;&gt; Trigger Unexpected Error &lt;/button&gt; &lt;ul *ngIf=&quot;!error&quot;&gt; &lt;li *ngFor=&quot;let post of posts&quot;&gt;{{ post.title }}&lt;/li&gt; &lt;/ul&gt; &lt;div *ngIf=&quot;error&quot; class=&quot;error-message&quot;&gt; {{ error }} &lt;/div&gt; `, // ... (styles omitted for brevity) }) export class AxiosPostsListsComponent implements OnInit { private client: AxiosInstance posts: any[] = [] loading = false error: string | null = null // Error simulation flags private simulateNetworkError = false private simulateGraphQLError = false private simulateUnexpectedError = false constructor(private cdr: ChangeDetectorRef) { this.client = axios.create({ baseURL: &quot;/graphql&quot;, headers: { &quot;Content-Type&quot;: &quot;application/json&quot;, }, }) } ngOnInit() { // Add a request interceptor this.client.interceptors.request.use( (config) =&gt; { if (this.simulateNetworkError) { return Promise.reject( new Error(&quot;Simulated network error&quot;), ) } return config }, (error) =&gt; Promise.reject(error), ) } private GET_DATA = ` query GetPosts($limit: Int) { posts(limit: $limit) { id title ${this.simulateGraphQLError ? &quot;nonExistentField&quot; : &quot;&quot;} } } ` async query(queryString: string, variables: any = {}) { try { if (this.simulateUnexpectedError) { throw new Error(&quot;Simulated unexpected error&quot;) } const response = await this.client.post(&quot;&quot;, { query: queryString, variables, }) return response.data } catch (error) { this.handleError(error) throw error } } async fetchPosts() { this.loading = true this.error = null this.posts = [] this.cdr.detectChanges() try { const result = await this.query(this.GET_DATA, { limit: 10, }) this.posts = result.data.posts this.loading = false this.cdr.detectChanges() } catch (error) { // Error is already handled in query method this.loading = false this.cdr.detectChanges() } } // ... (error handling and simulation methods omitted for brevity) }   This Axios-powered component is revving up to fetch those posts faster than you can say &quot;GraphQL&quot;! Let's break down what's happening in this high-octane code:  We're creating an Axios instance in the constructor. It's like customizing your car with a specific paint job (baseURL) and some cool decals (headers).The ngOnInit method adds a request interceptor. Think of it as a nitrous oxide system - it can give your requests an extra boost or, in this case, simulate a network error if you want to test your error handling.Our query method is like the engine of this muscle car. It takes a GraphQL query string and variables, then fires off the request. If something goes wrong, it calls our trusty mechanic (the handleError method).The fetchPosts method is where the rubber meets the road. It calls our query method with the posts query, then updates our component state with the results.We've got our error simulation methods, just like in the Apollo example. It's like having different test tracks for your muscle car - you can simulate various error conditions to make sure your code can handle any bumps in the road.  2. Error Handling​  Now, let's talk about handling of errors:   private handleError(error: any) { if (axios.isAxiosError(error)) { const axiosError = error as AxiosError; if (axiosError.response) { // The request was made and the server responded with a status code // that falls out of the range of 2xx this.error = `Server error: ${axiosError.response.status} ${axiosError.response.statusText}`; } else if (axiosError.request) { // The request was made but no response was received this.error = 'Network error. Please check your internet connection.'; } else { // Something happened in setting up the request that triggered an Error this.error = 'An unexpected error occurred. Please try again later.'; } } else if (error.graphQLErrors) { this.error = `GraphQL error: ${error.graphQLErrors .map((e: any) =&gt; e.message) .join(', ')}`; } else { this.error = 'An unexpected error occurred. Please try again later.'; } console.error('Error fetching posts:', error); }   This error handler is like the world's best shock absorber system. Whether you hit a pothole (network error), take a wrong turn (server error), or your engine misfires (unexpected error), it's got you covered with user-friendly messages. It even handles those tricky GraphQL-specific errors!  Wrapping Up Axios​  And there you have it, Axios - the muscle car of HTTP clients, now tuned up to handle GraphQL queries with style. It might not have all the GraphQL-specific features of Apollo, but it's a powerhouse that can handle just about anything you throw at it. Axios shines when you need a lightweight, versatile solution that can handle both REST and GraphQL APIs. It's like having a car that's equally at home on the racetrack and the city streets. Plus, if you're already familiar with Axios from REST API work, the learning curve here is as smooth as a freshly paved highway.  ","version":null,"tagName":"h3"},{"title":"3. Fetch API - The Lean, Mean, JavaScript Machine​","type":1,"pageTitle":"Apollo vs Urql vs Fetch: The Ultimate Showdown","url":"/blog/graphql-angular-client/#3-fetch-api---the-lean-mean-javascript-machine","content":" If Apollo was our luxury sports car and Axios our muscle car, then the Fetch API is like a nimble, lightweight motorcycle. It's built right into modern browsers, requires no external libraries, and can zip through traffic with ease. Let's see how this speed demon handles our GraphQL queries!  1. Installation and Integration Steps​  Here's the beauty of the Fetch API - there's nothing to install! 🎉 It's like finding out your new apartment comes with a free motorcycle in the garage. Just hop on and ride!  2. Code Snippets​  import {Component, ChangeDetectorRef} from &quot;@angular/core&quot; import {CommonModule} from &quot;@angular/common&quot; @Component({ selector: &quot;app-fetch-post-list&quot;, standalone: true, imports: [CommonModule], template: ` &lt;h2&gt;Posts (Fetch Angular)&lt;/h2&gt; &lt;button (click)=&quot;fetchPosts()&quot; [disabled]=&quot;loading&quot;&gt; {{ loading ? &quot;Loading...&quot; : &quot;Load Posts&quot; }} &lt;/button&gt; &lt;button (click)=&quot;triggerNetworkError()&quot;&gt; Trigger Network Error &lt;/button&gt; &lt;button (click)=&quot;triggerGraphQLError()&quot;&gt; Trigger GraphQL Error &lt;/button&gt; &lt;button (click)=&quot;triggerUnexpectedError()&quot;&gt; Trigger Unexpected Error &lt;/button&gt; &lt;ul *ngIf=&quot;!error&quot;&gt; &lt;li *ngFor=&quot;let post of posts&quot;&gt;{{ post.title }}&lt;/li&gt; &lt;/ul&gt; &lt;div *ngIf=&quot;error&quot; class=&quot;error-message&quot;&gt; {{ error }} &lt;/div&gt; `, // ... (styles omitted for brevity) }) export class FetchPostListComponent { private endpoint = &quot;/graphql&quot; posts: any[] = [] loading = false error: string | null = null // Error simulation flags private simulateNetworkError = false private simulateGraphQLError = false private simulateUnexpectedError = false constructor(private cdr: ChangeDetectorRef) {} private GET_DATA = ` query GetPosts($limit: Int) { posts(limit: $limit) { id title ${this.simulateGraphQLError ? &quot;nonExistentField&quot; : &quot;&quot;} } } ` async query(queryString: string, variables: any = {}) { if (this.simulateNetworkError) { throw new Error(&quot;Simulated network error&quot;) } if (this.simulateUnexpectedError) { throw new Error(&quot;Simulated unexpected error&quot;) } try { const response = await fetch(this.endpoint, { method: &quot;POST&quot;, headers: { &quot;Content-Type&quot;: &quot;application/json&quot;, }, body: JSON.stringify({ query: queryString, variables, }), }) if (!response.ok) { throw new Error( `HTTP error! status: ${response.status}`, ) } const result = await response.json() if (result.errors) { throw new Error( result.errors .map((e: any) =&gt; e.message) .join(&quot;, &quot;), ) } return result } catch (error) { this.handleError(error) throw error } } async fetchPosts() { this.loading = true this.error = null this.posts = [] this.cdr.detectChanges() try { const result = await this.query(this.GET_DATA, { limit: 10, }) this.posts = result.data.posts this.loading = false this.cdr.detectChanges() } catch (error) { // Error is already handled in query method this.loading = false this.cdr.detectChanges() } } // ... (error handling and simulation methods omitted for brevity) }   This Fetch-powered component is leaner than a greyhound and faster than a caffeinated cheetah! Let's break down what's happening in this high-speed code:  No imports needed for Fetch - it's built right into the browser. It's like having a motorcycle that doesn't need gas!Our query method is the engine of this speed machine. It takes a GraphQL query string and variables, then zooms off to fetch the data.We're using async/await syntax, which makes our asynchronous code read like a smooth ride down the highway.The fetchPosts method is where we kick into high gear. It calls our query method with the posts query, then updates our component state with the results.We've still got our error simulation methods. It's like having different obstacle courses for our motorcycle - we can test how it handles in various tricky situations.  Error Handling​  Now, let's talk about the suspension system of our Fetch motorcycle - the error handling:   private handleError(error: any) { if (error instanceof TypeError &amp;&amp; error.message === 'Failed to fetch') { this.error = 'Network error. Please check your internet connection.'; } else if (error instanceof Error) { if (error.message.includes('GraphQL error')) { this.error = `GraphQL error: ${error.message}`; } else if (error.message.startsWith('HTTP error!')) { this.error = `Server error: ${error.message}`; } else { this.error = 'An unexpected error occurred. Please try again later.'; } } else { this.error = 'An unexpected error occurred. Please try again later.'; } console.error('Error fetching posts:', error); }   This error handler efficiently manages various error types. It provides user-friendly messages for network issues, server errors, unexpected problems, and GraphQL-specific errors, ensuring a smooth user experience even when things go wrong.  Wrapping Up Fetch API​  And there you have it, The Fetch API - the nimble, lightweight motorcycle of HTTP clients, now revved up to handle GraphQL queries with style. It might not have all the bells and whistles of Apollo or the versatility of Axios, but it's fast, it's built-in, and it gets the job done with minimal fuss.  Fetch shines when you need a lightweight, no-dependency solution that can handle both REST and GraphQL APIs. It's like having a motorcycle that's equally at home zipping through city traffic or cruising on the open highway. Plus, if you're looking to keep your project dependencies to a minimum, Fetch is your go-to ride.  ","version":null,"tagName":"h3"},{"title":"4. GraphQL Request - The Precision-Engineered Sports Car​","type":1,"pageTitle":"Apollo vs Urql vs Fetch: The Ultimate Showdown","url":"/blog/graphql-angular-client/#4-graphql-request---the-precision-engineered-sports-car","content":" If Apollo was our luxury sedan, Axios our muscle car, and Fetch our nimble motorcycle, then GraphQL Request is like a finely-tuned sports car. It's designed specifically for GraphQL, offering a perfect balance of simplicity and power. Let's see how this beauty handles our data-fetching curves!  Installation and Integration StepsBefore we hit the track, let's get our GraphQL Request engine installed:  npm install graphql-request graphql   No special configuration needed in your app.config.ts. Just import it in your component, and you're ready to race!  Code Snippets  Now, let's pop the hood and examine our GraphQL Request-powered component:  import {Component, ChangeDetectorRef} from &quot;@angular/core&quot; import {CommonModule} from &quot;@angular/common&quot; import { GraphQLClient, gql, ClientError, } from &quot;graphql-request&quot; @Component({ selector: &quot;app-graphql-request-post-list&quot;, standalone: true, imports: [CommonModule], template: ` &lt;h2&gt;Posts (Graphql Request Angular)&lt;/h2&gt; &lt;button (click)=&quot;fetchPosts()&quot; [disabled]=&quot;loading&quot;&gt; {{ loading ? &quot;Loading...&quot; : &quot;Load Posts&quot; }} &lt;/button&gt; &lt;button (click)=&quot;triggerNetworkError()&quot;&gt; Trigger Network Error &lt;/button&gt; &lt;button (click)=&quot;triggerGraphQLError()&quot;&gt; Trigger GraphQL Error &lt;/button&gt; &lt;button (click)=&quot;triggerUnexpectedError()&quot;&gt; Trigger Unexpected Error &lt;/button&gt; &lt;ul *ngIf=&quot;!error&quot;&gt; &lt;li *ngFor=&quot;let post of posts&quot;&gt;{{ post.title }}&lt;/li&gt; &lt;/ul&gt; &lt;div *ngIf=&quot;error&quot; class=&quot;error-message&quot;&gt; {{ error }} &lt;/div&gt; `, // ... (styles omitted for brevity) }) export class GraphqlRequestPostListComponent { private client: GraphQLClient posts: any[] = [] loading = false error: string | null = null // Error simulation flags private simulateNetworkError = false private simulateGraphQLError = false private simulateUnexpectedError = false constructor(private cdr: ChangeDetectorRef) { this.client = new GraphQLClient( &quot;http://localhost:4200/graphql&quot;, ) } private GET_DATA = gql` query GetPosts($limit: Int) { posts(limit: $limit) { id title ${this.simulateGraphQLError ? &quot;nonExistentField&quot; : &quot;&quot;} } } ` async fetchPosts() { this.loading = true this.error = null this.posts = [] this.cdr.detectChanges() try { if (this.simulateNetworkError) { throw new Error(&quot;Simulated network error&quot;) } if (this.simulateUnexpectedError) { throw new Error(&quot;Simulated unexpected error&quot;) } const result: any = await this.client.request( this.GET_DATA, { limit: 10, }, ) this.posts = result.posts this.loading = false this.cdr.detectChanges() } catch (error) { this.handleError(error) this.loading = false this.cdr.detectChanges() } } // ... (error handling and simulation methods omitted for brevity) }   Let's break down what's happening in this high-performance code:  We're importing GraphQLClient and gql from graphql-request. It's like having a custom-built engine and transmission, specifically designed for GraphQL roads.In the constructor, we're initializing our GraphQLClient. It's like setting up the onboard computer of our sports car, telling it exactly where to go for our data.Our GET_DATA query is defined using the gql tag. It's like programming the GPS with the exact route we want to take.The fetchPosts method is where we put the pedal to the metal. We're using the client.request method, which is like engaging the launch control on our sports car - it handles everything for us, from acceleration to gear shifts.We've still got our error simulation methods. It's like having different road conditions we can simulate - wet roads, oil slicks, you name it!  Error Handling​  Now, let's talk about the advanced traction control system of our GraphQL Request sports car - the error handling:   private handleError(error: any) { if (error instanceof ClientError) { if (error.response.errors) { // GraphQL errors this.error = `GraphQL error: ${error.response.errors .map((e) =&gt; e.message) .join(', ')}`; } else { // Network errors or other HTTP errors this.error = `Network error: ${error.response.status} ${error.response['statusText']}`; } } else if (error instanceof Error) { if (error.message === 'Simulated network error') { this.error = 'Network error. Please check your internet connection.'; } else { this.error = 'An unexpected error occurred. Please try again later.'; } } else { this.error = 'An unexpected error occurred. Please try again later.'; } console.error('Error fetching posts:', error); }   This error handler is like having the world's best traction control and stability management system. Whether you hit a patch of black ice (network error), take a corner too fast (GraphQL error), or encounter an unexpected obstacle (other errors), it's got you covered with user-friendly messages. It even distinguishes between different types of errors, giving you precise control over how to handle each situation.  Wrapping Up GraphQL Request​  And there you have it, folks! GraphQL Request - the precision-engineered sports car of GraphQL clients. It's streamlined, efficient, and designed specifically for the twists and turns of GraphQL queries. GraphQL Request shines when you need a lightweight, GraphQL-specific solution that offers more than Fetch but doesn't require the full ecosystem of Apollo. It's like having a sports car that's perfect for both daily commutes and weekend track days. Plus, its simplicity makes it a joy to work with, especially for smaller to medium-sized projects.  ","version":null,"tagName":"h3"},{"title":"5. Urql in Angular​","type":1,"pageTitle":"Apollo vs Urql vs Fetch: The Ultimate Showdown","url":"/blog/graphql-angular-client/#5-urql-in-angular","content":" Installation and Integration Steps​  First things first, let's get our hands dirty with some installation magic. To bring Urql into your Angular project, you'll need to wave your command line wand and chant:  npm install @urql/core graphql   We need to set up our Urql client.  Code Snippets and Explanation​  Let's break down our UrqlPostListComponent which you'll create following the same format above and solder structure:  import { createClient, fetchExchange, cacheExchange, Client, } from &quot;@urql/core&quot; // ... other imports export class UrqlPostListComponent { client: Client constructor(private cdr: ChangeDetectorRef) { this.client = createClient({ url: &quot;http://localhost:4200/graphql&quot;, exchanges: [cacheExchange, fetchExchange], }) } // ... rest of the component }   Here, we're setting up our Urql client faster than you can say &quot;GraphQL&quot;. We're telling it where to find our GraphQL endpoint and which exchanges to use. Think of exchanges as middleware for your GraphQL requests - they're like bouncers at a club, deciding how to handle incoming and outgoing traffic.  Now, let's look at how we're fetching posts:   getPostsQuery = gql` query GetPosts($limit: Int) { posts(limit: $limit) { id title } } `; fetchPosts() { this.loading = true; this.error = null; this.posts = []; this.cdr.detectChanges(); this.client .query(this.getPostsQuery, { limit: 10 }) .toPromise() .then((result) =&gt; { if (result.error) { this.handleError(result.error); } else { this.posts = result.data?.posts || []; this.loading = false; this.cdr.detectChanges(); } }) .catch((error) =&gt; this.handleError(error)) .finally(() =&gt; { this.loading = false; this.cdr.detectChanges(); }); }   This fetchPosts method is where the magic happens. We're using Urql's query method to fetch our posts, handling the result like a pro juggler. If there's an error, we toss it to our error handler. If it's successful, we update our posts faster than you can say &quot;data fetched&quot;!  Error Handling​  Now, let's talk about error handling. In the world of APIs, errors are like unexpected plot twists in a movie - they keep things interesting, but you need to know how to handle them:   private handleError(error: any) { this.loading = false; if (error instanceof CombinedError) { if (error.networkError) { this.error = 'Network error. Please check your internet connection.'; } else if (error.graphQLErrors.length &gt; 0) { this.error = `GraphQL error: ${error.graphQLErrors .map((e) =&gt; e.message) .join(', ')}`; } } else if (error instanceof Error) { this.error = `An unexpected error occurred: ${error.message}`; } else { this.error = 'An unexpected error occurred. Please try again later.'; } console.error('Error fetching posts:', error); this.cdr.detectChanges(); }   This error handler is like a Swiss Army knife for API errors. Network error? We've got you covered. GraphQL error? No problem. Unexpected error that makes you question the nature of reality? We handle that too! Why Choose Urql? You might be wondering, &quot;Why should I choose Urql over other options?&quot; Well, let me tell you, Urql is like that cool, efficient friend who always knows the best way to get things done:  Lightweight: Urql is as light as a feather, which means your app won't feel like it's carrying extra baggage.Flexible: It's adaptable to various use cases, like a chameleon in the coding world.Great Developer Experience: With Urql, you'll feel like you're coding with a tailwind, not against a headwind.  tip Want to see all this in action? Check out our GitHub repo! We've put together a complete set of working examples for everything we've covered in this article. It's the perfect companion to help you dive deeper into Angular and GraphQL. Explore the code on GitHub  ","version":null,"tagName":"h3"},{"title":"Detailed Comparison Table​","type":1,"pageTitle":"Apollo vs Urql vs Fetch: The Ultimate Showdown","url":"/blog/graphql-angular-client/#detailed-comparison-table","content":" Method\tBundle Size (minified + gzip)*\tLearning Curve\tCaching Capabilities\tCommunity Support\tAdditional FeaturesApollo Angular¹\t258 KB\tModerate\tExtensive (InMemoryCache, customizable)\tHigh\tState management, optimistic UI updates Urql²\t17 KB\tLow\tModerate (Document and normalized caching)\tModerate\tExtensible architecture, lightweight, plugin system GraphQL-Request³\t58.6 KB\tLow\tNone (Minimal client)\tModerate\tSimplicity, works in Node and browsers Axios⁴\t24 KB\tLow\tNone (HTTP client only)\tHigh\tFamiliar HTTP handling, interceptors Fetch API\t0 KB (Browser built-in)\tLow\tNone (Native API)\tHigh\tNo additional dependency, widely supported  (*) Bundle sizes are based on bundlejs.com calculations using the provided export statements, with minification and gzip compression applied.  Notes:  Apollo Angular's bundle size (258 KB gzipped) is significantly larger than other options, which may impact initial load times for applications.Urql offers a much smaller bundle size (17 KB gzipped) while still providing both document caching and normalized caching through its plugin architecture.GraphQL-Request, despite being a minimal client, has a larger bundle size (58.6 KB gzipped) than expected, which might be due to including the full GraphQL parser.Axios, a general-purpose HTTP client, has a moderate bundle size (24 KB gzipped) considering its feature set.The Fetch API remains the lightest option as it's built into modern browsers, but it lacks some conveniences provided by other libraries.Bundle sizes for critical path libraries can significantly impact performance. Consider lazy-loading or code-splitting strategies when using larger libraries like Apollo Angular.  Bundle Size References:  Apollo Angular: bundlejs.com linkUrql: bundlejs.com linkGraphQL-Request: bundlejs.com linkAxios: bundlejs.com link  ","version":null,"tagName":"h2"},{"title":"Caching Capabilities​","type":1,"pageTitle":"Apollo vs Urql vs Fetch: The Ultimate Showdown","url":"/blog/graphql-angular-client/#caching-capabilities","content":" Apollo Angular Extensive caching capabilities through InMemoryCacheNormalization of data for efficient storage and retrievalCustomizable cache policies (cache-first, network-only, etc.)Automatic cache updates on mutationsSupport for pagination and optimistic UI updatesAbility to manually update and read from the cache Urql Document caching by defaultCustomizable caching through exchangeable cache implementationsSupports normalized caching with additional setupCache invalidation and updates through GraphQL mutationsSimpler caching model compared to Apollo, focusing on ease of use GraphQL-Request No built-in caching mechanismRequires manual implementation of caching if neededCan be combined with external caching solutions or state management libraries Axios No built-in GraphQL-specific cachingCan implement HTTP-level caching (e.g., using headers)Requires manual implementation of application-level cachingCan be combined with state management libraries for more sophisticated caching Fetch API No built-in GraphQL-specific cachingSupports basic HTTP caching through cache-control headersRequires manual implementation of application-level cachingCan be combined with other libraries or custom solutions for more advanced caching  In summary, Apollo Angular offers the most robust out-of-the-box caching solution, followed by Urql with its flexible caching system. GraphQL-Request, Axios, and Fetch API do not provide GraphQL-specific caching, requiring developers to implement their own caching strategies or integrate with other libraries for advanced caching needs.  When choosing an approach, consider your application's complexity, performance requirements, and willingness to manage caching manually versus leveraging built-in solutions.  ","version":null,"tagName":"h3"},{"title":"Common Issues and Resolutions​","type":1,"pageTitle":"Apollo vs Urql vs Fetch: The Ultimate Showdown","url":"/blog/graphql-angular-client/#common-issues-and-resolutions","content":" Apollo Angular Issue: Cache inconsistencies after mutations Resolution: Ensure proper cache updates in mutation's update functionUse refetchQueries option to refresh related queriesImplement optimisticResponse for immediate UI updates Issue: Over-fetching data Resolution: Utilize fragments for reusable field selectionsImplement proper query splitting for componentsUse @connection directive for pagination to avoid refetching all data Urql Issue: Stale data after mutations Resolution: Use the cache-and-network request policyImplement cache updates in mutation's updates optionUtilize the refocusExchange for automatic refetching on window focus Issue: Complex state management Resolution: Combine Urql with external state management libraries like NgRx if neededLeverage Urql's useQuery and useMutation hooks for simpler state handling GraphQL-Request Issue: Lack of automatic caching Resolution: Implement manual caching using services or state management librariesUse HTTP caching headers for basic caching needsConsider switching to Apollo or Urql for more complex applications Issue: Error handling complexities Resolution: Implement a centralized error handling serviceUse TypeScript for better type checking and error preventionWrap GraphQL-Request calls in try-catch blocks for granular error handling Axios Issue: Constructing complex GraphQL queries Resolution: Use template literals for dynamic query constructionImplement a query builder utility for complex queriesConsider using a GraphQL-specific library for very complex schemas Issue: Handling GraphQL errors Resolution: Check for errors array in the response bodyImplement custom error classes for different GraphQL error typesUse interceptors for global error handling Fetch API Issue: Verbose syntax for GraphQL operations Resolution: Create utility functions to abstract common GraphQL operationsUse TypeScript interfaces for better type safety and autocompletionConsider using a lightweight wrapper around Fetch for GraphQL specifics Issue: Limited built-in features Resolution: Implement custom middleware for features like retries and cachingUse external libraries for advanced features (e.g., Observable support)Create a custom Angular service to encapsulate Fetch API logic  General Resolutions:  Implement proper error boundaries in your Angular componentsUse TypeScript for better type checking and IDE supportLeverage Angular's HttpInterceptors for global request/response handlingImplement proper loading states to improve user experience during data fetchingUse environment variables for GraphQL endpoint configuration  By addressing these common issues, developers can create more robust and efficient GraphQL implementations in their Angular applications, regardless of the chosen approach.  ","version":null,"tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Apollo vs Urql vs Fetch: The Ultimate Showdown","url":"/blog/graphql-angular-client/#conclusion","content":" As we've journeyed through the landscape of GraphQL integration in Angular, we've explored five distinct approaches, each with its own strengths and considerations. Let's recap and draw some final insights:  Apollo Angular emerges as the powerhouse solution, offering a comprehensive feature set including robust caching, state management, and optimistic UI updates. It's ideal for large-scale applications with complex data requirements, though it comes with a steeper learning curve and larger bundle size. Urql strikes a balance between functionality and simplicity. Its lightweight nature and extensible architecture make it an excellent choice for projects that need flexibility without the full weight of Apollo. It's particularly suitable for medium-sized applications or teams that prefer a more customizable approach. GraphQL-Request shines in its simplicity. For small projects or microservices where basic GraphQL operations are all that's needed, it provides a no-frills solution with minimal overhead. However, it lacks built-in caching and advanced features, which may become limitations as your project grows. Axios, while not GraphQL-specific, leverages its widespread adoption and familiarity among developers. It's a solid choice for teams already using Axios in their stack or for projects that mix RESTful and GraphQL APIs. However, it requires more manual work for GraphQL-specific features. Fetch API represents the most lightweight approach, with zero additional bundle size. It's ideal for projects prioritizing minimal dependencies and maximum browser compatibility. However, it necessitates more boilerplate code and manual implementation of GraphQL-specific features.  The choice between these approaches ultimately depends on your project's specific needs, your team's expertise, and your application's scalability requirements. Here are some final recommendations:  For large, data-intensive applications with complex requirements, Apollo Angular is likely your best bet.If you're looking for a lightweight yet capable solution, Urql offers an excellent middle ground.For smaller projects or microservices, GraphQL-Request or Fetch API might be sufficient.If your project involves a mix of REST and GraphQL APIs, consider Axios for its versatility.  Remember, there's no one-size-fits-all solution. The best approach is the one that aligns with your project's needs and your team's capabilities. As your application evolves, don't hesitate to reassess and switch approaches if necessary.  Whichever path you choose, GraphQL's power in providing flexible, efficient data fetching can significantly enhance your Angular applications. By understanding these different approaches, you're now equipped to make an informed decision and leverage GraphQL to its full potential in your Angular projects.  Happy coding, and may your GraphQL queries be ever efficient! ","version":null,"tagName":"h2"},{"title":"GraphQL Conf 2023","type":0,"sectionRef":"#","url":"/blog/graphql-conf-2023/","content":"","keywords":"","version":null},{"title":"Workshops & Talks Highlights​","type":1,"pageTitle":"GraphQL Conf 2023","url":"/blog/graphql-conf-2023/#workshops--talks-highlights","content":" Is GraphQL BFF Necessary: An electrifying discussion led by Tanmay from Hasura, as he unravels the significance of the BFF layer in the era after ReactJS. One profound takeaway? GraphQL isn't just a fleeting tactic for instant gains—it's a visionary strategy that propels businesses toward unparalleled success! Interactive GraphQL with Envoy &amp; Kubernetes: The team from solo.io showcased the magic of adding GraphQL to an envoy gateway. It's all about giving clients more power while retaining essential gateway features. The Future of Efficiency: Benjie Gillam's talk was a rollercoaster! He introduced grafast, a new GraphQL execution engine that optimizes data loading through query planning. One to watch! Rethinking Rate Limiting: Meenakshi Dhanani from Postman took us on a journey through the intricacies of rate-limiting GraphQL queries. Traditional methods? Not so effective. Enter query cost analysis! GraphQL Fusion Unveiled: Michael Staib from ChilliCream introduced GraphQL Fusion, a revolutionary approach to building distributed GraphQL APIs. The future of federating GraphQL APIs is looking bright! The Null Saga: Stephen Spalding from Netflix delved into the history of 'null' and introduced the Client Controlled Nullability proposal. A game-changer for GraphQL clients, we are definitely looking forward to this one! The Right Size for GraphQL: Theo Browne's presentation was an eye-opener. He introduced us to scenarios where tRPC might be a better fit than GraphQL. Data Load 3.0: Jens from Wundergraph talked about the massive performance gains one could potentially get by using a BFS algorithm in data loaders.  ","version":null,"tagName":"h3"},{"title":"Unconference Session: Where Everyone's a Speaker!​","type":1,"pageTitle":"GraphQL Conf 2023","url":"/blog/graphql-conf-2023/#unconference-session-where-everyones-a-speaker","content":" This was our first time to such a thing. The conference kicked off with a dynamic unconference session. Everyone in attendance brainstormed discussion topics grouped them, and then dove deep into discussions. Our table delved into the multifaceted world of &quot;Federation&quot; - merging multiple GraphQL graphs into a supergraph. The consensus? The journey towards a supergraph is filled with challenges, but with tools like the Open Federation spec and GraphQL Fusion, the future looks promising!  ","version":null,"tagName":"h3"},{"title":"Networking & Global Connections​","type":1,"pageTitle":"GraphQL Conf 2023","url":"/blog/graphql-conf-2023/#networking--global-connections","content":" One of the highlights of GraphQLConf 23 was the global representation. Meeting tech enthusiasts from the Netherlands, New Zealand, Poland, Romania, and more was truly inspiring. Special shoutout to Gerard Klijs from AxonIQ for his unique take on CQRS and GraphQL!  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"GraphQL Conf 2023","url":"/blog/graphql-conf-2023/#conclusion","content":" Did you miss out on some sessions? No worries! All the talks are available on the GraphQL Foundation's YouTube channel. Dive in and get inspired!  GraphQLConf 2023 was more than just a conference for us; it was an experience. Here's to the future of GraphQL and the endless possibilities it holds! 🎉 ","version":null,"tagName":"h3"},{"title":"Are Hackers Using Your Own GraphQL API Against You?","type":0,"sectionRef":"#","url":"/blog/graphql-introspection-security/","content":"","keywords":"","version":null},{"title":"Understanding GraphQL Introspection​","type":1,"pageTitle":"Are Hackers Using Your Own GraphQL API Against You?","url":"/blog/graphql-introspection-security/#understanding-graphql-introspection","content":" Imagine having a magical lens that lets you peek into the very structure of a GraphQL server. That's essentially what introspection does! It's like having a detailed map of a treasure trove, showing you every nook and cranny of the API's capabilities. This self-documenting capability is incredibly useful for developers, enabling tools like GraphiQL and GraphQL Playground to provide rich, interactive documentation and auto-completion features.  A basic introspection query might look like this:  { __schema { types { name fields { name type { name } } } } }   This query asks the server to return information about all the types in the schema, including their fields and field types. The server's response provides a comprehensive map of its structure, which can be invaluable during development.  ","version":null,"tagName":"h2"},{"title":"The Security Implications of Introspection​","type":1,"pageTitle":"Are Hackers Using Your Own GraphQL API Against You?","url":"/blog/graphql-introspection-security/#the-security-implications-of-introspection","content":" While introspection is a goldmine for developers, it can also be a treasure map for attackers. Let's put on our black hat for a moment and see how a malicious actor might exploit this feature.  ","version":null,"tagName":"h2"},{"title":"Schema Reconnaissance​","type":1,"pageTitle":"Are Hackers Using Your Own GraphQL API Against You?","url":"/blog/graphql-introspection-security/#schema-reconnaissance","content":" One of the primary risks of introspection is schema reconnaissance. An attacker who gains access to a GraphQL endpoint can use introspection to explore the schema and identify potential targets for further attacks. This includes discovering sensitive types and fields, as well as understanding the relationships between different parts of the schema. Armed with this knowledge, an attacker can craft more effective queries to exploit vulnerabilities in the system.  For instance, an attacker might discover a 'User' type with fields like 'email', 'password', and 'isAdmin'. They could then craft a query to exploit this:  query { allUsers { email password isAdmin } }   If not properly secured, this query could potentially expose sensitive user data. The attacker might also notice an 'updateUser' mutation, which could be a target for privilege escalation attempts.  ","version":null,"tagName":"h3"},{"title":"Information Disclosure​","type":1,"pageTitle":"Are Hackers Using Your Own GraphQL API Against You?","url":"/blog/graphql-introspection-security/#information-disclosure","content":" Another significant risk is information disclosure. The introspection feature can inadvertently reveal implementation details that should remain hidden. This includes internal types, deprecated fields, and administrative functionalities. Such exposure can give attackers clues about the underlying system architecture and any potential weaknesses.  ","version":null,"tagName":"h3"},{"title":"Attack Surface Expansion​","type":1,"pageTitle":"Are Hackers Using Your Own GraphQL API Against You?","url":"/blog/graphql-introspection-security/#attack-surface-expansion","content":" By using introspection, attackers can significantly expand their attack surface. They can identify entry points for various attacks, including SQL injection, cross-site scripting (XSS), and denial of service (DoS) attacks. For instance, if introspection reveals that certain fields accept user input, an attacker might probe these fields for injection vulnerabilities.  ","version":null,"tagName":"h3"},{"title":"Mitigating Introspection Risks​","type":1,"pageTitle":"Are Hackers Using Your Own GraphQL API Against You?","url":"/blog/graphql-introspection-security/#mitigating-introspection-risks","content":" Now, let's switch gears and become the defenders of our GraphQL realm. Here are some battle-tested strategies to keep your API safe from prying eyes:  ","version":null,"tagName":"h2"},{"title":"Disable Introspection in Production​","type":1,"pageTitle":"Are Hackers Using Your Own GraphQL API Against You?","url":"/blog/graphql-introspection-security/#disable-introspection-in-production","content":" Disabling introspection in production is crucial because it significantly reduces the information available to potential attackers. Without introspection, they can't easily map out your API's structure or discover hidden fields and types. This forces attackers to rely on guesswork or prior knowledge, making their job much more difficult. However, it's important to note that this is not a silver bullet—determined attackers may still attempt to reverse-engineer your API through trial and error.  In many GraphQL implementations, disabling introspection is straightforward. For example, in Tailcall, you can disable introspection by setting the introspection option to false:  schema @server(introspection: false) { query: Query mutation: Mutation }   This configuration ensures that introspection is disabled.  ","version":null,"tagName":"h3"},{"title":"Implement Authentication and Authorization​","type":1,"pageTitle":"Are Hackers Using Your Own GraphQL API Against You?","url":"/blog/graphql-introspection-security/#implement-authentication-and-authorization","content":" Another critical measure is to implement robust authentication and authorization mechanisms. By ensuring that only authenticated and authorized users can access your GraphQL endpoint, you can reduce the risk of unauthorized introspection queries. Use industry-standard authentication protocols such as OAuth2 or JWT to secure your endpoints.  Imagine a GraphQL API for a banking application. You might implement role-based access control where only users with an 'ADMIN' role can access certain fields or mutations.  In Tailcall, you can achieve this by using the @protected directive.  Tailcall supports a variety of authentication and authorization mechanisms, including JWT, OAuth2, and custom authentication strategies.  This ensures that even if an attacker gains access to a regular user account, they can't use it to access sensitive admin-only data or operations.  ","version":null,"tagName":"h3"},{"title":"Rate Limiting and Throttling​","type":1,"pageTitle":"Are Hackers Using Your Own GraphQL API Against You?","url":"/blog/graphql-introspection-security/#rate-limiting-and-throttling","content":" Rate limiting and throttling can also help mitigate the risks of introspection. By limiting the number of queries a client can execute within a given timeframe, you can reduce the likelihood of an attacker using introspection to gather information about your schema. Implementing these controls can also help protect your server from DoS attacks.  ","version":null,"tagName":"h3"},{"title":"Query Allow Lists​","type":1,"pageTitle":"Are Hackers Using Your Own GraphQL API Against You?","url":"/blog/graphql-introspection-security/#query-allow-lists","content":" Query allow lists work by pre-registering all valid queries that your application needs. This is typically done during the build process of your frontend application. Each query is hashed, and these hashes are stored on the server. When a query comes in, its hash is checked against the allow list.  For example, you might have a client-side query like this:  query GetUserProfile($id: ID!) { user(id: $id) { name email } }   This query would be hashed and stored on the server. When executed, the server checks if the incoming query's hash matches any in its allow list. If not, it's rejected.  This approach is powerful because it completely prevents arbitrary queries, including introspection queries, from being executed. It does require more setup and maintenance, especially in applications where queries change frequently, but it provides a very high level of security.  ","version":null,"tagName":"h3"},{"title":"Monitor and Log Introspection Queries​","type":1,"pageTitle":"Are Hackers Using Your Own GraphQL API Against You?","url":"/blog/graphql-introspection-security/#monitor-and-log-introspection-queries","content":" Monitoring and logging introspection queries can provide valuable insights into potential security threats. By tracking when and how introspection queries are executed, you can identify suspicious activity and respond accordingly. Implement logging at both the application and network levels to capture detailed information about each query.  ","version":null,"tagName":"h3"},{"title":"Use a Web Application Firewall (WAF)​","type":1,"pageTitle":"Are Hackers Using Your Own GraphQL API Against You?","url":"/blog/graphql-introspection-security/#use-a-web-application-firewall-waf","content":" A WAF can be particularly effective for GraphQL APIs because it can be configured to understand GraphQL-specific threats. For instance, you can set up rules to:  Limit query depth: Prevent deeply nested queries that could overload your server.Restrict field counts: Avoid overly broad queries that request too many fields at once.Block known malicious patterns: Such as attempts to inject malicious code into queries.  For example, a WAF rule might look like this:  SecRule ARGS_POST:query &quot;@contains __schema&quot; \\ &quot;id:1000,\\ phase:2,\\ t:none,\\ block,\\ msg:'GraphQL introspection query detected'&quot;   This rule would block any POST request containing '__schema' in the query parameter, which is typically indicative of an introspection query.  By implementing these kinds of rules, a WAF adds an extra layer of protection, catching many potential attacks before they even reach your GraphQL server.  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Are Hackers Using Your Own GraphQL API Against You?","url":"/blog/graphql-introspection-security/#conclusion","content":" Securing GraphQL is like playing a high-stakes game of chess. You need to think several moves ahead, anticipating potential threats while leveraging the strengths of your position. By implementing these strategies, you're not just protecting your API—you're ensuring that GraphQL's power remains in the right hands. Stay vigilant, keep learning, and may your queries be ever secure!  By prioritizing security in your GraphQL implementation, you can harness the power of this modern query language while safeguarding your data and maintaining the trust of your users. Securing GraphQL is an ongoing process that requires vigilance and a proactive approach. Stay informed about the latest security developments, regularly review and update your security measures, and ensure that your development and security teams are aligned in their efforts to protect your applications. ","version":null,"tagName":"h2"},{"title":"GraphQL and Microservices: A Match Made in Heaven?","type":0,"sectionRef":"#","url":"/blog/graphql-match-microservices/","content":"","keywords":"","version":null},{"title":"Introduction​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#introduction","content":" In the fast-changing land of software development, two concepts have been gathering momentum: GraphQL and microservices. While the latter helps businesses decompose their applications into small independent services, the former makes it possible for the clients of these services to request only data of interest. Each of these technologies address specific challenges inherent in building modern applications, and when combined, they offer a powerful toolkit for developers aiming to create efficient and robust APIs.  But is it really worth combining the two or is it just a new shiny object with all the hype? Is it really cost-efficient and time-saving or just an expensive thing for tech majors? Read on as I explore the challenges, features and considerations of using GraphQL with microservices. 🚀  ","version":null,"tagName":"h2"},{"title":"What Are Microservices?​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#what-are-microservices","content":"   Compared to traditional monolithic architecture, in which all the constituents of an application are usually closely integrated and interwoven, microservices present a very compelling option. Microservices really orient the technique of decomposition and isolation. Development, scaling, and deployment for every service can be independent. It provides high flexibility and a better developer experience.  The three key characteristics of microservices are scalability, flexibility, and maintainability. The components of the system can be scaled as needed, and in terms of priority. Different languages and technologies can also be used to realize each service according to use cases appropriate for individual use, which can be developed and maintained independently by different teams. Cleanup will not only be in the debugging phase; it will also accelerate the development cycle, from which you can easily adapt and evolve your application over time.    ","version":null,"tagName":"h2"},{"title":"Example: Spotify​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#example-spotify","content":" Spotify is a prime example of successful microservice adoption. To efficiently support millions of monthly users, Spotify restructured its application into microservices, resulting in impressive performance and scalability. These microservices likely handle various specialized tasks, such as:  Recommending tracks based on a user’s listening history.Identifying the genre and theme of each track.Personalizing playlists for users by combining insights from the recommendation and genre microservices.Delivering lyrics for tracks.  Read: Migrating To Microservices.  ","version":null,"tagName":"h3"},{"title":"What is GraphQL?​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#what-is-graphql","content":" GraphQL was designed based on the concept of returning precisely what is asked for; no more, no less. Open-sourced by Facebook in 2015, it fixes ancient issues of over-fetching and under-fetching that plagued REST APIs right from their very invention.  It empowers the client with flexibility regarding which particular fields to request in any use case. This is possible due to the strongly typed schema that clearly defines the data structure of the API and specifies what it returns. Plus, subscriptions allow GraphQL to return real-time data, meeting demands of modern applications.  ","version":null,"tagName":"h2"},{"title":"Example: GitHub​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#example-github","content":" GitHub is one of the prominent adopters of GraphQL. By implementing GraphQL, GitHub provides its users with a more flexible and efficient way to interact with its API. Developers can query for specific data, such as repositories, issues, and commits, all within a single request, enhancing the efficiency of their applications.  ","version":null,"tagName":"h3"},{"title":"Combining GraphQL and Microservices​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#combining-graphql-and-microservices","content":" The true magic happens when GraphQL and microservices are combined. This pairing allows developers to harness the power of microservices while mitigating some of the complexities associated with them.  ","version":null,"tagName":"h2"},{"title":"Benefits of Combining GraphQL and Microservices​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#benefits-of-combining-graphql-and-microservices","content":" By design, GraphQL has made optimization of data retrieval and parallel resolutions intrinsic to the system. Error management is also much smoother because of the automatic process of partial resolutions and formation of response as a whole. Further, due to flexibility and clear ownership, GraphQL makes it possible for clients to fetch data from different microservices. This grants extra control to the clients while communicating with microservices.  fetching data from multiple microservices using Tailcall:  type Query { tracks: TrackData! @grpc(method: &quot;tracks.trackService.listTracks&quot;) } type Track { id: ID! title: String! audioUrl: String! reactions: [Reaction] @http(path: &quot;/tracks/{{.value.id}}/reactions&quot;) lyrics: [Lyric] @grpc( body: &quot;{{.value.id}}&quot; method: &quot;tracks.trackService.getLyrics&quot; ) } type TrackData { track: [Track]! } type Reaction { emoji: String! count: Int! } type Lyric { text: String! timestampSecond: Int! }   ","version":null,"tagName":"h3"},{"title":"Challenges of Combining GraphQL and Microservices​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#challenges-of-combining-graphql-and-microservices","content":" Sometimes, it's a pathway to overengineering for an application. You could end up writing long, sprawling schemas and queries for things you could have implemented in a few lines of code in REST. It can bring in unnecessary complexity and make it harder for another developer to implement something else in the app.    Another well-known challenge is the N+1 problem: this happens when a GraphQL query requesting nested data provokes plural sequential calls to a microservice, often due to a poorly designed schema. Fortunately, Tailcall has a solution to this problem built into the box, thus making your development easier and more efficient. Read How.  ","version":null,"tagName":"h3"},{"title":"Example: Netflix​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#example-netflix","content":" Netflix is a prime example of a company that successfully implemented microservices, transforming its monolithic application into a more scalable, fault-tolerant, and efficient system. By adopting this architecture, Netflix enables each service, such as user profiles, content delivery, and recommendations, to operate independently while seamlessly integrating to provide a cohesive user experience. This approach allows Netflix to scale services based on demand, with resource-intensive microservices like content recommendations being scaled more aggressively than less demanding ones, such as age-group rating calculations.  ","version":null,"tagName":"h3"},{"title":"Designing Scalable APIs with GraphQL and Microservices​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#designing-scalable-apis-with-graphql-and-microservices","content":" Designing scalable APIs that leverage both GraphQL and microservices requires careful planning and adherence to certain principles.  Schema Design: Begin with a robust, well-defined schema that accurately represents your data and services. A modular schema is crucial, as it allows your application to grow and evolve without causing disruptions. Ensure that the schema is flexible enough to accommodate new features and changes as your application scales. Service Orchestration: To manage the complexity of multiple microservices, implement a service orchestration layer that coordinates communication between the GraphQL server and underlying services. This layer should handle essential tasks such as load balancing, caching, and fallback mechanisms to ensure seamless interactions and maintain API performance under varying loads. Caching: Utilize effective caching strategies at both the GraphQL and microservice levels to enhance performance. Caching reduces the need for repeated data retrieval, lowering latency and improving the user experience. Consider using in-memory caches for frequently accessed data and implement cache invalidation strategies to ensure data consistency. Monitoring and Logging: Comprehensive monitoring and logging are vital for tracking API performance, identifying potential bottlenecks, and quickly resolving issues. Implementing detailed logging with tools like OpenTelemetry provides valuable insights into the behavior of your API, helping you maintain high availability and optimize performance over time. Security: With Tailcall's built-in auth and @protected directive, you can add auth functionality and make fields protected with just a few lines of code - which is intelligent enough to protect any query that indirectly resolves to that field:  type Reaction @protected { emoji: String! count: Int! }   Strong Typing: Nothing can be more painful than having to work with a poorly-typed GraphQL schema where you had email and url as string, but with handmade validation code. These omissions are a big mistake which could usher in potential errors and inconsistencies in handling your data. Instead, make full use of GraphQL's in-built scalars and custom types. It leverages these built-in scalars to ensure that fields are valid according to the expected data types, reducing the need for error-prone manual validation:  type Query { findMyAccount(phone: PhoneNumber!): Account! @http(path: &quot;/accounts?phone={{.args.phone}}&quot;) } type Account { id: ID! name: String! email: String! }   Read: Designing The Perfect GraphQL Schema  ","version":null,"tagName":"h2"},{"title":"Example: Airbnb​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#example-airbnb","content":" Airbnb successfully implemented scalable APIs by combining GraphQL and microservices. Airbnb’s GraphQL layer acts as an abstraction over numerous microservices, allowing clients to retrieve data efficiently and consistently. By following the principles of schema design, service orchestration, and caching, Airbnb has built a robust platform that can scale with demand.  ","version":null,"tagName":"h3"},{"title":"Where Tailcall Comes In​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#where-tailcall-comes-in","content":" When implementing a combination of GraphQL and microservices, the integration process can become complex, particularly when dealing with schema management, service orchestration, and security concerns. Tools like Tailcall can significantly simplify this process by providing a seamless integration layer that handles the intricacies of connecting GraphQL with various microservices. Tailcall enables developers to focus on building business logic rather than managing the underlying infrastructure, accelerating development and reducing potential errors.  Ready to build your next app with GraphQL? Don’t get left behind - Try Tailcall today Get Started  ","version":null,"tagName":"h3"},{"title":"Security and Authentication with GraphQL and Microservices​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#security-and-authentication-with-graphql-and-microservices","content":" Security is a major concern when integrating GraphQL with microservices. Without proper safeguards, the powerful flexibility of GraphQL can lead to significant risks.  ","version":null,"tagName":"h2"},{"title":"Major Concerns about Security:​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#major-concerns-about-security","content":" Query Complexity: The superpower of GraphQL is letting clients create incredibly intricate and deeply nested queries. Sometimes, however, this becomes a nemesis. Imagine this: a bad user sending a query that is as deep as a rabbit hole, asking for endless amounts of data and gasping your server's breath. To keep things at hand and prevent your server from melting down, some ground rules should be created. Design query complexity analysis and set depth limits to make sure that queries are of manageable size; otherwise, they can overload your server. Have A Look:  query { songs { # Fetch all songs author { # For each song, fetch the author's details songs { # For each author, fetch their songs author { # For each song by the author, fetch the author's details again comments # Retrieve the comments for each author } # and this can go forever - until your server overloads } } } }   Authentication and Authorization: If you need to protect your microservices, some strong security configuration is requisite. Every microservice should be armed with a guard at the level of authentication and authorization. But don't stop here. Scale up these security measures to the GraphQL layer. Next, it will help you set up solid authentication strategies and fine-grained access controls right in your GraphQL schema. Think of this as having a bouncer at your door to make sure only the proper users get access to the proper data. Exposure of Data: GraphQL's introspection and flexible queries can sometimes be a two-edged sword. Unless properly controlled, sensitive information may slip out and unintentionally be exposed. Implement strict field-level access control that guides how data can be queried and by whom to keep your data safe and sound. Read: How is Introspection a Hidden Treasure for Attackers  ","version":null,"tagName":"h3"},{"title":"Example: Facebook​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#example-facebook","content":" Facebook, the creator of GraphQL, has implemented robust security measures to protect its API. Query complexity analysis, rate limiting, and other strict authentication protocols are all part of Facebook's efforts to secure the platform. Read: Securing your GraphQL API  ","version":null,"tagName":"h3"},{"title":"Final Thoughts​","type":1,"pageTitle":"GraphQL and Microservices: A Match Made in Heaven?","url":"/blog/graphql-match-microservices/#final-thoughts","content":" In conclusion, while exploring these technologies can be exciting and straightforward for some, it can also lead to significant challenges or even career setbacks if approached without proper preparation. Always conduct thorough research and planning before diving into GraphQL. To make the process easier and more secure, consider using tools like Tailcall to streamline integration and fully unlock your API's potential. See you next time! 😄 ","version":null,"tagName":"h2"},{"title":"Simplify your monolith to microservices migration using GraphQL","type":0,"sectionRef":"#","url":"/blog/graphql-microservices-migration/","content":"","keywords":"","version":null},{"title":"Understanding Monoliths and Microservices​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#understanding-monoliths-and-microservices","content":" ","version":null,"tagName":"h2"},{"title":"What is a Monolithic Architecture?​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#what-is-a-monolithic-architecture","content":" A monolithic architecture is a traditional software development model where all components of an application are tightly coupled together and run as a single service. This architecture is characterized by:  Single Codebase: The entire application’s functionality is contained within one codebase.Tightly Coupled Components: All modules are interdependent, meaning a change in one module can affect the entire system.Single Deployment Unit: The entire application is deployed as a single unit, making scaling a challenge.  Monolithic architectures are straightforward to develop initially but become increasingly difficult to manage as the application grows. Changes to one part of the system require rebuilding and redeploying the entire application, leading to slower development cycles and potential downtime.  ","version":null,"tagName":"h3"},{"title":"What are Microservices?​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#what-are-microservices","content":" Microservices are a design pattern where an application is divided into smaller, independent services that communicate with each other through APIs. Key characteristics of microservices include:  Independently Deployable Services: Each service can be developed, deployed, and scaled independently.Decoupled Components: Services are loosely coupled, meaning changes in one service typically do not impact others.Domain-Driven Design: Each microservice is aligned with a specific business function or domain.  Microservice architecture addresses many of the scalability and maintainability challenges of monolithic systems. However, it can introduce complexity in initial development.  ","version":null,"tagName":"h3"},{"title":"Why Migrate from Monolith to Microservices?​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#why-migrate-from-monolith-to-microservices","content":" Migrating from a monolithic architecture to microservices offers several advantages:  Scalability: Microservices allow you to scale individual components independently based on demand.Agility: Independent services enable faster development cycles and easier maintenance.Resilience: Failures in one service do not necessarily bring down the entire application.  Despite these advantages, the migration process is complex and requires careful planning and execution.  ","version":null,"tagName":"h3"},{"title":"Challenges in Monolith to Microservices Migration​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#challenges-in-monolith-to-microservices-migration","content":" Migrating to microservices presents several challenges that organizations must address to ensure a successful transition.  ","version":null,"tagName":"h2"},{"title":"Data Management and Consistency​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#data-management-and-consistency","content":" In a monolithic system, data is typically stored in a single database, making it easier to maintain consistency. In a microservice architecture, each service often has its database, leading to challenges in maintaining data consistency across services. Data integrity and managing distributed transactions are significant hurdles in the migration process.  ","version":null,"tagName":"h3"},{"title":"Service Communication​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#service-communication","content":" Monolithic applications typically rely on in-process communication, which is efficient and straightforward. In a microservice architecture, services must communicate over a network, introducing latency and potential failures. Managing inter-service communication, especially in distributed environments, requires robust strategies such as service discovery, load balancing, and circuit breakers.  ","version":null,"tagName":"h3"},{"title":"Deployment Complexity​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#deployment-complexity","content":" Deploying a monolithic application is relatively simple, as there is only one deployment unit. However, in a microservice architecture, each service must be deployed independently, often with different versions running simultaneously. Managing these deployments, along with continuous integration and continuous deployment (CI/CD) pipelines, adds significant complexity.  ","version":null,"tagName":"h3"},{"title":"Introduction to GraphQL​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#introduction-to-graphql","content":" ","version":null,"tagName":"h2"},{"title":"What is GraphQL?​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#what-is-graphql","content":" GraphQL is a query language and runtime for APIs that was developed by Facebook in 2012 and open-sourced in 2015. Unlike REST, which exposes multiple endpoints for different types of data, GraphQL allows clients to request exactly the data they need through a single endpoint. This flexibility makes GraphQL an excellent choice for applications with complex data needs.Read More...  ","version":null,"tagName":"h3"},{"title":"Key Features of GraphQL​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#key-features-of-graphql","content":" Declarative Data Fetching: Clients specify the shape and structure of the data they need, which only fetches the required data.Single Endpoint: All data queries are sent to a single endpoint, simplifying API design and usage.Strong Typing: GraphQL schemas are strongly typed, providing clear documentation and reducing errors.API Contract GraphQL schema acts as a contract between the client and server, ensuring a clear understanding of data requirements.  ","version":null,"tagName":"h3"},{"title":"GraphQL vs REST​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#graphql-vs-rest","content":" While REST is based on a fixed set of endpoints that return specific data, GraphQL offers a Contract-First approach, which is crucial for decoupling the client and server. Which is very important so that your splitting of the monolith into microservices can be done without affecting the client.  To learn more about the differences between GraphQL and REST, read our article on GraphQL vs REST.  ","version":null,"tagName":"h3"},{"title":"How GraphQL Simplifies Microservices Migration​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#how-graphql-simplifies-microservices-migration","content":" ","version":null,"tagName":"h2"},{"title":"Unified Data Access Layer​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#unified-data-access-layer","content":" GraphQL provides a unified data access layer that abstracts the underlying microservices. This means that clients interact with a single GraphQL API, which then fetches and aggregates data from various microservices. This abstraction layer hides the complexity of the underlying architecture from clients, making the transition from a monolithic system smoother and less disruptive.  Let's take a look at this example using Tailcall:  schema { query: Query } type Query { users(id: Int!): User @http( baseURL: &quot;https://users.example.com&quot; path: &quot;/users/{{.args.id}}&quot; ) } type User { id: Int! name: String! orders: [Order] @http( baseURL: &quot;https://orders.example.com&quot; path: &quot;/users/{{.value.id}/orders&quot; ) } type Order { id: Int! userId: Int! total: Int! }   In this specification, the services that handle user accounts and store orders may be separate, while offering data for both under a unified API. This allows for a gradual migration of services without disrupting the client interface. Clients can continue to interact with the GraphQL API, even as the underlying services evolve.  ","version":null,"tagName":"h3"},{"title":"Efficient Data Fetching​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#efficient-data-fetching","content":" In microservice architectures, data is often spread across multiple services. GraphQL’s ability to request only the data needed in a single query reduces the need for multiple round trips to different services, improving performance and reducing latency.  query { users { orders { total } } }   This query fetches only the total of each user's order, optimizing the data transfer and reducing the load on the network.  ","version":null,"tagName":"h3"},{"title":"Schema Stitching and Federation​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#schema-stitching-and-federation","content":" GraphQL supports schema stitching and federation, which allow you to combine multiple GraphQL schemas into a single schema. This is particularly useful in microservice architectures, where each service might expose its own GraphQL schema. By stitching these schemas together, you can present a unified API to clients, further simplifying the migration process.  extend type Order { sellerId: Int! seller: Seller @http(path: &quot;/sellers/{{.value.sellerId}}&quot;) } type Seller { id: Int! name: String! }   In this example, the Order type is extended with a seller field, which could be fetched from a separate microservice for seller accounts, all integrated into a single schema.  ","version":null,"tagName":"h3"},{"title":"Gradual Migration Support​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#gradual-migration-support","content":" One of the most significant advantages of using GraphQL in your migration strategy is its support for gradual migration. You can introduce a GraphQL layer on top of your existing monolithic system and then incrementally refactor parts of the monolith into microservices. The GraphQL layer can continue to serve clients, even as the underlying architecture evolves, minimizing disruption to users.  ","version":null,"tagName":"h3"},{"title":"Step-by-Step Guide to Using GraphQL in Your Migration​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#step-by-step-guide-to-using-graphql-in-your-migration","content":" ","version":null,"tagName":"h2"},{"title":"Analyze Your Monolith​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#analyze-your-monolith","content":" Begin by analyzing your monolithic application to identify the domains and boundaries within the codebase. This will help you determine how to decompose the monolith into microservices. Look for areas of the code that are highly coupled and those that are relatively isolated.  ","version":null,"tagName":"h3"},{"title":"Implement GraphQL Layer​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#implement-graphql-layer","content":" Implement a GraphQL API that sits on top of your monolithic application. This API will serve as the single point of entry for clients, allowing you to start refactoring the monolith without disrupting the client interface.  ","version":null,"tagName":"h3"},{"title":"Design Your Microservice Architecture​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#design-your-microservice-architecture","content":" Next, design your microservice architecture based on the analysis. Define the services, their boundaries, and how they will communicate with each other. Ensure that each service is aligned with a specific business function or domain to maintain cohesion.  ","version":null,"tagName":"h3"},{"title":"Migrate Services Incrementally​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#migrate-services-incrementally","content":" Start migrating functionalities from the monolith to microservices incrementally. As you extract services, update the GraphQL layer to fetch data from the newly created microservices instead of the monolith. This approach allows for a smooth transition with minimal impact on the end users.  ","version":null,"tagName":"h3"},{"title":"Test and Optimize​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#test-and-optimize","content":" Throughout the migration process, continuously test the GraphQL API to ensure it functions correctly with both the monolithic and microservices-based backends. Optimize the GraphQL queries to ensure they are efficient and do not introduce unnecessary latency.    ","version":null,"tagName":"h3"},{"title":"Best Practices for GraphQL in Microservices Migration​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#best-practices-for-graphql-in-microservices-migration","content":" ","version":null,"tagName":"h2"},{"title":"Use Strong Type System​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#use-strong-type-system","content":" Leverage GraphQL’s strong typing to ensure your API is well-defined and less prone to errors. Define your types and schema carefully to ensure they align with your domain model and business logic.  ","version":null,"tagName":"h3"},{"title":"Implement Proper Error Handling​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#implement-proper-error-handling","content":" Ensure that your GraphQL API has robust error handling in place. Provide meaningful error messages to clients and ensure that failures in one microservice do not cascade and affect the entire API.  ","version":null,"tagName":"h3"},{"title":"Optimize Performance with Caching​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#optimize-performance-with-caching","content":" Implement caching strategies within your GraphQL layer to improve performance. This can be done at various levels, including query result caching, response caching, and even partial query caching.  ","version":null,"tagName":"h3"},{"title":"Ensure Security Measures​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#ensure-security-measures","content":" Security is critical when migrating to microservices, especially when introducing a new API layer like GraphQL. Implement proper authentication and authorization mechanisms. Additionally, consider rate limiting, input validation, and other security best practices to protect your GraphQL API.  ","version":null,"tagName":"h3"},{"title":"Successful Migration Stories Using GraphQL​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#successful-migration-stories-using-graphql","content":" ","version":null,"tagName":"h2"},{"title":"Netflix​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#netflix","content":" In 2021, Netflix published a blog post detailing the company’s adoption of GraphQL. Netflix encountered performance challenges as it expanded globally, requiring a more efficient way to manage data interactions between microservices. By integrating GraphQL as a central data layer, Netflix reduced the number of network requests and minimized data transfer, significantly lowering latency. This improvement allowed Netflix to deliver content more efficiently, maintaining high customer satisfaction across a growing user base.  ","version":null,"tagName":"h3"},{"title":"GitHub​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#github","content":" GitHub needed a more flexible and user-friendly API to meet increasing demands. By adopting GraphQL, they replaced their monolithic REST API with a single, unified API layer, allowing developers to query only the data they needed. This transition improved efficiency, reduced the complexity of API version management, and enabled GitHub to introduce new features more seamlessly.  ","version":null,"tagName":"h3"},{"title":"Airbnb​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#airbnb","content":" Airbnb faced inefficiencies with its monolithic architecture, as multiple REST API calls were needed to fetch data, leading to slow response times. In response, they entered a close partnership with Apollo. By implementing GraphQL as a unified data layer on top of their microservices, Airbnb reduced the number of API calls and improved performance. This allowed for more effective scaling and a better user experience while enabling independent development across teams.  ","version":null,"tagName":"h3"},{"title":"Shopify​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#shopify","content":" Shopify's monolithic REST API became a bottleneck as their platform grew in complexity. To address this, they introduced GraphQL to their tech stack, which provided a more flexible and powerful API. This enabled developers to request exactly the data they needed, improving efficiency and supporting larger merchants. The strong typing and introspection features of GraphQL also enhanced API documentation, fostering greater innovation among developers.  ","version":null,"tagName":"h3"},{"title":"Pinterest​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#pinterest","content":" Pinterest needed to scale its monolithic architecture while continuing to innovate. They used GraphQL as an intermediary layer during their migration to microservices, allowing for a gradual transition without disrupting the user experience. This approach enabled Pinterest to decouple its front end from the back end, facilitating independent development and smoother scaling.  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#conclusion","content":" Migrating from a monolithic architecture to microservices is a complex but rewarding process. By leveraging GraphQL, organizations can ease the transition, maintain a consistent API for clients, and gradually refactor their systems without significant disruption. The flexibility and efficiency of GraphQL make it a powerful tool for navigating the challenges of modern software architecture.  Contact us today to learn more about how Tailcall can help you overcome Monolith to Microservices Migration challenges using GraphQL.  Simplify your Microservices migration with Tailcall Try Tailcall today Get Started  ","version":null,"tagName":"h2"},{"title":"FAQs​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#faqs","content":" ","version":null,"tagName":"h2"},{"title":"What is the main advantage of using GraphQL in microservices migration?​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#what-is-the-main-advantage-of-using-graphql-in-microservices-migration","content":" GraphQL provides a unified API layer that abstracts the complexity of the underlying microservices, allowing for a smoother and less disruptive migration process.  ","version":null,"tagName":"h3"},{"title":"Can I use GraphQL with existing REST APIs?​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#can-i-use-graphql-with-existing-rest-apis","content":" Yes, GraphQL can be layered on top of existing REST APIs, allowing you to gradually transition to a more flexible API architecture.  ","version":null,"tagName":"h3"},{"title":"Is GraphQL secure?​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#is-graphql-secure","content":" Yes, but it requires proper security measures such as authentication, authorization, and rate limiting to ensure that the API is protected from threats.  ","version":null,"tagName":"h3"},{"title":"How does GraphQL improve performance in microservices?​","type":1,"pageTitle":"Simplify your monolith to microservices migration using GraphQL","url":"/blog/graphql-microservices-migration/#how-does-graphql-improve-performance-in-microservices","content":" GraphQL allows clients to request only the data they need in a single query, reducing the number of round trips and the amount of data transferred over the network. ","version":null,"tagName":"h3"},{"title":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 2","type":0,"sectionRef":"#","url":"/blog/graphql-schema-part-2-1/","content":"","keywords":"","version":null},{"title":"What Do You Already Know? 🧠💫​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 2","url":"/blog/graphql-schema-part-2-1/#what-do-you-already-know-","content":" GraphQL Schema Change Quiz! Question 1/5 Adding a new field to a GraphQL schema is generally a: Safe changeDangerous changeBreaking changeRequires deprecation  In our previous post, we learned scalable GraphQL schema is critical for building production-ready APIs that can evolve with your application's needs.  In this post, we will dive deeper into how to continuously evolve your schema to meet your application's changing requirements without hard-coded versioning.  ","version":null,"tagName":"h2"},{"title":"Adding Without Breaking: The Art of Additive Changes​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 2","url":"/blog/graphql-schema-part-2-1/#adding-without-breaking-the-art-of-additive-changes","content":" You know that feeling when you're working on a project, and suddenly you realize your schema needs to change? Maybe you need to add a new field, modify an existing one, or even remove something entirely. It's enough to make any developer break out in a cold sweat, right?  But fear not! I'm here to show you how to evolve your schema like a pro, keeping your API fresh and exciting without causing your clients to tear their hair out.  ","version":null,"tagName":"h2"},{"title":"The Good, The Bad, and The Ugly of Schema Changes​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 2","url":"/blog/graphql-schema-part-2-1/#the-good-the-bad-and-the-ugly-of-schema-changes","content":" Not all changes are created equal. In this section, we’ll analyze a few different types of changes and what makes them safe or unsafe.  First things first, let's break down the types of changes we might make to our schema:  Safe Changes: These are the golden children of schema evolution. You can make these changes anytime, and your clients won't even bat an eyelash.Dangerous Changes: These are the sneaky ones. They might not break anything outright, but they can cause subtle issues that'll have your clients scratching their heads. We'll need to proceed carefully here.Breaking Changes: The name says it all. These changes will send your clients' applications crashing down faster than you can say &quot;GraphQL&quot;. We want to avoid these like the plague, but sometimes they're necessary. Don't worry, I'll show you how to handle them like a pro.  ","version":null,"tagName":"h2"},{"title":"Additive Changes​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 2","url":"/blog/graphql-schema-part-2-1/#additive-changes","content":" Most of the time, these are safe as houses.  For example, adding fields &amp; adding types is unlikely to cause issues for clients. But, there are a few tricky scenarios to watch out for.  ","version":null,"tagName":"h2"},{"title":"The Optional Argument Conundrum​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 2","url":"/blog/graphql-schema-part-2-1/#the-optional-argument-conundrum","content":" Adding optional arguments is generally safe - it's like offering your clients a shiny new toy without forcing them to play with it.  However, there's a catch. Check this out:   type Query { - products(category: String): [Product!]! + products(category: String, inStock: Boolean): [Product!]! }   See what we did there? We added an optional inStock argument. Seems harmless, right?  Let's dive deeper into why changing the behavior of a resolver when an optional argument isn't provided can be problematic:  type Query { products(category: String, inStock: Boolean): [Product!]! }   Imagine you have clients that have been using this query:  query { products(category: &quot;Electronics&quot;) { name price } }   If your resolver suddenly starts filtering out out-of-stock products when inStock isn't provided, these clients will unexpectedly receive fewer results. This could break their UI or data processing logic.  To avoid this issue, you can implement a strategy to handle the absence of the inStock argument gracefully in your resolver, so that the behavior remains consistent for clients.  ","version":null,"tagName":"h3"},{"title":"The Required Argument Trap​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 2","url":"/blog/graphql-schema-part-2-1/#the-required-argument-trap","content":" Now, this is where things get spicy 🌶️.  Adding a required argument is almost always a breaking change.  But, fear not! There's a way out:   type Query { - products(category: String): [Product!]! + products(category: String, sortBy: SortOption!): [Product!]! }   This change is breaking, but it doesn't have to be.  You can provide a default value for the new argument to keep your existing clients happy.  type Query { - products(category: String): [Product!]! + products(category: String, sortBy: SortOption! = POPULARITY): [Product!]! }   See that = POPULARITY? That's your get-out-of-jail-free card. By providing a default value, you've made this addition safe.  Existing clients will use the default, and new clients can take advantage of the sorting option.  ","version":null,"tagName":"h3"},{"title":"The Interface and Union Twist​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 2","url":"/blog/graphql-schema-part-2-1/#the-interface-and-union-twist","content":" Now, let's talk about some trickier additive changes that can catch you off guard if you're not careful.  ","version":null,"tagName":"h3"},{"title":"Adding New Interface Implementations​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 2","url":"/blog/graphql-schema-part-2-1/#adding-new-interface-implementations","content":" Adding a new type that implements an existing interface might seem harmless, but it can cause some unexpected behavior. Check this out:  interface Node { id: ID! } type User implements Node { id: ID! name: String! } type Team implements Node { id: ID! name: String! } type Organization implements Node { id: ID! name: String! employees: [User!]! }   By adding the Organization type, we've expanded what could be returned by queries selecting for Node. This could break clients that aren't prepared to handle new types. Always encourage clients to use proper type checking.  query { node(id: &quot;1&quot;) { ... on User { name } ... on Team { name } ... on Organization { name employees { name } } } }   Without proper type checking, clients might encounter these issues:  Runtime Errors: If a client assumes all Node types have only a name field, they might try to access employees on a User or Team, causing errors.Missing Data: Clients might not display Organization-specific data if they're not prepared to handle it.Incorrect Data Processing: Business logic that assumes only User and Team types exist might produce incorrect results.  To mitigate these issues:  Use TypeScript or Flow on the client-side to catch type errors at compile-time.Implement exhaustive type checking in your client code:  function handleNode(node: Node) { switch (node.__typename) { case &quot;User&quot;: return handleUser(node) case &quot;Team&quot;: return handleTeam(node) case &quot;Organization&quot;: return handleOrganization(node) default: const _exhaustiveCheck: never = node throw new Error(`Unhandled node type: ${(_exhaustiveCheck as any).__typename}`) } }   This approach ensures that if a new type is added in the future, TypeScript will raise a compile-time error, prompting developers to update their code.  ","version":null,"tagName":"h3"},{"title":"The Union Expansion Conundrum​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 2","url":"/blog/graphql-schema-part-2-1/#the-union-expansion-conundrum","content":" Similar to interfaces, adding new members to a union can cause runtime surprises. Consider this:  - union SearchResult = User | Post + union SearchResult = User | Post | Comment   Surprise! Your clients might suddenly receive a type they weren't expecting. It's like opening a box of chocolates and finding a pickle - not necessarily bad, but definitely unexpected. Make sure to document how clients should handle these surprise types.  Let's delve into why union expansions can be tricky and how to handle them gracefully:  When you add Comment to the SearchResult union, existing clients might break in subtle ways:  Incomplete UI: If the client only has UI components for User and Post, Comment results won't be displayed.Runtime Errors: Code that assumes only User and Post types exist might throw errors when encountering a Comment.  To handle this gracefully:  Implement a fallback UI component for unknown types: function SearchResultItem({result}) { switch (result.__typename) { case &quot;User&quot;: return &lt;UserResult user={result} /&gt; case &quot;Post&quot;: return &lt;PostResult post={result} /&gt; case &quot;Comment&quot;: return &lt;CommentResult comment={result} /&gt; default: return &lt;UnknownResultType type={result.__typename} /&gt; } } Encourage clients to use introspection queries to stay updated on schema changes: query { __type(name: &quot;SearchResult&quot;) { kinds possibleTypes { name } } }   By implementing these strategies, clients can gracefully handle new union members without breaking existing functionality.  ","version":null,"tagName":"h3"},{"title":"The Enum Evolution​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 2","url":"/blog/graphql-schema-part-2-1/#the-enum-evolution","content":" Adding new enum values seems innocent enough, but it can impact client-side logic. Let's look at an example:   enum OrderStatus { PENDING COMPLETED + CANCELED + REFUNDED }   Clients that were using exhaustive switches might now have incomplete logic. Encourage clients to use default cases to handle new enum values.  switch (order.status) { case &quot;PENDING&quot;: return &quot;Order is pending&quot; case &quot;COMPLETED&quot;: return &quot;Order is completed&quot; default: return &quot;Order status unknown&quot; }   ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 2","url":"/blog/graphql-schema-part-2-1/#conclusion","content":" Evolving a GraphQL schema through additive changes allows you to expand your API's capabilities while maintaining backward compatibility. By following the principles and strategies outlined in this article, you can confidently add new fields, types, and arguments without causing disruptions to your clients.  Remember these key takeaways:  Favor Additive Changes: Whenever possible, add new fields, types, or arguments instead of modifying existing ones. This approach maintains backward compatibility while allowing your schema to grow. Provide Transition Paths: Introduce new features alongside existing ones to allow gradual client adoption.  By treating your GraphQL schema as a product with its own lifecycle and evolution strategy, you can build APIs that are both powerful and adaptable. This approach allows you to innovate rapidly while providing a stable and reliable service to your clients.  Stay tuned for the next part of this series, where we will dive into removing schema elements and handling breaking changes! ","version":null,"tagName":"h2"},{"title":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 3","type":0,"sectionRef":"#","url":"/blog/graphql-schema-part-2-2/","content":"","keywords":"","version":null},{"title":"What Do You Already Know? 🧠💫​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 3","url":"/blog/graphql-schema-part-2-2/#what-do-you-already-know-","content":" GraphQL Schema Change Quiz! Question 1/5 Changing the default value of an argument is considered a: Safe changeDangerous changeBreaking changeNon-issue  ","version":null,"tagName":"h2"},{"title":"Modifying Without Breaking: Navigating the Modification Minefield​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 3","url":"/blog/graphql-schema-part-2-2/#modifying-without-breaking-navigating-the-modification-minefield","content":" In our previous post, we explored how to make additive changes to your GraphQL schema without causing disruptions. Now, we'll dive into the tricky territory of modifying existing schema elements.  ","version":null,"tagName":"h2"},{"title":"Recap of Additive Changes​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 3","url":"/blog/graphql-schema-part-2-2/#recap-of-additive-changes","content":" In Part 2, we discussed the importance of making additive changes to your GraphQL schema to expand its capabilities while maintaining backward compatibility. By adding new fields, types, and arguments, you can enhance your API without causing disruptions to existing clients. We also emphasized the importance of providing transition paths to ensure a smooth adoption process.  ","version":null,"tagName":"h2"},{"title":"Safe, Dangerous, and Breaking Changes​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 3","url":"/blog/graphql-schema-part-2-2/#safe-dangerous-and-breaking-changes","content":" Safe Changes: Additive changes such as adding new fields or types that do not affect existing queries or functionality.Dangerous Changes: Modifications that might not break the schema immediately but can cause subtle issues, such as changing default values or making non-nullable fields nullable.Breaking Changes: Changes that will definitely break existing queries and require clients to update their code, such as removing fields or changing field types.  ","version":null,"tagName":"h3"},{"title":"The Modification Minefield​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 3","url":"/blog/graphql-schema-part-2-2/#the-modification-minefield","content":" Now, let's talk about modifying existing parts of your schema. This is where things can get really hairy. For example, changing a field’s type or changing the name of a type is a big-breaking change.  ","version":null,"tagName":"h2"},{"title":"The Default Value Dilemma​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 3","url":"/blog/graphql-schema-part-2-2/#the-default-value-dilemma","content":" Changing default values might seem innocent, but it can cause some serious headaches. Consider this:  type Query { - products(category: String, showOutOfStock: Boolean = False): [Product!]! + products(category: String, showOutOfStock: Boolean = True): [Product!]! }   Changing the default value of an argument or input field is unlikely to be a breaking change in terms of the schema itself, but is very likely to cause issues at runtime if the default value affects the runtime behavior of the field.  Avoid this change in general, but it may be possible to achieve if the behavior of the field does not change.  ","version":null,"tagName":"h3"},{"title":"The Non-Null to Null Transformation​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 3","url":"/blog/graphql-schema-part-2-2/#the-non-null-to-null-transformation","content":" This is one of the trickiest changes to make. You thought making a field non-null was a good idea, but now you need to change it back. Here's how to handle it:  For scalar fields, you might be able to save your users from errors by returning the default value instead of null.  For object types, sometimes it’s possible to use a Default Object when the result is null.  This approach can help prevent null pointer exceptions on the client side.  ","version":null,"tagName":"h3"},{"title":"Changing a Field Type​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 3","url":"/blog/graphql-schema-part-2-2/#changing-a-field-type","content":" Changing a field’s type is not a change we can make easily. Once again, approaching the change in an additive is often your best bet.  type User { bestFriend: String! @deprecated(reason: “Use `bestFriendObject` instead.”) + bestFriendObject: User! }   As you might have noticed, the downside of additive changes is that often the best names are already taken. If wanted, you may remove the original field and reintroduce it under the new object at that point.  type User { - bestFriend: String! @deprecated(reason: “Use `bestFriendObject` instead.”) bestFriendObject: User! + bestFriend: User! }   ","version":null,"tagName":"h3"},{"title":"Changing Description or Deprecation​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 3","url":"/blog/graphql-schema-part-2-2/#changing-description-or-deprecation","content":" Changing the description of fields, types and any member is unlikely to cause any harm to clients. Clients should not depend on schema descriptions for runtime logic!  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 3","url":"/blog/graphql-schema-part-2-2/#conclusion","content":" Modifying existing schema elements requires careful planning and execution to avoid breaking changes. By following the principles and strategies outlined in this article, you can confidently make necessary modifications while minimizing disruption to your clients.  Remember these key takeaways:  Deprecate Cautiously: Use deprecation notices, schema descriptions, and out-of-band communication to keep your clients informed about upcoming changes.Provide Transition Paths: When breaking changes are necessary, offer clear migration paths. This might involve introducing new fields alongside deprecated ones or providing new query structures that achieve the same results.Leverage Schema Design Tools: Use schema comparison tools like GraphQL Editor.  By treating your GraphQL schema as a product with its own lifecycle and evolution strategy, you can build APIs that are both powerful and adaptable. This approach allows you to innovate rapidly while providing a stable and reliable service to your clients.  Stay tuned for the next part of this series, where we will dive into removing schema elements and handling breaking changes! ","version":null,"tagName":"h2"},{"title":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 4","type":0,"sectionRef":"#","url":"/blog/graphql-schema-part-2-3/","content":"","keywords":"","version":null},{"title":"What Do You Already Know? 🧠💫​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 4","url":"/blog/graphql-schema-part-2-3/#what-do-you-already-know-","content":" GraphQL Schema Change Quiz! Question 1/6 What is a critical consideration before removing a field from a GraphQL schema? Ensuring the field is no longer in use by any clientsProviding a detailed explanation in the schema documentationImmediately notifying all clients via emailReplacing the field with a temporary placeholder  ","version":null,"tagName":"h2"},{"title":"Removing Without Breaking: The Subtraction Subterfuge​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 4","url":"/blog/graphql-schema-part-2-3/#removing-without-breaking-the-subtraction-subterfuge","content":" In our previous post, we explored how to modify existing schema elements without causing disruptions. Now, we'll tackle the most challenging part: removing schema elements and handling breaking changes.  ","version":null,"tagName":"h2"},{"title":"Recap of Additive Changes and Modifications​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 4","url":"/blog/graphql-schema-part-2-3/#recap-of-additive-changes-and-modifications","content":" In Part 2, we focused on additive changes, emphasizing the importance of expanding your schema's capabilities without disrupting existing clients. By adding new fields, types, and arguments, you can enhance your API while maintaining backward compatibility.  In Part 3, we delved into modifying existing schema elements, discussing how to handle changes such as updating default values, transforming non-null fields to nullable, and changing field types. We highlighted the need for clear communication, providing transition paths, and leveraging schema design tools to minimize client disruptions.  ","version":null,"tagName":"h2"},{"title":"Safe, Dangerous, and Breaking Changes​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 4","url":"/blog/graphql-schema-part-2-3/#safe-dangerous-and-breaking-changes","content":" Safe Changes: Additive changes such as adding new fields or types that do not affect existing queries or functionality.Dangerous Changes: Modifications that might not break the schema immediately but can cause subtle issues, such as changing default values or making non-nullable fields nullable.Breaking Changes: Changes that will definitely break existing queries and require clients to update their code, such as removing fields or changing field types.  ","version":null,"tagName":"h3"},{"title":"The Subtraction Subterfuge​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 4","url":"/blog/graphql-schema-part-2-3/#the-subtraction-subterfuge","content":" Removing things from your schema is almost always a breaking change. If you remove a field, type, or argument, clients that depend on it will break. You can't just take things away without consequences.  But sometimes, it's necessary. Here's how to do it without causing a riot.  ","version":null,"tagName":"h2"},{"title":"The Field Farewell​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 4","url":"/blog/graphql-schema-part-2-3/#the-field-farewell","content":" Let's say we want to remove a field because it's causing performance issues. Here's the smart way to do it:  Introduce a replacementDeprecate the old fieldWait (patiently!)Remove when usage has died down  type Query { - products(first: Int!): [Product!]! + products(first: Int!): [Product!]! @deprecated(reason: “products is deprecated and is getting replaced by the field `topProducts`.”) + topProducts(first: Int!): [Product!]! }   By introducing topProducts and deprecating products, we give our clients time to adapt. And hey, we've even improved our API in the process!  The old field may be removed after a certain period and if the usage for it has gone down. Keep in mind you don’t necessarily have to make the change unless absolutely needed. Additive changes and deprecations are sometimes enough to keep evolving the API.  ","version":null,"tagName":"h3"},{"title":"The Argument Abandonment​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 4","url":"/blog/graphql-schema-part-2-3/#the-argument-abandonment","content":" Removing an argument is similar to removing a field. You can deprecate it and  introduce a new field with the desired behavior. Clients will have time to migrate to the new field before the old one is removed.  type Query { - products(first: Int!, featured: Boolean): String! + products(first: Int!, featured: Boolean): String! @deprecated(reason: “products is deprecated, use `allProducts` for products and `featuredProducts` to get products that are featured”) + allProducts(first: Int!): String! + featuredProducts(first: Int!): String! }   If you need to make a change to an existing field, because arguments can’t be deprecated just yet, you should indicate that the argument is deprecated through its description.  type Query { - products(first: Int!, featured: Boolean): String! + products(first: Int!, + # DEPRECATED: This argument will be removed. Use query `featuredProducts`. + featured: Boolean + ): String! }   ","version":null,"tagName":"h3"},{"title":"The Type Deletion Dilemma​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 4","url":"/blog/graphql-schema-part-2-3/#the-type-deletion-dilemma","content":" Sometimes, you need to remove an entire type from your schema. This is a major operation and requires careful planning.  First, deprecate all fields that return this type:  type Query { oldUser(id: ID!): OldUser @deprecated(reason: &quot;Use `user` query with new User type instead&quot;) user(id: ID!): User }   If the type is part of a union or implements an interface, you'll need to be extra cautious. These can't be easily deprecated, so clear communication is key.Finally, after a long deprecation period and when usage has dropped to zero, you can remove the type entirely.  Note that you might want to deprecate using that type within your codebase to avoid developers to use that User type for new fields. Removing a type is even trickier when it’s part of union types or implements interfaces. Once again, union members and interface implementations cannot be marked as deprecated. This means that fields like node may stop working correctly if the type you’re removing was reachable through that field.  Your best bet in these cases are to either keep this type as part of unions and through interfaces or to communicate that change very carefully through descriptions and out of band communication like documentation and emails.  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 4","url":"/blog/graphql-schema-part-2-3/#conclusion","content":" Removing schema elements is a delicate process that requires strategic planning and clear communication to avoid breaking changes. By following the principles and strategies outlined in this article, you can confidently remove fields, arguments, and types while minimizing disruption to your clients.  Remember these key takeaways:  Deprecate Cautiously: Use deprecation notices, schema descriptions, and out-of-band communication to keep your clients informed about upcoming changes.Provide Transition Paths: When breaking changes are necessary, offer clear migration paths. This might involve introducing new fields alongside deprecated ones or providing new query structures that achieve the same results.Monitor Usage: Keep an eye on usage metrics to determine when it's safe to remove deprecated elements. Don't rush the process – give your clients time to adapt. note Tailcall supports a variety of integrations with monitoring tools to help you track usage metrics and make informed decisions about schema changes. you can check out our documentation for more information.  By treating your GraphQL schema as a product with its own lifecycle and evolution strategy, you can build APIs that are both powerful and adaptable. This approach allows you to innovate rapidly while providing a stable and reliable service to your clients.  Remember, a great GraphQL schema is never truly finished – it's a living, breathing entity that grows and evolves with your application's needs. Embrace this continuous evolution, and you'll create APIs that stand the test of time. ","version":null,"tagName":"h2"},{"title":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","type":0,"sectionRef":"#","url":"/blog/graphql-vs-grpc/","content":"","keywords":"","version":null},{"title":"Introduction​","type":1,"pageTitle":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","url":"/blog/graphql-vs-grpc/#introduction","content":" When it comes to choosing the tech stack for your application, it's never a straightforward task, especially when choosing between gRPC and graphQL - both backed by tech giants. Follow us as we discuss real world scenarios and perform a detailed feature-comparison on both, concluding exactly where each should be used.  ","version":null,"tagName":"h2"},{"title":"The Problem​","type":1,"pageTitle":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","url":"/blog/graphql-vs-grpc/#the-problem","content":" Let’s say you are building a social app like Reddit, and you have screens like home and popular. You implement a simple REST API on the backend and everything looks fine:  it wasn’t so challenging to setuphas tons of resources if anything goes wrongseems like a perfect solution.  Until the user base grows and there’s thousands of users - and disaster strikes: the loading times increase and the costs skyrocket, you begin to lose engagement of the users.  Deep down, the root cause of this problem is the slow nature of REST and over-fetching. What happens is that when a user opens the app, goes to the home screen, and the app fetches tons of unnecessary data from the backend: all pictures of a post, all comments and even related posts! Which is even worsened by the fact that the client has to call multiple endpoints to finally show the feed to the user. You are stuck in performance jargon, let’s rewind it. You use graphQL instead of REST, which has many advantages over the REST:  thanks to its predefined schemas you don’t have to spend hours writing simple validation tests to check that a parameter is a number and not a string.graphQL only serves what the client asks for, which means there’s no chance of over-fetchingnot to mention that one endpoint of graphQL is more useful and comprehensive than 5 REST API routes.  ","version":null,"tagName":"h2"},{"title":"Knowing gRPC​","type":1,"pageTitle":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","url":"/blog/graphql-vs-grpc/#knowing-grpc","content":" So what is behind the magic of gRPC ? Since Google open-sourced it in 2015, gRPC has been revolutionizing service-to-service communication with its robust, schema-driven framework. By harnessing the power of HTTP/2 and Protocol Buffers (Protobuf), gRPC unleashes high-performance, real-time data streaming and rock-solid typing - a winning combo that's made it a go-to tool for developers building scalable, efficient systems. No wonder tech titans like Tesla, Netflix, Coinbase and Dropbox are all on board!  Read more about What is gRPC.    ","version":null,"tagName":"h2"},{"title":"Unleashing GraphQL Magic!​","type":1,"pageTitle":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","url":"/blog/graphql-vs-grpc/#unleashing-graphql-magic","content":" GraphQL, born at Facebook in 2012 and unleashed to the world in 2015, revolutionizes API queries. It’s a powerful and flexible alternative to REST APIs, featuring declarative data fetching that ensures you get just the data you need—no more, no less. With a single endpoint, GraphQL simplifies API structures, eliminating the hassle of managing multiple endpoints. This efficiency and flexibility have made it the darling of tech giants like Github, Meta, Shopify and Microsoft . With GraphQL, you can build more efficient and intuitive APIs that make data fetching a breeze!  Read more about What is GraphQL and How it works?.    ","version":null,"tagName":"h2"},{"title":"Feature Comparison​","type":1,"pageTitle":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","url":"/blog/graphql-vs-grpc/#feature-comparison","content":" Feature\tgRPC\tGraphQLMessage Format\tBinary\tJSON Data Fetching\tFixed endpoints and methods\tFlexible queries, specified by clients Real-Time\tSupports streaming via server-side push\tSupports real-time updates via subscriptions Type Safety\tStrongly typed with Protocol Buffers\tStrongly typed with schema definition Introspection\tNo built-in introspection\tBuilt-in schema introspection Code Generation\tAutomatic code generation from .proto files\tCode generation tools available, but not automatic Tooling and Browser Support\tLimited browser support, requires proxies for web use\tStrong tooling support, works natively in browsers Community\tcurrently nascent\tGrowing rapidly, strong in web and mobile development Adoption\twidely in microservices\tmostly in mobile app development and PWAs Performance\tHigh performance with low latency\tGenerally efficient, schemas defined correctly Debugging and Troubleshooting\tnon-human-readable format, require tools for debugging.\tJSON response is easier to read and debug  ","version":null,"tagName":"h2"},{"title":"Scenarios for Using gRPC​","type":1,"pageTitle":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","url":"/blog/graphql-vs-grpc/#scenarios-for-using-grpc","content":" The ideal scenario for gRPC? When microservices need to communicate at lightning speed and with top-notch efficiency! Think of gRPC as the ultimate express lane for data—perfect when you need swift, reliable interactions and don’t need to be super flexible. It’s like having a fast track for your information, keeping everything running smoothly and quickly!  ","version":null,"tagName":"h2"},{"title":"Scenario 1: A social media app backend​","type":1,"pageTitle":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","url":"/blog/graphql-vs-grpc/#scenario-1-a-social-media-app-backend","content":"   Imagine a social media app where everything works like clockwork. Here’s how gRPC fits in: The Cast:  Media-Scanner: Analyzes media files with precision.Media-Tagger: Tags content accurately.Jobs-Manager: Handles tasks efficiently.Followers-Notifier: Sends timely updates to users.  In this setup, gRPC’s Protocol Buffers ensure fast, efficient communication, cutting down on overhead and latency. Each service gets exactly what it needs, there's no risk of overfetching. It’s a perfect match for microservices, where speed and efficiency are key.  ","version":null,"tagName":"h3"},{"title":"Scenario 2: A movie streaming backend​","type":1,"pageTitle":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","url":"/blog/graphql-vs-grpc/#scenario-2-a-movie-streaming-backend","content":"   Imagine the backend of a movie-streaming app, where Content-Age-Rater, Relations-Builder, Subtitles-Generator, and Subtitles-Translator each have their own star roles. They rate movies, connect related content, create subtitles, and translate them with precision. With gRPC, these services chat efficiently, making sure data zips around quickly and smoothly. No extra baggage—just a slick, high-performance team working seamlessly together. It’s like having a top-notch crew behind the scenes, making sure everything runs smooth! 🎬🍿  ","version":null,"tagName":"h3"},{"title":"Scenarios for Using GraphQL​","type":1,"pageTitle":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","url":"/blog/graphql-vs-grpc/#scenarios-for-using-graphql","content":" GraphQL shines when you need to tailor data fetching to match your frontend's needs precisely. It allows for fetching exactly the data you need, nothing more, nothing less, which can be a game-changer for optimizing performance and reducing over-fetching. This flexibility can really streamline interactions between the frontend and backend, especially in complex applications, as we discuss below:  ","version":null,"tagName":"h2"},{"title":"Scenario 1: Fetching Multiple Items​","type":1,"pageTitle":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","url":"/blog/graphql-vs-grpc/#scenario-1-fetching-multiple-items","content":" GitHub uses GraphQL to make fetching PR details a breeze. With gRPC, you'd have to set up different RPC methods for each data type—comments, commits, changed files—potentially resulting in several requests. Often, you just need the first and last comments right off the bat. GraphQL swoops in, pulling exactly those details with one neat query, cutting down on network strain and speeding things up.  query { repository(owner: &quot;username&quot;, name: &quot;repository-name&quot;) { pullRequest(number: 123) { title createdAt updatedAt author { login avatarUrl } comments(first: 2, orderBy: {field: CREATED_AT, direction: ASC}) { nodes { author { login } body createdAt } } } } }   Instagram uses a smart approach to fetch just a handful of comments on a reel—those that show up right under the title without diving into the full comments section. It’d be a hassle to pull 10 or 20 comments when only 5 are needed. This is where GraphQL shines, perfectly tuned for getting just the right data without any extra fluff.  ","version":null,"tagName":"h3"},{"title":"Scenario 2: Ecommerce App​","type":1,"pageTitle":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","url":"/blog/graphql-vs-grpc/#scenario-2-ecommerce-app","content":"   Think about an ecommerce app with loads of products. On the explore page, users just want a quick snapshot—picture, name, and a brief description. But when they dive into a product page, they’re looking for more details like weight and extra images. With gRPC, you’d need separate calls for each view, which can be a bit clunky and might pull in extra data. GraphQL, on the other hand, lets you customize your queries to get just what you need for each page, cutting down on excess data and making everything run smoother:  query { products { id name shortDescription imageUrl } }   For the product details page:  query { product(id: &quot;product-id&quot;) { id name description weight images { url } } }   This approach makes data retrieval a breeze and keeps performance top-notch, highlighting why GraphQL shines in dynamic content and ecommerce apps over gRPC. It’s all about getting exactly what you need, when you need it, and keeping things running smoothly!  ","version":null,"tagName":"h3"},{"title":"Integrating gRPC and GraphQL​","type":1,"pageTitle":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","url":"/blog/graphql-vs-grpc/#integrating-grpc-and-graphql","content":"   Picture a social media app where the backend whips up user feeds based on activity. The frontend needs different data for various screens—blogs or videos—so grabbing everything at once would be overkill. GraphQL steps in to save the day by letting the frontend fetch just what it needs, keeping things snappy and efficient.  Meanwhile, backend services like feed-generator and logs-handler are busy creating and analyzing feeds. They require steady input and don’t need much tweaking once live. For this, gRPC is perfect with its lightning-fast performance and low latency.  By mixing GraphQL on the frontend with gRPC on the backend, you get a dynamic, high-performance setup. GraphQL fine-tunes data requests while gRPC keeps backend communication smooth.  Read this guide explaining the challenges and details associated with integrating gRPC and graphQL: Building GraphQL over gRPC .  ","version":null,"tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"GraphQL vs gRPC: Which is Better? Uncover the Best Choice!","url":"/blog/graphql-vs-grpc/#conclusion","content":" In summary, both gRPC and graphQL have numerous advantages over each other, where gRPC has:  more boosted performanceLow payload sizesSimple and intuitive API design  On the other hand GraphQL takes the lead in:  API flexibilityFriendly nature for web and mobile appsEasier debugging  It doesn’t matter which one is better, what truly matters is how good it is implemented, and how well it suits the use case. Remember - as Doug LInder likes to say -  “A good programmer is someone who always looks both ways before crossing a one-way street”  this simple concept can elevate you to the top tier of programmers. ","version":null,"tagName":"h2"},{"title":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","type":0,"sectionRef":"#","url":"/blog/graphql-vs-openapi-part-3/","content":"","keywords":"","version":null},{"title":"Integration and Compatibility​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#integration-and-compatibility","content":" ","version":null,"tagName":"h2"},{"title":"Integrating with Existing Systems​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#integrating-with-existing-systems","content":" Integration capabilities are crucial for adopting new API specifications without disrupting existing systems.  Compatibility with Legacy Systems​  GraphQL: Integration Challenges: Integrating GraphQL with legacy systems may require significant changes, especially in how data is fetched and aggregated.Gateway Solutions: Using GraphQL gateways or proxies can help bridge the gap, allowing gradual migration without overhauling the entire system. OpenAPI: Seamless Integration: OpenAPI’s RESTful approach aligns well with existing systems, making it easier to integrate without major modifications.Backward Compatibility: The structured nature of OpenAPI allows for maintaining backward compatibility with legacy systems.  ","version":null,"tagName":"h3"},{"title":"Future-Proofing Your API Strategy​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#future-proofing-your-api-strategy","content":" Ensuring your API remains adaptable to emerging technologies and trends is crucial for maintaining its relevance and efficiency in the long term.  Adapting to Emerging Tech Trends​  GraphQL: Flexibility and Evolution: GraphQL’s flexibility and its ability to handle complex queries make it an excellent choice for modern applications, microservices, and evolving business requirements. Its schema-first approach allows for rapid iterations and modifications without breaking existing functionalities, making it future-proof as your business needs change.Real-Time Capabilities: GraphQL's subscription feature is designed for real-time applications, enabling a steady connection between the client and server. This is essential for applications that require real-time updates, such as live sports scores, stock trading, or social media feeds. For example, a live-updating stock trading application can use GraphQL subscriptions to push stock price updates to the client: subscription { stockPriceUpdate(symbol: &quot;AAPL&quot;) { price change lastUpdated } } This setup is more efficient than repeatedly polling an endpoint, as it reduces unnecessary network traffic and server load. Combining subscriptions with queries and mutations allows for a seamless user experience, integrating real-time data updates with other operations within the same endpoint. OpenAPI: Standardization and Stability: OpenAPI’s adherence to REST principles and its standardized approach ensure long-term stability and interoperability. This makes it a reliable choice for enterprises looking to maintain consistency and clarity in their API documentation and interactions. Adoption of New Features: OpenAPI continuously evolves with regular updates to its specification. These updates incorporate enhancements that align with industry best practices, such as improved support for asynchronous APIs, better integration with modern security protocols, and more detailed documentation capabilities. By keeping up with these updates, you can ensure your API remains up-to-date with the latest technological advancements. Example: An enterprise financial services provider can use OpenAPI to ensure their API remains compliant with evolving regulatory standards and security requirements. By utilizing OpenAPI’s robust validation features, they can enforce strict data schemas and authentication mechanisms, ensuring secure and reliable data exchanges across systems.  ","version":null,"tagName":"h3"},{"title":"Industry Adoption and Case Studies​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#industry-adoption-and-case-studies","content":" ","version":null,"tagName":"h2"},{"title":"Industry Leaders and Their Choices​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#industry-leaders-and-their-choices","content":" Examining the choices of industry leaders provides valuable insights into the practical applications of GraphQL and OpenAPI.  Examples from Tech Giants​  GraphQL: Facebook: The creator and primary user of GraphQL, leveraging its flexibility to power complex, real-time data interactions.GitHub: Adopted GraphQL to provide a more efficient and flexible API for developers.Shopify: Uses GraphQL to handle complex e-commerce data queries and real-time updates. OpenAPI: Microsoft: Utilizes OpenAPI for its Azure services, providing clear and standardized API definitions.IBM: Implements OpenAPI for its cloud services, ensuring robust and reliable API interactions.Google: Adopts OpenAPI for its various APIs, emphasizing clear documentation and ease of use.  ","version":null,"tagName":"h3"},{"title":"Real-World Case Studies​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#real-world-case-studies","content":" Exploring real-world case studies illustrates the practical benefits and challenges of using GraphQL and OpenAPI.  Success Stories and Lessons Learned​  GraphQL: Case Study 1: LinkedIn transitioned from its homegrown Deco library to GraphQL to improve data fetching efficiency and developer experience. The company faced challenges with Deco's schema-less nature, which led to production issues and a poor developer experience. GraphQL offered a more standardized approach, Read more here.Case Study 2: At Shopify, GraphQL has been utilized to overcome the limitations of REST APIs in mobile application development. Unlike REST, GraphQL provides a strongly typed, self-documented contract between clients and servers, eliminating the need for manual type casting and JSON mapping. More details on Shopify's Blog. OpenAPI: Case Study 1: A Spanish banking giant utilized OpenAPI to build an open-source security product. By standardizing their API documentation and using OpenAPI's robust validation features, they enhanced security and compliance across their digital services. For more information, visit their website.Case Study 2: A global agricultural solutions provider accelerated the development of their digital hub using OpenAPI. The clear structure and validation provided by OpenAPI ensured reliable data exchange and integration across their systems, streamlining operations and improving service delivery. See their implementation on their website.  These case studies illustrate how companies from various industries have successfully implemented GraphQL and OpenAPI to enhance their operations, streamline development processes, and improve overall efficiency.  ","version":null,"tagName":"h3"},{"title":"Migration Guide​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#migration-guide","content":" ","version":null,"tagName":"h2"},{"title":"Transitioning from REST to GraphQL using Tailcall​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#transitioning-from-rest-to-graphql-using-tailcall","content":" Migrating from a RESTful API to GraphQL can significantly enhance your application's performance and flexibility. Tailcall offers a streamlined approach to manage this transition effectively.  Read More:  Tailcall's GraphQL Getting StartedTailcall's Config Generator  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#conclusion","content":" In this third part of our series, we've examined the security features, tooling support, and future prospects of GraphQL and OpenAPI. We've seen how each specification handles security, the variety of tools available to support their implementation, and their potential for future growth and adaptation.  ","version":null,"tagName":"h2"},{"title":"Final Thoughts on Choosing Between GraphQL and OpenAPI​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#final-thoughts-on-choosing-between-graphql-and-openapi","content":" After following this 3 part Series selecting the appropriate API specification for your project is crucial and should be based on a thorough evaluation of your specific needs, constraints, and long-term objectives. Here are some final considerations to guide your decision:  Project Requirements: Assess the complexity of your data retrieval needs. If your application requires complex, nested queries or real-time updates, GraphQL might be more suitable.For standardized operations with well-defined endpoints, OpenAPI offers a more straightforward and reliable approach. Development Resources: Consider the expertise of your development team. If they are more familiar with RESTful principles, OpenAPI can be easier to adopt. Conversely, if your team is open to learning and working with flexible query languages, GraphQL provides significant advantages. Performance and Scalability: Evaluate the performance requirements and scalability challenges of your application. GraphQL's efficient data fetching can reduce response times, but optimizing complex queries may require additional effort. OpenAPI's structured endpoints may be easier to scale in high-traffic scenarios. Security Considerations: Determine the security requirements of your API. OpenAPI's built-in mechanisms offer robust security options out of the box. GraphQL requires a more hands-on approach to ensure secure data access and mitigate potential risks. Long-term Goals: Think about the future direction of your API strategy. GraphQL's flexibility makes it well-suited for evolving and modern applications, particularly in microservices architectures. OpenAPI's standardization ensures long-term stability and compliance with industry standards.  By carefully weighing these factors, you can make an informed decision that aligns with your project's unique needs and goals, ultimately leading to a more successful and efficient API implementation.  The future of APIs is looking bright! With GraphQL pushing the boundaries of flexibility and OpenAPI continually evolving, we're in for some exciting developments. Whether you need the dynamic, precise data fetching capabilities of GraphQL or the structured, standardized approach of OpenAPI, both tools have their unique strengths and can significantly enhance your API development process.  GraphQL is like a Swiss Army knife for your API needs, offering unmatched flexibility and efficiency, especially when dealing with complex, interconnected data. On the other hand, OpenAPI provides a well-organized and robust framework, perfect for creating clear, consistent, and scalable APIs.  In the end, the choice between GraphQL and OpenAPI often comes down to your specific project requirements and team preferences. By understanding the strengths and potential challenges of each, you can make an informed decision that will best serve your development goals.  So, which one will you choose for your next project? Whatever your choice, happy coding!  ","version":null,"tagName":"h3"},{"title":"FAQs​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#faqs","content":" ","version":null,"tagName":"h2"},{"title":"1. What are the cost implications of adopting GraphQL vs OpenAPI?​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#1-what-are-the-cost-implications-of-adopting-graphql-vs-openapi","content":" GraphQL: Initial setup and training can be costly, but it improves development efficiency and can lower long-term operational costs.  Tailcall offers a cost-effective solution for migrating to GraphQL.  OpenAPI: Easier and cheaper to adopt initially due to familiarity and extensive tooling, with reduced maintenance costs through auto-generated documentation.  ","version":null,"tagName":"h3"},{"title":"2. How do GraphQL and OpenAPI handle versioning and API changes?​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#2-how-do-graphql-and-openapi-handle-versioning-and-api-changes","content":" GraphQL: Encourages backward-compatible changes and schema evolution, with clear documentation for deprecated fields.  OpenAPI: Supports versioning through URL paths or query parameters, making it easy to manage and document changes while maintaining backward compatibility.  ","version":null,"tagName":"h3"},{"title":"3. What are the main challenges in implementing GraphQL vs OpenAPI?​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#3-what-are-the-main-challenges-in-implementing-graphql-vs-openapi","content":" GraphQL: Complexity in queries, steep learning curve, and choosing the right tools can be challenging.  OpenAPI: Managing over-fetching/under-fetching, handling multiple API versions, and maintaining up-to-date documentation can be labor-intensive.  ","version":null,"tagName":"h3"},{"title":"4. How do GraphQL and OpenAPI impact frontend development workflows?​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 3 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-3/#4-how-do-graphql-and-openapi-impact-frontend-development-workflows","content":" GraphQL: Simplifies data fetching, state management, and supports real-time updates through a single endpoint.  OpenAPI: Provides predictable endpoints, auto-generated client SDKs, and leverages standard REST practices for easier frontend development. ","version":null,"tagName":"h3"},{"title":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","type":0,"sectionRef":"#","url":"/blog/graphql-vs-openapi-part-2/","content":"","keywords":"","version":null},{"title":"Practical Application Scenarios​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-2/#practical-application-scenarios","content":" ","version":null,"tagName":"h2"},{"title":"Real-World Use Cases for GraphQL and OpenAPI​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-2/#real-world-use-cases-for-graphql-and-openapi","content":" Understanding the practical applications of GraphQL and OpenAPI is crucial for selecting the right tool for your API development needs. Let's explore some real-world scenarios where each excels.  ","version":null,"tagName":"h3"},{"title":"GraphQL: Ideal for Complex, Real-Time Data Requirements​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-2/#graphql-ideal-for-complex-real-time-data-requirements","content":" E-Commerce Platforms:  GraphQL is particularly well-suited for e-commerce platforms where the client needs to fetch various data types in a single request. For example, displaying product details, user reviews, and related items on a single page can be efficiently managed with GraphQL. The ability to request only the required data fields reduces the payload size and enhances performance.  Social Media Applications:  Social media platforms benefit from GraphQL's real-time data capabilities. Features like live updates on posts, comments, and user activities can be seamlessly integrated using GraphQL subscriptions. This ensures that users always see the most up-to-date information without the need for constant page refreshes.  Custom Dashboards:  For applications that require dynamic and customizable dashboards, GraphQL offers the flexibility to fetch specific data points needed by the user. This reduces the complexity of managing multiple endpoints and allows for more efficient data retrieval.  Example:  query { product(id: &quot;123&quot;) { name price reviews { rating comment } relatedProducts { id name } } }   ","version":null,"tagName":"h3"},{"title":"OpenAPI: Best for Standardized, Well-Defined Services​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-2/#openapi-best-for-standardized-well-defined-services","content":" Financial Services:  In the financial sector, regulatory compliance and security are paramount. OpenAPI supports various authentication methods such as OAuth2, API keys, and mutual TLS, which are essential for secure API development. Detailed schema definitions in OpenAPI facilitate clear documentation and consistent implementation, which are crucial for maintaining compliance with financial regulations.  Healthcare Applications:  Healthcare systems benefit from OpenAPI's ability to clearly define and validate data structures, ensuring reliable data exchange between different systems. This is crucial for maintaining data integrity and complying with healthcare regulations.  Example:  openapi: 3.0.0 info: title: Healthcare API version: 1.0.0 paths: /patients/{id}: get: summary: Get patient details parameters: - name: id in: path required: true schema: type: string responses: &quot;200&quot;: description: A patient object content: application/json: schema: $ref: &quot;#/components/schemas/Patient&quot; components: schemas: Patient: type: object properties: id: type: string name: type: string age: type: integer medicalHistory: type: array items: type: string   By understanding the strengths and practical applications of GraphQL and OpenAPI, developers can make informed decisions that align with their project's specific needs. GraphQL excels in scenarios requiring real-time updates and flexible data retrieval, while OpenAPI shines in environments where standardization, security, and extensive documentation are crucial.  ","version":null,"tagName":"h3"},{"title":"Performance and Scalability​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-2/#performance-and-scalability","content":" ","version":null,"tagName":"h2"},{"title":"Performance Considerations​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-2/#performance-considerations","content":" Response Time and Data Fetching Efficiency​  Let's dive deeper into the performance implications of GraphQL vs OpenAPI.  With GraphQL, the ability to request only needed fields can significantly reduce payload sizes. For example, if you're building a mobile app that displays a list of products, you might only need the product name, price, and thumbnail image. In a REST API, you might get all product details including lengthy descriptions, inventory data, etc. This extra data increases the payload size and parsing time on mobile devices.  Here's a concrete example:  REST API response (over-fetching):  { &quot;id&quot;: 1, &quot;name&quot;: &quot;Smartphone X&quot;, &quot;price&quot;: 999.99, &quot;description&quot;: &quot;A very long description...&quot;, &quot;inventory&quot;: 500, &quot;categoryId&quot;: 5, &quot;brandId&quot;: 3, &quot;specs&quot;: { ... }, &quot;reviews&quot;: [ ... ], &quot;relatedProducts&quot;: [ ... ] }   GraphQL query and response (precise data):  query { product(id: 1) { name price thumbnailUrl } }   { &quot;data&quot;: { &quot;product&quot;: { &quot;name&quot;: &quot;Smartphone X&quot;, &quot;price&quot;: 999.99, &quot;thumbnailUrl&quot;: &quot;https://example.com/thumb.jpg&quot; } } }   The GraphQL response is much smaller, leading to faster load times, especially on slower networks.  However, it's not all roses for GraphQL. Complex queries can put a heavier load on your database. For instance, a deeply nested query fetching users, their posts, comments on those posts, and information about the comment authors could result in multiple joins or separate database queries. This is where techniques like DataLoader (for batching and caching) become crucial in GraphQL implementations.  On the OpenAPI side, while over-fetching can be an issue, it also allows for easier caching at the network level (CDNs, reverse proxies) because the responses for a given URL are consistent. Additionally, for simple CRUD operations, the RESTful approach can be more straightforward to implement and may perform better out of the box.  ","version":null,"tagName":"h3"},{"title":"Scalability Challenges​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-2/#scalability-challenges","content":" Handling High Traffic and Data Complexity​  GraphQL's flexibility is both a blessing and a curse. While it allows for precise data retrieval, it can lead to complex queries that are tough to optimize. Think of it like asking for a custom sandwich with 20 specific ingredients at a busy deli – it can bog down the line. On the other hand, OpenAPI's structured endpoints are more like standard menu items – easier to prepare and scale but might require more trips to get everything you want.  ","version":null,"tagName":"h3"},{"title":"Security Implications​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-2/#security-implications","content":" ","version":null,"tagName":"h2"},{"title":"Security Challenges in GraphQL​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-2/#security-challenges-in-graphql","content":" GraphQL, with its dynamic nature, brings unique security challenges and opportunities for enhancement. Let's explore these and see how to keep our APIs safe.  Challenges and Mitigation Strategies​  Exposure of Sensitive Data: GraphQL's power can also be its Achilles' heel if sensitive data isn't properly protected. Field-Level Authorization: Just like a VIP section in a club, only certain users should have access to specific data fields. Implement fine-grained access controls based on user roles and permissions.Schema Introspection Control: Imagine giving a burglar a map of your house. To prevent attackers from discovering your schema, restrict or disable introspection in production environments. Read more about securing GraphQL APIs. Query Complexity and Abuse: GraphQL queries can become deeply nested, leading to performance issues and potential denial-of-service attacks. It's like a never-ending story that overloads your server. Query Complexity Analysis: Use tools to analyze and limit query complexity, ensuring they don't overload the server. Think of it as having a bouncer who stops overly complicated orders.Rate Limiting: Implement rate limiting to control the number of queries a client can execute within a given timeframe. It's like having a doorman who ensures not too many guests enter at once. Injection Attacks: GraphQL is vulnerable to injection attacks if inputs aren't properly sanitized. Input Validation and Sanitization: Always validate and sanitize all user inputs to prevent injection attacks. It's akin to screening all guests before letting them into the party.Use of Parameterized Queries: Where applicable, use parameterized queries to avoid injection vulnerabilities. This ensures the data is handled safely and securely.  ","version":null,"tagName":"h3"},{"title":"Security Features in OpenAPI​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-2/#security-features-in-openapi","content":" OpenAPI comes with a range of built-in mechanisms to bolster security. Let's dive into these robust features.  Built-in Mechanisms and Enhancements​  Authentication and Authorization: OpenAPI supports various authentication methods out of the box, ensuring secure access to your APIs. OAuth2: A robust and flexible framework for authentication and authorization, akin to having a secure, multi-factor locked door.API Keys: Simple and effective for identifying and authenticating API consumers. Think of it as a personal access card.Basic and Bearer Auth: Standard methods for securing API endpoints, much like having a key to a specific room. Data Validation: OpenAPI uses JSON Schema for defining request and response structures, ensuring data integrity. Schema Validation: All incoming and outgoing data adheres to predefined schemas, reducing the risk of malformed requests and responses. It's like having a quality control check before anything leaves the factory. Security Definitions and Requirements: OpenAPI allows you to define security requirements at both global and individual operation levels, ensuring consistent enforcement of security policies across your API.  ","version":null,"tagName":"h3"},{"title":"Developer Experience​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-2/#developer-experience","content":" ","version":null,"tagName":"h2"},{"title":"Learning Curve and Accessibility​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-2/#learning-curve-and-accessibility","content":" The developer experience difference between GraphQL and OpenAPI goes beyond just the initial learning curve. Let's break this down:  GraphQL:  Learning Curve: While GraphQL concepts like schemas, resolvers, and the query language itself take time to master, tools like GraphiQL provide an interactive playground that significantly eases the learning process. Developers can explore the API, auto-complete queries, and see instant results. Tailcall offers a cost-effective solution for migrating to GraphQL. Which easily integrates with your existing REST/gRPC APIs and provides a seamless transition to GraphQL, smoothing the learning curve for developers. Tooling: The GraphQL ecosystem has evolved rapidly. Tools like Apollo Client not only help with querying but also provide powerful caching mechanisms, state management, and optimistic UI updates. Here's a quick example of how Apollo Client simplifies data fetching in React: const GET_USER = gql` query GetUser($id: ID!) { user(id: $id) { name email } } ` function UserProfile({userId}) { const {loading, error, data} = useQuery(GET_USER, { variables: {id: userId}, }) if (loading) return &lt;p&gt;Loading...&lt;/p&gt; if (error) return &lt;p&gt;Error :(&lt;/p&gt; return &lt;h1&gt;{data.user.name}&lt;/h1&gt; }   This declarative approach to data fetching can significantly simplify frontend code.  Type Safety: GraphQL's strong typing, when combined with tools like TypeScript, can provide end-to-end type safety from your API to your frontend code, catching errors at compile time.  OpenAPI:  Familiarity: For developers already versed in REST principles, OpenAPI feels like a natural extension. Its structure mirrors typical REST endpoints, making it easier to adopt in existing projects. Code Generation: One of OpenAPI's strengths is the ability to generate both server and client code. For example, using a tool like Swagger Codegen, you can generate a fully functional API client in multiple languages from your OpenAPI spec. This can dramatically speed up development and reduce inconsistencies between API documentation and implementation. Standardization: OpenAPI's widespread adoption means that many cloud platforms and API gateways natively support OpenAPI specifications. For instance, Azure API Management can import an OpenAPI spec and automatically set up routing, request validation, and even mock responses for testing.  In practice, the choice often comes down to the specific needs of your project and team. GraphQL shines in scenarios with complex, interconnected data and when you need a flexible, powerful query language. OpenAPI excels in scenarios where you need a clear, standards-based approach, especially when working with external partners or in highly regulated environments.  Comparing the Ease of Adoption​  GraphQL: Flexibility and Complexity: GraphQL’s flexibility in querying data can be initially overwhelming for developers accustomed to REST. Learning to structure queries, manage resolvers, and handle errors can take time.Resources: Extensive resources, tutorials, and documentation are available, but hands-on experience is crucial for mastering GraphQL. OpenAPI: Structured and Predictable: OpenAPI’s structured approach is familiar to developers experienced with REST APIs. The clear definition of endpoints, methods, and data models makes it easier to understand and implement.Tooling: The extensive tooling and auto-generation capabilities for documentation and client SDKs streamline the development process.  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 2 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-2/#conclusion","content":" Having explored the performance and flexibility of GraphQL and OpenAPI, you now have a clearer understanding of their strengths and limitations in different scenarios. GraphQL shines in situations requiring complex, real-time data interactions, while OpenAPI excels in environments where standardization and extensive documentation are paramount. In the next installment, Part 3, we will delve into the security aspects, tooling support, and future prospects of GraphQL and OpenAPI, providing a comprehensive overview of how they integrate with existing systems and their compatibility with various development tools. ","version":null,"tagName":"h2"},{"title":"GraphQL vs REST vs gRPC - an unfair comparison","type":0,"sectionRef":"#","url":"/blog/graphql-vs-rest-vs-grpc/","content":"Since its inception, GraphQL has steadily gained popularity, often finding itself at the center of comparisons with other data query and manipulation languages such as REST and gRPC. The internet is replete with articles debating the merits and demerits of each, with some even questioning the viability of GraphQL. However, this discourse misses a crucial point: the unique strengths of GraphQL. This article aims to illuminate the distinct advantages GraphQL offers, particularly in addressing a common but complex challenge known as impedance mismatch. Impedance mismatch refers to the discordance between the capabilities of an existing API and the ideal features required for a specific use case. From the perspective of a platform engineer, the goal is to develop APIs that cater to a broad range of needs. Yet, crafting a unique API for every conceivable requirement is neither practical nor efficient. Consequently, engineers often end up creating generalized APIs. However, as a consumer, you might find these APIs lacking in some respects while being superfluous in others. Furthermore, as your needs evolve, so does your notion of the ideal API, exacerbating this mismatch. Herein lies the brilliance of GraphQL: it offers a framework for structuring data exposure and queries that significantly mitigates this issue. The GraphQL specification introduces the concept of viewing data as a graph composed of nodes, which represent domain entities for a business, interconnected by relationships that define their interactions. For instance, in the development of a social network, a user entity might have the ability to create a post, which in turn could receive comments, illustrating the interconnected nature of data entities. With the data conceptualized as a graph, GraphQL advocates for a method of querying that allows for precise data retrieval. This selective querying capability enables developers to request exactly the data they need, distinguishing GraphQL from REST and gRPC which aren't truly a &quot;queryable&quot;. The precision of GraphQL extends to the granularity of specifying individual fields within entities, facilitating extremely efficient and targeted queries. Notably, the GraphQL specification does not prescribe any specific data storage methodologies but focuses on the manner in which data is queried, hence the designation &quot;Graph Query Language.&quot; This approach allows for queries tailored to specific requirements, such as obtaining posts by the current user along with comments on those posts. By enabling precise data queries, GraphQL helps in avoiding the inefficiencies associated with over-fetching or under-fetching data, thereby enhancing overall system performance. The impedance mismatch is not solely a technical issue pertaining to the differences in API schemas. It extends into the realm of development processes as well. GraphQL significantly ameliorates this aspect by allowing the consumers of an API to begin their work even before the actual API is fully implemented. This is made possible through the agreement on a schema upfront. By decoupling the dependency between the consumer and the provider of the API, GraphQL facilitates a more efficient and flexible development process. Comparing GraphQL with REST or gRPC on this front might not do justice to their distinct objectives. REST and gRPC are primarily designed as lightweight RPC protocols, not specifically to address impedance mismatch for which a full fledged query language is more suitable. A more apt comparison would be with OpenAPI, which also allows for API composition. However, OpenAPI's capabilities in fine-tuning what an API delivers are somewhat constrained compared to GraphQL's flexible querying capabilities. Beyond the technical resolution of impedance mismatch, GraphQL addresses a critical business problem: the inefficiency in software development that arises from this gap between actual and ideal APIs. This inefficiency leads to developers spending excessive time on API orchestration—time that could be better spent on core application development. They find themselves constantly writing, revising, and optimizing APIs and their orchestration, as well as managing the fallout from breaking changes. By leveraging GraphQL, developers can significantly reduce these frictions, streamlining the development process and enhancing productivity. In essence, GraphQL not only solves a technical problem but also delivers substantial business value by enabling more efficient and flexible software development practices. GraphQL offers an excellent developer experience for API consumption with its intuitive query language that allows for retrieving deeply nested data independently of the upstream source. However, it does have some limitations. At Tailcall, we are dedicated to making GraphQL more accessible and easier to work with. If you like what you just read, please do subscribe and share on twitter and linkedin 🙏","keywords":"","version":null},{"title":"No one talks about API Orchestration","type":0,"sectionRef":"#","url":"/blog/no-one-talks-about-api-orchestration/","content":"","keywords":"","version":null},{"title":"Microservice​","type":1,"pageTitle":"No one talks about API Orchestration","url":"/blog/no-one-talks-about-api-orchestration/#microservice","content":" Microservices architecture is a design pattern in which a large application is built as a suite of modular services, each of which runs its process and communicates with other services through well-defined interfaces, typically using a lightweight messaging protocol. This approach has several benefits over a monolithic architecture, including improved scalability, resilience, and maintainability. In a microservices architecture, each service has a specific role and is independently deployable, so developers can work on different services in parallel and deploy them independently of each other. This can make the development process more agile and allow for faster deployment of new features.    An API gateway is a server that acts as a single point of entry for certain types of requests. It can receive requests from the client, route them to the appropriate backend service, and then return the response from the backend service to the client. An API gateway can also perform tasks such as authentication, rate limiting, and caching. This makes it a useful component in a microservices architecture, where each service has its API and the API gateway acts as the &quot;front door&quot; for clients to access the services.  ","version":null,"tagName":"h2"},{"title":"API Composition​","type":1,"pageTitle":"No one talks about API Orchestration","url":"/blog/no-one-talks-about-api-orchestration/#api-composition","content":" API composition refers to the process of combining multiple APIs to create a new API or a new functionality. This can be done by sending requests to multiple APIs and combining the results, or by creating a new API that acts as a façade for the underlying APIs.  💡 API Composition is also known as API Orchestration. This is however vastly different from Microservice Orchestration.  For example, consider a scenario where a client application wants to display a user's profile information and recent posts on a social media platform. In this case, the client can send two separate requests to two different APIs: one to retrieve the user's profile information, and another to retrieve their recent posts. The client can then combine the results from these two APIs to create a single response that contains all the required information. This new response can be considered as the output of the composed API.  To build a rich user interface, API composition is necessary on the client side. One of the main challenges with API composition on the client side is that it can lead to increased complexity in the client application. This is because the client needs to handle the process of sending requests to multiple APIs and combining the results, which can add to the overall size and complexity of the client code.  Another challenge with API composition on the client side is that it can result in reduced performance and increased latency. This is because the client needs to make multiple separate requests to different APIs, which can take more time and result in a slower response from the composed API.  In addition, API composition on the client side can also lead to increased security risks. This is because the client needs to handle sensitive information, such as API keys and authentication credentials, which can be vulnerable to attacks if not properly secured. The client doesn't have access to powerful CPUs or a reliable network either. This makes the composition problem even more challenging to implement and manage. It is therefore often more efficient and effective to perform API composition on the server side instead.  ","version":null,"tagName":"h2"},{"title":"Backend For Frontend​","type":1,"pageTitle":"No one talks about API Orchestration","url":"/blog/no-one-talks-about-api-orchestration/#backend-for-frontend","content":" A BFF layer can help to solve the challenges of API composition by providing a separate backend service that is optimized for each specific frontend client. This can enable the BFF to perform API composition on behalf of the client, which can help to improve the performance and reliability of the composed API. The BFF layer typically sits as a separate component in the overall architecture, between the frontend client and the microservices. It can communicate with both the frontend client and the microservices using well-defined interfaces and protocols, such as REST or gRPC.  The BFF can take advantage of a powerful CPU and access to a fast network to improve the performance and reliability of the composed API. It can also provide added flexibility and control over the composition process. This can make it a useful tool for developers who want to create new APIs by combining the functionality of multiple underlying APIs.    BFFs truly solve the problems mentioned above to a great extent, however they introduce new set of challenges viz.  ","version":null,"tagName":"h2"},{"title":"Highly Specialized​","type":1,"pageTitle":"No one talks about API Orchestration","url":"/blog/no-one-talks-about-api-orchestration/#highly-specialized","content":" One of the challenges with using a BFF layer is that it is a highly specialized solution that requires a significant amount of hand-written code. Unlike an API gateway, there is no standard BFF solution that can be deployed out-of-the-box, and each BFF implementation must be custom-tailored to the specific requirements of the frontend client. This lack of standardization and reusability can make the BFF solution more complex and difficult to maintain.  ","version":null,"tagName":"h3"},{"title":"Fragile​","type":1,"pageTitle":"No one talks about API Orchestration","url":"/blog/no-one-talks-about-api-orchestration/#fragile","content":" Another challenge with using a BFF layer is that it can be fragile and susceptible to failure. The BFF solution is dependent on the developers to follow best practices and handle all error scenarios, and if these steps are not taken, the solution can be prone to bugs and performance issues. Additionally, the BFF solution must be thoroughly tested, including performance testing, unit testing, and integration testing, to ensure that it is reliable and performs well in production. This can require significant effort and expertise, and if these steps are not properly followed, the BFF solution can be fragile and prone to failure. Also, it's worth mentioning that a BFF layer is an entry point to all your backend, it going down basically means nothing is accessible for the user so this layer needs to be robust and resilient to exceptions.  ","version":null,"tagName":"h3"},{"title":"Performance​","type":1,"pageTitle":"No one talks about API Orchestration","url":"/blog/no-one-talks-about-api-orchestration/#performance","content":" Because BFF layers are typically custom-written for each use case, it can be difficult to predict the performance impact of a small code change. Issues such as unoptimized algorithms, inefficient caching, and unnecessary downstream requests can go unnoticed and only be discovered very late in the development cycle. Typically companies perform thorough benchmarking and load testing before anything goes live. This results in a very high time to market even for minor changes.  ","version":null,"tagName":"h3"},{"title":"Monolith​","type":1,"pageTitle":"No one talks about API Orchestration","url":"/blog/no-one-talks-about-api-orchestration/#monolith","content":" Eventually, this layer turns out to be a big monolith touching every service in your backend. The layer contains a lot of handwritten spaghetti code that's hard to maintain. Onboarding new engineers also becomes harder and upgrading libraries or architecture gets costlier. Any tiny change requires a full-fledged deployment on your infrastructure.  ","version":null,"tagName":"h3"},{"title":"Canary Support (or lack thereof)​","type":1,"pageTitle":"No one talks about API Orchestration","url":"/blog/no-one-talks-about-api-orchestration/#canary-support-or-lack-thereof","content":" Every change that happens in the backend requires the deployment of the BFF layer. In fact, any feature that is built on the client also requires changes on the BFF layer. Such frequent changes can not be exposed to 100% of users because the reliability and performance of this system are unknown. A common way to solve this problem is to use blue-green deployments. This requires additional infrastructure and complex routing mechanisms. First-class support to do canary releases is very important and should be part of a modern BFF layer, however, most companies rely on DevOps for its support.  ","version":null,"tagName":"h3"},{"title":"Coupled Release​","type":1,"pageTitle":"No one talks about API Orchestration","url":"/blog/no-one-talks-about-api-orchestration/#coupled-release","content":" BFF layers can't be deployed independently since they act as a bridge between the clients and the services. Generally, the services need to go live first, and they need to make sure that the change is compatible with the current version of the BFF layer running in production. The interesting problem is in case there is a bug in the microservice and it needs to be reverted, even the BFF layer needs to be reverted. This kind of coupling makes it operationally very expensive to manage.  ","version":null,"tagName":"h3"},{"title":"Organizational Friction​","type":1,"pageTitle":"No one talks about API Orchestration","url":"/blog/no-one-talks-about-api-orchestration/#organizational-friction","content":" The Backends for Frontends (BFF) pattern is designed to create a tailor-made backend service for each user interface (e.g., desktop, mobile, etc.), with the aim of simplifying the client-side and improving the user experience.  However, in practice, this architecture sometimes creates friction within the organization, particularly when BFFs are developed and maintained by the backend team. Here are a few reasons why:  Communication and Responsiveness: As the backend team is typically in charge of the BFF, front-end teams often have to wait for them to make necessary changes. This slows down the development process, especially when backlogs are high or priorities differ. Different Skillsets: Backend and frontend developers often specialize in different programming languages and paradigms. If the backend team is in charge of the BFF, they might not be as comfortable or efficient at dealing with issues that are more closely related to the frontend. Lack of Ownership: Frontend teams often feel that they lack ownership and control over the part of the system that directly impacts their work. This leads to decreased motivation and productivity.  One potential solution to these issues is to shift the ownership of the BFFs to the front-end teams. Since these teams are the primary consumers of the BFFs, they could be better placed to design, implement, and maintain them. This would not only empower the front-end teams but also free up backend teams to focus on their core responsibilities.  However, this solution is not without its own challenges. For one, front-end teams would need to upskill to handle their new responsibilities. Also, the organization would need to ensure that there are clear lines of communication between the front-end and backend teams, so that any changes to shared resources can be coordinated effectively.  ","version":null,"tagName":"h3"},{"title":"Legacy Gateway​","type":1,"pageTitle":"No one talks about API Orchestration","url":"/blog/no-one-talks-about-api-orchestration/#legacy-gateway","content":" BFF layers often end up implementing some of the cross-cutting concerns of an API gateway such as rate limiting, authentication, throttling, etc. This makes its purpose quite confusing in the sense that do we need an API gateway if we are using a BFF layer. Moreover, it's not very clear if we use an API gateway with a BFF layer, where should we place it? Should we place it between the clients and the BFF layer or the BFF layer and the service mesh? These are subjective decisions that each company ends up making as there is no standard way of doing this. However, it's worth mentioning that legacy gateways do introduce a gap that's being attempted to be filled by a BFF layer.  BFF, Presentation Layer, Facade, Middleware, UI Layer, Orchestration Layer, API Adapter — Are all different nomenclatures used for the same thing.  To summarize, BFFs do indeed address the issues of API orchestration to a significant extent; however, they also present a new set of challenges for organizations to tackle. Clearly, there is more to the story. In our next blog post, we will discuss some of the solutions that large organizations with unlimited budgets have implemented to overcome this problem. So, please subscribe if you haven't already. ","version":null,"tagName":"h3"},{"title":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","type":0,"sectionRef":"#","url":"/blog/graphql-schema/","content":"","keywords":"","version":null},{"title":"The Power of GraphQL Schemas​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#the-power-of-graphql-schemas","content":" A well-designed GraphQL schema serves as the blueprint for your entire API. It defines:  The types of data availableThe relationships between those typesThe operations clients can perform (queries, mutations, subscriptions)The structure of requests and responses  Your schema acts as a contract between your backend and frontend teams. Once published, clients can rely on its structure, enabling them to build UIs with confidence. A thoughtful schema design upfront can save significant refactoring down the road.  ","version":null,"tagName":"h2"},{"title":"Our Example Application: TechTalent​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#our-example-application-techtalent","content":" To illustrate schema design principles, let's imagine we're building TechTalent - a platform connecting tech companies with job seekers. Our application will allow:  Companies to post job listingsCandidates to create profiles and apply to jobsRecruiters to search candidates and manage applications  We'll design our schema step-by-step to support these core features.  ","version":null,"tagName":"h2"},{"title":"Step 1: Identify Core Types​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#step-1-identify-core-types","content":" The first step is to identify the main entities in our domain. For TechTalent, our core types might include:  CompanyJobListingCandidateApplicationRecruiter  Let's start by defining these as object types in our schema:  type Company { id: ID! name: String! description: String # More fields to come } type JobListing { id: ID! title: String! description: String! # More fields to come } type Candidate { id: ID! name: String! email: String! # More fields to come } type Application { id: ID! # More fields to come } type Recruiter { id: ID! name: String! email: String! # More fields to come }   Notice we've only included a few basic fields at this stage. We'll flesh these out as we progress.  ","version":null,"tagName":"h2"},{"title":"Step 2: Model Relationships​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#step-2-model-relationships","content":" Next, we need to consider how these types relate to each other. In GraphQL, we model relationships by adding fields that reference other types. Let's update our types:  type Company { id: ID! name: String! description: String jobListings: [JobListing!]! recruiters: [Recruiter!]! } type JobListing { id: ID! title: String! description: String! company: Company! applications: [Application!]! } type Candidate { id: ID! name: String! email: String! applications: [Application!]! } type Application { id: ID! jobListing: JobListing! candidate: Candidate! status: ApplicationStatus! } type Recruiter { id: ID! name: String! email: String! company: Company! } enum ApplicationStatus { PENDING REVIEWED REJECTED ACCEPTED }   We've now established the core relationships:  Companies have job listings and recruitersJob listings belong to a company and have applicationsCandidates have applicationsApplications link a candidate to a job listingRecruiters belong to a company  Note the use of the ApplicationStatus enum to represent the fixed set of possible statuses.  ","version":null,"tagName":"h2"},{"title":"Step 3: Plan Query Operations​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#step-3-plan-query-operations","content":" With our core types defined, let's consider what query operations our clients will need. We'll start with some basic CRUD (Create, Read, Update, Delete) operations:  type Query { company(id: ID!): Company jobListing(id: ID!): JobListing candidate(id: ID!): Candidate # List operations companies: [Company!]! jobListings(filters: JobListingFilters): [JobListing!]! candidates(filters: CandidateFilters): [Candidate!]! } input JobListingFilters { companyId: ID title: String # Add more filter options } input CandidateFilters { skills: [String!] experienceYears: Int # Add more filter options }   We've added basic queries to fetch individual entities by ID, as well as list queries for our main types. Notice the use of input types for filters - this allows for more flexible and extensible querying.  ","version":null,"tagName":"h2"},{"title":"Step 4: Plan Mutation Operations​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#step-4-plan-mutation-operations","content":" Next, let's define some mutation operations to allow clients to modify data:  type Mutation { # Company mutations createCompany( input: CreateCompanyInput! ): CreateCompanyPayload! updateCompany( id: ID! input: UpdateCompanyInput! ): UpdateCompanyPayload! # Job Listing mutations createJobListing( input: CreateJobListingInput! ): CreateJobListingPayload! updateJobListing( id: ID! input: UpdateJobListingInput! ): UpdateJobListingPayload! # Candidate mutations createCandidate( input: CreateCandidateInput! ): CreateCandidatePayload! updateCandidate( id: ID! input: UpdateCandidateInput! ): UpdateCandidatePayload! # Application mutations submitApplication( input: SubmitApplicationInput! ): SubmitApplicationPayload! updateApplicationStatus( id: ID! status: ApplicationStatus! ): UpdateApplicationStatusPayload! } # Input and Payload types for each mutation...   Notice the pattern we're using for mutations:  Each mutation has a corresponding input typeEach mutation returns a payload type  This structure offers several benefits:  Input types allow for easy addition of new fields in the futurePayload types can include both the modified entity and any errors or metadataIt provides a consistent structure across all mutations  Let's look at an example input and payload type:  input CreateJobListingInput { companyId: ID! title: String! description: String! requirements: [String!]! salary: SalaryInput } input SalaryInput { min: Int! max: Int! currency: String! } type CreateJobListingPayload { jobListing: JobListing errors: [Error!] } type Error { message: String! path: [String!] }   This structure allows for detailed error reporting and future extensibility.  ","version":null,"tagName":"h2"},{"title":"Step 5: Consider Authentication and Authorization​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#step-5-consider-authentication-and-authorization","content":" In a production application, we need to consider authentication and authorization. Let's add some operations for user management:  type Mutation { # ... previous mutations signup(input: SignupInput!): AuthPayload! login(input: LoginInput!): AuthPayload! logout: Boolean! } input SignupInput { email: String! password: String! name: String! role: UserRole! } input LoginInput { email: String! password: String! } type AuthPayload { token: String! user: User! } type User { id: ID! email: String! name: String! role: UserRole! } enum UserRole { CANDIDATE RECRUITER ADMIN }   We've added basic authentication operations and a User type to represent authenticated users. In a real-world scenario, you'd likely want to implement more robust authentication and authorization mechanisms.  ","version":null,"tagName":"h2"},{"title":"Step 6: Implement Pagination​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#step-6-implement-pagination","content":" As our application grows, we'll need to implement pagination for our list queries. Let's update our jobListings query to use cursor-based pagination:  type Query { # ... other queries jobListings( first: Int after: String filters: JobListingFilters ): JobListingConnection! } type JobListingConnection { edges: [JobListingEdge!]! pageInfo: PageInfo! } type JobListingEdge { node: JobListing! cursor: String! } type PageInfo { hasNextPage: Boolean! endCursor: String }   This implementation follows the Relay connection specification, which provides a standardized way to handle pagination in GraphQL.  ","version":null,"tagName":"h2"},{"title":"Step 7: Plan for Real-time Updates​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#step-7-plan-for-real-time-updates","content":" For certain features, we might want to provide real-time updates. Let's add a subscription to notify when new job listings are posted:  type Subscription { newJobListing: JobListing! }   Clients can subscribe to this operation to receive updates whenever a new job listing is created.  ","version":null,"tagName":"h2"},{"title":"Step 8: Implement Custom Scalars​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#step-8-implement-custom-scalars","content":" Our schema might benefit from some custom scalar types for specific data formats. For example, let's add a DateTime scalar:  scalar DateTime type JobListing { # ... other fields postedAt: DateTime! applicationDeadline: DateTime }   We'll need to implement the serialization/deserialization logic for this scalar in our resolvers.  ","version":null,"tagName":"h2"},{"title":"Step 9: Use Interfaces for Shared Fields​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#step-9-use-interfaces-for-shared-fields","content":" As our schema grows, we might notice some types sharing common fields. We can use interfaces to model this shared structure:  interface Node { id: ID! } interface Timestamped { createdAt: DateTime! updatedAt: DateTime! } type Company implements Node &amp; Timestamped { id: ID! createdAt: DateTime! updatedAt: DateTime! # ... other fields } type JobListing implements Node &amp; Timestamped { id: ID! createdAt: DateTime! updatedAt: DateTime! # ... other fields }   This approach promotes consistency and can make it easier to implement features that work across multiple types.  ","version":null,"tagName":"h2"},{"title":"Step 10: Document Your Schema​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#step-10-document-your-schema","content":" Finally, it's crucial to document your schema thoroughly. GraphQL allows for built-in documentation:  &quot;&quot;&quot; Represents a company on the TechTalent platform. &quot;&quot;&quot; type Company implements Node &amp; Timestamped { &quot;&quot;&quot; Unique identifier for the company. &quot;&quot;&quot; id: ID! &quot;&quot;&quot; The name of the company. &quot;&quot;&quot; name: String! # ... other fields }   Good documentation helps both your team and API consumers understand the purpose and usage of each type and field.  ","version":null,"tagName":"h2"},{"title":"Visualizing the Schema​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#visualizing-the-schema","content":" To better understand the relationships in our schema, let's visualize the core types:    This diagram illustrates the key relationships between our main entities, helping us ensure our schema accurately represents our domain.  To visualize your schema, you can use tools like GraphQL Voyager.  ","version":null,"tagName":"h2"},{"title":"Best Practices and Considerations​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#best-practices-and-considerations","content":" As we've designed our schema, we've touched on several best practices. Let's recap some key points and add a few more considerations:  Start with the UI in mind: Design your schema based on how the data will be used in your UI, not just how it's stored in your database. Use clear, consistent naming: Adopt a naming convention (e.g., PascalCase for types, camelCase for fields) and stick to it. Leverage GraphQL features: Make use of enums, interfaces, and unions to create a rich, expressive schema. Plan for change: Use input types for mutations and consider versioning strategies for evolving your schema over time. Optimize for performance: Be mindful of N+1 query problems and consider implementing DataLoader or similar batching mechanisms. Secure your schema: Implement proper authentication and authorization. Consider using directives for field-level permissions. Validate input: Use non-nullable fields and custom scalars to enforce data integrity at the schema level. Provide meaningful errors: Return detailed error information in your mutation payloads to help clients handle failures gracefully. Monitor and analyze: Implement logging and monitoring to understand how your schema is being used and where optimizations can be made. Keep it DRY: Use interfaces and abstract types to reduce duplication in your schema.  ","version":null,"tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Design a GraphQL Schema So Good, It'll Make REST APIs Cry - Part 1","url":"/blog/graphql-schema/#conclusion","content":" Designing a production-grade GraphQL schema is an iterative process that requires careful thought and planning. By starting with core types and relationships, then gradually adding queries, mutations, and advanced features, we can build a schema that's both powerful and maintainable.  Remember, your schema is a living document. As your application evolves, so too will your schema. By following these principles and best practices, you'll be well-equipped to design and maintain a GraphQL schema that can grow with your needs.  The TechTalent example we've explored here demonstrates many real-world considerations, but every application will have its unique requirements. Always design with your specific use cases in mind, and don't be afraid to iterate as you learn more about how your API is used in practice.  By investing time in thoughtful schema design upfront, you'll create a solid foundation for your GraphQL API, enabling efficient development and a great experience for your API consumers.  Alright greatttt! You have successfully completed the first part of a very intricate series!! Pat yourslef and maybe high five your cat! Here are the links to the next blogs in the series that have already been published.    Next Part ","version":null,"tagName":"h2"},{"title":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","type":0,"sectionRef":"#","url":"/blog/graphql-vs-openapi-part-1/","content":"","keywords":"","version":null},{"title":"Overview of GraphQL and OpenAPI​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#overview-of-graphql-and-openapi","content":" ","version":null,"tagName":"h2"},{"title":"GraphQL​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#graphql","content":" Imagine having a magical tool that can fetch exactly what you need, no more, no less—GraphQL is just that! Developed by Facebook in 2012 and open-sourced in 2015, GraphQL is your go-to for flexible, precise API queries. It's like a Swiss Army knife for your data needs, making it a favorite among developers.  ","version":null,"tagName":"h3"},{"title":"OpenAPI​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#openapi","content":" If OpenAPI were a tool, it would be a precisely engineered blueprint for a complex machine, where every part (or API endpoint) is clearly defined and meticulously documented. Initially known as Swagger, OpenAPI was created by SmartBear in 2010 and has since become the gold standard for defining RESTful APIs. This structured approach provided clarity and consistency in several of my projects, making the development process smooth and predictable  ","version":null,"tagName":"h3"},{"title":"Importance of Choosing the Right API Specification​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#importance-of-choosing-the-right-api-specification","content":" Choosing between GraphQL and OpenAPI? Buckle up, because this decision will steer your development workflow, performance, scalability, and ultimately, the success of your project. Let's dive into their differences and find out which one suits your needs best!  ","version":null,"tagName":"h3"},{"title":"Quick Comparison Table: GraphQL vs OpenAPI at a Glance​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#quick-comparison-table-graphql-vs-openapi-at-a-glance","content":" Feature\tGraphQL\tOpenAPIData Retrieval\tQuery Language\tREST Endpoints Schema Definition\tSDL\tSwagger API Documentation\tSelf-Documenting\tManual/Auto-Generated Typing\tStrong Typing at Runtime\tSchema Validation Performance\tEfficient Data Fetching\tStandardized Operations Scalability\tHandles Complex Queries\tReliable for High Traffic Security\tCustom Security Measures\tBuilt-in Mechanisms  ","version":null,"tagName":"h3"},{"title":"Understanding the Fundamentals​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#understanding-the-fundamentals","content":" ","version":null,"tagName":"h2"},{"title":"A. What is GraphQL?​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#a-what-is-graphql","content":" Definition and Core Features​  Think of GraphQL as a master chef who takes your order (query) and prepares exactly what you want, without any extras. It's a flexible query language for APIs, allowing clients to request precise data and get exactly what they need. Read More!&quot;  ","version":null,"tagName":"h3"},{"title":"B. What is OpenAPI?​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#b-what-is-openapi","content":" Definition and Core Features​  Initially known as Swagger, OpenAPI was crafted by SmartBear in 2010 and has since become the go-to standard for defining RESTful APIs. It provides a comprehensive framework for defining APIs, allowing both humans and machines to understand the capabilities of a service without accessing its source code.  ","version":null,"tagName":"h3"},{"title":"Key Differences​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#key-differences","content":" ","version":null,"tagName":"h2"},{"title":"A. Approach to Data Retrieval​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#a-approach-to-data-retrieval","content":" GraphQL Query Language vs OpenAPI REST Endpoints​  GraphQL allows clients to define the structure of the response, making it highly flexible. OpenAPI, on the other hand, relies on predefined endpoints for data retrieval.  GraphQL: Query Flexibility​  GraphQL's query flexibility is a game-changer for frontend developers. Imagine you're building a user profile page that needs to display a user's name, email, recent posts, and follower count. With a REST API, you might need to make multiple requests to different endpoints (/user, /posts, /followers) to gather all this data. But with GraphQL, you can request all this information in a single query:  query { user(id: &quot;123&quot;) { name email recentPosts(limit: 5) { title date } followerCount } }   This not only reduces the number of network requests but also eliminates over-fetching of data. If you only need the user's name and email, you simply omit the other fields from your query. This flexibility allows frontend developers to iterate quickly without waiting for backend changes, significantly speeding up development cycles.  OpenAPI: Defined Endpoints​  OpenAPI follows the REST architecture, where each endpoint corresponds to a specific resource or action, providing a clear structure but less flexibility.  ","version":null,"tagName":"h3"},{"title":"B. Type System and Validation​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#b-type-system-and-validation","content":" GraphQL: Strong Typing at Runtime​  GraphQL uses a robust type system to validate queries at runtime, ensuring clients only request valid data and fields. This strong typing mechanism helps prevent errors before they occur by enforcing a strict schema that defines the types of data that can be queried and the relationships between different data entities. By validating queries against this schema, GraphQL ensures that clients can only access the data they are permitted to and that they do so in a predictable manner. This type safety not only improves the reliability of the API but also enhances developer productivity by providing clear, self-documenting APIs.  Example GraphQL Schema:  type User { id: ID! name: String! email: String! posts: [Post] } type Post { id: ID! title: String! content: String! author: User } type Query { user(id: ID!): User allUsers: [User] post(id: ID!): Post allPosts: [Post] } type Mutation { createUser(name: String!, email: String!): User createPost( title: String! content: String! authorId: ID! ): Post }   Example GraphQL Query:  query { user(id: &quot;123&quot;) { id name email posts { id title content } } allPosts { id title content author { id name } } }   In this example, the schema defines User and Post types, their fields, and the relationships between them. The Query type includes operations for fetching users and posts, and the Mutation type includes operations for creating users and posts. The query fetches a specific user and their posts, as well as all posts and their authors.  For a deeper dive into GraphQL schemas and types, you can explore this resource.  OpenAPI: Schema Validation​  OpenAPI's use of JSON/YAML Schema for validation is more powerful than it might initially appear. Let's break this down with an example. Suppose you're building an e-commerce API. You could define a product schema like this:  components: schemas: Product: type: object required: - id - name - price properties: id: type: integer name: type: string minLength: 1 maxLength: 100 price: type: number minimum: 0 description: type: string categories: type: array items: type: string   This schema does more than just define the structure. It enforces business rules:  Products must have an id, name, and price (required fields) Product names must be between 1 and 100 characters Prices can't be negative  By defining these constraints in the OpenAPI spec, you're not just documenting your API - you're creating a contract that can be enforced by API gateways, automatically validated in tests, and used to generate accurate client SDKs. This level of detail at the design stage catches errors early, improves API consistency, and significantly reduces the likelihood of bugs in production.  ","version":null,"tagName":"h3"},{"title":"C. Schema Definition​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#c-schema-definition","content":" GraphQL SDL vs OpenAPI Swagger​  GraphQL and OpenAPI use different approaches to define and document their APIs.  GraphQL: Schema Definition Language (SDL)  GraphQL uses the Schema Definition Language (SDL) to define the types and relationships within an API. SDL is a human-readable language that allows developers to describe the data structures and operations available on the GraphQL server. This schema acts as a contract between the client and server, ensuring that all queries and mutations adhere to the defined types and structures.  Example of GraphQL SDL:  type User { id: ID! name: String! email: String! posts: [Post] } type Post { id: ID! title: String! content: String! author: User } type Query { user(id: ID!): User allUsers: [User] post(id: ID!): Post allPosts: [Post] } type Mutation { createUser(name: String!, email: String!): User createPost( title: String! content: String! authorId: ID! ): Post }   In this example, the schema defines User and Post types, their fields, and the relationships between them. It also defines queries to fetch users and posts, and mutations to create new users and posts.  OpenAPI: Swagger  OpenAPI uses JSON or YAML to describe endpoints, parameters, and responses. This specification format allows for detailed documentation of RESTful APIs, including request and response formats, authentication methods, and error handling. OpenAPI specifications can be used to generate API documentation, client SDKs, and server stubs, making it a comprehensive tool for API development.  Example of OpenAPI Swagger (YAML format):  openapi: 3.0.0 info: title: Example API version: 1.0.0 paths: /users: get: summary: Get a list of users responses: &quot;200&quot;: description: A list of users content: application/json: schema: type: array items: $ref: &quot;#/components/schemas/User&quot; /users/{id}: get: summary: Get a user by ID parameters: - name: id in: path required: true schema: type: string responses: &quot;200&quot;: description: A user object content: application/json: schema: $ref: &quot;#/components/schemas/User&quot; /posts: post: summary: Create a new post requestBody: required: true content: application/json: schema: $ref: &quot;#/components/schemas/Post&quot; responses: &quot;201&quot;: description: The created post content: application/json: schema: $ref: &quot;#/components/schemas/Post&quot; components: schemas: User: type: object properties: id: type: string name: type: string email: type: string Post: type: object properties: id: type: string title: type: string content: type: string authorId: type: string   In this OpenAPI example, the specification defines paths for fetching users and creating posts, along with the necessary parameters and responses. It also defines the User and Post schemas used in the API.  By using these tools, both GraphQL and OpenAPI provide clear, structured ways to define and document APIs, each with their own strengths and use cases.  ","version":null,"tagName":"h3"},{"title":"D. API Documentation​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#d-api-documentation","content":" GraphQL: Self-Documenting​  GraphQL schemas are inherently self-documenting, allowing clients to introspect the schema and understand available operations. Tools like GraphiQL provide an interactive environment where developers can explore the schema, view available types and fields, and see the relationships between different data entities. This self-documenting feature of GraphQL significantly enhances the developer experience by providing built-in API documentation.  Example: GraphiQL Interface  To demonstrate, let's use the Star Wars API (SWAPI) GraphiQL endpoint here. By navigating to the SWAPI GraphQL interface, you can interact with the API and see how the schema is documented.  Example Query:  { allFilms { films { title director releaseDate } } allPeople { people { name birthYear homeworld { name } } } }   This query fetches details about films and characters from the Star Wars universe. The GraphiQL interface allows you to see the available types, queries, and fields in the documentation tab.  GraphiQL Documentation Snapshot:  In this snapshot of the GraphiQL interface, you can see the documentation tab open, displaying the schema with types and fields such as Film and Person, with fields like title, director, releaseDate, name, birthYear, and homeworld. This clean and professional interface reflects the self-documenting nature of GraphQL schemas, making it easy for developers to understand and use the API effectively.  By using the introspection capabilities of GraphQL and tools like GraphiQL, developers can quickly get up to speed with the API and explore its capabilities interactively.    OpenAPI: Manual and Auto-Generated Options​  OpenAPI supports both manual and auto-generated documentation, which enhances the ease of sharing API details. Tools like Swagger UI allow developers to create interactive API documentation that can be explored and tested directly from the browser. This makes it easier for both developers and non-developers to understand and interact with the API.  Example: Spotify API Documentation  Spotify uses OpenAPI to provide comprehensive and interactive API documentation. Their public-facing documentation, which can be accessed here, showcases the power of auto-generated documentation. With detailed descriptions of endpoints, parameters, and response formats, along with interactive features to test the API, Spotify's documentation serves as an excellent example of how OpenAPI can streamline the process of API development and consumption.  Swagger UI Example:  openapi: 3.0.0 info: title: Spotify API version: 1.0.0 paths: /tracks/{id}: get: summary: Get a track parameters: - name: id in: path required: true schema: type: string responses: &quot;200&quot;: description: A track object content: application/json: schema: $ref: &quot;#/components/schemas/Track&quot; components: schemas: Track: type: object properties: id: type: string name: type: string artist: type: string album: type: string   With Swagger UI, this specification can be rendered into a fully interactive API documentation interface, where users can explore different endpoints, see example requests and responses, and even try out API calls directly from the documentation page. This approach not only improves the developer experience but also helps in maintaining up-to-date and accessible API documentation.  Below, we have a snapshot of the Spotify OpenAPI documentation:    OpenAPI: Manual and Auto-Generated Options​  OpenAPI supports both manual and auto-generated documentation through tools like Swagger UI, making it easier to share API details.  ","version":null,"tagName":"h3"},{"title":"E. Development Ecosystem​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#e-development-ecosystem","content":" Comparison of Tooling and Community Support​  Both GraphQL and OpenAPI have extensive ecosystems with robust tooling and strong community support, each catering to different aspects of API development.  GraphQL:  GraphQL has a vibrant and rapidly growing ecosystem. Some of the most popular tools include:  Apollo: Apollo provides a suite of tools for building, querying, and managing GraphQL APIs. Apollo Client simplifies data fetching in frontend applications by providing features like caching, state management, and real-time updates through subscriptions. Apollo Server helps in creating a GraphQL server with minimal setup and integrates well with various data sources and services.  Example:  // Apollo Client setup import { ApolloClient, InMemoryCache, gql, } from &quot;@apollo/client&quot; const client = new ApolloClient({ uri: &quot;https://example.com/graphql&quot;, cache: new InMemoryCache(), }) client .query({ query: gql` query GetUsers { users { id name } } `, }) .then((result) =&gt; console.log(result))   Relay: Developed by Facebook, Relay is a JavaScript framework for building data-driven React applications with GraphQL. It focuses on efficient data fetching, minimizing the amount of data sent over the network, and ensuring that the data fetched is always up to date.  Example:  // Relay setup import { Environment, Network, RecordSource, Store, } from &quot;relay-runtime&quot; const fetchQuery = (operation, variables) =&gt; { return fetch(&quot;https://example.com/graphql&quot;, { method: &quot;POST&quot;, headers: { &quot;Content-Type&quot;: &quot;application/json&quot;, }, body: JSON.stringify({ query: operation.text, variables, }), }).then((response) =&gt; response.json()) } const environment = new Environment({ network: Network.create(fetchQuery), store: new Store(new RecordSource()), })   The community around GraphQL is active and supportive, with numerous tutorials, documentation, and forums available to help developers at all levels.  OpenAPI:  OpenAPI has a well-established community and a mature ecosystem. Some of the most prominent tools include:  Swagger: Swagger is a suite of tools that helps design, build, document, and consume RESTful web services. Swagger Editor allows you to design APIs in a user-friendly interface and generate interactive API documentation. Swagger Codegen can generate client SDKs and server stubs in various programming languages from an OpenAPI specification.  Example:  openapi: 3.0.0 info: title: Sample API version: 1.0.0 paths: /users: get: summary: Retrieves a list of users responses: &quot;200&quot;: description: A list of users content: application/json: schema: type: array items: $ref: &quot;#/components/schemas/User&quot; components: schemas: User: type: object properties: id: type: string name: type: string   Postman: Postman is a popular tool for API development and testing. It allows developers to create and test API requests, automate testing with scripts, and manage environments and variables. Postman can import OpenAPI specifications to quickly generate requests and document APIs.  Example:  { &quot;info&quot;: { &quot;name&quot;: &quot;Sample API&quot; }, &quot;item&quot;: [ { &quot;name&quot;: &quot;Get Users&quot;, &quot;request&quot;: { &quot;method&quot;: &quot;GET&quot;, &quot;url&quot;: { &quot;raw&quot;: &quot;https://example.com/users&quot;, &quot;protocol&quot;: &quot;https&quot;, &quot;host&quot;: [&quot;example&quot;, &quot;com&quot;], &quot;path&quot;: [&quot;users&quot;] } } } ] }   Insomnia: Insomnia is another powerful tool for API design and testing, supporting both REST and GraphQL. It provides features like environment variables, plugin support, and code generation from API definitions, making it a versatile choice for API development.  The OpenAPI community has been around for a long time, providing extensive documentation, guides, and support forums. This mature ecosystem ensures that developers have access to a wealth of resources to help them design, document, and consume APIs effectively.  By leveraging these tools and community support, developers can streamline their API development processes, ensuring robust and well-documented APIs for their applications..  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"GraphQL vs OpenAPI: Part 1 of the API Comparison Series","url":"/blog/graphql-vs-openapi-part-1/#conclusion","content":" As we wrap up this introduction to GraphQL and OpenAPI, it's clear that both have their unique advantages and use cases. GraphQL excels in offering flexible, precise data queries, while OpenAPI provides a structured, standardized approach to defining RESTful APIs. In the next part of our series, we will compare their performance, flexibility, and ease of use in greater detail, providing insights into how they fare in real-world scenarios.  Stay tuned for the next part to learn more about how these API specifications can impact your development workflow and project success. ","version":null,"tagName":"h2"},{"title":"Unraveling the Challenges of BFF Federation","type":0,"sectionRef":"#","url":"/blog/unraveling-the-challenges-of-bff-federation/","content":"","keywords":"","version":null},{"title":"Using a BFF Federation​","type":1,"pageTitle":"Unraveling the Challenges of BFF Federation","url":"/blog/unraveling-the-challenges-of-bff-federation/#using-a-bff-federation","content":" Federation, as a concept, is not exclusive to GraphQL. In essence, it's about abstracting multiple data sources or services into a unified, single API interface that can be consumed by clients. This approach is not unique to any particular technology or framework and can be implemented with various tools and languages.  However, GraphQL has played a significant role in popularizing the concept of federation. With its strong typing, introspective capabilities, and its natural fit for defining schemas across distributed services, it has provided an elegant solution to the challenge of federating APIs.  While this blog discusses federation in the context of GraphQL, it's essential to understand that the core principles and challenges of the federation can be applied beyond GraphQL. Remember, the implementation of federation is not about a specific technology, but about the architectural approach to create a unified interface from multiple data sources.  With this in mind, let's delve into the pros and cons of the federation, using GraphQL as our main context for the discussion. As you'll see, the benefits and pitfalls of federation are relevant, whether you're using GraphQL or not.  Federation is a concept that originates from the philosophy of microservices. This approach promotes the partitioning of large monolithic systems into smaller, more manageable components. In a federated architecture, instead of having a monolithic Backend-for-Frontend (BFF) handling all requests, you have multiple smaller BFFs that handle different aspects of the request.  Imagine a client makes a request to your system. This request still goes through an API gateway, which serves as the entry point to your system. However, instead of hitting a monolithic BFF, it now meets a BFF Router, specifically designed to understand and route requests to the appropriate BFFs.  The Router is smart. It understands the client's request and can break it down into smaller parts. It then delegates these smaller tasks to the appropriate services, each responsible for a specific aspect of the request. These services work in parallel, handling their part of the request, which often involves calling downstream microservices and orchestrating their responses.  Once the BFFs have finished their tasks, they send their responses back to the Router. The Router, in turn, takes these individual responses, combines them into a single response that fulfils the original request, and sends it back to the client.  This system, where individual services handle specific parts of a request in a coordinated manner, is often referred to as a Federation. The term &quot;Apollo Federation&quot; or &quot;Super Graph&quot; is commonly used to describe this setup when it's implemented with Apollo, a popular GraphQL implementation, but the concept is not limited to any specific technology or tool.    ","version":null,"tagName":"h2"},{"title":"Federation Benefits​","type":1,"pageTitle":"Unraveling the Challenges of BFF Federation","url":"/blog/unraveling-the-challenges-of-bff-federation/#federation-benefits","content":" Many large organizations using GraphQL in production have transitioned to this architecture to accommodate their scaling needs. The primary selling points of this architecture are:  Enhanced Team Ownership: GraphQL Federation fosters a sense of ownership among teams by allowing each team to own and maintain its GraphQL service. With Federation, teams can operate independently, focusing on their specific domain without worrying about the overall schema. This separation of concerns leads to more maintainable code, faster development cycles, and increased productivity. It empowers teams to work in parallel, each owning a piece of the larger schema while ensuring that the entire system operates as a cohesive whole. This significantly enhances team efficiency and collaboration, particularly in larger organizations with multiple teams working on different services. This alone is by far the most significant aspect of using GraphQL Federation. Incremental Adoption: A major advantage of GraphQL Federation is its ability to support incremental adoption. This means teams can gradually wrap their domain-specific microservices with a GraphQL layer, one at a time, and integrate it into the federated schema without disrupting the entire system. This flexible approach minimizes the impact on existing workflows and reduces the risks associated with large-scale changes. From the frontend perspective, GraphQL Federation offers a unified interface for querying the data. This simplifies the frontend code and enables the development of rich, interactive UIs with less effort. As soon as the first services are federated, frontend developers can begin transitioning their queries to the federated schema, reducing disruption and allowing for a smoother adoption process. This incremental approach also allows teams to evaluate and demonstrate the value of federation at each step, building confidence and promoting buy-in across the organization. It ensures teams are not overwhelmed by the complexity of new technology or architecture and can adjust their practices as they learn.  ","version":null,"tagName":"h2"},{"title":"Federation vs BFF​","type":1,"pageTitle":"Unraveling the Challenges of BFF Federation","url":"/blog/unraveling-the-challenges-of-bff-federation/#federation-vs-bff","content":"   It's not hard to see that GraphQL Federation carries some serious muscle over its monolithic adversary, the BFF. But before we declare a champion, let's take a few rounds to scrutinize the limitations we've come across in our BFF solution, and see how the GraphQL Federation stands up under pressure. It's time for a head-to-head comparison!  Specialization: Both BFF and GraphQL Federation require a certain amount of manual intervention. In the BFF approach, the entire layer is custom-built, meaning there's no ready-to-use solution, which necessitates significant manual management. On the other hand, GraphQL Federation provides an open-source, ready-to-use Apollo Router. However, it's not an all-inclusive solution, as the individual GraphQL services still need to be manually maintained and written by hand for specific use cases. While it's still a tough fight, the federation manages to land a jab here and gets a few extra points in this round. Fragility: Federation offers an enhanced strategy. In a federated architecture, when a GraphQL service malfunction, only its segment of the graph becomes inaccessible to the user. This results in a more resilient system, less prone to total failure, demonstrating the ability to continue the fight even after taking a hit. In this round, Federation steps up and delivers a solid punch. Performance: When it comes to Performance, the Federation architecture introduces an extra journey for each packet. The request has to travel through the router, then to the individual GraphQL services, before finally reaching the domain service. This journey can add a few milliseconds of latency, a difference that may not be perceptible to the end user. However, this seemingly small delay has a broader impact on the performance of the entire architecture. The addition of the router introduces a requirement for more infrastructure and increases the frequency of data serialization and deserialization. This increased complexity affects both the system's throughput and infrastructure costs. In this round, the Federation architecture might not be the clear knockout winner we were hoping for. Monolith Tendency: It's a clear knockout in this round for the Federation! It elegantly sidesteps the monolith tendency, keeping the architecture agile and modular. BFF, in contrast, takes a heavy fall with its tendency to become a monolithic layer over time. Canary Release: Federation, unlike BFF, reveals graph dependencies and compatibility issues at runtime, not compile time. This amps up the need for first-class canary releases. However, when it comes to canary support, it's a draw. Both fighters are still in the ring, each showing resilience in their own way. No knockout here, folks! Coupled Release: In the Federation architecture, each GraphQL service operates independently, significantly reducing the coupling between services and the router. This independence allows each team to manage its own release cycles, putting an end to the wide-scale halts that were commonplace with the BFF layer. However, it's important to note that each GraphQL service still maintains a tight connection with its corresponding downstream domain service. While this is a form of coupling, it's considerably less invasive than the BFF approach, where the entire layer was intertwined. Despite this necessary connection to the domain services, the Federation architecture proves to be more agile. In this round, GraphQL Federation edges out the BFF approach. Organizational Friction: With Federation, the responsibility for managing the architecture often falls squarely on the shoulders of backend engineers. The reason is simple: the complexity of the architecture and its intimate ties with downstream domain services necessitate a deep level of technical understanding. This is a departure from the BFF paradigm, where frontend teams could claim ownership of this part of the infrastructure. The intricate nature of the Federation, however, makes this almost untenable. When put head-to-head with BFFs, the Federation seems to take a step back in this regard. The power to control abstraction slips away from the consumer. In this round, BFFs manage to hold their ground. Legacy Gateway: Just as in the BFF model, the API gateway maintains its place in the Federation architecture, and rightfully so. However, we find ourselves reestablishing a substantial amount of resiliency and caching logic within these new layers, duplicating efforts previously expended on a traditional gateway. This redundancy marks a lack of efficiency in the Federation approach, signaling a tie in this round.  Overall, this round favors GraphQL Federation. It proves to be a significantly more robust architecture when evaluated based on the aforementioned criteria. Let's explore further and assess how it performs in isolation and as the company expands.  ","version":null,"tagName":"h2"},{"title":"Pitfalls of GraphQL Federation​","type":1,"pageTitle":"Unraveling the Challenges of BFF Federation","url":"/blog/unraveling-the-challenges-of-bff-federation/#pitfalls-of-graphql-federation","content":" While GraphQL Federation has numerous benefits, it is not without its downsides. Here are some points of caution that should be considered when deciding to use this architecture:  Cost and Complexity: GraphQL Federation introduces significant complexity into the architecture. Setting up, maintaining, and testing a federated graph can be a challenge as it requires a deep understanding of both GraphQL and distributed systems. Additionally, this architecture demands more infrastructure and a larger team for maintenance. As such, the adoption and migration process can be complex and costly. Typically, only large organizations with platform teams, robust budgets, and a governing body to maintain the schema's sanctity and system reliability, tend to consider adopting this approach. The inherent complexity and cost implications make the Federation a less likely choice for small to medium-sized organizations. Ownership Challenges: It is often argued that domain service owners maintain their individual GraphQL layers. However, this doesn't always reflect the reality. Services can frequently be divided or merged, leading to uncertainty about how to modify the GraphQL layer. This results in a complex web of requests from GraphQL services to domain services outside the team's control. Infrastructure Scaling: Each subgraph in a federated architecture operates on a separate piece of infrastructure, scaling independently. This brings its own set of challenges. For instance, when a subgraph is divided or merged, computing and scaling requirements need to be re-evaluated. Moreover, a deployment in another subgraph can trigger a substantial increase in load from the router on your subgraph, potentially causing unexpected stress on your infrastructure. This underscores the need for robust scaling and load-balancing strategies within a federated architecture.  While GraphQL Federation has the potential to solve some issues of traditional BFF architecture, it brings in its own set of challenges. Therefore, it's important to evaluate these considerations based on the specific requirements and constraints of your project before deciding to implement this architecture.  ","version":null,"tagName":"h2"},{"title":"We are onto something​","type":1,"pageTitle":"Unraveling the Challenges of BFF Federation","url":"/blog/unraveling-the-challenges-of-bff-federation/#we-are-onto-something","content":" When examining the underlying issue, the debate essentially revolves around microservices and monoliths. Undoubtedly, the federated solution offers better scalability compared to a monolithic architecture; however, it also introduces a myriad of distinct challenges related to maintenance and costs that warrant careful consideration. This is not the end of the discussion, as client requests pass through CDNs and the Gateway before reaching the router, and we have yet to explore those components of the infrastructure. In the following sections, we will delve into these components and further investigate how they interact, as well as delve deeper into GraphQL. ","version":null,"tagName":"h2"},{"title":"The truth about scaling Automatic Persisted Queries","type":0,"sectionRef":"#","url":"/blog/the-truth-about-scaling-automatic-persisted-queries/","content":"","keywords":"","version":null},{"title":"The Problem​","type":1,"pageTitle":"The truth about scaling Automatic Persisted Queries","url":"/blog/the-truth-about-scaling-automatic-persisted-queries/#the-problem","content":" Large Queries​  Clients send queries to a GraphQL server as HTTP requests that include the query as the body. When these queries become large, they can lead to increased latency and network usage, degrading client performance.  For example, a normal GraphQL query might look like this:  curl -X POST -H &quot;Content-Type: application/json&quot; \\ --data '{&quot;query&quot;: &quot;{ largeQuery { field1 field2 ... } }&quot;}' \\ http://your-graphql-server.com/graphql   Each GraphQL query is parsed every time the server receives it. If it's large, the parsing can take a significant amount of time, increasing latency even further.  Legacy Infrastructure​  Existing CDN infrastructure is designed to cache only GET calls. To make a GraphQL request, one must make a POST call. This limits the usage of CDNs for caching purposes.  ","version":null,"tagName":"h3"},{"title":"Solution: Persisted Queries (PQ)​","type":1,"pageTitle":"The truth about scaling Automatic Persisted Queries","url":"/blog/the-truth-about-scaling-automatic-persisted-queries/#solution-persisted-queries-pq","content":" Definition and Benefits​  To enhance network performance for large query strings, GraphQL server supports Persisted Queries (PQ). A PQ is a GraphQL query cached server-side, identified by its SHA-256 hash. Clients send this identifier instead of the query, dramatically reducing request sizes (without affecting response), saving parsing time, and enabling GET calls instead of POST.  A PQ request might look like this:  curl -X GET -H &quot;Content-Type: application/json&quot; \\ --data-urlencode 'extensions={&quot;persistedQuery&quot;:{&quot;version&quot;:1,&quot;sha256Hash&quot;:&quot;&lt;SHA 256&gt;&quot;}}' \\ http://your-graphql-server.com/graphql   Application with CDNs​  Using the PQ link automatically sends short hashed queries as GET requests, enabling CDNs to serve them.  Latency Reduction​  No Parsing Overhead: Since the query isn't sent to the server, the parsing stage, which can be computationally expensive, is eliminated. This saves valuable server processing time, directly reducing client latency. Network Efficiency: By transmitting only the hash instead of the full query, the request size is dramatically reduced, leading to faster network transmission and lower latency.  Security Enhancements​  Control Over Allowed Queries: The server can start with a finite set of &quot;allowed&quot; queries, ensuring that unauthorized or unoptimized GraphQL requests cannot be made. This control is a significant safeguard for production environments, preventing potential abuse or inefficiencies. Reduction in Attack Surface: By limiting the queries to a pre-defined set, the risk of malicious queries is reduced, enhancing the security profile of the application.  Problem​  While PQs provide remarkable benefits, they are not without challenges:  Schema Rigidity: If you aim to keep the schema open and queries dynamic, supporting any possible query becomes complex. Maintenance of Cached Queries: Managing the cache of allowed queries and keeping them in sync with evolving client needs can become a maintenance burden, especially in a fast-changing environment.  ","version":null,"tagName":"h3"},{"title":"Automatic Persisted Queries (APQs)​","type":1,"pageTitle":"The truth about scaling Automatic Persisted Queries","url":"/blog/the-truth-about-scaling-automatic-persisted-queries/#automatic-persisted-queries-apqs","content":" APQs vs PQs​  APQs are a supposed improvement over PQs. In a PQ setup, the server runs with a known set of queries, meaning client changes require server updates. This has implications for maintenance costs, particularly in supporting multiple versions of queries and making a server deployment for every change in the client query. APQs were introduced to overcome these challenges.  How APQs Work​  The APQ process is a two-step approach:  Hash Request: The client sends a request with the hash of the query. If the server recognizes the hash, it returns the corresponding response: curl -X GET -H &quot;Content-Type: application/json&quot; \\ --data-urlencode 'extensions={&quot;persistedQuery&quot;:{&quot;version&quot;:1,&quot;sha256Hash&quot;:&quot;&lt;SHA 256&gt;&quot;}}' \\ http://your-graphql-server.com/graphql Full Query Request: If the server does not recognize the hash, it returns an error. The client then sends a new request that includes both the hash and the full query string: curl --get http://localhost:4000/graphql \\ --header 'content-type: application/json' \\ --data-urlencode '{&quot;query&quot;: &quot;{ largeQuery { field1 field2 ... } }&quot;}' \\ --data-urlencode 'extensions={&quot;persistedQuery&quot;:{&quot;version&quot;:1,&quot;sha256Hash&quot;:&quot;&lt;HASH&gt;&quot;}}' The server parses the full query, caches it for future use, and returns the GraphQL response. Subsequent requests use the hash.  This process optimizes network performance while allowing flexibility in the queries that can be run. You can read more about APQ here  ","version":null,"tagName":"h3"},{"title":"Problems with APQs​","type":1,"pageTitle":"The truth about scaling Automatic Persisted Queries","url":"/blog/the-truth-about-scaling-automatic-persisted-queries/#problems-with-apqs","content":" Thundering Herd Problem​  Consider a situation where a server has just been deployed or restarted, and the cache is empty. Now, multiple clients send hash requests for queries that are not yet cached.  Massive Error Responses: Since the cache is empty, the server returns errors for all hash requests, signaling the clients to send the full query strings. Simultaneous Full Query Requests: All clients now simultaneously send full query requests, causing a sudden surge in demand. Server Strain: The server must parse and cache each unique query, placing significant strain on its resources. This can lead to increased latency and even server failure if the demand is too high. Repeated Pattern: If the server struggles to cache the queries quickly enough, the clients may continue to receive errors and retry the full query requests, perpetuating the problem.  In an environment with many clients and dynamically changing queries, the system can become vulnerable to sudden surges in demand. This vulnerability can undermine the performance benefits APQs are designed to provide, leading to potential system instability.  Cache Limitations​  Queries are typically cached in memory, requiring cache warmup on each instance, hindering deployment on server-less solutions. An alternative could be using a centralized cache, but it typically nullifies performance gains due to serialization, deserialization, and IO call overhead.  Security Concerns​  Automatically persisting queries can cause memory leaks, as clients can send varying query combinations, exhausting server memory. Mitigation through cache size limits and eviction mechanisms may lead to frequent cache misses, leading to doubling request numbers.  ","version":null,"tagName":"h3"},{"title":"Possible Solution​","type":1,"pageTitle":"The truth about scaling Automatic Persisted Queries","url":"/blog/the-truth-about-scaling-automatic-persisted-queries/#possible-solution","content":" Persistent queries are a great improvement over regular queries. They clearly improve performance and are more secure. APQs on the other hand though try to give more flexibility they can become quite messy to deal with as you scale. One alternative that is significantly more effective, is to run GraphQL on Edge itself. Essentially write your own CDN layer that is smart enough to understand that it's a graphQL and deploy it on edge with caching and whatnot! This is hard, and that's exactly what Tailcall helps solve.  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"The truth about scaling Automatic Persisted Queries","url":"/blog/the-truth-about-scaling-automatic-persisted-queries/#conclusion","content":" Automatic persisted queries, while offering some advantages in network performance, reveal significant challenges when it comes to scaling. The complexities of caching, potential security risks, and the inherent problems with automatic persistence highlight that persisted queries may not be the one-size-fits-all solution they are often portrayed as.  The question of whether to implement PQ or APQ must be approached with caution, taking into account the specific requirements and potential scalability issues of your system. While they may serve as a useful tool in certain scenarios, understanding the limitations and conducting thorough analysis is vital to avoid falling into the trap of a solution that doesn't truly scale. This blog post has aimed to shed light on these complexities, encouraging a more nuanced perspective on a topic that is often oversimplified. ","version":null,"tagName":"h3"},{"title":"How Tailcall statically identifies N+1 issues in GraphQL","type":0,"sectionRef":"#","url":"/blog/tailcall-n+1-identification-algorithm/","content":"","keywords":"","version":null},{"title":"High-Level Working​","type":1,"pageTitle":"How Tailcall statically identifies N+1 issues in GraphQL","url":"/blog/tailcall-n+1-identification-algorithm/#high-level-working","content":" Unlike a traditional GraphQL implementation where the resolvers are written by hand, Tailcall encourages developers to take a configuration-driven approach. This has many benefits, and we have talked about them in our previous blog.  One of the main advantages of not handwriting is the ability to introspect and optimize. Let's take an example of two functions written in Rust, though the problem is evident in all general purpose programming languages.  const BASE_URL: &amp;str = &quot;https://jsonplaceholder.typicode.com&quot; // Describes a typical Post returned from the /posts API struct Post { id: i32, user_id: i32 title: String, body: String, user: Option&lt;User&gt; } // Describes a typical User object from the /users API struct User { id: i32 name: String, email: String } // Asynchronously retrieves a `User` object by making a GET request using the given `user_id`. async fn get_user(user_id: i32) -&gt; User { let response = request(Method::GET, format!(&quot;{}/users/{}&quot;, BASE_URL, user_id)).await; // Decode the body as a User decode(response.body) } // Asynchronously fetches and updates posts with user details from the API. async fn get_posts() -&gt; Vec&lt;Post&gt; { let response = request(Method::GET, format!(&quot;{}/posts&quot;, BASE_URL)).await; // Decode the response into a Vec&lt;Post&gt; let mut posts = decode(response.body) // Set the actual user by making an HTTP call for post in posts { post.user = Some(get_user(post.user_id).await); } posts }   You might have identified that there are few issues in the implementation above:  For each post item we end up making a call for the user independently, there is a clear N+1 issue here.It's possible that two posts can be written by the same user, and yet we will end up making duplicate calls for the same user.All calls to the /users API is being made in sequence, even though they can be paralyzed.There are multiple points of failure which the above code doesn't handle.  Now, yes all of these issues can be solved by better coding practices, using a Result type and using a DataLoader but that's besides the point. The point here is - Semantic analysis of any code is critical to building a robust systems and is only possible with some sort of human intervention typically in the form of code reviews or perhaps using some LLM if you are into that hype. What you can't do is - Write an algorithm to identify the N+1 issue in your GraphQL implementation that 100% accurate.  With a configuration its a completely different story, take the below Tailcall configuration for example:  schema @upstream( baseURL: &quot;https://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: ID! userId: ID! title: String! body: String! user: User @http(path: &quot;/users{{.value.userId}}&quot;) } type User { id: ID name: String email: String }   It's simple, expressive and doesn't expose the guts of how data will be queried, batched, deduped, parsed etc. Sure, configurations take away flexibility from writing anything but in return it liberates you from a ton of such nitty gritties of building a robust software system. The above configuration file can be parsed, validated and semantically analyzed accurately to identify issues such as N+1 very precisely using the check command as follows:    ","version":null,"tagName":"h2"},{"title":"The Algorithm​","type":1,"pageTitle":"How Tailcall statically identifies N+1 issues in GraphQL","url":"/blog/tailcall-n+1-identification-algorithm/#the-algorithm","content":" Tailcall reads your configuration, parses it, and internally stores it in an efficient graph data-structure that resembles a HashMap. This allows O(1) access to a GraphQL type which represented as a node by its name. Once the graph data-structure is ready we make it go through a series of validators, one of them being the N+1 tracker.  Now, here's where it gets fascinating. We use a Depth-First Search (DFS) algorithm, starting at the root query and traversing all the connected nodes. Let me walk you through this cool process:  Initialize two variables to track the currently traversed path and visited fields so that we can avoid cycles.Start at the root query and begin traversing the graph data structure.For each field in the current node, check if it has a resolver and is not batched. We know if the node contains a resolver if that node has a @http or a @grpc. Tailcall supports powerful batching primitives and if a field uses a Batch API, then that resolver is whitelisted and dropped from the list of potential N+1 candidates.If the field has a resolver and is not batched, and the current path contains a list, then the current path is added to the result.Otherwise, we recursively traverse the graph data structure, updating the current path and visited fields as necessary.If a cycle is detected, return the cached result instead of re-traversing the path.Once the traversal is complete, return the result, which represents the identified N+1 issues.  This algorithm allows Tailcall to efficiently identify potential N+1 issues across your entire GraphQL schema, even in complex, deeply nested structures.  tip To see the actual implementation you can check out the tracker.rs implementation.  ","version":null,"tagName":"h2"},{"title":"Performance​","type":1,"pageTitle":"How Tailcall statically identifies N+1 issues in GraphQL","url":"/blog/tailcall-n+1-identification-algorithm/#performance","content":" While starting, Tailcall automatically performs these validations and one of our users complained that it would take around 5 minutes to start the server for their configuration which was around 10,000 lines. This caught our attention! The thing is, finding N+1 issues is a complex dynamic-programming problem. All this while our team has been focused on benchmarking and optimizing the runtime performance of the server. This was the first time perhaps that we were surprised to see such a degradation in performance. We quickly realized that this is a dynamic programming problem and there are certain tricks to make such algorithms efficient. For us, it boiled down to two key optimizations:  ","version":null,"tagName":"h2"},{"title":"1. Memoization​","type":1,"pageTitle":"How Tailcall statically identifies N+1 issues in GraphQL","url":"/blog/tailcall-n+1-identification-algorithm/#1-memoization","content":" Our algorithm uses a cache to store the results of previous traversals. The cache is used to avoid re-traversing the same path multiple times. It's essentially memoization however is super critical if you have a huge configuration that you'd want to validate.  ","version":null,"tagName":"h3"},{"title":"2. Chunk Data Structure​","type":1,"pageTitle":"How Tailcall statically identifies N+1 issues in GraphQL","url":"/blog/tailcall-n+1-identification-algorithm/#2-chunk-data-structure","content":" Let me introduce you to our secret weapon: a special yet simple data structure that we affectionately call &quot;Chunk&quot;. It's a game-changer for storing and manipulating query paths. The chunk data structure is implemented as an enum with three variants:  enum Chunk&lt;A&gt; { Empty, Append(A, Rc&lt;Chunk&lt;A&gt;&gt;), Concat(Rc&lt;Chunk&lt;A&gt;&gt;, Rc&lt;Chunk&lt;A&gt;&gt;) } impl&lt;A&gt; Chunk&lt;A&gt; { pub fn new() -&gt; Self { Self::Empty } pub fn is_null(&amp;self) -&gt; bool { matches!(self, Chunk::Empty) } pub fn append(self, a: A) -&gt; Self { Chunk::Append(a, Rc::new(self)) } pub fn concat(self, other: Chunk&lt;A&gt;) -&gt; Self { if self.is_null() { return other; } if other.is_null() { return self; } Self::Concat(Rc::new(self), Rc::new(other)) } pub fn as_vec(&amp;self) -&gt; Vec&lt;&amp;A&gt; { // ... converts the chunk into a vec } }   Variant\tNil\tRepresents an empty chunk Append\tRepresents an append operation performed on an existing chunk Concat\tRepresents the concatenation of two chunks  The chunk data structure has the following properties:  O(1) complexity for append and concat operations.Uses Reference Counting instead of Boxing to make cloning faster.Can be converted to a vector of references to the elements in the chunk.  You can clearly see that we don't actually perform an append or a concat operation instead we store a representation of that operation. This is a significant optimization because while performing the DFS, we create a lot of temporary query paths. However with the chunk data structure we don't need to allocate any additional memory on the heap or perform any form of wasted computation for paths that don't produce an N+1 query.  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"How Tailcall statically identifies N+1 issues in GraphQL","url":"/blog/tailcall-n+1-identification-algorithm/#conclusion","content":" Lastly to ensure that we are always correct and no N+1 issues go unidentified we perform tests with actual configurations.    Hopefully, this peek behind the curtain gives you some insight into how Tailcall identifies N+1 issues in your GraphQL configuration. Pretty cool, right?  If you think we can make our N+1 detection faster or better in some other way, please help us improve by contributing 🙏If you find this interesting please spread the word 🙌 ","version":null,"tagName":"h2"},{"title":"Writing a GraphQL Backend by Hand is Long Gone","type":0,"sectionRef":"#","url":"/blog/writing-a-graphql-backend-by-hand-is-long-gone/","content":"","keywords":"","version":null},{"title":"Complexity with GraphQL​","type":1,"pageTitle":"Writing a GraphQL Backend by Hand is Long Gone","url":"/blog/writing-a-graphql-backend-by-hand-is-long-gone/#complexity-with-graphql","content":" If you see, most of the concerns with GraphQL are around building a robust GraphQL backend. It's rarely about consuming GraphQL, because if you look closely at the GraphQL spec, you will find that it's focused on how to elegantly consume data. As long as the output of your backend matches what's expected in the query, the specification doesn't care about how the backend is implemented.  Hence, the main complexity with GraphQL comes with how GraphQL is built. One of the major hurdles in hand-coding a GraphQL backend is managing performance. Issues like batching, incorrect usage of data loaders, caching, and the notorious N+1 problem can cripple your application.  Manually implementing batching mechanisms and data loaders can be incredibly tedious. While libraries like DataLoader can assist, integrating them seamlessly into your system requires a deep understanding of both your data and the GraphQL query patterns. Overuse of data loaders is so common with most GraphQL implementations that ultimately it becomes the main culprit for high latency.  Secondly, traditional caching doesn't work with GraphQL, so you have to resort to all sorts of solutions, using persisted queries or some vendor-specific implementation of caching. Implementing effective caching strategies is essential for performance but it's tricky. Developers must decide what to cache, when to invalidate the cache, and how to manage cache consistency, which adds another layer of complexity.  The N+1 issue, boy, that's perhaps everyone's favorite issue with GraphQL. It arises when executing multiple upstream requests that could have been combined into one, leading to massive performance degradation. Detecting and solving this requires meticulous analysis of query patterns and database access, which requires developers to have the context of the whole query at once, generate a query plan, translate it to appropriate upstream calls, and then execute! That's a lot of complex engineering effort; building a general-purpose query engine is not for the faint-hearted, and in the midst of all this complex yet interesting work, I need to ship features!  Grafast is an upcoming generalized query planner that could make query-planning in JS a bit more tamed.  GraphQL’s flexibility can be a double-edged sword when it comes to security, necessitating robust mechanisms for authentication and authorization. Like caching, traditional route-based API access doesn't work with GraphQL. Implementing these security layers correctly involves ensuring that only authenticated users can access the GraphQL entity and that they can only access data or fields that they are authorized to see. This requires fine-grained control and often custom logic and the invention of a new standard that works just for you.  Lastly, but most importantly, ensuring your GraphQL API is reliable means tackling error handling, propagation, and telemetry. Proper error handling in GraphQL is crucial for providing meaningful feedback to clients and maintaining the integrity of your application. The GraphQL team recently started working on a standard for serving GraphQL over HTTP, which won't be easy to integrate if you already have a GraphQL API running in production. Moreover, integrating telemetry within a GraphQL backend isn't easy either; it is a very involved process to integrate spans to trace GraphQL resolvers. And, if you have written your GraphQL layer by hand in JavaScript, be ready for some significant performance degradation.  ","version":null,"tagName":"h2"},{"title":"GraphQL is more like SQL and less like REST​","type":1,"pageTitle":"Writing a GraphQL Backend by Hand is Long Gone","url":"/blog/writing-a-graphql-backend-by-hand-is-long-gone/#graphql-is-more-like-sql-and-less-like-rest","content":" We talked about it in our previous blog why GraphQL isn't like REST or gRPC. I would argue that SQL is a closer elder sibling of GraphQL than REST or gRPC. Writing a GraphQL backend can be likened to building an SQL engine manually. Imagine if every time you wanted to interact with a database, you had to write the SQL engine from scratch. Every time you made a database change, you would need to rewrite your engine so that it can work with the new schema or indexes. It’s inefficient and impractical; no one does that. Fortunately, modern databases come with embedded, high-performance SQL engines such as Apache Calcite that adhere to the SQL specification but abstract away the complexities around building it. These databases allow developers to focus on writing queries and managing data without worrying about the underlying mechanics, thanks to their sophisticated query engines.  GraphQL, much like SQL, is a query language designed to allow clients to request exactly the data they need. Unlike REST, which relies on fixed endpoints, or gRPC, which focuses on remote procedure calls, GraphQL provides a flexible, hierarchical way to fetch and manipulate data, making it a closer analog to SQL in terms of expressiveness and precision. And I believe the future of GraphQL is going to be like the journey of this elder sibling.  ","version":null,"tagName":"h2"},{"title":"The future of GraphQL​","type":1,"pageTitle":"Writing a GraphQL Backend by Hand is Long Gone","url":"/blog/writing-a-graphql-backend-by-hand-is-long-gone/#the-future-of-graphql","content":" The future of GraphQL development is moving towards generalized automated solutions built on modern, low-level system stacks like Rust and Zig, and moving away from the prevalent hand-written Node.js-based solutions of today.    These engines will connect to data sources of any type and build a GraphQL endpoint on top of them. They will find connections between other data sources, sometimes completely automatically and sometimes using hints given by the developer, creating a unified GraphQL experience. Similar to SQL engines, which use JIT techniques to identify performance optimizations at runtime, GraphQL engines will become extremely smart about performance. My hope is that GraphQL will eventually move away from its dependency on the JSON protocol, into something more efficient such as protobuf. There is definitely going to be a lot of work put into the standardization of the loose ends. GraphQL engines will eventually converge on error handling and error propagation strategies. GraphQL on HTTP is the first step in that direction. Authentication and Authorization too will very quickly become standard features of GraphQL, so you won't need to worry about inventing a new way of authentication. This will all be packed into a GraphQL standard. This might be a stretch, but if the standards team gets together, I think even GraphQL caching will be consistent across all GraphQL engines, and you will be able to switch from one caching solution to another without locking into a vendor-specific implementation.  You might have already seen a wave of open-source solutions that build GraphQL on top of existing data sources. One such solution paving the way is Tailcall. Tailcall’s platform is designed to automate the creation, validation, and optimization of GraphQL backends. Sticking to standards and ensuring developers don't ever have to pay the heavy tax of using GraphQL that they do today, do check it out!  Lastly, if you are reading this today and thinking of writing a GraphQL server by hand, I urge you to reconsider and use something that does this for you. Before you know it, your handwritten solution will be deprecated in favor of something faster, easier, and more secure: an automatic GraphQL solution. ","version":null,"tagName":"h2"},{"title":"gRPC Decoded: The API Protocol That's Changing Everything","type":0,"sectionRef":"#","url":"/blog/what-is-grpc/","content":"","keywords":"","version":null},{"title":"The Evolution of API Communication​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#the-evolution-of-api-communication","content":"   Request–response protocols date back to early distributed computing in the late 1960s. Theoretical proposals of remote procedure calls as the model of network operations date to the 1970s, with practical implementations emerging in the early 1980s. Traditional RPC mechanisms had limitations in terms of performance, language independence, and flexibility. gRPC addresses these issues by leveraging modern protocols and technologies.  gRPC was initially created by Google, which used a single general-purpose RPC infrastructure called Stubby to connect its numerous microservices. In 2015, Google decided to build the next version of Stubby and make it open source.  ","version":null,"tagName":"h2"},{"title":"Understanding gRPC​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#understanding-grpc","content":" gRPC is a high-performance, language-neutral RPC framework. It uses Protobuf for serialization and HTTP/2 for transport, offering features like streaming, multiplexing, and bidirectional communication. It uses HTTP/2 for transport, Protocol Buffers as the interface description language, and provides features such as authentication, bidirectional streaming and flow control, blocking or nonblocking bindings, and cancellation and timeouts.  ","version":null,"tagName":"h2"},{"title":"Key components of gRPC​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#key-components-of-grpc","content":" Protocol Buffers (Protobuf): A language-neutral, platform-neutral, extensible mechanism for serializing structured data. It is used to define the structure of messages (request and response payloads) that gRPC services exchange. HTTP/2: Provides additional capabilities such as multiplexing, header compression, and server push, which are not as efficient and reliable in HTTP/1.1  ","version":null,"tagName":"h3"},{"title":"How gRPC works (step-by-step process)​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#how-grpc-works-step-by-step-process","content":"   gRPC (Remote Procedure Call) works using a straightforward yet powerful mechanism that facilitates communication between clients and servers in a distributed system.  ","version":null,"tagName":"h3"},{"title":"1. Service Definition​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#1-service-definition","content":" Protocol Buffers (Protobuf): The starting point for using gRPC is defining a service and its methods using Protocol Buffers (Protobuf). Protobuf is a language-neutral, platform-neutral, extensible mechanism for serializing structured data. The structure of data and services is defined in a .proto file.  An Example Snippet From Linkerd  Example of a simple .proto file :  syntax = &quot;proto3&quot;; package calculator; service CalculatorService { rpc Add (AddRequest) returns (AddResponse); } message AddRequest { double number1 = 1; double number2 = 2; } message AddResponse { double result = 1; }   ","version":null,"tagName":"h3"},{"title":"2. Code Generation​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#2-code-generation","content":" Once a service is defined in a .proto file, the Protocol Buffer compiler (protoc) is used to generate client and server code in your chosen programming languages. This step is crucial as it automates the creation of the boilerplate code needed for the gRPC service and client to communicate effectively. The generated code includes:  Service Stubs: These are classes with methods that correspond to the service methods defined in the .proto file. They handle the marshalling and unmarshalling of request and response messages, abstracting away the complexities of network communication. Client-Side Stubs: These are used by the client application to make remote procedure calls to the server. The client stubs handle the creation and sending of requests, as well as receiving and processing responses.  For Example if the calculator example is converted to python, it would look something like this:  # -*- coding: utf-8 -*- # Generated by the protocol buffer compiler. DO NOT EDIT! # source: calculator &quot;&quot;&quot;Generated protocol buffer code.&quot;&quot;&quot; from google.protobuf import descriptor as _descriptor from google.protobuf import descriptor_pool as _descriptor_pool from google.protobuf import message as _message from google.protobuf import reflection as _reflection from google.protobuf import symbol_database as _symbol_database # @@protoc_insertion_point(imports) _sym_db = _symbol_database.Default() DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\ncalculator\\x12\\ncalculator\\&quot;.\\n\\nAddRequest\\x12\\x0f\\n\\x07number1\\x18\\x01 \\x01(\\x01\\x12\\x0f\\n\\x07number2\\x18\\x02 \\x01(\\x01\\&quot;\\x1d\\n\\x0b\\x41\\x64\\x64Response\\x12\\x0e\\n\\x06result\\x18\\x01 \\x01(\\x01\\x32K\\n\\x11\\x43\\x61lculatorService\\x12\\x36\\n\\x03\\x41\\x64\\x64\\x12\\x16.calculator.AddRequest\\x1a\\x17.calculator.AddResponseb\\x06proto3') _ADDREQUEST = DESCRIPTOR.message_types_by_name['AddRequest'] _ADDRESPONSE = DESCRIPTOR.message_types_by_name['AddResponse'] AddRequest = _reflection.GeneratedProtocolMessageType('AddRequest', (_message.Message,), { 'DESCRIPTOR' : _ADDREQUEST, '__module__' : 'calculator_pb2' # @@protoc_insertion_point(class_scope:calculator.AddRequest) }) _sym_db.RegisterMessage(AddRequest) AddResponse = _reflection.GeneratedProtocolMessageType('AddResponse', (_message.Message,), { 'DESCRIPTOR' : _ADDRESPONSE, '__module__' : 'calculator_pb2' # @@protoc_insertion_point(class_scope:calculator.AddResponse) }) _sym_db.RegisterMessage(AddResponse) _CALCULATORSERVICE = DESCRIPTOR.services_by_name['CalculatorService'] if _descriptor._USE_C_DESCRIPTORS == False: DESCRIPTOR._options = None _ADDREQUEST._serialized_start=26 _ADDREQUEST._serialized_end=72 _ADDRESPONSE._serialized_start=74 _ADDRESPONSE._serialized_end=103 _CALCULATORSERVICE._serialized_start=105 _CALCULATORSERVICE._serialized_end=180 # @@protoc_insertion_point(module_scope)   ","version":null,"tagName":"h3"},{"title":"3. Client-Server Communication​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#3-client-server-communication","content":" Transmission: When a gRPC client initiates a request to a gRPC server, it sends an HTTP/2 request containing the service name, specific method, and serialized parameters using Protobuf. HTTP/2's advantages include multiplexing, enabling concurrent handling of multiple streams over a single connection, binary framing that minimizes overhead and accelerates data exchange, efficient header compression via HPACK, and integrated flow control mechanisms.  ","version":null,"tagName":"h3"},{"title":"4. Serialization and Deserialization​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#4-serialization-and-deserialization","content":" Protobuf Serialization: Data exchanged between gRPC clients and servers is serialized and deserialized using Protobuf.  ","version":null,"tagName":"h3"},{"title":"gRPC Service Methods​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#grpc-service-methods","content":"   Unary RPC: This is the simplest form where the client sends a single request to the server and receives a single response: service MyService { rpc UnaryExample(MyRequest) returns (MyResponse); } Server Streaming RPC: The client sends a request to the server and receives a stream of responses: service MyService { rpc UnaryExample(MyRequest) returns (stream MyResponse); } Client Streaming RPC: The client sends a stream of requests to the server and receives a single response: service MyService { rpc UnaryExample(stream MyRequest) returns (MyResponse); } Bidirectional Streaming RPC: Both the client and server send a stream of messages to each other, establishing a persistent connection: service MyService { rpc UnaryExample(stream MyRequest) returns (stream MyResponse); }   ","version":null,"tagName":"h2"},{"title":"gRPC vs. REST: Basic Comparison​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#grpc-vs-rest-basic-comparison","content":"   A comparison of payload sizes: REST JSON vs gRPC binary checkout full comparison   ","version":null,"tagName":"h2"},{"title":"Communication model​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#communication-model","content":" gRPC: RPC-based, strong typing, and allows unary and bi-directional streaming, making it feasible for modern-day applications and use-cases.REST: Stateless, used for CRUD-based operations over HTTP, follows a simple unary request/response cycle.  ","version":null,"tagName":"h3"},{"title":"Data format and serialization​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#data-format-and-serialization","content":" gRPC: Uses Protobuf for efficient binary serialization.REST: Uses a plain-text format like JSON and XML, which requires more processing in order to parse.  ","version":null,"tagName":"h3"},{"title":"Use cases for each​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#use-cases-for-each","content":" gRPC: Suitable for internal microservices, real-time applications, and situations needing high-performance and time-sensitive communication.REST: Better for public APIs, browser-based applications, and situations requiring stateless operations where ease of use is a priority.  ","version":null,"tagName":"h3"},{"title":"Advantages of gRPC​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#advantages-of-grpc","content":" ","version":null,"tagName":"h2"},{"title":"Efficiency and performance​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#efficiency-and-performance","content":"   Protobuf efficiently serializes messages on both the server and client sides, ensuring that data is transmitted in a compact binary format. This results in smaller message payloads, which are quicker to transmit over the network compared to the verbose JSON format used in REST APIs.  In addition, HTTP/2 uses features like header-compression, multiplexing and server-push which significantly reduce the payload size, as well as make response faster.  These features collectively contribute to significant performance gains, making gRPC 7-10 times faster than traditional REST APIs using JSON.  ","version":null,"tagName":"h3"},{"title":"Language-agnostic nature​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#language-agnostic-nature","content":"   gRPC uses Protocol Buffers (Protobuf) as its (IDL) for describing both the structure and the semantics of the messages sent between clients and servers. Protobuf is independent of programming languages, meaning you can define your API once using Protobuf and then generate code in various languages to interact with it. This allows seamless integration of sub-systems API specification, while also enhancing the DX.  ","version":null,"tagName":"h3"},{"title":"Strong typing and code generation​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#strong-typing-and-code-generation","content":" Protocol Buffers (Protobuf) defines both the structure and the types of messages exchanged between clients and servers within a .proto file, thereby establishing a clear and standardized API contract. This contract specifies the fields and their data types for each message, ensuring consistency and predictability in communication. By enforcing strong typing, Protobuf enhances code reliability by detecting type-related errors during compilation rather than at runtime. This approach not only prevents type mismatches and potential bugs but also saves developers time that would otherwise be spent implementing manual type-checking. Additionally, Protobuf's built-in type safety simplifies the development process, allowing developers to focus more on business logic and less on handling data integrity issues, thus improving the developer experience.  ","version":null,"tagName":"h3"},{"title":"Bidirectional streaming capabilities​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#bidirectional-streaming-capabilities","content":" Unlike traditional RPC methods that are unidirectional (either client-to-server or server-to-client), gRPC's bidirectional streaming allows both parties to establish a persistent connection and send a sequence of messages asynchronously.  Bidirectional streaming is particularly beneficial for applications requiring interactive and responsive communication, such as chat systems, collaborative tools, multiplayer games, and real-time data feeds.  ","version":null,"tagName":"h3"},{"title":"Extensibility and backward compatibility​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#extensibility-and-backward-compatibility","content":" gRPC using Protobuf as the IDL opens support for extensibility by allowing new fields, messages, and services to be added to the .proto file definitions. As services evolve, these changes can be propagated through automated code generation using the protoc compiler, which produces language-specific stubs and serializers/deserializers.  Moreover, explicit versioning and API contracts defined in the .proto files help manage compatibility between different versions of services. During the RPC connection handshake, gRPC allows clients and servers to negotiate capabilities, ensuring that both parties can communicate effectively even if they support different versions or extensions.  Example:  syntax = &quot;proto3&quot;; package greet.v1; service Greeter { rpc SayHello (HelloRequest) returns (HelloReply); } message HelloRequest { string name = 1; } message HelloReply { string message = 1; }   ","version":null,"tagName":"h3"},{"title":"Challenges and Considerations​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#challenges-and-considerations","content":" ","version":null,"tagName":"h2"},{"title":"Learning curve​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#learning-curve","content":" gRPC has a much steeper learning curve compared to the traditional REST, mainly due to some new concepts like HTTP/2 and Protobuf which require significant practice and experience.  ","version":null,"tagName":"h3"},{"title":"Debugging complexity​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#debugging-complexity","content":" Debugging gRPC applications can be really challenging compared to traditional REST APIs. The binary nature of Protobuf messages makes it difficult to inspect and manipulate payloads directly. Tools for debugging and tracing gRPC calls are available, but they often require additional setup and expertise.  ","version":null,"tagName":"h3"},{"title":"Ecosystem maturity​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#ecosystem-maturity","content":" While gRPC has gained significant traction and support, its ecosystem is still maturing compared to REST. Some languages and frameworks may have limited or incomplete support for gRPC features. Additionally, there is less developer support on the internet, less browser-support and very few articles published which makes it challenging to learn especially for beginners.  ","version":null,"tagName":"h3"},{"title":"Browser support limitations​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#browser-support-limitations","content":" Current browser limitations prevent direct implementation of the HTTP/2 gRPC specification. Browsers lack the necessary APIs to provide fine-grained control over requests. For instance:  There's no way to enforce the use of HTTP/2.Even if HTTP/2 could be enforced, browsers can't access raw HTTP/2 frames.  To address these limitations, the gRPC-Web specification was developed. It builds upon the HTTP/2 spec but introduces key differences:  Support for both HTTP/1.1 and HTTP/2 protocols.A new method for handling gRPC trailers: Trailers are sent at the very end of request/response bodies.A new bit in the gRPC message header indicates the presence of trailers. Requirement of a proxy server: This proxy translates between gRPC-Web requests and standard gRPC HTTP/2 responses.It's a mandatory component in the gRPC-Web architecture.  These adaptations allow gRPC-like functionality in web browsers while working within current browser constraints.  gRPC is powerful for service to service communication, but it may not be the best choice for public APIs or browser-based applications where REST/GraphQL is more prevalent.  tip To seamlessly integrate the benefits of both gRPC and GraphQL, you can easily generate GraphQL from gRPC using Tailcall. Check out the documentation here: gRPC to GraphQL .Automated gRPC to GraphQL  ","version":null,"tagName":"h3"},{"title":"Implementing gRPC: Best Practices​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#implementing-grpc-best-practices","content":" ","version":null,"tagName":"h2"},{"title":"Designing Effective Protobuf Schemas​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#designing-effective-protobuf-schemas","content":" Creating efficient and maintainable Protobuf schemas is crucial. Use meaningful field names and provide clear comments for each field, otherwise you may end up in a nested jargon of types! Versioning schemas properly ensures backward and forward compatibility makes it easier to evolve your API without breaking existing clients.  ","version":null,"tagName":"h3"},{"title":"Error Handling and Status Codes​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#error-handling-and-status-codes","content":" Define and document all possible error codes your service can return. Consistent and informative error messages aid in debugging and provide a better experience for developers integrating with your API, if the API is not verbose about the error, the developer trying to integrate the API on the other side may get frustrated:  info A bad API is like a traffic jam - frustrating, confusing, and costly. - Joshua Bloch  ","version":null,"tagName":"h3"},{"title":"Security Considerations (Authentication, Encryption)​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#security-considerations-authentication-encryption","content":" Secure your gRPC services by implementing authentication and encryption. Use Transport Layer Security (TLS) to encrypt communication between clients and servers. Leverage gRPC's support for various authentication mechanisms, such as OAuth, JWT, or custom tokens, to ensure that only authorized clients can access your services.  ","version":null,"tagName":"h3"},{"title":"Performance Optimization Techniques​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#performance-optimization-techniques","content":" gRPC API performance can be boosted in many ways. The channels are expensive to make, and reusing them instead of remaking has a significant impact.  Example:  const grpc = require(&quot;grpc&quot;) // Singleton instance for the gRPC channel let channel = null function getGrpcChannel() { if (!channel) { // Create a new channel if it doesn't exist channel = new grpc.Client(&quot;localhost:50051&quot;, grpc.credentials.createInsecure()) } return channel } // Example usage: const myChannel = getGrpcChannel() // Use `myChannel` to make gRPC calls   Alongside with reusing channels, many other ways can improve performance like implementing load-balancers and using streaming instead of unary where needed.  ","version":null,"tagName":"h3"},{"title":"gRPC Use Cases and Real-World Examples​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#grpc-use-cases-and-real-world-examples","content":" ","version":null,"tagName":"h2"},{"title":"Microservices Architecture​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#microservices-architecture","content":" gRPC is well-suited for microservices architectures, enabling efficient communication between services. Companies like Netflix and Google use gRPC to connect their microservices, benefiting from its performance and strong typing. It ensures reliable, low-latency communication, which is crucial for maintaining responsive and scalable microservices.  ","version":null,"tagName":"h3"},{"title":"Real-Time Communication Systems​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#real-time-communication-systems","content":"   gRPC is ideal for real-time communication systems such as chat applications, online gaming, and live streaming services. Its support for bidirectional streaming allows for seamless and efficient data exchange between clients and servers, enabling real-time interactions and reducing latency.  A snippet from Open-Match, a gaming framework:   // Tickets in matches returned by FetchMatches are moved from active to // pending, and will not be returned by query. rpc FetchMatches(FetchMatchesRequest) returns (stream FetchMatchesResponse) { option (google.api.http) = { post: &quot;/v1/backendservice/matches:fetch&quot; body: &quot;*&quot; }; }   ","version":null,"tagName":"h3"},{"title":"IoT and Edge Computing​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#iot-and-edge-computing","content":" In IoT and edge computing scenarios, gRPC's low overhead and efficient communication make it suitable for resource-constrained devices. It enables reliable communication between edge devices and central servers, facilitating data collection, processing, and command execution in real time.  ","version":null,"tagName":"h3"},{"title":"Mobile and Web Applications​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#mobile-and-web-applications","content":" gRPC is increasingly used in mobile and web applications to improve performance and reduce bandwidth usage. For example, companies like Lyft use gRPC to enhance the efficiency of their mobile apps, ensuring faster response times and a smoother user experience.  ","version":null,"tagName":"h3"},{"title":"Tools and Frameworks for gRPC Development​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#tools-and-frameworks-for-grpc-development","content":" ","version":null,"tagName":"h2"},{"title":"Popular gRPC Libraries for Different Languages​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#popular-grpc-libraries-for-different-languages","content":" gRPC has libraries and tooling support for various programming languages:  gRPC Core - C, C++, Ruby, Node.js, Python, PHP, C#, Objective-CgRPC Java - The Java gRPC implementation. HTTP/2 based RPCgRPC Node.js - gRPC for Node.jsgRPC Go - The Go language implementation of gRPC. HTTP/2 based RPCgRPC C# - The C# language implementation of gRPCgRPC Web - gRPC for Web Clients  ","version":null,"tagName":"h3"},{"title":"Testing and Debugging Tools​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#testing-and-debugging-tools","content":" ghzgatling-grpc  ","version":null,"tagName":"h3"},{"title":"API Management Platforms​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#api-management-platforms","content":" Postmanletmegrpc  ","version":null,"tagName":"h3"},{"title":"Future of gRPC and API Communication​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#future-of-grpc-and-api-communication","content":" ","version":null,"tagName":"h2"},{"title":"Emerging Trends in API Design​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#emerging-trends-in-api-design","content":" The future of API design is moving towards more efficient and flexible communication protocols like gRPC. With the rise of microservices, IoT, and real-time applications, gRPC's performance advantages make it a compelling choice. Trends like GraphQL and RESTful JSON APIs will continue to coexist, but gRPC will gain traction for specific use cases requiring high efficiency and low latency.  ","version":null,"tagName":"h3"},{"title":"gRPC's Role in Cloud-Native Applications​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#grpcs-role-in-cloud-native-applications","content":" gRPC is becoming a cornerstone of cloud-native applications, facilitating communication in containerized environments orchestrated by platforms like Kubernetes. Its ability to handle high-performance, low-latency communication is essential for the scalability and reliability of cloud-native architectures.  ","version":null,"tagName":"h3"},{"title":"Potential Improvements and Extensions​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#potential-improvements-and-extensions","content":" The gRPC ecosystem is continuously evolving, with potential improvements and extensions on the horizon. Enhancements in tooling, support for more languages, better integration with existing frameworks, and increased adoption of gRPC-Web are some areas of expected growth. The community's efforts to address current limitations will make gRPC more accessible and robust for a wider range of applications.  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#conclusion","content":" Recap of gRPC's key features and benefits​  In summary, gRPC offers efficient, low-latency communication, strong typing through Protobuf, and support for multiple languages. Its bidirectional streaming and multiplexing capabilities make it ideal for real-time and microservices-based applications. The performance and reliability of gRPC provide significant advantages over traditional REST APIs in many scenarios, mainly because of the new HTTP/2 and its binary nature.  Considerations for Adopting gRPC in Projects​  When considering gRPC for your projects, ensure that your team is prepared to handle the challenges and leverage the best practices discussed to design, implement, and maintain robust gRPC services. Make sure you have enough support resources and officials, as gRPC doesn't have a community as large as REST.  ","version":null,"tagName":"h2"},{"title":"Further Resources​","type":1,"pageTitle":"gRPC Decoded: The API Protocol That's Changing Everything","url":"/blog/what-is-grpc/#further-resources","content":" Official documentation and tutorials​  gRPC Official Documentation  Community forums and support​  gRPC Twitter handlegRPC StackOverflow taggRPC Gitter roomgRPC Google Group  Books for in-depth learning​  gRPC: Up and RunninggRPC Microservices in Go ","version":null,"tagName":"h3"},{"title":"GraphQL in Vue: 5 Best Approaches for Data Fetching","type":0,"sectionRef":"#","url":"/blog/graphql-vue-client/","content":"","keywords":"","version":null},{"title":"🛠️ Project Setup​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#️-project-setup","content":" Let's start by setting up our Vue project with Vite, which provides a faster and leaner development experience:  npm create vite@latest vue-graphql-tailcall-showcase -- --template vue-ts cd vue-graphql-tailcall-showcase npm install   This creates a new Vue 3 project with TypeScript support. Now, let's install the necessary dependencies for our GraphQL experiments:  npm install @apollo/client @vue/apollo-composable graphql npm install @urql/vue npm install axios npm install villus   These installations will allow us to explore different GraphQL client options in our Vue application.  ","version":null,"tagName":"h2"},{"title":"🔧 Tailcall Backend Configuration​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#-tailcall-backend-configuration","content":" Now, let's set up our Tailcall backend that will wrap the JSONPlaceholder API, providing a GraphQL interface to RESTful data.  First, create a tailcall directory in the project root:  mkdir tailcall   Then, create a jsonplaceholder.graphql file in this directory:  # File: tailcall/jsonplaceholder.graphql schema @server(port: 8000, hostname: &quot;0.0.0.0&quot;) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; httpCache: 42 ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) }   This GraphQL schema defines our API structure, mapping RESTful endpoints to GraphQL types and queries.  To start the Tailcall server, you'll need to have Tailcall installed. If you haven't installed it yet, follow the installation instructions from the Tailcall documentation. Once installed, you can start the server with:  tailcall start ./tailcall/jsonplaceholder.graphql   This command starts a GraphQL server on http://localhost:8000, which will act as a bridge between our Vue application and the JSONPlaceholder API.  With this setup, we're ready to dive into the exciting world of GraphQL in Vue! 🚀 Our Tailcall backend provides a perfect playground for exploring different GraphQL client approaches, allowing us to fetch posts and user data with the flexibility and power of GraphQL queries. In the following sections, we'll explore how to leverage this backend with various GraphQL clients in our Vue application. Get ready for some data-fetching magic! ✨  Alright, let's dive into our first approach: Apollo Client! 🚀  ","version":null,"tagName":"h3"},{"title":"Apollo Client - The Swiss Army Knife of GraphQL​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#apollo-client---the-swiss-army-knife-of-graphql","content":" Apollo Client stands out in the GraphQL ecosystem due to its comprehensive feature set, including intelligent caching, real-time updates, and optimistic UI rendering. For Vue developers working on data-intensive applications, Apollo Client provides a sophisticated approach to state management and data fetching.  ","version":null,"tagName":"h2"},{"title":"1. Setting Up Apollo Client in a Vue.js Project​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#1-setting-up-apollo-client-in-a-vuejs-project","content":" Begin by installing the necessary packages:  npm install @apollo/client @vue/apollo-composable graphql   Configuration​  Set up Apollo Client in your Vue application:  // src/apollo.ts import { ApolloClient, InMemoryCache, createHttpLink, } from &quot;@apollo/client/core&quot; const httpLink = createHttpLink({ uri: &quot;https://your-graphql-endpoint.com/graphql&quot;, }) export const apolloClient = new ApolloClient({ link: httpLink, cache: new InMemoryCache(), defaultOptions: { watchQuery: { fetchPolicy: &quot;cache-and-network&quot;, }, }, }) // main.ts import {createApp, provide, h} from &quot;vue&quot; import {DefaultApolloClient} from &quot;@vue/apollo-composable&quot; import App from &quot;./App.vue&quot; import {apolloClient} from &quot;./apollo&quot; const app = createApp({ setup() { provide(DefaultApolloClient, apolloClient) }, render: () =&gt; h(App), }) app.mount(&quot;#app&quot;)   This configuration creates an Apollo Client instance with a default in-memory cache and provides it to the entire Vue application.  ","version":null,"tagName":"h3"},{"title":"2. Executing Queries with Apollo Client​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#2-executing-queries-with-apollo-client","content":" Apollo Client provides the useQuery composable for executing GraphQL queries. Here's an example of fetching a list of posts:  &lt;script setup lang=&quot;ts&quot;&gt; import {useQuery} from &quot;@vue/apollo-composable&quot; import gql from &quot;graphql-tag&quot; import {computed} from &quot;vue&quot; interface Post { id: number title: string body: string user: { name: string } } const GET_POSTS = gql` query GetPosts($limit: Int!) { posts(limit: $limit) { id title body user { name } } } ` const {result, loading, error, refetch} = useQuery&lt;{ posts: Post[] }&gt;(GET_POSTS, { limit: 10, }) const posts = computed(() =&gt; result.value?.posts || []) const fetchPosts = () =&gt; { refetch() } &lt;/script&gt; &lt;template&gt; &lt;div&gt; &lt;button @click=&quot;fetchPosts&quot; :disabled=&quot;loading&quot;&gt; Fetch Posts &lt;/button&gt; &lt;div v-if=&quot;loading&quot;&gt;Loading...&lt;/div&gt; &lt;ul v-else-if=&quot;posts.length&quot;&gt; &lt;li v-for=&quot;post in posts&quot; :key=&quot;post.id&quot;&gt; {{ post.title }} by {{ post.user.name }} &lt;/li&gt; &lt;/ul&gt; &lt;div v-else-if=&quot;error&quot;&gt;Error: {{ error.message }}&lt;/div&gt; &lt;/div&gt; &lt;/template&gt;   This example demonstrates:  Defining a GraphQL query using gql tagUsing the useQuery composable to manage the query executionHandling loading, error, and success statesImplementing a refetch mechanism for manual query execution  ","version":null,"tagName":"h3"},{"title":"3. Mutations and Optimistic Updates​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#3-mutations-and-optimistic-updates","content":" Apollo Client supports GraphQL mutations with optimistic updates for responsive UIs:  &lt;script setup lang=&quot;ts&quot;&gt; import {useMutation} from &quot;@vue/apollo-composable&quot; import gql from &quot;graphql-tag&quot; import {ref} from &quot;vue&quot; const CREATE_POST = gql` mutation CreatePost($title: String!, $body: String!) { createPost(input: {title: $title, body: $body}) { id title body } } ` const { mutate: createPost, loading, error, } = useMutation(CREATE_POST) const title = ref(&quot;&quot;) const body = ref(&quot;&quot;) const submitPost = async () =&gt; { try { const {data} = await createPost( { title: title.value, body: body.value, }, { optimisticResponse: { createPost: { __typename: &quot;Post&quot;, id: &quot;temp-id&quot;, title: title.value, body: body.value, }, }, update: (cache, {data}) =&gt; { // Update cache logic here }, }, ) console.log(&quot;Post created:&quot;, data.createPost) // Reset form title.value = &quot;&quot; body.value = &quot;&quot; } catch (e) { console.error(&quot;Error creating post:&quot;, e) } } &lt;/script&gt; &lt;template&gt; &lt;form @submit.prevent=&quot;submitPost&quot;&gt; &lt;input v-model=&quot;title&quot; placeholder=&quot;Title&quot; required /&gt; &lt;textarea v-model=&quot;body&quot; placeholder=&quot;Body&quot; required &gt;&lt;/textarea&gt; &lt;button type=&quot;submit&quot; :disabled=&quot;loading&quot;&gt; Create Post &lt;/button&gt; &lt;div v-if=&quot;error&quot;&gt;Error: {{ error.message }}&lt;/div&gt; &lt;/form&gt; &lt;/template&gt;   This example showcases:  Defining a GraphQL mutationUsing the useMutation composableImplementing optimistic updates for immediate UI feedbackHandling form submission and mutation execution  ","version":null,"tagName":"h3"},{"title":"4. Advanced Apollo Client Features​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#4-advanced-apollo-client-features","content":" ","version":null,"tagName":"h3"},{"title":"Caching and Normalization​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#caching-and-normalization","content":" Apollo Client's normalized cache is a powerful feature for efficient data management:  import {InMemoryCache, makeVar} from &quot;@apollo/client/core&quot; export const cache = new InMemoryCache({ typePolicies: { Query: { fields: { posts: { merge(existing, incoming) { return incoming }, }, }, }, Post: { fields: { isLiked: { read() { return likedPostsVar().includes(this.id) }, }, }, }, }, }) export const likedPostsVar = makeVar&lt;number[]&gt;([])   This setup demonstrates:  Custom merge functions for query resultsComputed fields based on reactive variablesUsing reactive variables for local state management  Error Handling and Retry Logic​  Implement robust error handling and retry logic:  import {ApolloLink} from &quot;@apollo/client/core&quot; import {onError} from &quot;@apollo/client/link/error&quot; import {RetryLink} from &quot;@apollo/client/link/retry&quot; const errorLink = onError( ({graphQLErrors, networkError}) =&gt; { if (graphQLErrors) graphQLErrors.forEach(({message, locations, path}) =&gt; console.log( `[GraphQL error]: Message: ${message}, Location: ${locations}, Path: ${path}`, ), ) if (networkError) console.log(`[Network error]: ${networkError}`) }, ) const retryLink = new RetryLink({ delay: { initial: 300, max: Infinity, jitter: true, }, attempts: { max: 5, retryIf: (error, _operation) =&gt; !!error, }, }) const link = ApolloLink.from([ errorLink, retryLink, httpLink, ])   This configuration adds comprehensive error logging and automatic retry for failed requests.  ","version":null,"tagName":"h3"},{"title":"5. Performance Optimization​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#5-performance-optimization","content":" To optimize performance when using Apollo Client with Vue:  Implement pagination for large datasets: &lt;script setup lang=&quot;ts&quot;&gt; import {useQuery} from &quot;@vue/apollo-composable&quot; import gql from &quot;graphql-tag&quot; import {ref, computed} from &quot;vue&quot; const GET_POSTS = gql` query GetPosts($offset: Int!, $limit: Int!) { posts(offset: $offset, limit: $limit) { id title } } ` const limit = ref(10) const offset = ref(0) const {result, loading, fetchMore} = useQuery( GET_POSTS, () =&gt; ({ offset: offset.value, limit: limit.value, }), ) const posts = computed(() =&gt; result.value?.posts || []) const loadMore = () =&gt; { offset.value += limit.value fetchMore({ variables: { offset: offset.value, limit: limit.value, }, }) } &lt;/script&gt; Use fragments for reusable query parts: import gql from &quot;graphql-tag&quot; export const POST_FRAGMENT = gql` fragment PostDetails on Post { id title body createdAt } ` export const GET_POSTS = gql` ${POST_FRAGMENT} query GetPosts { posts { ...PostDetails } } ` Leverage Apollo Client DevTools for performance monitoring and cache inspection.  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#conclusion","content":" Apollo Client provides a powerful and flexible solution for integrating GraphQL into Vue.js applications. Its advanced features like normalized caching, optimistic updates, and comprehensive error handling make it an excellent choice for complex, data-intensive applications.  Key takeaways:  Apollo Client offers a robust caching system that optimizes data fetching and managementThe useQuery and useMutation composables provide a clean API for GraphQL operationsOptimistic updates enable responsive UIs even before server responsesAdvanced features like custom cache policies and reactive variables offer fine-grained control over data managementPerformance optimization techniques such as pagination and fragments are crucial for scalable applications  ","version":null,"tagName":"h3"},{"title":"URQL - A Lightweight GraphQL Client for Modern Web Development​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#urql---a-lightweight-graphql-client-for-modern-web-development","content":" URQL stands out for its simplicity and modularity, making it an excellent choice for Vue.js projects that require GraphQL integration without the overhead of more complex libraries. Its lightweight nature contributes to faster load times and improved performance, especially in resource-constrained environments.  ","version":null,"tagName":"h2"},{"title":"Key Features of URQL:​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#key-features-of-urql","content":" Minimal bundle sizeBuilt-in cache and normalized caching optionEasy to extend with custom exchangesFirst-class TypeScript support  ","version":null,"tagName":"h3"},{"title":"2. Setting Up URQL in a Vue.js Project​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#2-setting-up-urql-in-a-vuejs-project","content":" Installation​  Begin by installing URQL and its Vue integration:  npm install @urql/vue graphql   Configuration​  Set up the URQL client in your Vue application:  import {createApp} from &quot;vue&quot; import urql, {createClient} from &quot;@urql/vue&quot; import App from &quot;./App.vue&quot; const client = createClient({ url: &quot;https://your-graphql-endpoint.com/graphql&quot;, }) const app = createApp(App) app.use(urql, client) app.mount(&quot;#app&quot;)   This configuration creates an URQL client and integrates it with Vue's plugin system, making it available throughout your application.  ","version":null,"tagName":"h3"},{"title":"3. Executing Queries with URQL​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#3-executing-queries-with-urql","content":" URQL provides a useQuery composable for executing GraphQL queries. Here's an example of fetching a list of posts:  &lt;script setup lang=&quot;ts&quot;&gt; import {useQuery} from &quot;@urql/vue&quot; import {ref, watch} from &quot;vue&quot; const postsQuery = ` query GetPosts { posts { id title body user { name } } } ` const {executeQuery, fetching, error, data} = useQuery({ query: postsQuery, pause: true, // Start paused to allow manual execution }) const posts = ref([]) const fetchPosts = () =&gt; { executeQuery() } watch(data, (newData) =&gt; { if (newData) { posts.value = newData.posts } }) &lt;/script&gt; &lt;template&gt; &lt;div&gt; &lt;button @click=&quot;fetchPosts&quot; :disabled=&quot;fetching&quot;&gt; Fetch Posts &lt;/button&gt; &lt;div v-if=&quot;fetching&quot;&gt;Loading...&lt;/div&gt; &lt;ul v-else-if=&quot;posts.length&quot;&gt; &lt;li v-for=&quot;post in posts&quot; :key=&quot;post.id&quot;&gt; {{ post.title }} by {{ post.user.name }} &lt;/li&gt; &lt;/ul&gt; &lt;div v-else-if=&quot;error&quot;&gt;Error: {{ error.message }}&lt;/div&gt; &lt;/div&gt; &lt;/template&gt;   This example demonstrates how to:  Define a GraphQL queryUse the useQuery composable to manage the query executionHandle loading, error, and success statesManually trigger the query execution  ","version":null,"tagName":"h3"},{"title":"4. Mutations and State Updates​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#4-mutations-and-state-updates","content":" URQL also supports GraphQL mutations for modifying data. Here's an example of creating a new post:  &lt;script setup lang=&quot;ts&quot;&gt; import {useMutation} from &quot;@urql/vue&quot; import {ref} from &quot;vue&quot; const createPostMutation = ` mutation CreatePost($title: String!, $body: String!) { createPost(input: { title: $title, body: $body }) { id title body } } ` const {executeMutation, fetching, error} = useMutation( createPostMutation, ) const title = ref(&quot;&quot;) const body = ref(&quot;&quot;) const createPost = async () =&gt; { const result = await executeMutation({ title: title.value, body: body.value, }) if (result.data) { console.log(&quot;Post created:&quot;, result.data.createPost) // Reset form or update local state title.value = &quot;&quot; body.value = &quot;&quot; } } &lt;/script&gt; &lt;template&gt; &lt;form @submit.prevent=&quot;createPost&quot;&gt; &lt;input v-model=&quot;title&quot; placeholder=&quot;Title&quot; required /&gt; &lt;textarea v-model=&quot;body&quot; placeholder=&quot;Body&quot; required &gt;&lt;/textarea&gt; &lt;button type=&quot;submit&quot; :disabled=&quot;fetching&quot;&gt; Create Post &lt;/button&gt; &lt;div v-if=&quot;error&quot;&gt;Error: {{ error.message }}&lt;/div&gt; &lt;/form&gt; &lt;/template&gt;   This example showcases:  Defining a GraphQL mutationUsing the useMutation composableHandling form submission and mutation executionManaging loading and error states for the mutation  ","version":null,"tagName":"h3"},{"title":"5. Advanced URQL Features and Best Practices​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#5-advanced-urql-features-and-best-practices","content":" Caching and Normalization​  URQL provides a document cache by default, but for more complex applications, you might want to use the normalized cache:  import { createClient, dedupExchange, cacheExchange, fetchExchange, } from &quot;@urql/vue&quot; import {normalizedCache} from &quot;@urql/exchange-graphcache&quot; const client = createClient({ url: &quot;https://your-graphql-endpoint.com/graphql&quot;, exchanges: [ dedupExchange, normalizedCache({ keys: { Post: (data) =&gt; data.id, }, resolvers: { Query: { post: (_, args) =&gt; ({ __typename: &quot;Post&quot;, id: args.id, }), }, }, }), fetchExchange, ], })   This setup enables more efficient caching and automatic updates for related queries when mutations occur.  Error Handling and Retry Logic​  Implement robust error handling and retry logic:  import {retry} from &quot;@urql/exchange-retry&quot; const client = createClient({ // ... other configuration exchanges: [ dedupExchange, cacheExchange, retry({ retryIf: (error) =&gt; !!(error.networkError || error.graphQLErrors), maxNumberAttempts: 3, }), fetchExchange, ], })   This configuration adds automatic retry for network errors or GraphQL errors, improving the resilience of your application.  ","version":null,"tagName":"h3"},{"title":"6. Performance Optimization​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#6-performance-optimization","content":" To optimize performance when using URQL with Vue:  Leverage server-side rendering (SSR) for initial data loading: import {createClient, ssrExchange} from &quot;@urql/vue&quot; const ssr = ssrExchange({ isClient: typeof window !== &quot;undefined&quot;, }) const client = createClient({ url: &quot;https://your-graphql-endpoint.com/graphql&quot;, exchanges: [ dedupExchange, cacheExchange, ssr, fetchExchange, ], }) Implement pagination for large datasets: &lt;script setup lang=&quot;ts&quot;&gt; import {useQuery} from &quot;@urql/vue&quot; import {ref, computed} from &quot;vue&quot; const postsQuery = ` query GetPosts($limit: Int!, $offset: Int!) { posts(limit: $limit, offset: $offset) { id title } } ` const limit = ref(10) const offset = ref(0) const {data, fetching, error} = useQuery({ query: postsQuery, variables: computed(() =&gt; ({ limit: limit.value, offset: offset.value, })), }) const loadMore = () =&gt; { offset.value += limit.value } &lt;/script&gt; Use fragments for reusable query parts: const PostFragment = ` fragment PostDetails on Post { id title body createdAt } ` const postsQuery = ` ${PostFragment} query GetPosts { posts { ...PostDetails } } `   ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#conclusion-1","content":" URQL provides a lightweight yet powerful solution for integrating GraphQL into Vue.js applications. Its simplicity, coupled with advanced features like normalized caching and SSR support, makes it an excellent choice for developers seeking efficiency and flexibility. By following the best practices and optimization techniques outlined in this tutorial, you can build performant, scalable Vue applications with GraphQL.  Key takeaways:  URQL offers a minimal bundle size and easy integration with Vue.jsThe useQuery and useMutation composables provide a clean API for GraphQL operationsAdvanced features like normalized caching and SSR support enhance application performanceProper error handling and retry logic improve application resiliencePerformance optimization techniques such as pagination and fragments are crucial for scalable applications  As you implement URQL in your Vue projects, remember to stay updated with the latest developments in both URQL and the GraphQL ecosystem to leverage new features and best practices as they emerge.  ","version":null,"tagName":"h3"},{"title":"Fetch API - The DIY Dynamo​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#fetch-api---the-diy-dynamo","content":" In modern web development, effective data fetching is a cornerstone for building dynamic and responsive applications. While powerful libraries like Apollo and URQL offer extensive features for GraphQL integration, there are situations where a more hands-on approach is desirable. Enter the Fetch API: a versatile, built-in tool for making network requests, allowing developers to craft their GraphQL interactions from the ground up. This tutorial will guide you through using the Fetch API for GraphQL data fetching in Vue.js, providing a deep understanding of the process and its practical applications.  ","version":null,"tagName":"h2"},{"title":"Step-by-Step Instructions​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#step-by-step-instructions","content":" Installation and Integration Steps​  One of the key advantages of the Fetch API is its built-in availability in modern browsers. This means no additional package installations are required, simplifying the setup process.  Code Snippets​  Let's start by setting up a basic Vue component that uses the Fetch API to query a GraphQL endpoint.  &lt;template&gt; &lt;div class=&quot;fetch-example&quot;&gt; &lt;h2&gt;Fetch API Example&lt;/h2&gt; &lt;button @click=&quot;fetchPosts&quot; :disabled=&quot;loading&quot;&gt; Fetch Posts &lt;/button&gt; &lt;div v-if=&quot;networkError&quot; class=&quot;error&quot;&gt; Network Error: {{ networkError }} &lt;/div&gt; &lt;div v-if=&quot;graphqlError&quot; class=&quot;error&quot;&gt; GraphQL Error: {{ graphqlError }} &lt;/div&gt; &lt;div v-if=&quot;unexpectedError&quot; class=&quot;error&quot;&gt; Unexpected Error: {{ unexpectedError }} &lt;/div&gt; &lt;ul&gt; &lt;li v-for=&quot;post in posts&quot; :key=&quot;post.id&quot;&gt; {{ post.title }} by {{ post.user.name }} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/template&gt; &lt;script setup lang=&quot;ts&quot;&gt; import {ref} from &quot;vue&quot; interface Post { id: number title: string body: string user: { name: string } } const posts = ref&lt;Post[]&gt;([]) const loading = ref(false) const networkError = ref&lt;string | null&gt;(null) const graphqlError = ref&lt;string | null&gt;(null) const unexpectedError = ref&lt;string | null&gt;(null) const fetchPosts = async () =&gt; { loading.value = true networkError.value = null graphqlError.value = null unexpectedError.value = null try { const response = await fetch(&quot;/graphql&quot;, { method: &quot;POST&quot;, headers: {&quot;Content-Type&quot;: &quot;application/json&quot;}, body: JSON.stringify({ query: ` query GetPosts { posts { id title body user { name } } } `, }), }) if (!response.ok) { throw new Error( `HTTP error! status: ${response.status}`, ) } const result = await response.json() if (result.errors &amp;&amp; result.errors.length &gt; 0) { graphqlError.value = result.errors .map((e: any) =&gt; e.message) .join(&quot;, &quot;) } else { posts.value = result.data.posts.slice(0, 4) } } catch (err: any) { if (err.message.startsWith(&quot;HTTP error!&quot;)) { networkError.value = err.message } else { unexpectedError.value = err.message } } finally { loading.value = false } } &lt;/script&gt;   Error Handling​  Handling errors effectively is crucial in any data-fetching scenario. The above code includes a robust error-handling system that categorizes errors into network errors, GraphQL errors, and unexpected errors.  try { // ... fetch logic ... } catch (err: any) { if (err.message.startsWith(&quot;HTTP error!&quot;)) { networkError.value = err.message } else { unexpectedError.value = err.message } } finally { loading.value = false }   This approach ensures that your application can gracefully handle and display errors, enhancing user experience.  ","version":null,"tagName":"h3"},{"title":"Industry Best Practices and Potential Technical Challenges​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#industry-best-practices-and-potential-technical-challenges","content":" ","version":null,"tagName":"h2"},{"title":"Best Practices​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#best-practices","content":" Modular Code: Break down your Fetch API logic into reusable functions or composables to promote code reusability and maintainability.Error Handling: Implement comprehensive error handling to manage different types of errors (network, GraphQL, unexpected) effectively.Security: Always validate and sanitize input data, especially when constructing GraphQL queries dynamically.  ","version":null,"tagName":"h3"},{"title":"Technical Challenges​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#technical-challenges","content":" Verbose Error Handling: Handling errors manually can be verbose and requires meticulous coding to cover all edge cases.Scalability: For larger projects, the Fetch API might lack the convenience features offered by dedicated GraphQL clients, such as caching and automatic batching.State Management: Managing loading states and errors can become complex, especially as the application grows.  ","version":null,"tagName":"h3"},{"title":"Real-World Applications​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#real-world-applications","content":" ","version":null,"tagName":"h2"},{"title":"Professional Development Scenarios​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#professional-development-scenarios","content":" Custom Solutions: In scenarios where fine-grained control over GraphQL requests is needed, such as specific headers or request configurations, the Fetch API shines.Learning and Prototyping: Using the Fetch API is a great way to learn the basics of GraphQL and network requests, making it suitable for educational purposes and prototyping.Lightweight Applications: For smaller applications or micro-frontends where adding a full-fledged GraphQL client is overkill, the Fetch API provides a lightweight alternative.  ","version":null,"tagName":"h3"},{"title":"Comparison to Alternative Technologies​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#comparison-to-alternative-technologies","content":" ","version":null,"tagName":"h2"},{"title":"Apollo Client​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#apollo-client","content":" Pros: Robust, feature-rich, automatic caching, extensive community support.Cons: Heavier bundle size, additional dependencies, potentially overkill for simple use cases.  ","version":null,"tagName":"h3"},{"title":"URQL​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#urql","content":" Pros: Lightweight, flexible, built-in support for common GraphQL patterns.Cons: Less mature than Apollo, fewer built-in features.  ","version":null,"tagName":"h3"},{"title":"Axios​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#axios","content":" Pros: Versatile HTTP client, can be used with GraphQL, additional features like request cancellation.Cons: Requires additional configuration for GraphQL, less intuitive compared to dedicated GraphQL clients.  ","version":null,"tagName":"h3"},{"title":"Summary of Key Technical Insights​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#summary-of-key-technical-insights","content":" Control and Flexibility: The Fetch API offers unmatched control over GraphQL requests, making it ideal for custom solutions.Built-In Availability: No need for additional dependencies, simplifying the development and deployment process.Error Handling: Robust error handling is crucial to manage different types of errors effectively.Learning Opportunity: Using the Fetch API provides a deeper understanding of GraphQL and network requests, beneficial for both entry-level and intermediate developers.  ","version":null,"tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#conclusion-2","content":" The Fetch API serves as a powerful tool for developers looking to craft their GraphQL solutions with precision and control. While it may not offer the convenience and features of dedicated GraphQL clients, it provides a lightweight and versatile alternative. By following best practices and understanding potential challenges, developers can effectively leverage the Fetch API for various professional development scenarios, gaining valuable insights and experience in the process.  ","version":null,"tagName":"h2"},{"title":"Axios - The Smooth Operator​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#axios---the-smooth-operator","content":" In the world of HTTP clients, Axios is like a sous chef in your kitchen, handling the tedious tasks and ensuring your GraphQL requests are prepared with finesse. Unlike the Fetch API, Axios simplifies and streamlines data fetching, making it an attractive option for developers seeking efficiency without sacrificing control. Let's dive into how Axios can enhance your Vue.js application with smooth and efficient GraphQL data fetching.  ","version":null,"tagName":"h2"},{"title":"1. Installation and Integration Steps​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#1-installation-and-integration-steps","content":" First, we need to install Axios in our Vue project. This can be done quickly via npm:  npm install axios   That's it! Axios is now ready to use, providing a smooth and easy setup process.  ","version":null,"tagName":"h3"},{"title":"2. Code Snippets​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#2-code-snippets","content":" Here's how you can use Axios to fetch data from a GraphQL endpoint in a Vue component:  &lt;script setup lang=&quot;ts&quot;&gt; import {ref} from &quot;vue&quot; import axios from &quot;axios&quot; interface Post { id: number title: string body: string user: { name: string } } const posts = ref&lt;Post[]&gt;([]) const loading = ref(false) const networkError = ref&lt;string | null&gt;(null) const graphqlError = ref&lt;string | null&gt;(null) const unexpectedError = ref&lt;string | null&gt;(null) const fetchPosts = async () =&gt; { loading.value = true networkError.value = null graphqlError.value = null unexpectedError.value = null try { const response = await axios.post(&quot;/graphql&quot;, { query: ` query GetPosts { posts { id title body user { name } } } `, }) if (response.status !== 200) { throw new Error( `HTTP error! status: ${response.status}`, ) } const result = response.data if (result.errors &amp;&amp; result.errors.length &gt; 0) { graphqlError.value = result.errors .map((e: any) =&gt; e.message) .join(&quot;, &quot;) } else { posts.value = result.data.posts.slice(0, 4) } } catch (err: any) { if (err.response) { networkError.value = `HTTP error! status: ${err.response.status}` } else { unexpectedError.value = err.message } } finally { loading.value = false } } &lt;/script&gt; &lt;template&gt; &lt;div class=&quot;axios-example&quot;&gt; &lt;h2&gt;Axios API Example&lt;/h2&gt; &lt;button @click=&quot;fetchPosts&quot; :disabled=&quot;loading&quot;&gt; Fetch Posts &lt;/button&gt; &lt;div v-if=&quot;networkError&quot; class=&quot;error&quot;&gt; Network Error: {{ networkError }} &lt;/div&gt; &lt;div v-if=&quot;graphqlError&quot; class=&quot;error&quot;&gt; GraphQL Error: {{ graphqlError }} &lt;/div&gt; &lt;div v-if=&quot;unexpectedError&quot; class=&quot;error&quot;&gt; Unexpected Error: {{ unexpectedError }} &lt;/div&gt; &lt;ul&gt; &lt;li v-for=&quot;post in posts&quot; :key=&quot;post.id&quot;&gt; {{ post.title }} by {{ post.user.name }} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/template&gt;   Axios simplifies the process of making GraphQL requests, handling much of the boilerplate code associated with Fetch API. This makes your code cleaner and easier to maintain.  ","version":null,"tagName":"h3"},{"title":"3. Error Handling​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#3-error-handling","content":" Axios provides robust error handling capabilities, making it easier to manage different types of errors:  try { // ... axios request ... } catch (err: any) { if (err.response) { networkError.value = `HTTP error! status: ${err.response.status}` } else { unexpectedError.value = err.message } } finally { loading.value = false }   This error-handling structure allows you to neatly categorize and handle various error scenarios, ensuring your application remains robust and user-friendly.  ","version":null,"tagName":"h3"},{"title":"4. Why Axios Rocks​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#4-why-axios-rocks","content":" Automatic Transforms: Axios automatically transforms your response data, allowing for smoother data handling. It's like having a translator who speaks both JSON and JavaScript fluently. Request and Response Interceptors: Need to add an auth token to every request or log all responses? Axios interceptors handle these tasks effortlessly, acting like a gatekeeper for your requests. Browser and Node.js Support: Axios works seamlessly in both browser and Node.js environments, providing flexibility for different project requirements. Cancellation Support: Axios allows you to cancel requests, providing an &quot;undo&quot; button for your API calls. This is particularly useful for handling stale or unnecessary requests.  ","version":null,"tagName":"h3"},{"title":"Industry Best Practices and Potential Technical Challenges​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#industry-best-practices-and-potential-technical-challenges-1","content":" ","version":null,"tagName":"h2"},{"title":"Best Practices​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#best-practices-1","content":" Use Interceptors: Leverage Axios interceptors to manage repetitive tasks like setting headers or logging requests and responses.Error Handling: Implement comprehensive error handling to ensure your application can gracefully recover from various error conditions.Modular Code: Organize your Axios requests into reusable functions or composables to keep your codebase clean and maintainable.  ","version":null,"tagName":"h3"},{"title":"Technical Challenges​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#technical-challenges-1","content":" Bundle Size: Although Axios is relatively lightweight, it's still an additional dependency that can increase your project's bundle size.Customization: While Axios is highly customizable, it may require additional setup compared to more specialized GraphQL clients.  ","version":null,"tagName":"h3"},{"title":"Real-World Applications​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#real-world-applications-1","content":" ","version":null,"tagName":"h2"},{"title":"Professional Development Scenarios​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#professional-development-scenarios-1","content":" API Integration: Axios is ideal for integrating with RESTful and GraphQL APIs, providing a consistent and efficient approach for data fetching.Middleware Implementation: Use Axios interceptors to implement middleware for logging, authentication, or other cross-cutting concerns.Server-Side Rendering (SSR): With its support for both browser and Node.js environments, Axios is well-suited for SSR applications, ensuring consistent data fetching across platforms.  ","version":null,"tagName":"h3"},{"title":"Summary of Key Technical Insights​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#summary-of-key-technical-insights-1","content":" Efficiency and Convenience: Axios offers a balance of control and convenience, making it easier to manage GraphQL requests with minimal boilerplate.Robust Error Handling: Built-in error handling features help manage network and unexpected errors effectively.Flexibility: With support for both browser and Node.js environments, Axios is versatile and adaptable to various project needs.Interceptors and Cancellation: Advanced features like request/response interceptors and request cancellation provide additional control and flexibility.  ","version":null,"tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#conclusion-3","content":" Axios stands out as a versatile and efficient tool for handling GraphQL requests in Vue.js applications. Its combination of automatic data transformation, robust error handling, and advanced features like interceptors and cancellation support make it a powerful choice for developers seeking a smooth and streamlined data-fetching experience. By incorporating best practices and understanding potential challenges, developers can leverage Axios to build robust and responsive applications, gaining valuable insights and experience in the process.  Stay tuned as we continue our journey through the world of GraphQL data fetching in Vue.js. Our final approach will bring everything together, providing the ultimate guide to mastering GraphQL in your Vue applications.  ","version":null,"tagName":"h2"},{"title":"Villus - The Vue-Native Virtuoso​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#villus---the-vue-native-virtuoso","content":" For the grand finale of our GraphQL journey, let's introduce Villus! 🎭 If our previous approaches were a warm-up, Villus is the show-stopping final act. It's a Vue-native GraphQL client that makes your data fetching seamless and elegant, tailored perfectly for Vue.js applications.  ","version":null,"tagName":"h2"},{"title":"1. Installation and Integration Steps​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#1-installation-and-integration-steps-1","content":" First, let's set up Villus in your Vue project:  npm install villus graphql   Next, configure Villus in your main.js file:  import {createApp} from &quot;vue&quot; import {createClient as createVillusClient} from &quot;villus&quot; import App from &quot;./App.vue&quot; const villusClient = createVillusClient({ url: &quot;/graphql&quot;, }) const app = createApp(App) app.use(villusClient) app.mount(&quot;#app&quot;)   ","version":null,"tagName":"h3"},{"title":"2. Code Snippets​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#2-code-snippets-1","content":" Here's how to use Villus to fetch data from a GraphQL endpoint in a Vue component:  &lt;script setup lang=&quot;ts&quot;&gt; import {useQuery} from &quot;villus&quot; import {ref} from &quot;vue&quot; interface Post { id: number title: string body: string user: { name: string } } interface QueryResult { posts: Post[] } const posts = ref&lt;Post[]&gt;([]) const loading = ref(false) const networkError = ref&lt;string | null&gt;(null) const graphqlError = ref&lt;string | null&gt;(null) const unexpectedError = ref&lt;string | null&gt;(null) const query = useQuery&lt;QueryResult&gt;({ query: ` query GetPosts { posts { id title body user { name } } } `, paused: true, }) const fetchPosts = async () =&gt; { loading.value = true networkError.value = null graphqlError.value = null unexpectedError.value = null try { const result = await query.execute() if (result.error) { throw result.error } if (result.data &amp;&amp; result.data.posts) { posts.value = result.data.posts.slice(0, 4) } else { throw new Error(&quot;Posts not found in query result&quot;) } } catch (e: any) { if (e.message.startsWith(&quot;Network Error&quot;)) { networkError.value = e.message } else if (e.graphQLErrors) { graphqlError.value = e.graphQLErrors .map((err: any) =&gt; err.message) .join(&quot;, &quot;) } else { unexpectedError.value = e.message } } finally { loading.value = false } } &lt;/script&gt; &lt;template&gt; &lt;div class=&quot;container&quot;&gt; &lt;h2&gt;Villus Example&lt;/h2&gt; &lt;button @click=&quot;fetchPosts&quot; :disabled=&quot;loading&quot;&gt; Fetch Posts &lt;/button&gt; &lt;div v-if=&quot;networkError&quot; class=&quot;error&quot;&gt; Network Error: {{ networkError }} &lt;/div&gt; &lt;div v-if=&quot;graphqlError&quot; class=&quot;error&quot;&gt; GraphQL Error: {{ graphqlError }} &lt;/div&gt; &lt;div v-if=&quot;unexpectedError&quot; class=&quot;error&quot;&gt; Unexpected Error: {{ unexpectedError }} &lt;/div&gt; &lt;ul&gt; &lt;li v-for=&quot;post in posts&quot; :key=&quot;post.id&quot;&gt; {{ post.title }} by {{ post.user.name }} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/template&gt;   Villus integrates seamlessly with Vue, providing a smooth and elegant way to handle GraphQL queries.  ","version":null,"tagName":"h3"},{"title":"3. Error Handling​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#3-error-handling-1","content":" Villus comes with robust error handling, making it easy to manage various error scenarios:  try { const result = await query.execute() if (result.error) { throw result.error } // ... handle successful result ... } catch (e: any) { if (e.message.startsWith(&quot;Network Error&quot;)) { networkError.value = e.message } else if (e.graphQLErrors) { graphqlError.value = e.graphQLErrors .map((err: any) =&gt; err.message) .join(&quot;, &quot;) } else { unexpectedError.value = e.message } }   This error-handling structure ensures that your application can gracefully recover from various issues, providing a robust user experience.  ","version":null,"tagName":"h3"},{"title":"4. Why Villus Rocks​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#4-why-villus-rocks","content":" Vue-Native: Villus is built specifically for Vue, making it a perfect fit for Vue applications. It's like having a custom-tailored suit for your Vue app.Lightweight: Villus is lightweight and efficient, ensuring that your application remains fast and responsive.Composable: With its composition API support, Villus integrates seamlessly with Vue 3, enhancing the development experience.Smart Defaults: Villus comes with smart defaults that work out of the box, but it is also highly customizable to fit your specific needs.  ","version":null,"tagName":"h3"},{"title":"Industry Best Practices and Potential Technical Challenges​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#industry-best-practices-and-potential-technical-challenges-2","content":" Best Practices​  Use the Composition API: Leveraging Vue's composition API with Villus makes your code more modular and maintainable.Error Handling: Implement comprehensive error handling to ensure a robust application.Modular Code: Organize your Villus queries into reusable functions or composables to keep your codebase clean.  Technical Challenges​  Learning Curve: For developers new to GraphQL or the composition API, there might be a learning curve.Customization: While Villus is highly customizable, it may require additional setup for more complex use cases.  ","version":null,"tagName":"h3"},{"title":"Real-World Applications​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#real-world-applications-2","content":" Professional Development Scenarios​  API Integration: Villus is perfect for integrating with GraphQL APIs in Vue applications, providing a seamless data fetching experience.State Management: Villus can be used alongside Vue's reactive state management, providing a powerful combination for managing application state.Server-Side Rendering (SSR): With its support for both client-side and server-side rendering, Villus ensures consistent data fetching across platforms.  ","version":null,"tagName":"h3"},{"title":"Summary of Key Technical Insights​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#summary-of-key-technical-insights-2","content":" Efficiency and Convenience: Villus offers a balance of efficiency and convenience, making it easy to manage GraphQL requests in Vue applications.Robust Error Handling: Built-in error handling features help manage network and unexpected errors effectively.Vue-Native Integration: Villus is built specifically for Vue, providing seamless integration and enhancing the development experience.Lightweight and Composable: Villus is lightweight and leverages the composition API, making it a powerful tool for modern Vue development.  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#conclusion-4","content":" Villus stands out as a versatile and efficient tool for handling GraphQL requests in Vue.js applications. Its Vue-native design, robust error handling, and lightweight nature make it an excellent choice for developers seeking a seamless data-fetching experience. By incorporating best practices and understanding potential challenges, developers can leverage Villus to build robust and responsive applications, gaining valuable insights and experience in the process.  With this, we've completed our exploration of various data-fetching approaches in Vue. Each approach offers unique strengths and is suited for different scenarios, providing you with the tools and knowledge to choose the best solution for your projects. Happy coding! 🎉  ","version":null,"tagName":"h3"},{"title":"Comparison Table​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#comparison-table","content":" Feature\tApollo Client\tURQL\tFetch API\tAxios\tVillusBundle Size (Minified + Gzipped)*\t47.8 kB\t10.2 kB\t2.8kB\t13.2kB\t4.6kB Learning Curve\tSteep\tModerate\tLow\tLow\tModerate Caching Capabilities\tAdvanced\tGood\tManual\tManual\tGood Community Support\tExtensive\tGrowing\tWidespread\tExtensive\tLimited Additional Features\tRich ecosystem, dev tools, local state management\tLightweight, customizable\tNative browser API\tRequest/response interceptors, automatic transforms\tVue-specific, lightweight  *Bundle sizes culled from bundlephobia.com  Here's a brief explanation of the ratings:  Learning Curve: Apollo Client: Steep due to its extensive features and concepts.URQL: Moderate as it's simpler than Apollo but still has GraphQL-specific concepts.Fetch API: Low as it's a basic browser API.Axios: Low as it's straightforward to use for HTTP requests.Villus: Moderate as it's Vue-specific but simpler than Apollo. Caching Capabilities: Apollo Client: Advanced with sophisticated normalization and cache policies.URQL: Good built-in caching with customizable options.Fetch API: Manual caching required.Axios: Manual caching required.Villus: Good basic caching capabilities. Community Support: Apollo Client: Extensive due to its popularity in the GraphQL ecosystem.URQL: Growing community, but not as large as Apollo's.Fetch API: Widespread as it's a web standard.Axios: Extensive due to its popularity for HTTP requests.Villus: Limited as it's a newer and more niche library. Additional Features: Apollo Client: Rich ecosystem with developer tools and local state management.URQL: Lightweight and highly customizable.Fetch API: Native browser API, no extra features.Axios: Request/response interceptors, automatic transforms for data.Villus: Vue-specific integration, lightweight alternative to Apollo.  This table provides a high-level comparison of the different approaches for GraphQL data fetching in Vue. Each approach has its strengths and may be more suitable depending on the specific requirements of a project.  ","version":null,"tagName":"h2"},{"title":"Caching Capabilities​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#caching-capabilities","content":" Apollo Client: Offers a sophisticated normalized cacheSupports various cache policies (cache-first, network-only, etc.)Allows for fine-grained cache updates and invalidationProvides optimistic UI updates URQL: Implements a document cache by defaultSupports customizable caching strategiesOffers a normalized cache through the Normalized Cache exchangeProvides easy cache updates and invalidation Fetch API: No built-in caching mechanismRequires manual implementation of caching logicCan leverage browser's HTTP cache or custom in-memory/storage solutions Axios: No built-in caching mechanism for GraphQLRequires manual implementation of caching logicCan be combined with external caching libraries Villus: Provides a simple document cacheSupports cache policies similar to Apollo (cache-first, network-only)Offers manual cache manipulation methodsLighter weight caching compared to Apollo  ","version":null,"tagName":"h3"},{"title":"Common Issues and Resolutions​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#common-issues-and-resolutions","content":" Apollo Client: Issue: Over-fetching data Resolution: Use fragments and optimized queriesIssue: Cache inconsistencies Resolution: Manually update cache or use refetchQueriesIssue: Performance with large datasets Resolution: Implement pagination or infinite scrolling URQL: Issue: Lack of advanced caching features out-of-the-box Resolution: Use additional exchanges like the Normalized Cache exchangeIssue: Limited dev tools compared to Apollo Resolution: Rely on browser network tab or implement custom loggingIssue: Learning curve for exchanges concept Resolution: Start with basic setup and gradually add exchanges as needed Fetch API: Issue: Verbose syntax for GraphQL requests Resolution: Create utility functions to simplify request creationIssue: No built-in error handling for GraphQL errors Resolution: Implement custom error checking and handling logicIssue: Manual caching and state management Resolution: Use state management libraries like Vuex or Pinia alongside Fetch Axios: Issue: Not GraphQL-specific, requiring more boilerplate Resolution: Create custom wrapper functions for GraphQL operationsIssue: Handling GraphQL errors separately from HTTP errors Resolution: Implement middleware to check for and handle GraphQL-specific errorsIssue: No built-in caching for GraphQL queries Resolution: Implement custom caching layer or use with a state management solution Villus: Issue: Limited ecosystem compared to Apollo Resolution: Combine with other Vue libraries for missing featuresIssue: Less community resources and examples Resolution: Refer to official documentation and reach out to maintainers for supportIssue: Potential performance issues with larger applications Resolution: Consider using more robust solutions like Apollo for very complex apps  Each approach has its own set of challenges, but also offers unique advantages. The choice between them often depends on the specific requirements of your project, the complexity of your GraphQL operations, and your team's familiarity with the tools.  ","version":null,"tagName":"h2"},{"title":"The Grand Finale​","type":1,"pageTitle":"GraphQL in Vue: 5 Best Approaches for Data Fetching","url":"/blog/graphql-vue-client/#the-grand-finale","content":" We've journeyed through the land of GraphQL in Vue, exploring five fantastic approaches:  Apollo Client: The Swiss Army knifeURQL: The lightweight contenderFetch API: The DIY dynamoAxios: The smooth operatorVillus: The Vue-native virtuoso  Examples and Resources Code snippets used in this article can be found in the GitHub repository. Feel free to explore, experiment, and adapt them to your projects!  Each approach has its own strengths, like instruments in an orchestra. The choice depends on your project's needs, your team's expertise, and the symphony you want to create.  Remember, in the world of web development, there's no one-size-fits-all solution. It's about finding the right tool for your unique masterpiece. So go forth, experiment, and may your Vue apps be forever data-rich and performant!  And with that, we bring down the curtain on our GraphQL in Vue extravaganza. But don't worry, the show never really ends in the ever-evolving world of web development. Keep learning, keep coding, and most importantly, keep having fun! 🎭🚀 ","version":null,"tagName":"h2"},{"title":"Guidelines","type":0,"sectionRef":"#","url":"/docs/contribution-guidelines/","content":"","keywords":"","version":"Next"},{"title":"The Basics​","type":1,"pageTitle":"Guidelines","url":"/docs/contribution-guidelines/#the-basics","content":" Fork and Clone: Fork the repository on GitHub and clone your fork locally. git clone https://github.com/yourusername/tailcall.git Set Up Your Environment: Install Rust: Use rustup to install Rust and the nightly toolchain.Install Prettier: Required for linting, install Prettier.Build the Application: Navigate to the project directory and execute cargo build.Start the Server: Run cargo run -- start ./examples/jsonplaceholder.graphql to start the server and access the GraphiQL interface at https://tailcall.run/playground.  ","version":"Next","tagName":"h2"},{"title":"Making and Discussing Changes​","type":1,"pageTitle":"Guidelines","url":"/docs/contribution-guidelines/#making-and-discussing-changes","content":" Create a New Branch: Always work on a new branch created from the latest main branch. git checkout -b feature/your-feature-name Develop Incrementally: Use small, stacked PRs for complex features. Break down large tasks into smaller, manageable pieces, each with its own PR. If you are working on a large bounty item add the bounty on your main PR and create stacked PRs wrt to your main PR. Discuss on Discord: For real-time discussions, use the #contributors channel on Discord. Create a thread for each PR to facilitate focused discussions.  ","version":"Next","tagName":"h2"},{"title":"Pull Requests and Code Quality​","type":1,"pageTitle":"Guidelines","url":"/docs/contribution-guidelines/#pull-requests-and-code-quality","content":" Keep PRs Small: Focus each PR on a single topic to simplify review and potential reverts. Describe your changes clearly in the PR description, explaining the solution and linking to any relevant discussions or issues. Commit Clearly: Write concise, descriptive commit messages. Each commit should represent a self-contained change. Submit PRs: Push your branch to GitHub and open a PR against the main branch. In the PR description, detail the purpose of your changes and any additional context needed. Code Review: Engage with reviewers on GitHub and address feedback promptly. Use discussions on Discord to resolve complex issues or debates efficiently.  ","version":"Next","tagName":"h2"},{"title":"Community Engagement​","type":1,"pageTitle":"Guidelines","url":"/docs/contribution-guidelines/#community-engagement","content":" Star and Share: Star the repository if you find it helpful and share your contributions on social media using #tailcall and tagging @tailcallhq.  ","version":"Next","tagName":"h2"},{"title":"Final Notes​","type":1,"pageTitle":"Guidelines","url":"/docs/contribution-guidelines/#final-notes","content":" Tailcall thrives through your contributions. We aim to maintain a respectful and inclusive community. Thank you for helping to enhance Tailcall for everyone! ","version":"Next","tagName":"h2"},{"title":"Bounty","type":0,"sectionRef":"#","url":"/docs/contributors/bounty/","content":"","keywords":"","version":"Next"},{"title":"Our Philosophy​","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#our-philosophy","content":" We’re all about meritocracy here. That means the best ideas and implementations win! We love seeing your quality work and fast moves. And yes, we recognize and appreciate your efforts when you exceed expectations.  ","version":"Next","tagName":"h2"},{"title":"Quick & Quality​","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#quick--quality","content":" Speedy Gonzalez: We like fast results! Quick feedback, quick updates. The faster, the better!A+ Quality: But hey, don’t rush it if it means cutting corners. We want your best – make it shine!  ","version":"Next","tagName":"h2"},{"title":"Teamwork Makes the Dream Work​","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#teamwork-makes-the-dream-work","content":" Join Us on Discord: Our Discord server is THE place to collaborate, get tips, and find your next bestie. Let’s make magic together.Share the Love: Inspired by someone’s PR? Working together? Feel free to /split that bounty – sharing is caring!  ","version":"Next","tagName":"h2"},{"title":"How to Dive In​","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#how-to-dive-in","content":" Pick a Challenge: Use /attempt in the comments to call dibs on an issue. It’s like saying “I got this!”Show Your Work: Got an issue? Great! Now, whip up a draft PR within 24 hours to show you’re on it.Go for Gold: Once you’re ready, switch that draft to Ready for Review. Make sure it’s polished and gleaming!Extra Mile Alert: We’ve got bonuses for those who add that special touch. Clean up, optimize, or fix something extra? We’re here for it!  ","version":"Next","tagName":"h2"},{"title":"The Rules of the Game​","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#the-rules-of-the-game","content":" Be Quick or Be… Late: No PR within 24 hours? Then it’s open season for that issue again.There Can Be One Winner: Multiple folks can try, but it's the top PR that emerges victorious. If there's a tie, the first submission takes the prize.No Copycats: Be original; be yourself. Avoid merely copying someone else's hard work.Consider Before You Contribute: If there’s already a PR in progress, perhaps take a moment to review it before submitting your own.  ","version":"Next","tagName":"h2"},{"title":"Identifying Plagiarism​","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#identifying-plagiarism","content":" To keep our Bounty Program fair and fun, we have a strict no-plagiarism policy. Here’s how we keep it original:  Manual Review: Our team manually checks all submissions to spot any sneaky copy-pasting.Raise the Alarm: If you think someone’s trying to pull a fast one, let us know ASAP! Before the copycat's PR gets merged, shout it out in our Discord channel and drop a comment on their PR.  Caught cheating? That means disqualification from the current bounty, a possible ban from future bounties, and a heads-up to the community. So, keep it real and let’s make this program a blast for everyone!  ","version":"Next","tagName":"h2"},{"title":"Wrapping Up​","type":1,"pageTitle":"Bounty","url":"/docs/contributors/bounty/#wrapping-up","content":" We’re stoked to have you! This program is your chance to shine and get rewarded while at it. Stick to these friendly guidelines, and let’s make something awesome together. We look forward to seeing what you bring to the table. ","version":"Next","tagName":"h2"},{"title":"Getting Started with GraphQL","type":0,"sectionRef":"#","url":"/docs/","content":"","keywords":"","version":"Next"},{"title":"Installing the Tailcall CLI​","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#installing-the-tailcall-cli","content":"  You can install the latest version - by using NPM.   ","version":"Next","tagName":"h2"},{"title":"NPM​","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#npm","content":" If you don't already have nodejs installed, you can find the instructions here. Install Tailcall by running the following command in your terminal: npm i -g @tailcallhq/tailcall To verify the correct installation of Tailcall, run: tailcall note Do not use the --force flag during npm installations, as it ignores installing platform-specific builds.  ","version":"Next","tagName":"h3"},{"title":"Yarn​","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#yarn","content":" Install Tailcall by running the following command in your terminal: yarn global add @tailcallhq/tailcall To verify the correct installation of Tailcall, run: tailcall   ","version":"Next","tagName":"h3"},{"title":"Homebrew​","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#homebrew","content":" If you don't already have Homebrew installed, you can find the instructions here. Add the Tailcall repository to Homebrew by running the following command in your terminal: brew tap tailcallhq/tailcall brew install tailcall To verify the correct installation of Tailcall, run: tailcall After completing the installation, perform upgrades with: brew update brew upgrade tailcall   ","version":"Next","tagName":"h3"},{"title":"Curl​","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#curl","content":" Follow the steps below to manually install the cli on your system:  curl -sSL https://tailcall.run/install.sh | bash -s --   This command fetches and executes the Tailcall installation script. The ~/.tailcall directory contains the installed files.  Upon completion of the installation, extend your PATH environment variable to include the ~/.tailcall/bin directory:  # export PATH=$PATH:~/.tailcall/bin   ","version":"Next","tagName":"h3"},{"title":"Docker​","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#docker","content":" To install Tailcall with Docker, follow the steps below. Please note that currently, this installation method only works on Linux/amd64 systems. Before starting, make sure you have Docker installed on your system. If not, download it from here.  Pull the latest Tailcall Docker image using the following command: docker pull tailcall.docker.scarf.sh/tailcallhq/tailcall/tc-server: This command fetches the latest version of the Tailcall Docker image from the Docker registry. Run the Tailcall Docker container with the following command: docker run -d --name graphql-server -p 8000:8000 \\ -v /path/to/your/configs:/etc/tailcall \\ --entrypoint &quot;/bin/sh&quot; \\ ghcr.io/tailcallhq/tailcall/tc-server: \\ -c &quot;export PATH=$PATH:~/.tailcall/bin &amp;&amp; tailcall start /etc/tailcall/config.graphql&quot; This command launches the GraphQL server in a Docker container, exposing the GraphQL endpoint on port 8080.  ","version":"Next","tagName":"h3"},{"title":"Initializing a GraphQL project​","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#initializing-a-graphql-project","content":" Once you have installed the Tailcall binaries, you can simply use the init command to initialize your GraphQL project.  tailcall init &lt;directory&gt;   The command will ask you a few questions and based on your input bootstrap a new GraphQL project with a few files:  .tailcallrc.schema.json: Provides autocomplete in your editor when the configuration is written in json or yml format..graphqlrc.yml: An IDE configuration that references your GraphQL configuration (if it's in .graphql format) and the following .tailcallrc.graphql..tailcallrc.graphql: Contains Tailcall specific auto-completions for .graphql format.main.graphql: This is your root configuration that contains  ","version":"Next","tagName":"h2"},{"title":"Writing a GraphQL Configuration​","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#writing-a-graphql-configuration","content":" For our first example, we are going to compose a GraphQL schema from the REST APIs at https://jsonplaceholder.typicode.com, a free online REST API with some fake data. We will use the API at /users to get a list of users, and /users/:id/posts to get the posts for each user, and compose them into a single GraphQL schema.  We can use the following formats to define our GraphQL schema: .graphql, .yml, .json.  Create one of the following files and paste the contents into it.  graphqlymljson schema # Specify server configuration: Start GraphQL server at 0.0.0.0:8000 @server(port: 8000) # Specify a base url for all http requests @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query } type Query { # Specify the http path for the users query users: [User] @http(path: &quot;/users&quot;) } # Create a user type with the fields returned by the users api type User { id: Int! name: String! username: String! email: String! # Extend the user type with the posts field # Use the current user's id to construct the path posts: [Post] @http(path: &quot;/users/{{.value.id}}/posts&quot;) } # Create a post type with the fields returned by the posts api type Post { id: Int! title: String! body: String! }   The above file is a standard .graphQL file, with some minor additions such as @upstream and @http directives. Basically we specify the GraphQL schema and how to resolve that GraphQL schema in the same file, without having to write any code!  ","version":"Next","tagName":"h2"},{"title":"Starting the GraphQL server​","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#starting-the-graphql-server","content":" Now, run the following command to start the server with the full path to the file that you created earlier.  graphqlymljson tailcall start ./jsonplaceholder.graphql   If the command succeeds, you should see logs like the following below.  INFO File read: ./jsonplaceholder.graphql ... ok INFO N + 1 detected: 0 INFO 🚀 Tailcall launched at [0.0.0.0:8000] over HTTP/1.1 INFO 🌍 Playground: https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql   The server starts with the schema provided and prints out a load of meta information. We will cover those in detail in a bit. For now, open the playground URL in a new tab in your browser and try it out for yourself!  ","version":"Next","tagName":"h2"},{"title":"Making GraphQL requests to the server​","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#making-graphql-requests-to-the-server","content":" Open a web browser and go to https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql. This should load the GraphiQL interface. In the query editor of GraphiQL, enter the following query query { users { id name posts { title } } } After running the query in GraphiQL, expect to see a JSON response structured like this: { &quot;data&quot;: { &quot;users&quot;: [ { &quot;id&quot;: 1, &quot;name&quot;: &quot;Leanne Graham&quot;, &quot;posts&quot;: [ { &quot;title&quot;: &quot;sunt aut facere repellat provident occaecati excepturi option reprehenderit&quot; } // Posts truncated for brevity ] }, { &quot;id&quot;: 2, &quot;name&quot;: &quot;Ervin Howell&quot;, &quot;posts&quot;: [ { &quot;title&quot;: &quot;et ea vero quia laudantium autem&quot; }, { &quot;title&quot;: &quot;in quibusdam tempore odit est dolorem&quot; } // Posts truncated for brevity ] } // Users truncated for brevity ] } }   ","version":"Next","tagName":"h2"},{"title":"Deploying GraphQL on Production​","type":1,"pageTitle":"Getting Started with GraphQL","url":"/docs/#deploying-graphql-on-production","content":" Now that you have a running GraphQL server, you can follow our Github Actions Guide to deploy the application on one of the following cloud providers.  AWS LambdaFly.io ","version":"Next","tagName":"h2"},{"title":"Micro Benchmarks","type":0,"sectionRef":"#","url":"/docs/contributors/micro-benchmark/","content":"","keywords":"","version":"Next"},{"title":"Running Benchmarks​","type":1,"pageTitle":"Micro Benchmarks","url":"/docs/contributors/micro-benchmark/#running-benchmarks","content":" Install cargo-criterion and rust-script: cargo install cargo-criterion rust-script Execute the benchmarks: cargo bench This command will run all benchmarks and display the results. To run a specific benchmark you could modify the command and pass a pattern to the command: cargo bench -- 'foo.*bar'   ","version":"Next","tagName":"h2"},{"title":"Comparing Benchmarks​","type":1,"pageTitle":"Micro Benchmarks","url":"/docs/contributors/micro-benchmark/#comparing-benchmarks","content":" To facilitate benchmark comparison, we have developed a Rust script capable of contrasting the outcomes of two benchmarks.  # Checkout the base branch git checkout main # Run the benchmarks for the main branch and store the result in a file cargo bench --message-format=json &gt; main.json # Checkout the feature branch git checkout feature # Run the benchmarks again in your feature branch cargo bench --message-format=json &gt; feature.json # Perform a comparison check between the two branches ./scripts/criterion_compare.rs main.json feature.json table   If the benchmarks indicate a degradation exceeding 10%, the script will terminate with an error. You can refer to the automatically generated benches/benchmark.md file to identify which benchmarks underperformed and investigate the corresponding code changes before submitting a pull request. ","version":"Next","tagName":"h2"},{"title":"Telemetry","type":0,"sectionRef":"#","url":"/docs/contributors/telemetry/","content":"Telemetry At Tailcall, we adhere to high observability standards in line with the OpenTelemetry specification. Our implementation utilizes several key Rust crates: rust-opentelemetry and associated crates are used to support the collection and export of telemetry data.tracing and tracing-opentelemetry facilitate the definition of logs and traces. Integration with OpenTelemetry allows for the automatic transfer of this data to the OpenTelemetry system. This layered approach ensures that the tracing library, which is effective across various scenarios, can also function as a standalone telemetry system for logging when OpenTelemetry integration is not required. When developing any features that necessitate observability, consider the following guidelines: Implement traces for tasks that represent a significant operation. This practice aids in the efficient diagnosis of issues and performance bottlenecks.Name spans clearly and specifically, adhering to the guidelines outlined in the OpenTelemetry specifications. Avoid names that introduce a high cardinality of potential values.Due to the constraints of tracing libraries, span names must be static strings. This limitation can be overcome by adding an extra field named otel.name to provide more dynamic descriptions (see the tracing-opentelemetry documentation for more details).Attribute naming should follow OpenTelemetry's semantic conventions. Utilize constants available in the opentelemetry_semantic_conventions crate for standardized attribute names.","keywords":"","version":"Next"},{"title":"Integration Testing","type":0,"sectionRef":"#","url":"/docs/contributors/integration-testing/","content":"","keywords":"","version":"Next"},{"title":"How does it work?​","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#how-does-it-work","content":" Execution Spec implements a custom markdown-based testing framework for Tailcall. The framework is designed to help write integration tests for GraphQL configs.  ","version":"Next","tagName":"h2"},{"title":"Run all tests​","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#run-all-tests","content":" The integration tests are executed as usual integration test so you can use test options and filters like with usual test.  cargo test   To run integration tests skipping other tests run following command:  cargo test --test execution_spec   After running you will get an output of all executed integration tests.  ","version":"Next","tagName":"h3"},{"title":"Run a single test​","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#run-a-single-test","content":" Similar to filtering unit tests to execute a single markdown configuration you can pass it's name to the test command:  cargo test --test execution_spec grpc Compiling tailcall-fixtures v0.1.0 (/Users/tushar/Documents/Projects/tailcall/tailcall-fixtures) Compiling tailcall v0.1.0 (/Users/tushar/Documents/Projects/tailcall) Finished `test` profile [unoptimized + debuginfo] target(s) in 15.96s Running tests/execution_spec.rs (target/debug/deps/execution_spec-6779d7c5c29b9b0b) running 18 tests test run_execution_spec::test-grpc-invalid-method-format.md ... ok test run_execution_spec::test-grpc-invalid-proto-id.md ... ok test run_execution_spec::test-grpc-group-by.md ... ok test run_execution_spec::test-grpc-missing-fields.md ... ok test run_execution_spec::test-grpc-nested-optional.md ... ok test run_execution_spec::test-grpc-nested-data.md ... ok test run_execution_spec::test-grpc-proto-path.md ... ok test run_execution_spec::grpc-proto-with-same-package.md ... ok test run_execution_spec::grpc-reflection.md ... ok test run_execution_spec::test-grpc-optional.md ... ok test run_execution_spec::test-grpc-service-method.md ... ok test run_execution_spec::test-grpc-service.md ... ok test run_execution_spec::grpc-error.md ... ok test run_execution_spec::grpc-simple.md ... ok test run_execution_spec::grpc-batch.md ... ok test run_execution_spec::grpc-url-from-upstream.md ... ok test run_execution_spec::grpc-override-url-from-upstream.md ... ok test run_execution_spec::test-grpc.md ... ok   In the above command all tests with the name grpc will be executed.  ","version":"Next","tagName":"h3"},{"title":"Skipping a test​","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#skipping-a-test","content":" Skipping the test is also possible by passing the --skip parameter:  cargo test --test execution_spec -- --skip grpc   Sometimes, you might want to skip the test per permanently for everyone and the CI. You could achieve it by setting the skip configuration in your markdown:  --- skip: true --- &lt;!-- Rest of the configurations --&gt;   ","version":"Next","tagName":"h3"},{"title":"Folder Structure​","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#folder-structure","content":" All execution_spec tests are located in tests/execution. The results generated by these tests are stored as snapshots in tests/core/snapshots. An execution_spec test is always a markdown file with a .md extension.  ","version":"Next","tagName":"h2"},{"title":"File Structure​","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#file-structure","content":" Each .md file runs in its own scope, so no two tests can interfere with each other. The file structure is as follows:  ","version":"Next","tagName":"h2"},{"title":"Heading​","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#heading","content":" The heading of file is used to provide metadata about the test. It is a YAML front matter block that contains the following fields:  identity - This instructs the runner to check if the configuration when parsed and then printed back, is the same as the original configuration. This is useful to check whenever a new feature is added in the configuration and the parsers + printer needs to be updated.error - This instructs the runner to expect a validation error while parsing the configuration. This is useful to test validation logic written while converting config to blueprint.skip - This is a special annotation that ensures that the test is skipped.  --- identity: true error: true skip: true ---   The rest of the file is the test's body consisting of code blocks and descriptions.  ","version":"Next","tagName":"h3"},{"title":"Config​","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#config","content":" Codeblocks can be enhanced with additional meta information for the test parser to make sense of the code. So for example a GraphQL configuration could be written in a code block with the graphql language and a @config meta information could be attached to it.  ```graphql @config schema { query: Query } type Query { users: [User] posts: [Post] } ```   For each config a few tests are automatically executed:  We check if the config written is valid. If it's not and unless error: true is set in the front matter, the test will fail.We check if the config when parsed and then printed back is the same as the original config. This is useful to check whenever a new feature is added in the configuration and the parsers + printer needs to be updated.We check if the config when merged with an empty configuration is the same as the original config. This is useful to check whenever a new feature is added in the configuration and the merger needs to be updated.We autogenerate the schema of the GraphQL server and snapshot it for later. This is useful to see what would the final GraphQL schema look like.  ","version":"Next","tagName":"h3"},{"title":"Test​","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#test","content":" An @test block specifies HTTP requests that the runner should perform in YAML format. It solely contains requests. The response for each request is automatically generated and compared with the snapshot.  note There may be at most one @test block in a test.  Example:  ```yml @test - method: POST url: http://localhost:8080/graphql body: query: query { user { name } } ```   ","version":"Next","tagName":"h3"},{"title":"Mock​","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#mock","content":" Mock provides a way to match requests and send back a predefined response. It is used to mock HTTP &amp; gRPC requests in the test.  ```yml @mock - request: # The method to match on (default: Any) method: POST # The URL to match on (default: Any) url: http://jsonplaceholder.typicode.com/users/1 # Predefined response response: status: 200 body: id: 1 name: foo # Number of time we expect this request to be hit (default: 1) expectedHits: 1 # Whether we should assert the number of hits (default: true) assertHits: true ```   ","version":"Next","tagName":"h3"},{"title":"Env​","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#env","content":" An @env block specifies environment variables in YAML that the runner should use in the app context. There may be at most one @env block in a test.  Example:  ```yml @env TEST_ID: 1 ```   ","version":"Next","tagName":"h3"},{"title":"File​","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#file","content":" A @file block creates a file in the spec's virtual file system. The @config block will have exclusive access to files created in this way: the true filesystem is not available to it.  Every @file block has the filename declared in the header. The language of the code block is optional and does not matter.  Example:  ```js @file:worker.js function onRequest({request}) { request.headers[&quot;x-test&quot;] = &quot;test&quot; return {request} } ``` ```graphql @config schema @link(file: &quot;worker.js&quot;) { query: Query } ```   In the above example we are able to link the worker.js file to the schema and write an integration test where all the requests will be modified by the onRequest function.  ","version":"Next","tagName":"h3"},{"title":"Snapshots​","type":1,"pageTitle":"Integration Testing","url":"/docs/contributors/integration-testing/#snapshots","content":" Tailcall uses the Insta snapshot engine. Snapshots are automatically generated with a .new suffix if there is no pre-existing snapshot, or if the compared data didn't match the existing snapshot.  Instead of writing result cases in tests and updating them when behaviour changes, a snapshot-based testing workflow relies on auto-generation. Whenever a .new snapshot is generated, it means one of the following:  Your code made an unexpected breaking change, and you need to fix it.Your code made an expected breaking change, and you need to accept the new snapshot.  You need to determine which one is the case, and take action accordingly.  Usage of cargo-insta is recommended:  cargo insta test --review   This will regenerate all snapshots without interrupting the test every time there's a diff, and it will also open the snapshot review interface, so that you can accept or reject .new snapshots.  To clean unused snapshots, run:  cargo insta test --delete-unreferenced-snapshots  ","version":"Next","tagName":"h2"},{"title":"Unit Testing","type":0,"sectionRef":"#","url":"/docs/contributors/testing/","content":"","keywords":"","version":"Next"},{"title":"Running Tests​","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#running-tests","content":" To execute tests locally on your machine, follow these steps:  Ensure the Rust toolchain is installed on your machine. Execute all tests with the following command in the terminal: cargo test To run a specific test or group of tests, modify the command accordingly: cargo test test_name To view all output from tests (useful if you have added debug logs to your tests), use the command: cargo test -- --show-output For more details and options on how tests function, please refer to the Rust Book Testing Chapter and the rustc tests guide.  ","version":"Next","tagName":"h2"},{"title":"Filtering Running Tests​","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#filtering-running-tests","content":" To execute a specific set of tests or exclude some tests, use the following commands:  To run tests that match a certain pattern:  cargo test test_pattern # e.g., to run grpc related tests: cargo test grpc   To run a specific test by passing the full module path:  cargo test -- --exact test_name # e.g., for grpc protobuf conversion: cargo test -- --exact grpc::protobuf::tests::convert_value   To skip certain tests:  cargo test -- --skip test_pattern # e.g., to ignore grpc related tests: cargo test -- --skip grpc   For more available options, please refer to rustc filter's documentation.  ","version":"Next","tagName":"h3"},{"title":"Writing Tests​","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#writing-tests","content":" ","version":"Next","tagName":"h2"},{"title":"Unit Tests​","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#unit-tests","content":" Unit tests should focus on individual components, ensuring each functions as expected:  Place unit tests in the same file as your code, under a #[cfg(test)] module. Use descriptive function names for your tests, for eg: #[cfg(test)] mod tests { #[test] fn test_addition() { assert_eq!(2 + 2, 4); } } For every new feature or bug fix, structure your tests as follows: Set up the value using helper methods in tests. Compare an actual and an expected value. Assert the two values on separate lines. Ensure there is one assertion per test. For eg: use pretty_assertions::assert_eq; fn test_something_important() { // Setup let value = setup_something_using_a_function(); // Compute Actual let actual = perform_some_operation_on_the_value(value); // Compute Expected let expected = ExpectedValue {foo: 1, bar: 2}; // Compare Actual and Expected assert_eq!(actual, expected); } Before submitting a pull request, verify all tests pass.  ","version":"Next","tagName":"h3"},{"title":"Integration Tests​","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#integration-tests","content":" Integration testing is conducted using our markdown-based DSL. Please refer to its own documentation for detailed information.  ","version":"Next","tagName":"h3"},{"title":"Naming Conventions​","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#naming-conventions","content":" Test functions should begin with test_ followed by a description of their purpose.Use underscores to separate words in the test function names for readability.  ","version":"Next","tagName":"h2"},{"title":"What to Test​","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#what-to-test","content":" In essence, test everything! Write unit tests for modules that can be tested independently and supplement them with integration tests to ensure the overall system stability.  ","version":"Next","tagName":"h2"},{"title":"Troubleshooting Common Issues​","type":1,"pageTitle":"Unit Testing","url":"/docs/contributors/testing/#troubleshooting-common-issues","content":" Ensure your branch is up-to-date with the latest commits from the main branch.Verify that your environment conforms to the required configurations (e.g., versions of Rust and dependencies).Confirm that test failures are not caused by your changes (e.g., run tests with a clean build on the main branch). ","version":"Next","tagName":"h2"},{"title":"Mutability","type":0,"sectionRef":"#","url":"/docs/contributors/mutability/","content":"","keywords":"","version":"Next"},{"title":"Using References​","type":1,"pageTitle":"Mutability","url":"/docs/contributors/mutability/#using-references","content":" When calling functions that do not need to modify the values they receive, pass references to these values. This avoids unnecessary copying and preserves the original data integrity.💰  Consider a function that calculates the total number of items in a list. This function does not alter the list, so pass the list as a reference:  fn count_items(items: &amp;Vec&lt;i32&gt;) -&gt; usize { items.len() } let my_items = vec![1, 2, 3]; let total = count_items(&amp;my_items);   ","version":"Next","tagName":"h2"},{"title":"Using Ownership​","type":1,"pageTitle":"Mutability","url":"/docs/contributors/mutability/#using-ownership","content":" When calling functions that need to modify the values they receive, pass ownership of these values to the function. This makes it clear that the function might change the value. Ensure that the modified values are returned from the function if further use is required.  Consider a function that adds an item to a list. Since this modifies the list, pass the list with ownership and return the modified list:  fn add_item(mut items: Vec&lt;i32&gt;, item: i32) -&gt; Vec&lt;i32&gt; { items.push(item); items } let my_items = vec![1, 2, 3]; let updated_items = add_item(my_items, 4);   ","version":"Next","tagName":"h2"},{"title":"Using Mutable References​","type":1,"pageTitle":"Mutability","url":"/docs/contributors/mutability/#using-mutable-references","content":" Mutable references are particularly useful when you need to modify the data a function receives without taking ownership of it. This approach is ideal for types that behave like classical stateful services, where maintaining state across multiple function calls is necessary.  Consider a caching mechanism where data needs to be frequently updated or retrieved based on function calls. In this case, using a mutable reference allows the cache to be updated without transferring ownership each time:  struct Cache { data: HashMap&lt;String, String&gt;, } impl Cache { fn add_entry(&amp;mut self, key: String, value: String) { self.data.insert(key, value); } fn get_entry(&amp;self, key: &amp;str) -&gt; Option&lt;&amp;String&gt; { self.data.get(key) } } let mut my_cache = Cache { data: HashMap::new() }; my_cache.add_entry(&quot;session1&quot;.to_string(), &quot;User123&quot;.to_string()); if let Some(user) = my_cache.get_entry(&quot;session1&quot;) { println!(&quot;Cached user: {}&quot;, user); }   note Even though in Rust mutability is a lot more tamed than other languages, as a standard we try to stay away from mutable references as much as possible.  ","version":"Next","tagName":"h2"},{"title":"Exceptions​","type":1,"pageTitle":"Mutability","url":"/docs/contributors/mutability/#exceptions","content":" The approach outlined above may not be suitable for performance-sensitive components or frequently executed sections of code (hot code paths). In such scenarios, prioritize efficiency and adopt optimization strategies to enhance performance. Sometimes the API design of a dependent library can also influence the way we write code. These are all the exceptions where it's ok to move away from the above set guidelines. ","version":"Next","tagName":"h2"},{"title":"Macro Benchmarks","type":0,"sectionRef":"#","url":"/docs/contributors/wrk-benchmark/","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#prerequisites","content":" Rust and Cargo (https://rustup.rs/)wrk benchmarking tool (Installation instructions: https://github.com/wg/wrk)  ","version":"Next","tagName":"h2"},{"title":"Step 1: Build Tailcall​","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#step-1-build-tailcall","content":" Ensure you are on the desired branch you want to benchmark, and then build Tailcall in release mode to optimize performance:  cargo build --release   ","version":"Next","tagName":"h2"},{"title":"Step 2: Start the Server​","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#step-2-start-the-server","content":" Start the Tailcall server by setting the appropriate environment variable to control log output and using the release binary:  export TC_LOG_LEVEL=error cargo run --release -- start ./jsonplaceholder.graphql   This command sets the log level to error to minimize logging output, which can affect performance during benchmarks.  ","version":"Next","tagName":"h2"},{"title":"Step 3: Verify Server is Running​","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#step-3-verify-server-is-running","content":" Before running wrk, verify that the server is responsive. Use curl to send a request:  curl -X POST -H &quot;Content-Type: application/json&quot; \\ -d '{&quot;operationName&quot;:null,&quot;variables&quot;:{},&quot;query&quot;:&quot;{posts{title}}&quot;}' \\ http://127.0.0.1:8000/graphql   Repeat this a couple of times to ensure the server is handling requests correctly.  ","version":"Next","tagName":"h2"},{"title":"Step 4: Customize WRK Setup with Lua Script​","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#step-4-customize-wrk-setup-with-lua-script","content":" To customize the wrk setup, create a Lua script named wrk_script.lua and paste the following content:  wrk.method = &quot;POST&quot; wrk.body = '{&quot;operationName&quot;:null,&quot;variables&quot;:{},&quot;query&quot;:&quot;{posts{title}}&quot;}' wrk.headers[&quot;Connection&quot;] = &quot;keep-alive&quot; wrk.headers[&quot;Content-Type&quot;] = &quot;application/json&quot;   This script configures wrk to send POST requests with a specific JSON body and headers.  ","version":"Next","tagName":"h2"},{"title":"Step 5: Run the Benchmark​","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#step-5-run-the-benchmark","content":" Open another terminal window and execute wrk to start the benchmark. Here is a basic example:  wrk -t12 -c400 -d30s -s wrk_script.lua http://127.0.0.1:8000/graphql   This command uses 12 threads and maintains 400 open HTTP connections over a duration of 30 seconds, targeting the server running on localhost port 8000.  ","version":"Next","tagName":"h2"},{"title":"Step 6: Interpreting Results​","type":1,"pageTitle":"Macro Benchmarks","url":"/docs/contributors/wrk-benchmark/#step-6-interpreting-results","content":" wrk will output statistics about the tests, which include:  Total number of requests completedThroughput, measured in requests per secondLatency distribution  These metrics help assess the performance capabilities and robustness of your server under high load conditions. ","version":"Next","tagName":"h2"},{"title":"Deploy Tailcall GraphQL on Fly.io","type":0,"sectionRef":"#","url":"/docs/deploy-tailcall-graphql-fly-actions/","content":"","keywords":"","version":"Next"},{"title":"Generate API Key for Fly.io​","type":1,"pageTitle":"Deploy Tailcall GraphQL on Fly.io","url":"/docs/deploy-tailcall-graphql-fly-actions/#generate-api-key-for-flyio","content":" Follow these steps to generate an API key:  Go to the Fly.io dashboard. Click on Tokens in the left sidebar. Optionally, provide a name and an expiry date for the token. Click on Create Organization Token to generate the token. Copy the generated token and store it securely. You will need this token as input to the tailcallhq/gh-action when deploying to Fly.io.  ","version":"Next","tagName":"h2"},{"title":"Setting Up the Project Repository​","type":1,"pageTitle":"Deploy Tailcall GraphQL on Fly.io","url":"/docs/deploy-tailcall-graphql-fly-actions/#setting-up-the-project-repository","content":" Next, create a new repository on GitHub and use the tailcallhq/gh-action GitHub action to deploy it. The easiest way to get started is by using this template repository: https://github.com/tailcallhq/deploy-tailcall.  Go to the repository and click on Use this template to create a new repository. Name your repository and click on Create repository. After creating the repository, add the Fly.io API token to the repository secrets. To do this, click on Settings. Click on Secrets and variables in the left sidebar to expand the section, then click on Actions. Click on New repository secret to add a new secret. Name the secret FLY_API_TOKEN or any preferred name, and paste the Fly.io API token you generated earlier into the value field. Click on Add secret to save it.  You are now ready to deploy your tailcall server on Fly.io.  ","version":"Next","tagName":"h2"},{"title":"Deploy on Fly.io​","type":1,"pageTitle":"Deploy Tailcall GraphQL on Fly.io","url":"/docs/deploy-tailcall-graphql-fly-actions/#deploy-on-flyio","content":" In this example, we will deploy a simple GraphQL server using tailcall on Fly.io, which converts the JSONPlaceholder REST API to a GraphQL API.  Below is the configuration present in the template repository, which will be used for this deployment.  tip You can learn more about the configuration here  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) }   To deploy the server, update the provider to fly in the deploy-tailcall job in the .github/workflows/main.yml file, as shown below.  on: [push] jobs: deploy_tailcall: runs-on: ubuntu-latest name: Deploy Tailcall steps: - name: Checkout repository uses: actions/checkout@v2 - name: Deploy Tailcall id: deploy-tailcall uses: tailcallhq/gh-action@&lt;version&gt; # Replace &lt;version&gt; with the desired version with: provider: &quot;fly&quot; # Specifies the cloud provider as 'fly' fly-api-token: ${{ secrets.FLY_API_TOKEN }} fly-app-name: &lt;app-name&gt; # Replace &lt;app-name&gt; with the desired app name fly-region: &quot;lax&quot; tailcall-config: &quot;./config.graphql&quot;   important When specifying the fly-app-name in your GitHub Actions workflow for deploying to Fly.io, ensure the app name you choose is unique across all Fly.io users.  Fly.io requires each app name to be globally unique. If the name you select is already taken by another user, your deployment will fail. To avoid this issue, consider using a name that includes unique identifiers such as your organization name, project name, etc. If you do not specify the app name, &lt;orgname&gt;-&lt;reponame&gt; will be used.  After updating the main.yml file, commit the changes and push them to the repository. This will trigger the deployment of the tailcall server on Fly.io. Once the deployment is successful, you can access the GraphQL playground at https://tailcall.run/playground/?u=https://&lt;fly-app-name&gt;.fly.dev/graphql. ","version":"Next","tagName":"h2"},{"title":"Github Action for Deploying GraphQL","type":0,"sectionRef":"#","url":"/docs/deploy-graphql-github-actions/","content":"","keywords":"","version":"Next"},{"title":"Deploying to Fly​","type":1,"pageTitle":"Github Action for Deploying GraphQL","url":"/docs/deploy-graphql-github-actions/#deploying-to-fly","content":" Below is an example of how to deploy a tailcall server to Fly using the tailcallhq/gh-action action.  on: [push] jobs: deploy_tailcall: runs-on: ubuntu-latest name: Deploy Tailcall steps: - name: Checkout repository uses: actions/checkout@v2 - name: Deploy Tailcall id: deploy-tailcall uses: tailcallhq/gh-action@&lt;version&gt; # Replace &lt;version&gt; with the desired version with: provider: &quot;fly&quot; # Specifies the cloud provider as 'fly' fly-api-token: ${{ secrets.FLY_API_TOKEN }} fly-app-name: &quot;tailcall&quot; fly-region: &quot;lax&quot; tailcall-config: &quot;config.graphql&quot;   ","version":"Next","tagName":"h2"},{"title":"Inputs for tailcallhq/gh-action​","type":1,"pageTitle":"Github Action for Deploying GraphQL","url":"/docs/deploy-graphql-github-actions/#inputs-for-tailcallhqgh-action","content":" Following are the inputs for the tailcallhq/gh-action action when deploying to Fly:  Input\tDescriptionprovider\tWhen deploying to Fly, this should be set to fly. tailcall-config\tThe path of the tailcall configuration file. tailcall-version\tSpecifies the version of tailcall to use for deployment. If not provided, the Action defaults to the latest available version. fly-api-token\tThe Fly API token required for authentication. Ensure this value is stored securely, such as in GitHub Secrets. fly-app-name\tThe name of the Fly app being deployed. Defaults to &lt;orgname&gt;-&lt;reponame&gt; if not specified. fly-region\tThe region where the Fly app will be deployed. Defaults to ord if not specified.  ","version":"Next","tagName":"h3"},{"title":"Deploying to AWS Lambda​","type":1,"pageTitle":"Github Action for Deploying GraphQL","url":"/docs/deploy-graphql-github-actions/#deploying-to-aws-lambda","content":" on: [push] jobs: deploy_tailcall: runs-on: ubuntu-latest name: Deploy Tailcall steps: - name: Checkout repository uses: actions/checkout@v2 - name: Deploy Tailcall id: deploy-tailcall uses: tailcallhq/gh-action@&lt;version&gt; # Replace &lt;version&gt; with the desired version with: provider: &quot;aws&quot; aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} aws-region: &quot;us-east-1&quot; aws-iam-role: &quot;iam_for_tailcall&quot; terraform-api-token: ${{ secrets.TERRAFORM_API_TOKEN }} tailcall-config: &quot;config.graphql&quot;   ","version":"Next","tagName":"h2"},{"title":"Inputs for tailcallhq/gh-action​","type":1,"pageTitle":"Github Action for Deploying GraphQL","url":"/docs/deploy-graphql-github-actions/#inputs-for-tailcallhqgh-action-1","content":" Following are the inputs for the tailcallhq/gh-action action when deploying to AWS Lambda:  Input\tDescriptionprovider\tWhen deploying to AWS Lambda, this should be set to aws. tailcall-config\tThe path to the tailcall configuration file used for deployment. tailcall-version\tSpecifies the version of tailcall to use for deployment. If not provided, the Action defaults to the latest available version. aws-access-key-id\tThe AWS access key ID required for authentication. Ensure this value is stored securely, such as in GitHub Secrets. aws-secret-access-key\tThe AWS secret access key required for authentication. Store this securely, such as in GitHub Secrets. aws-region\tThe AWS region where the Lambda function will be deployed (e.g., us-east-1). aws-iam-role\tThe IAM role name to be created and used for the deployment. If not specified, defaults to iam_for_tailcall. aws-lambda-function-name\tThe name assigned to the created Lambda function. Defaults to tailcall if not specified. terraform-api-token\tThe Terraform Cloud API token required for authentication. Ensure this value is stored securely, such as in GitHub Secrets. ","version":"Next","tagName":"h3"},{"title":"GraphQL Best Practices","type":0,"sectionRef":"#","url":"/docs/graphql-best-practices-tailcall/","content":"","keywords":"","version":"Next"},{"title":"General Naming Principles​","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#general-naming-principles","content":" Consistency is Key: Ensure that naming conventions are uniform across your entire schema to maintain clarity and consistency.Descriptive Over Generic: Opt for descriptive, specific names rather than broad, generic ones to avoid ambiguity.Avoid Abbreviations: Avoid the use of acronyms, initialism, and abbreviations to keep your schema intuitive and understandable.  ","version":"Next","tagName":"h2"},{"title":"Detailed Naming Cases​","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#detailed-naming-cases","content":" ","version":"Next","tagName":"h2"},{"title":"Fields, Arguments, and Directives​","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#fields-arguments-and-directives","content":" Adopt camelCase: Utilize camelCase for field names, argument names, and directive names to achieve a clear, consistent structure.  type Query { postTitle(userId: Int): String } directive @includeIf on FIELD   ","version":"Next","tagName":"h3"},{"title":"Types​","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#types","content":" Prefer PascalCase: Use PascalCase for defining types, enabling easy identification and differentiation.  type Post { ... } enum StatusEnum { ... } interface UserInterface { ... } union SearchResult = ... scalar Date   Enum Values in SCREAMING_SNAKE_CASE: Distinguish enum values by using SCREAMING_SNAKE_CASE.  enum StatusEnum { PUBLISHED DRAFT }   ","version":"Next","tagName":"h3"},{"title":"Field Naming Best Practices​","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#field-naming-best-practices","content":" ","version":"Next","tagName":"h2"},{"title":"Queries​","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#queries","content":" Avoid get or list Prefixes: Refrain from using prefixes like get or list in your query names to ensure predictability and consistency.  type Query { # 👎 Avoid getPosts: [Post] # 👍 Prefer posts: [Post] }   Maintain consistency between root and nested fields:  # 👎 Avoid query PostQuery { getPosts { id getUser { name } } } # 👍 Prefer query PostQuery { posts { id user { name } } }   ","version":"Next","tagName":"h3"},{"title":"Mutations​","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#mutations","content":" Verb Prefixes for Mutations: Begin mutation field names with a verb to indicate the action being performed, improving schema readability.  type Mutation { # 👎 Avoid postAdd(input: AddPostInput): AddPostPayload! # 👍 Prefer addPost(input: AddPostInput): AddPostPayload! }   ","version":"Next","tagName":"h3"},{"title":"Type Naming Conventions​","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#type-naming-conventions","content":" ","version":"Next","tagName":"h2"},{"title":"Input Types​","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#input-types","content":" Input Suffix: Denote input types by appending Input to their names, specifying their use case.  input AddPostInput { title: String! body: String! userId: Int! }   ","version":"Next","tagName":"h3"},{"title":"Output Types​","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#output-types","content":" Response or Payload Suffix: Use a consistent suffix like Response or Payload for the output types resulting from mutations.  type Mutation { addPost(input: AddPostInput!): AddPostResponse! } type AddPostResponse { success: Boolean! post: Post }   ","version":"Next","tagName":"h3"},{"title":"Advanced Naming Strategies​","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#advanced-naming-strategies","content":" ","version":"Next","tagName":"h2"},{"title":"Resolving Namespace Conflicts​","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#resolving-namespace-conflicts","content":" For addressing naming conflicts across different domains within your schema:  Use PascalCase Prefix: Distinguish similar types from distinct domains for clear separation without resorting to underscores. This method ensures a cleaner, more professional look while maintaining the integrity and readability of your schema.  type BlogPost { ... } type ForumPost { ... }   ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"GraphQL Best Practices","url":"/docs/graphql-best-practices-tailcall/#conclusion","content":" Implementing a consistent, descriptive, and intuitive naming convention is crucial for developing an understandable and maintainable GraphQL schema. By following the best practices outlined you can improve the clarity and effectiveness of your schema. ","version":"Next","tagName":"h2"},{"title":"Optimizing Performance of your GraphQL Server","type":0,"sectionRef":"#","url":"/docs/graphql-client-performance-tuning/","content":"","keywords":"","version":"Next"},{"title":"HTTP (Hypertext Transfer Protocol)​","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#http-hypertext-transfer-protocol","content":" HTTP, the most widely used protocol for communication between clients and servers, carries your request to the server and then brings back the data to your client. TCP forms the foundation of HTTP.  ","version":"Next","tagName":"h3"},{"title":"HTTP Versions: 1.x, 2, and 3​","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#http-versions-1x-2-and-3","content":" Each version has enhanced HTTP's flexibility and performance.  HTTP/1.x: Creates a separate TCP connection for each HTTP request (or reuses one sequentially).HTTP/2: Introduces multiplexing to allow concurrent sending of requests and responses over a single TCP connection, enhancing performance.HTTP/3: Employs QUIC instead of TCP, further reducing connection setup time and improving packet loss and network change handling.  note The server determines the HTTP version. Thus, if the server supports HTTP/1, the client cannot make an HTTP/2 request, even if compatible. If the client supports HTTP/1, the server should, according to the specification, downgrade to serve the request over HTTP/1.  ","version":"Next","tagName":"h3"},{"title":"TCP (Transmission Control Protocol)​","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#tcp-transmission-control-protocol","content":" TCP ensures the data sent and received over the internet reaches its destination and in order.  TCP, like dialing a number before talking on the phone, establishes a connection between the client and server before exchanging data using HTTP. This guide will show how to tune Tailcall's HTTP client to enhance this connection's performance. Learn more about TCP in detail here.  ","version":"Next","tagName":"h3"},{"title":"QUIC (Quick UDP Internet Connections)​","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#quic-quick-udp-internet-connections","content":" Developed by Google, QUIC aims to make web communications faster and more efficient than TCP. It reduces connection establishment time, handles packet loss better, and supports multiplexed streams over a single connection, preventing a slow request from holding up others. HTTP/3 uses QUIC. Learn more about QUIC in detail here.  ","version":"Next","tagName":"h3"},{"title":"Why Managing Connections is Important?​","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#why-managing-connections-is-important","content":" Performance Overhead: Establishing TCP connections with HTTP/1.x consumes time due to the complete TCP handshake for each new connection. This process adds latency and increases system resources. Limited Ports on Client Side: A unique combination of an IP address and a port number is necessary for each TCP connection from a client. With each new connection, the IP remains the same because the client is the same, but a new port gets used. The number of available ports on a machine is 65535. These ports get shared among all processes, and not all are available for use. Excessive creation of new connections can lead to port exhaustion on the client side, preventing new connections and causing system failures across running processes. tip Use lsof and netstat commands to check the ports to process mapping.  Connection pooling mitigates these issues by reusing existing connections for requests, reducing connection establishment frequency (and thus handshake overhead) and conserving client-side ports. This approach enhances application performance by minimizing the resources and time spent on managing connections.  ","version":"Next","tagName":"h3"},{"title":"Tuning HTTP Client​","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#tuning-http-client","content":" Tailcall uses connection pooling by default and sets up with default tuning suitable for most use cases. You might need to further tune the HTTP client to improve your application's performance. Tailcall DSL provides a directive named @upstream for this purpose.  note Connection pooling optimizes HTTP/1. Since HTTP/2 and HTTP/3 support multiplexing, pooling enabled does not noticeably affect performance.  When using HTTP/1.x, tune the connection pool with the following parameters:  ","version":"Next","tagName":"h2"},{"title":"poolMaxIdlePerHost​","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#poolmaxidleperhost","content":" poolMaxIdlePerHost specifies the allowed number of idle connections per host, defaulting to 60. Example:  schema @upstream( poolMaxIdlePerHost: 60 ) { query: Query }   Too idle connections can unnecessarily consume memory and ports, while too few might cause delays as new connections need frequent establishment. poolMaxIdlePerHost ensures judicious use of network and memory resources, avoiding wastage on seldom-used connections.  For applications connecting to hosts, set this value lower to keep connections available for other hosts. Conversely, if you have hosts and all requests must resolve through them, maintain a higher value for this setting.  ","version":"Next","tagName":"h3"},{"title":"tcpKeepAlive​","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#tcpkeepalive","content":" tcpKeepAlive keeps TCP connections alive for a duration, during inactivity, by periodically sending packets to the server to check if the connection remains open. In connection pooling, tcpKeepAlive maintains reusable connections in a ready-to-use state. This setting is useful for long-lived connections, preventing -lived connections, preventing the client from using a connection the server has closed due to inactivity. Without tcpKeepAlive, connections in the pool might get dropped by the server or intermediate network devices (like firewalls or load balancers). When your client tries to use such a dropped connection, it would fail, causing delays and errors. Keeping connections alive and monitored means you can efficiently reuse them, reducing the overhead of establishing new connections frequently.  Tailcall provides a parameter named tcpKeepAlive for the upstream which defaults to 5 seconds. Example: schema  @upstream ( tcpKeepAlive: 300 ) { query: Query }   ","version":"Next","tagName":"h3"},{"title":"connectTimeout​","type":1,"pageTitle":"Optimizing Performance of your GraphQL Server","url":"/docs/graphql-client-performance-tuning/#connecttimeout","content":" connectTimeout specifically applies to the phase where your client attempts to establish a connection with the server. When making a connection request, the client tries to resolve the DNS, complete the SSL handshake, and establish a TCP connection. In environments where pods are frequently created and destroyed, maintaining a low connectTimeout is crucial to avoid unnecessary delays. In systems using connection pooling, the system aborts the attempt if it cannot establish a connection within the connectTimeout period. This approach prevents indefinite waiting for a connection to establish, which could cause delays and timeouts.  Tailcall offers a connectTimeout parameter to set the connection timeout in seconds for the HTTP client, defaulting to 60 seconds. Example:  schema @upstream( connectTimeout: 10 ) { query: Query }   In summary, maximizing HTTP client performance requires understanding the underlying protocols and configuring client settings through testing. This ensures efficient, robust, and high-performing client-server communication, crucial for the smooth operation of modern web applications. ","version":"Next","tagName":"h3"},{"title":"Sequencing & Parallelism","type":0,"sectionRef":"#","url":"/docs/graphql-data-access-parallel-vs-sequence/","content":"","keywords":"","version":"Next"},{"title":"Examples​","type":1,"pageTitle":"Sequencing & Parallelism","url":"/docs/graphql-data-access-parallel-vs-sequence/#examples","content":" ","version":"Next","tagName":"h2"},{"title":"Example 1: Fetching a Specific User and Their Posts​","type":1,"pageTitle":"Sequencing & Parallelism","url":"/docs/graphql-data-access-parallel-vs-sequence/#example-1-fetching-a-specific-user-and-their-posts","content":" Imagine you're building a blog and want to display a specific user's profile page containing their information and all their posts.  Schema:  type Query { # Retrieve a specific user by ID user(id: Int!): User @http(path: &quot;/users/{{.value.id}}&quot;) } type User { id: Int! name: String! username: String! email: String! # Access user's posts using their ID in the path posts: [Post] @http(path: &quot;/users/{{.value.id}}/posts&quot;) } type Post { id: Int! title: String! body: String! }   GraphQL Query:  query getUserAndPosts($userId: Int!) { # Fetch the user by ID user(id: $userId) { id name username email # Sequentially retrieve all posts for the fetched user posts { id title body } } }   Tailcall understands that retrieving the user's posts depends on knowing the user's ID, which is obtained in the first step. Therefore, it automatically fetches the user first and then uses their ID to retrieve all their posts in a sequential manner.  ","version":"Next","tagName":"h3"},{"title":"Example 2: Searching Multiple Posts and Users by ID​","type":1,"pageTitle":"Sequencing & Parallelism","url":"/docs/graphql-data-access-parallel-vs-sequence/#example-2-searching-multiple-posts-and-users-by-id","content":" Suppose you're building a social media platform and want to display profiles of specific users and their recent posts.  Schema:  type Query { # Retrieve users from the &quot;/users&quot; endpoint users: [User] @http(path: &quot;/users&quot;) } type User { id: Int! name: String! username: String! email: String! # Access user's posts using their ID in the path posts: [Post] @http(path: &quot;/users/{{.value.id}}/posts&quot;) } type Post { id: Int! title: String! body: String! }   GraphQL Query:  query getUsersWithLatestPosts { # Retrieve all users users { id name username email # Access user's posts through the nested field posts { id title body } } }   This query retrieves details of multiple users and their most recent posts based on the provided user IDs. Tailcall recognizes that fetching user details and their individual posts are independent tasks. As a result, it can execute these requests concurrently for each user.  ","version":"Next","tagName":"h3"},{"title":"Example 3: Fetching Posts with Users​","type":1,"pageTitle":"Sequencing & Parallelism","url":"/docs/graphql-data-access-parallel-vs-sequence/#example-3-fetching-posts-with-users","content":" Imagine you're building a social media platform and want to display a list of posts with each post's author. Traditionally, you might write a query that retrieves all posts and then, for each post, make a separate request to fetch its corresponding user. This approach leads to the N+1 problem, where N represents the number of posts, and 1 represents the additional request per post to retrieve its user.  Schema:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) } type User { id: Int! name: String! }   GraphQL Query:  query getPostsWithUsers { posts { id userId title body user { id name } } }   Tailcall analyzes the schema and recognizes that fetching user details for each post is independent. It can potentially execute these requests to /users/{{.value.userId}} concurrently, fetching user data for multiple posts simultaneously.  In summary, Tailcall automates the management of sequence and parallelism in API calls. It analyzes the defined schema to optimize execution, freeing developers from manual intervention. ","version":"Next","tagName":"h3"},{"title":"Data Dog Telemetry Integration","type":0,"sectionRef":"#","url":"/docs/graphql-data-dog-telemetry-tailcall/","content":"Data Dog Telemetry Integration This guide is based on the official doc. Go to datadoghq.comLogin to your account (make sure you choose right region for your account on login)Go to Organization Settings -&gt; API Keys and copy the value of existing key or create a new oneIntegration with datadog requires OpenTelemetry Collector to be able to send data to. As an example we can use following config for the collector: receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 exporters: logging: verbosity: detailed datadog: traces: span_name_as_resource_name: true hostname: &quot;otelcol&quot; api: key: ${DATADOG_API_KEY} # make sure to specify right datadog site based on # https://docs.datadoghq.com/getting_started/site/ site: us5.datadoghq.com processors: batch: datadog/processor: probabilistic_sampler: sampling_percentage: 30 service: pipelines: traces: receivers: [otlp] processors: [batch, datadog/processor] exporters: [datadog] metrics: receivers: [otlp] processors: [batch] exporters: [datadog] logs: receivers: [otlp] processors: [batch] exporters: [datadog] Go to your GraphQL configuration and update it to: schema @telemetry( export: {otlp: {url: &quot;http://localhost:4317&quot;}} ) { query: Query } Set the api key you've copied before to the environment variable named DATADOG_API_KEY and start Otel collector and tailcall with updated config Now make some requests to running service and wait a little bit until Datadog proceeds the data. After that you can go to APM -&gt; Traces, locate the span with name request and click on it. You should see something like on screenshot below: To see metrics now go to Metrics -&gt; Explorer and search for metric you want to see. After updating the query you should see something like on example below:","keywords":"","version":"Next"},{"title":"Field Level GraphQL Authentication","type":0,"sectionRef":"#","url":"/docs/field-level-access-control-graphql-authentication/","content":"","keywords":"","version":"Next"},{"title":"What is Authentication?​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#what-is-authentication","content":" Authentication is the process of verifying a user's identity before granting access to data. In most modern applications, some information, such as a list of products in an e-commerce application, is accessible to all users without requiring identification. However, personal data, like a user's order history, is accessible to the user who owns that information. Verifying a user's identity to access such personal data is known as authentication.  The primary reasons for implementing authentication in an application include:  Protecting User-Specific Data Ensuring that data belonging to a user is not accessible by others.Security The ability to block users based on certain criteria necessitates identifying them.Customized User Experiences Delivering personalized experiences based on a user's identity.  Authentication can be implemented using credential validation mechanisms, such as:  Basic AuthJWTOAuthAPI Key  ","version":"Next","tagName":"h2"},{"title":"Entity Level Authentication in GraphqQL​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#entity-level-authentication-in-graphqql","content":" Entity level authentication in GraphQL refers to applying authentication logic to specific entities or types within your GraphQL schema, rather than at the API entry point or resolver level for individual queries or mutations. This approach allows you to control access to particular data types or fields based on the user's authentication status, enabling a more granular and flexible security model.  Advantages of this approach:  Flexibility: Tailors security measures to precisely fit the needs of your application, enhancing the protection of sensitive data.Scalability: Facilitates extending security policies to new entities and fields as your schema expands.Customization: Enables implementing different authentication mechanisms for distinct entities based on their security requirements.  ","version":"Next","tagName":"h3"},{"title":"GraphQL Authentication​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#graphql-authentication","content":" Tailcall provides a straightforward way to implement entity level authentication in your GraphQL schema. By leveraging custom directives, you can define which entities or fields require authentication to access their data. Tailcall supports multiple authentication providers, such as Basic Auth and JWT, allowing you to choose the authentication mechanism that best suits your application's requirements. to know more about how to use it, read the following articles:  Basic AuthJWT  ","version":"Next","tagName":"h2"},{"title":"GraphQL Configuration​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#graphql-configuration","content":" Enabling support for authentication in Tailcall could be done in two steps:  With the help of @link directive connect multiple authentication files as you need for different provides. To connect it use either Htpasswd or Jwks link typeMark that some type of field requires authentication to be fetched with the help of @protected directive  Your config could look like this now:  schema @server(port: 8000) @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) @link(id: &quot;auth-basic&quot;, type: Htpasswd, src: &quot;htpasswd&quot;) @link(id: &quot;auth-jwt&quot;, type: Jwks, src: &quot;jwks.json&quot;) { query: Query mutation: Mutation } type Query { posts: [Post] @http(path: &quot;/posts&quot;) user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type Mutation { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type User @protected { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! @protected user: User @http(path: &quot;/users/{{.value.userId}}&quot;) }   In that case the whole User type and Post.body are marked as protected and therefore requiring authentication to resolve its content. That means following points:  any query for Post.body will require authenticationany query for any field of User will require authenticationany field that resolves to User type will require authentication  For more info about possible configuration for available providers read articles for Basic Auth and JWT  ","version":"Next","tagName":"h2"},{"title":"Making test requests​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#making-test-requests","content":" Now let's try to access some data from the example above. Start the graphql server with provided config and use graphQL playground that should be opened automatically in your browser.  If you execute the query that don't have any @protected fields like  { posts { title } }   Then the data for this will be resolved as usual without providing any additional info. showing the list of posts with their titles:But if you change the query to access protected data, then if you don't provide any authentication data, i.e. for query:  { posts { body } }   You will get an authentication failure error stating that authentication parameters were not provided. e.g.:  { &quot;data&quot;: null, &quot;errors&quot;: [ { &quot;message&quot;: &quot;Authentication Failure: Missing Authorization Header.&quot;, &quot;locations&quot;: [ { &quot;line&quot;: 3, &quot;column&quot;: 5 } ] } ] }     Now update the request by providing additional Authorization header. You can do in the Playground by navigating to the tab HTTP HEADERS at the bottom by adding following header for Basic Auth:  { &quot;Authorization&quot;: &quot;Basic dGVzdHVzZXIxOnBhc3N3b3JkMTIzs&quot; }   Now after executing the request again you'll get the response for all the requested fields without any error.  ","version":"Next","tagName":"h2"},{"title":"How it works​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#how-it-works","content":" ","version":"Next","tagName":"h2"},{"title":"@protected Type​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#protected-type","content":" If type is marked with @protected then:  attempt to request any field of that type will require authenticationattempt to request any field from other type that resolves to protected type will require authentication and the underlying IO operation won't be executed without it  ","version":"Next","tagName":"h3"},{"title":"Mutation​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#mutation","content":" For mutation entity level authentication works similar to queries. But since mutation involves requests that changes external state you should be careful where do you specify @protected directive because marking some nested field as protected doesn't prevent from executing the request to resolve the parent fields. I.e. following example is problematic:  schema { query: Query mutation: Mutation } type Query { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type Mutation { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;, method: POST) } type User { id: Int! name: String! website: String @protected }   Here you can still execute the mutation without any authentication and fail on attempting to resolve website field.  To resolve this issue, consider marking root fields as protected in case they require authentication, i.e.:  schema { query: Query mutation: Mutation } type Query { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type Mutation { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;, method: POST) @protected } type User { id: Int! name: String! website: String @protected }   ","version":"Next","tagName":"h3"},{"title":"Multiple auth providers​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#multiple-auth-providers","content":" In case you linked multiple authentication files all of them will be used to execute validation process. In that case, by default, Tailcall will validate all of them in parallel and succeed if at least one of them succeed.  ","version":"Next","tagName":"h3"},{"title":"Authentication headers​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#authentication-headers","content":" To validate authentication for user request the specific headers are used (like Authorization header). In case auth is enabled for tailcall those headers will be also added to the allowedHeaders list and therefore they will be forwarded to the upstream requests implicitly.  ","version":"Next","tagName":"h3"},{"title":"Basic Authentication​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#basic-authentication","content":" Basic Authentication is a straightforward authentication scheme that sends base64-encoded usernames and passwords in the HTTP Authorization header with each request. It's simple to implement but requires HTTPS to ensure security due to its lack of encryption.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#prerequisites","content":" To be able to use Basic Authentication support you should have configured htpasswd file that contains users credentials data.  To generate this data you can use Apache tooling itself or available web-tool  important Since this file stores secure information make sure to hash the password you use with secure algorithms  ","version":"Next","tagName":"h3"},{"title":"Basic Auth GraphQL Configuration​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#basic-auth-graphql-configuration","content":" To use Basic Auth you should first include htpasswd file generated from Prerequisites with the help of @link directive.  We can use that file as an example for it that has data for testuser:mypassword credentials in encrypted format:  htpasswd htpasswd testuser:$2y$10$wJ/mZDURcAOBIrswCAKFsO0Nk7BpHmWl/XuhF7lNm3gBAFH3ofsuu   After adding @link you can use the @protected directive to mark the fields that requiring success authentication to be requested.  The whole example could look like this:  schema @server(port: 8000) @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) @link(id: &quot;auth-basic&quot;, type: Htpasswd, src: &quot;htpasswd&quot;) { query: Query } type Query { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type User @protected { id: Int! name: String! username: String! email: String! phone: String website: String }   ","version":"Next","tagName":"h3"},{"title":"Making test request​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#making-test-request","content":" Now you can run the example file with Tailcall and try to make a query for data with specifying credentials.  To make the request first create base64 encoded string from the testuser:mypassword string and then append the result to the Authorization: Basic header.  A request example with curl:  curl --request POST \\ --url http://localhost:8000/graphql \\ --header 'Authorization: Basic dGVzdHVzZXI6bXlwYXNzd29yZA==' \\ --data '{&quot;query&quot;:&quot;query {\\n\\tuser(id: 1) { name }\\n}&quot;}'   or you can use the GraphQL Playground and add the header in the HTTP Headers section:  { &quot;Authorization&quot;: &quot;Basic dGVzdHVzZXIyOm15cGFzc3dvcmQ=&quot; }   with query:  query { user(id: 1) { name } }   Executing such request should be resolved with the user and its name.  ","version":"Next","tagName":"h3"},{"title":"JWT Authentication​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#jwt-authentication","content":" JWT Authentication uses digitally signed tokens to authenticate and transmit user information in a compact JSON format, allowing stateless and secure communication between clients and servers. It offers greater flexibility and security, supporting expiration times and custom data embedding within the token itself.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#prerequisites-1","content":" To be able to use JWT authentication you should have configured JSON Web Key Sets (JWKS for short) file.  To create this file you can use available web-tools like JWK creator in case you already have RSA key-pair or mkjwk if you don't.  ","version":"Next","tagName":"h3"},{"title":"JWT Auth GraphQL Configuration​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#jwt-auth-graphql-configuration","content":" To use JWT you should first include JWKS file generated from Prerequisites with the help of @link directive.  We can use that file as an example for it:  jwks.json jwks.json { &quot;keys&quot;: [ { &quot;kty&quot;: &quot;RSA&quot;, &quot;use&quot;: &quot;sig&quot;, &quot;alg&quot;: &quot;RS256&quot;, &quot;kid&quot;: &quot;I48qMJp566SSKQogYXYtHBo9q6ZcEKHixNPeNoxV1c8&quot;, &quot;n&quot;: &quot;ksMb5oMlhJ_HzAebCuBG6-v5Qc4J111ur7Aux6-8SbxzqFONsf2Bw6ATG8pAfNeZ-USA3_T1mGkYTDvfoggXnxsduWV_lePZKKOq_Qp_EDdzic1bVTJQDad3CXldR3wV6UFDtMx6cCLXxPZM5n76e7ybPt0iNgwoGpJE28emMZJXrnEUFzxwFMq61UlzWEumYqW3uOUVp7r5XAF5jQ_1nQAnpHBnRFzdNPVb3E6odMGu3jgp8mkPbPMP16Fund4LVplLz8yrsE9TdVrSdYJThylRWn_BwvJ0DjUcp8ibJya86iClUlixAmBwR9NdStHwQqHwmMXMKkTXo-ytRmSUobzxX9T8ESkij6iBhQpmDMD3FbkK30Y7pUVEBBOyDfNcWOhholjOj9CRrxu9to5rc2wvufe24VlbKb9wngS_uGfK4AYvVyrcjdYMFkdqw-Mft14HwzdO2BTS0TeMDZuLmYhj_bu5_g2Zu6PH5OpIXF6Fi8_679pCG8wWAcFQrFrM0eA70wD_SqD_BXn6pWRpFXlcRy_7PWTZ3QmC7ycQFR6Wc6Px44y1xDUoq3rH0RlZkeicfvP6FRlpjFU7xF6LjAfd9ciYBZfJll6PE7zf-i_ZXEslv-tJ5-30-I4Slwj0tDrZ2Z54OgAg07AIwAiI5o4y-0vmuhUscNpfZsGAGhE&quot;, &quot;e&quot;: &quot;AQAB&quot; } ] }   After adding @link you can use the @protected directive to mark the fields that requiring success authentication to be requested.  The whole example could look like this:  schema @server(port: 8000) @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) @link(id: &quot;auth-jwks&quot;, type: Jwks, src: &quot;jwks.json&quot;) { query: Query } type Query { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type User @protected { id: Int! name: String! username: String! email: String! phone: String website: String }   ","version":"Next","tagName":"h3"},{"title":"Making test request​","type":1,"pageTitle":"Field Level GraphQL Authentication","url":"/docs/field-level-access-control-graphql-authentication/#making-test-request-1","content":" Now you can run the example file with Tailcall and try to make a query for data with specifying credentials.  To make the request first obtain JWT token compatible with JWKS file you've linked before (if you've used the example jwks.json file from above then you can use the token from the example below).  An request example with curl:  curl --request POST \\ --url http://localhost:8000/graphql \\ --header 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6Ikk0OHFNSnA1NjZTU0tRb2dZWFl0SEJvOXE2WmNFS0hpeE5QZU5veFYxYzgifQ.eyJleHAiOjIwMTkwNTY0NDEuMCwiaXNzIjoibWUiLCJzdWIiOiJ5b3UiLCJhdWQiOlsidGhlbSJdfQ.cU-hJgVGWxK3-IBggYBChhf3FzibBKjuDLtq2urJ99FVXIGZls0VMXjyNW7yHhLLuif_9t2N5UIUIq-hwXVv7rrGRPCGrlqKU0jsUH251Spy7_ppG5_B2LsG3cBJcwkD4AVz8qjT3AaE_vYZ4WnH-CQ-F5Vm7wiYZgbdyU8xgKoH85KAxaCdJJlYOi8mApE9_zcdmTNJrTNd9sp7PX3lXSUu9AWlrZkyO-HhVbXFunVtfduDuTeVXxP8iw1wt6171CFbPmQJU_b3xCornzyFKmhSc36yvlDfoPPclWmWeyOfFEp9lVhQm0WhfDK7GiuRtaOxD-tOvpTjpcoZBeJb7bSg2OsneyeM_33a0WoPmjHw8WIxbroJz_PrfE72_TzbcTSDttKAv_e75PE48Vvx0661miFv4Gq8RBzMl2G3pQMEVCOm83v7BpodfN_YVJcqZJjVHMA70TZQ4K3L4_i9sIK9jJFfwEDVM7nsDnUu96n4vKs1fVvAuieCIPAJrfNOUMy7TwLvhnhUARsKnzmtNNrJuDhhBx-X93AHcG3micXgnqkFdKn6-ZUZ63I2KEdmjwKmLTRrv4n4eZKrRN-OrHPI4gLxJUhmyPAHzZrikMVBcDYfALqyki5SeKkwd4v0JAm87QzR4YwMdKErr0Xa5JrZqHGe2TZgVO4hIc-KrPw' \\ --data '{&quot;query&quot;:&quot;query {\\n\\tuser(id: 1) { name }\\n}&quot;}'   Executing such request should be resolved with the user and its name. ","version":"Next","tagName":"h3"},{"title":"Reading Environment Variables","type":0,"sectionRef":"#","url":"/docs/graphql-environment-variables/","content":"","keywords":"","version":"Next"},{"title":"Need for Environment Variables​","type":1,"pageTitle":"Reading Environment Variables","url":"/docs/graphql-environment-variables/#need-for-environment-variables","content":" Applications rely on external tools, authentication methods, and configurations. For proper functioning, our code needs to access these values.  Consider a scenario of JWT authentication. When signing tokens for our users, we need:  Expiry time: The duration after which the token expires.Secret key: The key for encrypting the token.Issuer: The token issuer, often the organization's name.  There are two ways to manage this:  Hardcode the values in our code: This approach, while simple, poses a massive security risk by exposing sensitive information and requires code changes and application redeployment for updates. Store the values in environment variables: Storing sensitive values in the OS of the server running your application allows runtime access without code modifications, keeping sensitive information secure and simplifying value changes.  ","version":"Next","tagName":"h2"},{"title":"Environment Variables​","type":1,"pageTitle":"Reading Environment Variables","url":"/docs/graphql-environment-variables/#environment-variables","content":" With Tailcall, you can seamlessly integrate environment variables into your GraphQL schema. Tailcall supports this through a env Context variable. All directives share this Context, allowing you to resolve values in your schema.  Example schema:  type Query { users: [User]! @http( baseUrl: &quot;https://jsonplaceholder.typicode.com&quot; path: &quot;/users&quot; ) }   Here, we fetch a list of users from the JSONPlaceholder API. The users field will contain the fetched value at runtime. This works fine, but what if we want to change the API endpoint? We would need to update the code and redeploy the application, which is cumbersome.  We can address this issue using environment variables. Replace the API endpoint with an environment variable, allowing us to change the variable's value without altering our codebase.  type Query { users: [User]! @http(baseUrl: &quot;{{env.API_ENDPOINT}}&quot;, path: &quot;/users&quot;) }   Here, you must set API_ENDPOINT as an environment variable on the device running your server. Upon startup, the server retrieves this value and makes it accessible through the env Context variable.  This approach allows us to change the API endpoint without modifying our codebase. For instance, we might use different API endpoints for development (stage-api.example.com) and production (api.example.com) environments.  Remember, environment variables are not limited to the baseUrl or @http directive. You can use them throughout your schema, as a Mustache template handles their evaluation.  Here's another example, using an environment variable in the headers of @grpc:  type Query { users: [User] @grpc( service: &quot;UserService&quot; method: &quot;ListUsers&quot; protoPath: &quot;./proto/user_service.proto&quot; baseURL: &quot;https://grpc-server.example.com&quot; headers: [ {key: &quot;X-API-KEY&quot;, value: &quot;{{.env.API_KEY}}&quot;} ] ) }   ","version":"Next","tagName":"h2"},{"title":"Security Aspects and Best Practices​","type":1,"pageTitle":"Reading Environment Variables","url":"/docs/graphql-environment-variables/#security-aspects-and-best-practices","content":" Environment variables help reduce security risks, but it's crucial to understand that they do not remove these risks entirely because the values are in plain text. Even if configuration values are not always highly sensitive, there is still a potential for compromising secrets. To ensure your secrets remain secure, consider the following tips:  Use a .env file: It's a common practice to create a .env file in your project's root directory for storing all environment variables. Avoid committing this file to your version control system; instead, add it to .gitignore to prevent public exposure of your secrets. For clarity and collaboration, maintain a .env.example file that enumerates all the necessary environment variables for your application, thereby guiding other developers on what variables they need to set. Within Tailcall (or in other environments), you can make use of this .env file by exporting its key-value pairs to your operating system. For example, if your .env file looks like this: API_ENDPOINT=https://jsonplaceholder.typicode.com Export it to your OS with: export $(cat .env | xargs) On Windows: Get-Content .env | Foreach-Object { [System.Environment]::SetEnvironmentVariable($_.Split(&quot;=&quot;)[0], $_.Split(&quot;=&quot;)[1], &quot;User&quot;) } After this, you can access API_ENDPOINT in your codebase. Use Kubernetes Secrets: When deploying your application with Kubernetes, use its Secrets feature to manage environment variables. This approach ensures your secrets remain private and are not embedded in your codebase, while also making it easier to update values as necessary. Store Secrets Through Cloud Provider GUIs: For deployments using a cloud provider, use their GUI for environment variable management. These interfaces are intuitive and practical for containerized applications that automatically scale.  Following these practices ensures effective and secure management of your environment variables. ","version":"Next","tagName":"h2"},{"title":"Honeycomb Telemetry Integration","type":0,"sectionRef":"#","url":"/docs/graphql-honeycomb-telemetry-tailcall/","content":"Honeycomb Telemetry Integration Go to honeycomb.ioLogin to your accountGo to Account -&gt; Team Settings -&gt; Environments and API Keys -&gt; Configuration and create new or copy existing api keyGo to your GraphQL configuration and update settings: schema @telemetry( export: { otlp: { url: &quot;https://api.honeycomb.io:443&quot; headers: [ { key: &quot;x-honeycomb-team&quot; value: &quot;{{.env.HONEYCOMB_API_KEY}}&quot; } { key: &quot;x-honeycomb-dataset&quot; value: &quot;&lt;your-dataset&gt;&quot; } ] } } ) { query: Query } Set the api key you've copied before to the environment variable named HONEYCOMB_API_KEY and start tailcall with updated config Now make some requests to running service and wait a little bit until honeycomb proceeds the data. After that you can go to Home -&gt; Total traces and click on the trace with name request. Now choose Traces in the bottom and click on the first trace from the list. You should see the picture similar to this: Here you can see data about the request that was made to the GraphQL server and what actions were made to handle this request. To see metrics now go Query and run a query to fetch the data about metrics. You can use following screenshot as an example:","keywords":"","version":"Next"},{"title":"Using HTTP Cache","type":0,"sectionRef":"#","url":"/docs/graphql-http-cache-guide-tailcall/","content":"","keywords":"","version":"Next"},{"title":"Understanding HTTP Caching​","type":1,"pageTitle":"Using HTTP Cache","url":"/docs/graphql-http-cache-guide-tailcall/#understanding-http-caching","content":" HTTP Caching involves saving copies of HTTP responses to serve identical future requests directly from the cache, bypassing the need for new API calls. This reduces latency, conserves bandwidth, and alleviates the load on upstream services by utilizing a cache keyed by request URLs and headers.  By default, HTTP caching is turned off in Tailcall. Enabling it requires setting the httpCache parameter to integer value which is greater than 0 in the @upstream configuration. Tailcall employs a in-memory Least_Recently_Used (LRU) cache mechanism to manage stored responses, adhering to upstream-provided caching directives like Cache-Control to optimize the caching process and minimize redundant upstream API requests.  ","version":"Next","tagName":"h3"},{"title":"Enabling HTTP Caching​","type":1,"pageTitle":"Using HTTP Cache","url":"/docs/graphql-http-cache-guide-tailcall/#enabling-http-caching","content":" To activate HTTP caching, adjust the upstream configuration in Tailcall by setting httpCache to appropriate cache size, as shown in the following example:  schema @server(port: 4000) @upstream( baseURL: &quot;https://api.example.com&quot; httpCache: 42 ) { query: Query }   This configuration instructs Tailcall to cache responses from the designated upstream API.  ","version":"Next","tagName":"h3"},{"title":"Cache-Control headers in responses​","type":1,"pageTitle":"Using HTTP Cache","url":"/docs/graphql-http-cache-guide-tailcall/#cache-control-headers-in-responses","content":" Enabling the cacheControl setting in Tailcall ensures that Cache-Control headers are included in the responses returned to clients. When activated, Tailcall dynamically sets the max-age directive in the Cache-Control header to the minimum max-age value encountered in any of the responses from upstream services. This approach guarantees that the caching duration for the composite response is conservative, aligning with the shortest cache validity period provided by the upstream services. By default, this feature is disabled (false), meaning Tailcall will not modify or add Cache-Control headers unless explicitly instructed to do so. This setting is distinct from the general HTTP cache setting, which controls whether responses are cached internally by Tailcall; cacheControl specifically controls the caching instructions sent to clients.  Here is how you can enable the cacheControl setting within your Tailcall schema to apply these caching instructions:  schema @server(headers: {cacheControl: true}) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"Best Practices for Enhancing REST API Performance on GraphQL​","type":1,"pageTitle":"Using HTTP Cache","url":"/docs/graphql-http-cache-guide-tailcall/#best-practices-for-enhancing-rest-api-performance-on-graphql","content":" The combination of httpCache and cacheControl provides a comprehensive caching solution. While httpCache focuses on internal caching to reduce the impact of high latency and frequent requests, cacheControl manages client-side caching policies, ensuring an optimal balance between performance, data freshness, and efficient resource use.  These caching primitives are beneficial for REST APIs that are latency-sensitive, have a high rate of request repetition, or come with explicit caching headers indicating cacheable responses. Together, they tackle the common challenges of optimizing REST API performance by minimizing unnecessary network traffic and server load while ensuring response accuracy.  To further enhance the performance of any API with Tailcall, integrating the @cache directive offers protocol agnostic control over caching at the field level within a GraphQL schema. ","version":"Next","tagName":"h3"},{"title":"GraphQL over HTTP/2","type":0,"sectionRef":"#","url":"/docs/graphql-http2-guide-tailcall/","content":"","keywords":"","version":"Next"},{"title":"SSL​","type":1,"pageTitle":"GraphQL over HTTP/2","url":"/docs/graphql-http2-guide-tailcall/#ssl","content":" For Tailcall to serve GraphQL over HTTP/2 we need to first enable SSL for which we need to generate a certificate and a key. To generate the required certificates (cert.pem and key.pem) OpenSSL is a widely used option. Here are the steps to get started with SSL:  Install OpenSSL: Download and install OpenSSL from its official website if it's not already installed on your system. Generate Private Key openssl genrsa -out key.pem 2048 This creates a 2048-bit RSA private key, storing it in a file named key.pem. Generate Certificate Signing Request (CSR) openssl req -new -key key.pem -out csr.pem You will be prompted to provide information for the certificate, such as the Common Name (CN), organization details, and locality. This information is embedded into the CSR, saved in a file named csr.pem. This file can be used to request a certificate from a Certificate Authority (CA) or generate a self-signed certificate. Generate Self-Signed Certificate openssl x509 -req -days 365 -in csr.pem -signkey key.pem -out cert.pem This generates a self-signed certificate valid for 365 days using the CSR from step 3 and the private key from step 2. The validity period can be adjusted by changing the number of days (-days). A &quot;Signature ok&quot; prompt confirms the successful creation. Cleanup Intermediate Files rm csr.pem After using the CSR to generate the self-signed certificate (cert.pem), the CSR file (csr.pem) becomes redundant. This step removes intermediate files created during the certificate generation process.  tip Use self-signed certificates for HTTP/2 configurations in development environments. While they enable convenient HTTPS testing locally, in production, always opt for certificates issued by trusted Certificate Authorities.  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"GraphQL over HTTP/2","url":"/docs/graphql-http2-guide-tailcall/#configuration","content":" Once the certificate and key are generated we can link them with our main configuration using the @link directive, to enable HTTPS.  schema @link(type: &quot;Cert&quot;, src: &quot;./cert.pem&quot;) @link(type: &quot;Key&quot;, src: &quot;./key.pem&quot;) { query: Query mutation: Mutation } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type User { id: Int! name: String! }   Once HTTPS is enabled we set the version to HTTP2 for the server:  schema @link(type: &quot;Cert&quot;, src: &quot;./cert.pem&quot;) @link(type: &quot;Key&quot;, src: &quot;./key.pem&quot;) @server(version: HTTP2) { query: Query mutation: Mutation } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type User { id: Int! name: String! }   That's pretty much all that's required. Now you can go ahead and launch your server as usual.  INFO File read: ./jsonplaceholder.graphql ... ok INFO N + 1 detected: 0 INFO 🚀 Tailcall launched at [0.0.0.0:8000] over HTTP/2.0 INFO 🌍 Playground: https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql  ","version":"Next","tagName":"h2"},{"title":"Step-by-Step Tutorial: Building GraphQL over gRPC","type":0,"sectionRef":"#","url":"/docs/graphql-grpc-tailcall/","content":"","keywords":"","version":"Next"},{"title":"What is gRPC?​","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#what-is-grpc","content":" This guide assumes a basic familiarity with gRPC. It is a high-performance framework created by Google for remote procedure calls (RPCs). Its key features include:  HTTP/2 Transport: Ensures efficient and fast data transfer.Protocol Buffers (Protobuf): Serves as a powerful interface description language.Efficiency: Offers binary serialization, reduces latency, and supports data streaming.  This combination of features makes gRPC ideal for microservices and distributed systems. If you need a more detailed understanding or are new to gRPC, we recommend visiting the official gRPC website for comprehensive documentation and resources.  Now, let's explore how gRPC can be integrated into our proxy gateway to enhance communication and data exchange in distributed systems.  ","version":"Next","tagName":"h2"},{"title":"gRPC upstream​","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#grpc-upstream","content":" We need some gRPC service available to be able to execute requests from the Tailcall gateway. For pure example purposes, we will build some simple gRPC services.  ","version":"Next","tagName":"h2"},{"title":"Protobuf definition​","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#protobuf-definition","content":" First, we need to create an example protobuf file that will define the structure of the data we want to transmit using gRPC. Here is the definition of NewsService that implements CRUD operations on news data that we'll put into the news.proto file.  syntax = &quot;proto3&quot;; import &quot;google/protobuf/empty.proto&quot;; package news; // Define message type for News with all its fields message News { int32 id = 1; string title = 2; string body = 3; string postImage = 4; } // Message with the id of a single news message NewsId { int32 id = 1; } // List of IDs of news to get multiple responses message MultipleNewsId { repeated NewsId ids = 1; } // List of all news message NewsList { repeated News news = 1; } // NewsService defines read and write operations for news items service NewsService { // GetAllNews retrieves all news items without any arguments rpc GetAllNews (google.protobuf.Empty) returns (NewsList) {} // GetNews fetches a single news item by its ID rpc GetNews (NewsId) returns (News) {} // GetMultipleNews retrieves multiple news items based on their IDs rpc GetMultipleNews (MultipleNewsId) returns (NewsList) {} }   ","version":"Next","tagName":"h3"},{"title":"Implement gRPC service​","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#implement-grpc-service","content":" Now having the protobuf file you can write a server that implements NewsService at any language you want that supports gRPC. Tailcall organization has a sample node.js service inside this repo that you can pull to your local machine. To spin up the sample service run inside the repo and wait for logs about the service running.  npm i npm start   ","version":"Next","tagName":"h3"},{"title":"GraphQL Configuration for GRPC​","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#graphql-configuration-for-grpc","content":" Now when we have a running gRPC service we're going to write Tailcall's config to make the integration. To do this we need to specify GraphQL types corresponding to gRPC types we have defined in the protobuf file. Let's create a new file grpc.graphql file with the following content:  # The GraphQL representation for News message type type News { id: Int title: String body: String postImage: String } # Input type that is used to fetch news data by its id input NewsInput { id: Int } # Resolves multiple news entries type NewsData { news: [News]! }   Now when we have corresponding types in schema we want to define GraphQL Query that specifies the operation we can execute onto news. We can extend our config with the next Query:  type Query { # Get all news i.e. NewsService.GetAllNews news: NewsData! # Get single news by id i.e. NewsService.GetNews newsById(news: NewsInput!): News! }   Also, let's specify options for Tailcall's ingress and egress at the beginning of the config using @server and @upstream directives.  schema @server(port: 8000) @upstream( baseURL: &quot;http://localhost:50051&quot; httpCache: 42 ) { query: Query }   To specify the protobuf file to read types from, use the @link directive with the type Protobuf on the schema. id is an important part of the definition that will be used by the @grpc directive later  schema @link(id: &quot;news&quot;, src: &quot;./news.proto&quot;, type: Protobuf)   Now you can connect GraphQL types to gRPC types. To do this you may want to explore more about @grpc directive. Its usage is pretty straightforward and requires you to specify the path to a method that should be used to make a call. The method name will start with the package name, followed by the service name and the method name, all separated by the . symbol.  If you need to provide any input to the gRPC method call you can specify it with the body option that allows you to specify a Mustache template and therefore it could use any input data like args and value to construct the body request. The body value is specified in the JSON format if you need to create the input manually and cannot use args input.  type Query { news: NewsData! @grpc(method: &quot;news.news.NewsService.GetAllNews&quot;) newsById(news: NewsInput!): News! @grpc( service: &quot;news.news.NewsService.GetNews&quot; body: &quot;{..args.news}}&quot; ) }   Wrapping up the whole result config that may look like this:  # file: app.graphql schema @server(port: 8000) @upstream( baseURL: &quot;http://localhost:50051&quot; httpCache: 42 ) @link(id: &quot;news&quot;, src: &quot;./news.proto&quot;, type: Protobuf) { query: Query } type Query { news: NewsData! @grpc(method: &quot;news.news.NewsService.GetAllNews&quot;) newsById(news: NewsInput!): News! @grpc( method: &quot;news.news.NewsService.GetNews&quot; body: &quot;{{.args.news}}&quot; ) } type News { id: Int title: String body: String postImage: String } input NewsInput { id: Int } type NewsData { news: [News]! }   Start the server by pointing it to the config.  tailcall start ./app.graphql   And now you can go to the page http://127.0.0.1:8000/graphql and execute some GraphQL queries e.g.:  { news { news { id title body } } }   Or  { newsById(news: {id: 2}) { id title body } }   ","version":"Next","tagName":"h2"},{"title":"Batching​","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#batching","content":" Another important feature of the @grpc directive is that it allows you to implement request batching for remote data almost effortlessly as soon as you have gRPC methods that resolve multiple responses for multiple inputs in a single request.  In our protobuf example file, we have a method called GetMultipleNews that we can use. To enable batching we need to enable @upstream.batch option first and specify batchKey option for the @grpc directive.  schema @server(port: 8000) @upstream( baseURL: &quot;http://localhost:50051&quot; httpCache: 42 batch: {delay: 10} ) @link(id: &quot;news&quot;, src: &quot;./news.proto&quot;, type: Protobuf) { query: Query } type Query { newsById(news: NewsInput!): News! @grpc( method: &quot;news.NewsService.GetNews&quot; body: &quot;{{.args.news}}&quot; batchKey: [&quot;news&quot;, &quot;id&quot;] ) }   Restart the GraphQL server and make the query with multiple news separately, e.g.:  { n1: newsById(news: {id: 1}) { id title body } n2: newsById(news: {id: 2}) { id title body } }   Those 2 requests will be executed inside a single request to the gRPC method GetMultipleNews  ","version":"Next","tagName":"h2"},{"title":"Reflection​","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#reflection","content":" gRPC reflection is a potent feature enabling clients to dynamically discover services and their methods at runtime. Tailcall enhances this capability by obviating the need for developers to link each proto file individually. This feature proves particularly valuable in environments where proto files are continuously evolving or when services dynamically expose varying methods. Here are the steps to follow:  Add the gRPC endpoint as a [link] with type set to Grpc. This enables the GraphQL server to understand that the specified source is a gRPC endpoint that supports reflection. schema @link( src: &quot;https://my-grpc-service.com:50051&quot; type: Grpc ) { query: Query } Next, as before we will just add the methods with a fully qualified name: type Query { news: [News] @grpc(method: &quot;news.NewsService.GetAllNews&quot;) } type News { id: Int title: String body: String postImage: String }   ","version":"Next","tagName":"h2"},{"title":"Can I Automatically Generate GraphQL Schema from .proto?​","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#can-i-automatically-generate-graphql-schema-from-proto","content":" Of course, you can! Tailcall CLI provides a command called tailcall gen that can generate a GraphQL config from a proto file. This command can help you to quickly generate a GraphQL config from a protofile. You can find more information aboutTailcall Config auto generation.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#conclusion","content":" Well done on integrating a gRPC service with the Tailcall gateway! This tutorial has demonstrated the straightforward and efficient process, showcasing Tailcall's compatibility with advanced communication protocols like gRPC.  You can find this working example and test it by yourself by the next links:  node-grpc - example implementation for gRPC service in node.jsgRPC example config - Tailcall's config to integrate with gRPC service above  ","version":"Next","tagName":"h2"},{"title":"Key Takeaways​","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#key-takeaways","content":" Simplicity of Integration: The integration of gRPC with Tailcall seamlessly enhances the overall capability of your system to handle high-performance and efficient data composition.Scalability and Performance: By leveraging the power of gRPC along with Tailcall, we've laid a foundation for building scalable and high-performing distributed systems.  ","version":"Next","tagName":"h3"},{"title":"Next Steps​","type":1,"pageTitle":"Step-by-Step Tutorial: Building GraphQL over gRPC","url":"/docs/graphql-grpc-tailcall/#next-steps","content":" With the basics in place, we encourage you to explore further:  Dive Deeper: Tailcall gateway offers a lot of other features and configurations that you can utilize. Dive deeper into our documentation to explore more advanced settings and customization options.Explore Other Guides: Our documentation includes a variety of guides and tutorials that can help you leverage the full potential of Tailcall in different scenarios. Whether it's adding security layers, load balancing, or detailed logging, there's a lot more to explore. ","version":"Next","tagName":"h3"},{"title":"Logging Levels Configuration","type":0,"sectionRef":"#","url":"/docs/graphql-logging-levels-tailcall/","content":"","keywords":"","version":"Next"},{"title":"error​","type":1,"pageTitle":"Logging Levels Configuration","url":"/docs/graphql-logging-levels-tailcall/#error","content":" This is the highest severity level. It indicates a critical issue that may lead to the failure of the program or a part of it.  TAILCALL_LOG_LEVEL=error tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=error tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"warn​","type":1,"pageTitle":"Logging Levels Configuration","url":"/docs/graphql-logging-levels-tailcall/#warn","content":" This log level signifies potential issues or warnings that do not necessarily result in immediate failure but may require attention.  TAILCALL_LOG_LEVEL=warn tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=warn tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"info​","type":1,"pageTitle":"Logging Levels Configuration","url":"/docs/graphql-logging-levels-tailcall/#info","content":" This level offers general information about the program's execution, providing insights into its state and activities.  TAILCALL_LOG_LEVEL=info tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=info tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"debug​","type":1,"pageTitle":"Logging Levels Configuration","url":"/docs/graphql-logging-levels-tailcall/#debug","content":" The debug log level is useful for developers during the debugging process, providing detailed information about the program's internal workings.  TAILCALL_LOG_LEVEL=debug tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=debug tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"trace​","type":1,"pageTitle":"Logging Levels Configuration","url":"/docs/graphql-logging-levels-tailcall/#trace","content":" The trace log level is the most detailed logging level, used for fine-grained debugging. This level provides exhaustive details about the program's execution flow.  TAILCALL_LOG_LEVEL=trace tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=trace tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"off​","type":1,"pageTitle":"Logging Levels Configuration","url":"/docs/graphql-logging-levels-tailcall/#off","content":" This level serves as a special indicator for generating no logs, allowing the option to disable logging entirely.  TAILCALL_LOG_LEVEL=off tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=off tailcall &lt;COMMAND&gt;   info The default log level is info.  Log levels are hierarchical, meaning if you set the log level to a specific level, it includes all the levels above it. For example, setting the log level to info will include logs at the info, warn, and error levels, but exclude debug and trace logs.    info You can specify log levels in either uppercase or lowercase; both yield the same result. For example, TAILCALL_LOG_LEVEL=DEBUG and TAILCALL_LOG_LEVEL=debug are same. ","version":"Next","tagName":"h3"},{"title":"Customizing using Javascript","type":0,"sectionRef":"#","url":"/docs/graphql-javascript-customization/","content":"","keywords":"","version":"Next"},{"title":"Getting Started​","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#getting-started","content":" To leverage this customization, JavaScript functions must be created in a JavaScript file and linked with the main configuration file using the @link directive. There are two primary ways to achieve this:  Define an onRequest property with the JS function name in the http directive.Define it in the upstream directive, which acts as a global middleware for all requests.  tip If you specify a onRequest handler for both http and upstream the http one will always take precedence over the global onRequest handler.  The function serves as middleware, allowing for the interception and modification of the request, as well as the production of artificial responses. Here is a simple example of a worker.js file with a function named foo, which takes a request object as an argument, logs the request, and returns the original request without any modifications.  function foo({request}) { console.log(`${request.method} ${request.uri.path}`) return {request} }   Once you have a worker file ready, link that file to the GraphQL configuration using the @link directive and define the onRequest property.  schema @link(type: Script, src: &quot;./worker.js&quot;) @upstream(onRequest: &quot;foo&quot;) { query: Query }   Now, you can start the server using the usual start command. Requests made to the GraphQL server will now be intercepted by the worker and logged to the console.  ","version":"Next","tagName":"h2"},{"title":"Modify Request​","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#modify-request","content":" You can modify the request by returning a request object from the onRequest function. Below is an example where we are modifying the request to add a custom header.  function onRequest({request}) { request.headers[&quot;x-custom-header&quot;] = &quot;Hello, Tailcall!&quot; return {request} }   ","version":"Next","tagName":"h2"},{"title":"Create Response​","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#create-response","content":" You can respond with custom responses by returning a response object from the onRequest function. Below is an example where we are responding with a custom response for all requests that start with https://api.example.com.  function onRequest({request}) { if (request.uri.path.startsWith(&quot;https://api.example.com&quot;)) { return { response: { status: 200, headers: { &quot;content-type&quot;: &quot;application/json&quot; }, body: JSON.stringify({message: &quot;Hello, Tailcall!&quot;}) } } } else { return {request} }   ","version":"Next","tagName":"h2"},{"title":"Response Redirect​","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#response-redirect","content":" Sometimes you might want to redirect the request to a different URL. You can do this by returning a response object with a status of 301 or 302 and a Location header. The following example redirects all requests to https://example.com to https://tailcall.com.  function onRequest({request}) { if (request.uri.path.startsWith(&quot;https://example.com&quot;)) { return { response: { status: 301, headers: { Location: &quot;https://tailcall.com&quot;, }, }, } } else { return {request} } }   important The new request that's created as a result of the redirect will not be intercepted by the worker.  ","version":"Next","tagName":"h2"},{"title":"Schema​","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#schema","content":" The onRequest function takes a single argument that contains the request object. The return value of the onRequest function can be a request object, or a response object. It can not be null or undefined.  ","version":"Next","tagName":"h2"},{"title":"Request​","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#request","content":" The request object has the following shape:  type Request = { method: string uri: { path: string query?: {[key: string]: string} scheme: &quot;Http&quot; | &quot;Https&quot; host?: string port?: number } headers: {[key: string]: string} body?: string }   By default the headers field will be empty in most cases, unless headers are whitelisted via the allowedHeaders setting in @upstream.  The http filter doesn't have access to the request's body, hence you can't directly modify the body of an outgoing request. This is more of a design choice than a limitation we have made to ensure that developers don't misuse this API to write all kind of business logic in Tailcall.  tip As an escape hatch you can pass the request body as a query param instead of an actual request body and read in the JS.  The modified request that's returned from the above onRequest function can optionally provide the body. This body is used by Tailcall as the request body while making the upstream request.  ","version":"Next","tagName":"h3"},{"title":"Response​","type":1,"pageTitle":"Customizing using Javascript","url":"/docs/graphql-javascript-customization/#response","content":" The response object has the following shape:  type Response = { status: number headers: {[key: string]: string} body?: string }  ","version":"Next","tagName":"h3"},{"title":"New Relic Telemetry Integration","type":0,"sectionRef":"#","url":"/docs/graphql-newrelic-guide-telemetry/","content":"New Relic Telemetry Integration The guide is based on official doc Go to newrelic.comLogin to your accountGo to &lt;your user name&gt; -&gt; Api Keys and copy license value for key with access to write dataGo to GraphQL configuration and update it with: schema @telemetry( export: { otlp: { url: &quot;https://otlp.nr-data.net:4317&quot; headers: [ { key: &quot;api-key&quot; value: &quot;{{.env.NEWRELIC_API_KEY}}&quot; } ] } } ) { query: Query } Set the api key you've copied before to the environment variable named NEWRELIC_API_KEY and start tailcall with updated config Now make some requests to running service and wait a little bit until New Relic proceeds the data. After that you can go to Traces locate request trace, click on it, then pick one of the available traces and click on it. You should see something like the screenshot below: To see metrics now go to APM &amp; Services -&gt; Metrics Explorer and choose the metrics you want to see like on example below.","keywords":"","version":"Next"},{"title":"GraphQL Playground","type":0,"sectionRef":"#","url":"/docs/graphql-playground-guide/","content":"","keywords":"","version":"Next"},{"title":"Performance and Security​","type":1,"pageTitle":"GraphQL Playground","url":"/docs/graphql-playground-guide/#performance-and-security","content":" Performance Impact: The showcase feature prioritizes flexibility and ease of testing over speed, leading to slower response times due to the overhead of dynamically applied configurations.Security Risk: There's a potential security risk as it may allow unauthorized access to files and environment variables.  important Due to these concerns, this mode is not recommended for production environments. ","version":"Next","tagName":"h2"},{"title":"GraphQL Configuration Generation with Tailcall","type":0,"sectionRef":"#","url":"/docs/graphql-configuration-generation-with-tailcall/","content":"","keywords":"","version":"Next"},{"title":"What is Configuration Generation?​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#what-is-configuration-generation","content":" Configuration generation is the process of automatically generating graphQL configurations from the various sources such as REST, gRPC and already existing GraphQL configuration files.  ","version":"Next","tagName":"h2"},{"title":"Why is it Hard to Write GraphQL Schemas by Hand?​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#why-is-it-hard-to-write-graphql-schemas-by-hand","content":" Writing GraphQL schemas manually presents several challenges that can complicate and slow down the development process:  Complex API Responses: Large and Detailed Responses: APIs often return extensive and intricate data, making it laborious to map these responses accurately to GraphQL types.Nested Structures: Dealing with deeply nested JSON objects requires careful handling to ensure all relationships and data hierarchies are correctly represented in the schema. Data Consistency: Missing Properties: APIs can have inconsistent data where some items might lack certain properties, necessitating meticulous examination to define accurate types and optional fields.Dynamic Data: Handling APIs with dynamic data fields adds another layer of complexity, requiring flexible and robust schema definitions to accommodate various data shapes. Migration Efforts: Manual Workload: Converting existing REST APIs or gRPC to GraphQL involves substantial manual effort, such as Type and Schema Writing: Each endpoint must be meticulously mapped to corresponding GraphQL types and queries.Type Merging: Identifying types that are similar in configuration and merging them into single type is tedious and time taking task and prone to errors.Duplicate Type: Identifying and eliminating duplicate in the entire configuration is challenging especially for large scheams, to ensure a clean schema.Type Naming: Inferring and naming types manually, which requires a deep understanding of the underlying data structures and their relationships. Error-Prone Process: The manual creation of schemas increases the likelihood of errors, leading to potential issues in data fetching and integration.  These challenges highlight the need for automated tools, which streamline the process of generating GraphQL schemas, ensuring accuracy and efficiency while reducing the manual workload and error potential.  For more insights on why manual GraphQL schema writing is becoming obsolete, you can read this blog post by Tailcall.  ","version":"Next","tagName":"h3"},{"title":"Features​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#features","content":"   ","version":"Next","tagName":"h2"},{"title":"Effortless REST Integration​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#effortless-rest-integration","content":" Tailcall simplifies GraphQL schema generation from REST APIs, supporting various request types and scenarios. Let's understand this through various examples.  Simple GET Request: In the following example, we demonstrate how to generate a GraphQL schema from https://jsonplaceholder.typicode.com/posts endpoint. This configuration allows Tailcall to fetch data from the specified endpoint and generate a GraphQL schema and save it to output path provided in configuration. JSON Config FormatYML Config Format { &quot;inputs&quot;: [ { &quot;curl&quot;: { &quot;src&quot;: &quot;https://jsonplaceholder.typicode.com/posts&quot;, &quot;fieldName&quot;: &quot;posts&quot;, &quot;headers&quot;: { &quot;Accept&quot;: &quot;application/json&quot;, &quot;secretToken&quot;: &quot;{{.env.TOKEN}}&quot; } } } ], &quot;preset&quot;: { &quot;mergeType&quot;: 1.0 }, &quot;output&quot;: { &quot;path&quot;: &quot;./jsonplaceholder.graphql&quot;, &quot;format&quot;: &quot;graphQL&quot; }, &quot;schema&quot;: { &quot;query&quot;: &quot;Query&quot; } } Let's understand the above configuration file. Input: Defines the API endpoints that the configuration interacts with. Each input specifies: src: Specifies the endpoint URL (https://jsonplaceholder.typicode.com/posts) in this example. fieldName: A unique name that should be used as the field name, which is then used in the operation type. In the example above, it's set to posts. important Ensure that each field name is unique across the entire configuration to prevent overwriting previous definitions. headers: Optional section for specifying HTTP headers required for the API request. tip Never store sensitive information like access tokens directly in configuration files. Leverage templates to securely reference secrets from environment variables. Preset: We've applied only one tuning parameter for the configuration. let's understand it in short. We've set mergeType to 1.0, which basically tells config generator to merge any two GraphQL types that are exactly similar. if you're interested in understanding preset's in detail head over to preset section. Output: Specifies where and in what format the output data should be saved. path: Defines the output file path (in above example, it's ./jsonplaceholder.graphql).format: Specifies the output format as GraphQL (in above example, it's graphQL). Schema: Specifies the name of the Query operation type, which is Query in this example. Generated GraphQL Configuration Generated GraphQL Configuration schema @server @upstream( baseURL: &quot;https://jsonplaceholder.typicode.com&quot; ) { query: Query } type Post { body: String id: Int title: String userId: Int } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } Simple Post Request In the following example, we demonstrate how to generate a GraphQL schema from https://jsonplaceholder.typicode.com/posts endpoint which requires some request body in order to produce the response. This configuration allows Tailcall to make a POST request to the upstream API and retrieve the response to generate a GraphQL schema, which is then saved to the output path specified in the configuration. JSON Config FormatYML Config Format { &quot;inputs&quot;:[ { &quot;curl&quot;: { &quot;src&quot;: &quot;https://jsonplaceholder.typicode.com/posts&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;body&quot;: { &quot;title&quot;: &quot;Tailcall - Modern GraphQL Runtime&quot;, &quot;body&quot;: &quot;Tailcall - Modern GraphQL Runtime&quot;, &quot;userId&quot;: 1 }, &quot;headers&quot;: { &quot;Content-Type&quot;: &quot;application/json&quot;, &quot;Accept&quot;: &quot;application/json&quot; }, &quot;isMutation&quot;: true, &quot;fieldName&quot;: &quot;createPost&quot; } } ], &quot;preset&quot;: { &quot;mergeType&quot;: 1.0 }, &quot;output&quot;:{ &quot;path&quot;:&quot;./jsonplaceholder.graphql&quot;, &quot;format&quot;:&quot;graphQL&quot; }, &quot;schema&quot;:{ &quot;mutation&quot;:&quot;Mutation&quot; } } Let's understand the above configuration file. Input: Defines the API endpoints that the configuration interacts with. Each input specifies: src: Specifies the endpoint URL (https://jsonplaceholder.typicode.com/posts in this example). fieldName: A unique name that should be used as the field name, which is then used in the operation type. In the example above, it's set to createPost. important Ensure that each field name is unique across the entire configuration to prevent overwriting previous definitions. headers: Users can specify the required headers to make the HTTP request in the headers section. tip Never store sensitive information like access tokens directly in configuration files. Leverage templates to securely reference secrets from environment variables. body: This property allows you to specify the request body for methods like POST or PUT. If the endpoint requires a payload, include it here. method: Specify the HTTP method for the request (e.g. GET, POST, PUT, DEL). If not provided, the default method is GET. in above example, it's set to POST. isMutation: This flag indicates whether the request should be treated as a GraphQL Mutation. Set isMutation to true to configure the request as a Mutation. If not specified or set to false, the request will be treated as a Query by default. in above example it's set to true. Preset: We've applied only one tuning parameter for the configuration. let's understand it in short. We've set mergeType to 1.0, which basically tells config generator to merge any two GraphQL types that are exactly similar. if you're interested in understanding preset's in detail head over to preset section. Output: Specifies where and in what format the output data should be saved. path: Defines the output file path (in above example, it's ./jsonplaceholder.graphql).format: Specifies the output format as GraphQL (in above example, it's graphQL). Schema: Specifies the operation type. In this example, it's a Mutation operation with the name Mutation.  Generated GraphQL Configuration Generated GraphQL Configuration schema @server @upstream { mutation: Mutation } input PostInput { body: String title: String userId: Int } type Mutation { createPost(createPostInput: PostInput): Post @http( baseURL: &quot;https://jsonplaceholder.typicode.com&quot; body: &quot;{{.args.createPostInput}}&quot; method: &quot;POST&quot; path: &quot;/posts&quot; ) } type Post { body: String id: Int title: String userId: Int }   info This flexible configuration approach allows you to adapt Tailcall for various HTTP methods by modifying key sections like method, body, isMutation and headers. Tailcall will handle generating the appropriate GraphQL schema based on the provided API interactions.  ","version":"Next","tagName":"h3"},{"title":"Effortless gRPC Integration​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#effortless-grpc-integration","content":" Tailcall simplifies the process of generating GraphQL schemas from gRPC. By specifying the proto file path, Tailcall parses it and generates the corresponding GraphQL types and queries within minutes.  gRPC Integration: In the following example, we demonstrate how to generate a GraphQL schema from a news.proto file. This configuration allows Tailcall to parse the proto file, generate a GraphQL schema and save it to the output path provided in the configuration. JSON Config FormatYML Config Format { &quot;inputs&quot;: [ { &quot;proto&quot;: { &quot;src&quot;: &quot;./news.proto&quot; } } ], &quot;preset&quot;: { &quot;mergeType&quot;: 1.0 }, &quot;output&quot;: { &quot;path&quot;: &quot;./jsonplaceholder.graphql&quot;, &quot;format&quot;: &quot;graphQL&quot; }, &quot;schema&quot;: { &quot;query&quot;: &quot;Query&quot; } }   Let's understand the above configuration file.  Proto: Defines the path to the proto file that the configuration interacts with.  src: Specifies the path to the proto file (./news.proto in this example).  Preset: We've applied only one tuning parameter for the configuration. let's understand it in short.  We've set mergeType to 1.0, which basically tells config generator to merge any two GraphQL types that are exactly similar. if you're interested in understanding preset's in detail head over to preset section.  Output: Specifies where and in what format the output data should be saved.  path: Defines the output file path (in above example, it's ./jsonplaceholder.graphql).format: Specifies the output format as GraphQL (in above example, it's graphQL).  Schema: Specifies the name of the Query operation type, which is Query in this example.  Generated GraphQL Configuration Generated GraphQL Configuration schema @link(src: &quot;./news.proto&quot;, type: Protobuf) @server { query: Query } type News @tag(id: &quot;news.News&quot;) { id: Int title: String content: String author: String } type Query { news: [News] @grpc(method: &quot;news.NewsService.GetNews&quot;) }   for more insights on how gPRC works with GraphQL, you can read this GraphQL over gRPC article.  ","version":"Next","tagName":"h3"},{"title":"Hybrid Integration (REST + gRPC)​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#hybrid-integration-rest--grpc","content":" The Configuration Generator with Tailcall supports a hybrid integration of REST and gRPC. This feature allows you to leverage the strengths of both REST APIs and gRPC to create a unified GraphQL schema. By integrating both sources, you can ensure that your GraphQL schema is comprehensive and up-to-date with your existing APIs and data definitions.  Example Configuration​  Here is an example configuration that demonstrates how to set up a hybrid integration using a REST and gRPC:  JSON Config FormatYML Config Format { &quot;inputs&quot;: [ { &quot;curl&quot;: { &quot;src&quot;: &quot;https://jsonplaceholder.typicode.com/posts&quot;, &quot;fieldName&quot;: &quot;posts&quot; } }, { &quot;proto&quot;: { &quot;src&quot;: &quot;./news.proto&quot; } } ], &quot;preset&quot;: { &quot;mergeType&quot;: 1.0 }, &quot;output&quot;: { &quot;path&quot;: &quot;./output.graphql&quot;, &quot;format&quot;: &quot;graphQL&quot; }, &quot;schema&quot;: { &quot;query&quot;: &quot;Query&quot; } }   Let's understand the above configuration file.  Inputs​  curl - section where we can specify the REST endpoint. src: The URL of the REST API endpoint.fieldName: The field name to use in the GraphQL schema for the REST data. proto - section where we can specify the Proto File. src: The path to the Proto file.  Preset: We've applied only one tuning parameter for the configuration. let's understand it in short.  We've set mergeType to 1.0, which basically tells config generator to merge any two GraphQL types that are exactly similar. if you're interested in understanding preset's in detail head over to preset section.  Output: Specifies where and in what format the output data should be saved.  path: Defines the output file path (in above example, it's ./jsonplaceholder.graphql).format: Specifies the output format as GraphQL (in above example, it's graphQL).  Schema: Specifies the name of the Query operation type, which is Query in this example.  schema @link(src: &quot;./news.proto&quot;, type: Protobuf) @upstream(baseURL: &quot;https://jsonplaceholder.typicode.com&quot;) @server { query: Query } type News @tag(id: &quot;news.News&quot;) { id: Int title: String content: String author: String } type Post { body: String id: Int title: String userId: Int } type Query { posts: [Post] @http(path: &quot;/posts&quot;) news: [News] @grpc(method: &quot;news.NewsService.GetNews&quot;) }   ","version":"Next","tagName":"h3"},{"title":"Understanding Presets​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#understanding-presets","content":" This section is optional and can be used to generate a more optimized configuration by applying various transformers that improve the config generation process, such as automatically inferring meaningful names of the types, merging duplicate types, removing unused types, and more. If you find that the generated GraphQL configuration is sufficient for your needs, you can skip this section.  The config generator provides a set of tuning parameters that can make the generated configurations more readable by reducing duplication and making configuration more readable. This can be configured using the preset section present in configuration.  JSONYML { &quot;preset&quot;: { &quot;mergeType&quot;: 0.8, &quot;consolidateURL&quot;: 0.8, &quot;treeShake&quot;: true, &quot;unwrapSingleFieldTypes&quot;: true, &quot;inferTypeNames&quot;: true, } }   Let's understand how each of the parameter works.  ","version":"Next","tagName":"h2"},{"title":"mergeType​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#mergetype","content":" This setting merges types in the configuration that satisfy the threshold criteria. It takes a threshold value between 0.0 and 1.0 to determine if two types should be merged or not. The default is 1.0. MergeType also supports union types as well as interface types but merging of these types will happen only when they match exactly.  Example 1: following types T1 and T2 are exactly similar, and with a threshold value of 1.0, they can be merged into a single type called M1:  Merging type T1 and T2 into M1 Merging type T1 and T2 into M1 # BEFORE type T1 { id: ID firstName: String lastName: String } type T2 { id: ID firstName: String lastName: String } # AFTER: T1 and T2 are merged into M1. type M1 { id: ID firstName: String lastName: String }   Example 2: following types T1 and T2 are similar with a threshold value of 0.5, they can be merged into a single type called M1:  Merging type T1 and T2 into M1 Merging type T1 and T2 into M1 # BEFORE type T1 { id: ID firstName: String age: Int } type T2 { id: ID firstName: String lastName: String } # AFTER: T1 and T2 are merged into M1. type M1 { id: ID firstName: String lastName: String age: Int }   Example 3: following types T1 and T2 are similar with a threshold value of 0.5 but we can't merge them as they have same field name but different types:  Can't Merge type T1 and T2 as they've same field name but different type Can't Merge type T1 and T2 as they've same field name but different type # BEFORE type T1 { id: ID firstName: String age: Int } type T2 { id: ID firstName: String age: Float }   Example 4: following types Foo and Bar will be merged into type M1 as they match exactly and same change will reflected in union type FooBar.  Merging type Foo and Bar into M1 Merging type Foo and Bar into M1 # BEFORE type Foo { id: ID firstName: String age: Int } type Bar { id: ID firstName: String age: Int } union FooBar = Foo | Bar # After merging type M1 { id: ID firstName: String age: Int } union FooBar = M1   Example 5: following types Foo and Bar won't be merged into type M1 as they don't match exactly.  Can't Merge type T1 and T2 as they've same field name but different type Can't Merge type T1 and T2 as they've same field name but different type # BEFORE type Foo { id: ID firstName: String age: Float } type Bar { id: ID firstName: String age: Int } union FooBar = Foo | Bar     ","version":"Next","tagName":"h3"},{"title":"consolidateURL​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#consolidateurl","content":" The setting identifies the most common base URL among multiple REST endpoints and uses this URL in the upstream directive. It takes a threshold value between 0.0 and 1.0 to determine the most common endpoint. The default is 0.5.  For example, if the Query type has three base URLs, using the consolidateURL setting with a 0.5 threshold will pick the base URL that is used in more than 50% of the http directives, http://jsonplaceholder.typicode.com, and add it to the upstream, cleaning the base URLs from the Query type.  schema @server(hostname: &quot;0.0.0.0&quot;, port: 8000) @upstream(httpCache: 42) { query: Query } type Query { post(id: Int!): Post @http( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; path: &quot;/posts/{{.args.id}}&quot; ) posts: [Post] @http( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; path: &quot;/posts&quot; ) user(id: Int!): User @http( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; path: &quot;/users/{{.args.id}}&quot; ) users: [User] @http( baseURL: &quot;http://jsonplaceholder-1.typicode.com&quot; path: &quot;/users&quot; ) }   After enabling the consolidateURL setting:  schema @server(hostname: &quot;0.0.0.0&quot;, port: 8000) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; httpCache: 42 ) { query: Query } type Query { post(id: Int!): Post @http(path: &quot;/posts/{{.args.id}}&quot;) posts: [Post] @http(path: &quot;/posts&quot;) user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) users: [User] @http( baseURL: &quot;http://jsonplaceholder-1.typicode.com&quot; path: &quot;/users&quot; ) }     ","version":"Next","tagName":"h3"},{"title":"unwrapSingleFieldTypes​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#unwrapsinglefieldtypes","content":" This setting instructs Tailcall to flatten out types with single field.  for example:  type Query { foo: Foo } # Type with only one field type Foo { bar: Bar } # Type with only one field type Bar { a: Int }   After setting unwrapSingleFieldTypes to true:  type Query { foo: Int }   This helps in flattening out types into single field.    ","version":"Next","tagName":"h3"},{"title":"treeShake​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#treeshake","content":" This setting removes unused types from the configuration. When enabled, any type that is defined in the configuration but not referenced anywhere else (e.g., as a field type, union member, or interface implementation) will be removed. This helps to keep the configuration clean and free from unnecessary definitions.  Before applying treeShake, the configuration might look like this. Before applying treeShake, the configuration might look like this. type Query { foo: Foo } type Foo { bar: Bar } # Type not used anywhere else type UnusedType { baz: String } type Bar { a: Int }   After enabling treeShake, the UnusedType will be removed. After enabling treeShake, the UnusedType will be removed. type Query { foo: Foo } type Foo { bar: Bar } type Bar { a: Int }     ","version":"Next","tagName":"h3"},{"title":"inferTypeNames​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#infertypenames","content":" The inferTypeNames setting aims to enhance type naming consistency and readability by suggesting meaningful type names derived from its usage and shape.  Heuristic Algorithm  This is the default algorithm used to infer the name of the types in the configuration.  Generates Type Names: Creates type names from field names using pluralization and other heuristics.Updates Configuration: Replaces existing type names with the inferred names and updates all references.  Before enabling inferTypeNames setting Before enabling inferTypeNames setting type T1 { id: ID name: String email: String post: [T2] } type T2 { id: ID title: String body: String } type Query { users: [T1] @http(path: &quot;/users&quot;) }   User: Derived from T1, since T1 is linked to user data through the users field in the Query type. The new name User clearly indicates the type represents user information. Post: Derived from T2, since T2 is linked to post data through the post field within User. The new name Post clearly indicates the type represents post information.  After enabling inferTypeNames setting After enabling inferTypeNames setting type User { id: ID name: String email: String post: [Post] } type Post { id: ID title: String body: String } type Query { user: User @http(path: &quot;/users&quot;) }   By leveraging field names to derive type names, the schema becomes more intuitive and aligned with the data it represents, making it easier to understand and maintain.  Additional Considerations:  Priority Handling: Types directly associated with root operations are given higher priority during inference. For example, if T2 were associated with a root query or mutation type, it might have a higher priority for inference compared to other types. Pluralization Rules: The inferred type names are converted to singular form to align with typical GraphQL naming conventions. For instance, a type derived from a plural field name like comments would be singularized to Comment.  ","version":"Next","tagName":"h3"},{"title":"LLM Powered Inference​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#llm-powered-inference","content":" This is a more advanced completely opt-in feature. Sometimes it's not possible to infer names correctly based on usage, or a name is not available because its been used already. In such scenarios we leverage LLMs that understand relationships between fields, their schema and other meta information to infer type names. To allow Tailcall to connect to LLMs, you need to provide the API key in the configuration file.  JSONYML { &quot;llm&quot;: { &quot;model&quot;: &quot;gpt-4o&quot;, &quot;secret&quot;: &quot;{{env.LLM_API_KEY}}&quot; } }   tip Checkout our LLM section to get a list of all the LLM models that Tailcall supports.  ","version":"Next","tagName":"h2"},{"title":"Best Practices​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#best-practices","content":" When setting up your configuration file for GraphQL generation with Tailcall, consider these key parameters to optimize and customize your setup:  Merge Type: Controls the merging of similar GraphQL types to reduce duplication. Adjust the threshold (0.0 to 1.0) based on how strictly you want types to match for merging. the closer the number to 1.0, you get the best type inference in graphQL playground. Recommended threshold is anything above 0.9. JSONYML { &quot;preset&quot;: { &quot;mergeType&quot;: 0.9 } } Consolidate URL: Identifies the most common base URL among multiple REST endpoints and uses it in the @upstream directive. Set a threshold (0.0 to 1.0) to determine when to consolidate URLs. Recommended threshold is anything above 0.5. JSONYML { &quot;preset&quot;: { &quot;consolidateURL&quot;: 0.5 } } Headers: Never store sensitive information like access tokens directly in configuration files. Leverage templates to securely reference secrets from environment variables. JSONYML { &quot;headers&quot;: { &quot;secretToken&quot;: &quot;{{.env.TOKEN}}&quot; } }   ","version":"Next","tagName":"h2"},{"title":"FAQ's​","type":1,"pageTitle":"GraphQL Configuration Generation with Tailcall","url":"/docs/graphql-configuration-generation-with-tailcall/#faqs","content":" Q. Can I use environment variables in my configuration?  Answer: Yes, you can use environment variables to securely reference sensitive information like access tokens. Here is an example:  JSONYML { &quot;curl&quot;: { &quot;src&quot;: &quot;https://jsonplaceholder.typicode.com/posts/1&quot;, &quot;fieldName&quot;: &quot;post&quot;, &quot;headers&quot;: { &quot;secretToken&quot;: &quot;{{.env.TOKEN}}&quot; } } }   Q. How do I merge similar types in the configuration?  Answer: Adjust the mergeType parameter in the preset section to control the merging of similar types. A threshold value between 0.0 and 1.0 determines if two types should be merged or not. if you to understand this in detail then please head over to preset section. Here is an example:  JSONYML { &quot;preset&quot;: { &quot;mergeType&quot;: 0.9 } }   Q. What if I have multiple REST endpoints with different base URLs?  Answer: Use the consolidateURL parameter to identify the most common base URL among multiple REST endpoints and it will automatically select the most common base url and add it to the @upstream directive. Here is an example:  JSONYML { &quot;preset&quot;: { &quot;consolidateURL&quot;: 0.5 } }   Q. Can I specify multiple input sources in a single configuration?  Answer: Yes, you can specify multiple input sources, such as different REST endpoints or Proto files, in a single configuration. Here is an example:  JSONYML { &quot;inputs&quot;: [ { &quot;curl&quot;: { &quot;src&quot;: &quot;https://jsonplaceholder.typicode.com/posts&quot;, &quot;fieldName&quot;: &quot;posts&quot; } }, { &quot;proto&quot;: { &quot;src&quot;: &quot;./news.proto&quot; } } ], &quot;schema&quot;: { &quot;query&quot;: &quot;Query&quot; } }  ","version":"Next","tagName":"h2"},{"title":"GraphQL Resolver Context","type":0,"sectionRef":"#","url":"/docs/graphql-resolver-context-tailcall/","content":"","keywords":"","version":"Next"},{"title":"Schema Definition​","type":1,"pageTitle":"GraphQL Resolver Context","url":"/docs/graphql-resolver-context-tailcall/#schema-definition","content":" type Context = { args: Map&lt;string, JSON&gt; value: JSON env: Map&lt;string, string&gt; vars: Map&lt;string, string&gt; headers: Map&lt;string, string&gt; }   Context operates by storing values as key-value pairs, which can be accessed through mustache template syntax.  ","version":"Next","tagName":"h2"},{"title":"args​","type":1,"pageTitle":"GraphQL Resolver Context","url":"/docs/graphql-resolver-context-tailcall/#args","content":" This property facilitates access to query arguments. Consider the example:  type Query { user(id: ID!): User @http(path: &quot;/users/{{.args.id}}&quot;) }   Here, args.id is utilized to retrieve the id argument provided to the user query.  ","version":"Next","tagName":"h3"},{"title":"value​","type":1,"pageTitle":"GraphQL Resolver Context","url":"/docs/graphql-resolver-context-tailcall/#value","content":" This enables access to the fields of the specified type.  type Post { id: ID! title: String! body: String! comments: [Comment] @http(path: &quot;/posts/{{.value.id}}/comments&quot;) }   In this case, value.id accesses the id field of the Post type.  ","version":"Next","tagName":"h3"},{"title":"env​","type":1,"pageTitle":"GraphQL Resolver Context","url":"/docs/graphql-resolver-context-tailcall/#env","content":" Environment variables, set at server startup, allow directives to dynamically adapt behavior based on external configurations without altering the server configuration itself.  Example:  type Query { users: [User]! @http(baseUrl: &quot;{{.env.API_ENDPOINT}}&quot;, path: &quot;/users&quot;) }   env.API_ENDPOINT references an environment variable named API_ENDPOINT, which specifies the base URL for HTTP requests.  ","version":"Next","tagName":"h3"},{"title":"vars​","type":1,"pageTitle":"GraphQL Resolver Context","url":"/docs/graphql-resolver-context-tailcall/#vars","content":" vars offers a mechanism for defining reusable variables within the configuration. Unlike env, these are embedded and can be universally applied across configurations.  schema @server( vars: {key: &quot;apiKey&quot;, value: &quot;{{.env.AUTH_TOKEN}}&quot;} ) { query: Query } type Query { user(id: ID!): [User] @http( url: &quot;/users&quot; headers: [ { key: &quot;Authorization&quot; value: &quot;Bearer {{.vars.apiKey}}&quot; } ] ) }   Here, the variable apiKey is set using an environment variable and subsequently utilized in the Authorization header for HTTP requests.  ","version":"Next","tagName":"h3"},{"title":"headers​","type":1,"pageTitle":"GraphQL Resolver Context","url":"/docs/graphql-resolver-context-tailcall/#headers","content":" Headers originate from the request made to the GraphQL server.  type Query { commentsForUser: [Comment] @http(path: &quot;/users/{{.headers.x-user-id}}/comments&quot;) }   In this example, headers.x-user-id extracts the value of the x-user-id header present in the request, dynamically constructing the request path. ","version":"Next","tagName":"h3"},{"title":"Exposing GraphQL as REST APIs","type":0,"sectionRef":"#","url":"/docs/graphql-rest-integration/","content":"","keywords":"","version":"Next"},{"title":"How it works​","type":1,"pageTitle":"Exposing GraphQL as REST APIs","url":"/docs/graphql-rest-integration/#how-it-works","content":" This guide show you how to expose REST endpoints for your GraphQL operations by using the @rest directive like follows:  There are three main steps to this process:  Define your Tailcall GraphQL configuration file.Define an operation using @rest directive in a separate file.Link the operation to the main config file.  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Exposing GraphQL as REST APIs","url":"/docs/graphql-rest-integration/#example","content":" ","version":"Next","tagName":"h2"},{"title":"Step 1: Define your GraphQL configuration​","type":1,"pageTitle":"Exposing GraphQL as REST APIs","url":"/docs/graphql-rest-integration/#step-1-define-your-graphql-configuration","content":" schema @upstream( baseURL: &quot;https://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { post(id: Int!): Post @http(path: &quot;/posts/{{.args.id}}&quot;) } type Post { userId: Int! id: Int title: String body: String user: User @http(path: &quot;/users/{{.value.userId}}&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String }   for more information on how to define your Tailcall GraphQL configuration file, please refer to the Tailcall GraphQL Configuration.  ","version":"Next","tagName":"h3"},{"title":"Step 2: Define an operation using @rest directive​","type":1,"pageTitle":"Exposing GraphQL as REST APIs","url":"/docs/graphql-rest-integration/#step-2-define-an-operation-using-rest-directive","content":" We will define an operation and use the @rest directive to define a REST endpoint for the operation. We will create a new file and add the following content to it. Save the file with the filename: user-operation.graphql. You can name the file anything you want, but make sure to link it to the main config file in the next step.  query ($id: Int!) @rest(method: GET, path: &quot;/post/$id&quot;) { post(id: $id) { id title body user { id name } } }   to know more about the @rest directive, please refer to the Tailcall GraphQL Directives.  ","version":"Next","tagName":"h3"},{"title":"Step 3: Link the operation to the main config file​","type":1,"pageTitle":"Exposing GraphQL as REST APIs","url":"/docs/graphql-rest-integration/#step-3-link-the-operation-to-the-main-config-file","content":" checkout the @link directive in the config snippet below to link the operation file. This step is crucial to make the REST endpoint available.  schema @upstream(baseURL: &quot;https://jsonplaceholder.typicode.com&quot;) @link(type: Operation, src: &quot;user-operation.graphql&quot;) { query: Query }   To know more about the @link directive, please refer to the Tailcall GraphQL Directives.  Response​    In summary, by utilizing the @rest directive, we've seamlessly exposed RESTful services over Tailcall's GraphQL, enhancing the traditional posts API to offer richer functionality without additional code. This approach combines the simplicity and ubiquity of REST with the modularity and flexibility of GraphQL, allowing for easy consumption from any HTTP client while leveraging GraphQL's powerful data querying capabilities. ","version":"Next","tagName":"h3"},{"title":"Solving GraphQL N+1 Problem with Tailcall","type":0,"sectionRef":"#","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/","content":"","keywords":"","version":"Next"},{"title":"What is the N+1 Problem?​","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#what-is-the-n1-problem","content":" In simple terms, the N+1 problem occurs when your server fetches data in an inefficient manner that is - instead of making a single request to retrieve necessary data set, it makes multiple, separate requests.  For instance, if you're fetching a list of posts and their authors, an inefficient server might first fetch the posts (1 request). Then, for each post, it makes request to fetch their author (N requests). This results in N+1 total requests.  This approach can quickly become problematic as your nested data grows. It leads to a large number of unnecessary requests, slowing down your server and wasting resources.  ","version":"Next","tagName":"h2"},{"title":"Why is N+1 a Problem for GraphQL?​","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#why-is-n1-a-problem-for-graphql","content":" The N+1 problem in GraphQL queries can lead to inefficiencies in data fetching due to poorly optimized resolvers. Let's delve into this issue with a simplified explanation:  Resolver Efficiency: In GraphQL, each nested field within a single query might require its own request. For instance, if you're dealing with a list of N items, this results in N additional requests, culminating in a total of N+1 requests. Complexity in Detection: Identifying and resolving the N+1 problem can be challenging for developers, especially by merely examining GraphQL queries, schema or the server side resolver logic. Optimization Necessity: Addressing this issue often requires employing advanced techniques such as batching request or utilizing open source tools like DataLoader for batch loading to minimize the number of requests triggered by resolvers on your GraphQL server. While effective, these solutions can introduce additional complexity into the development process.    ","version":"Next","tagName":"h2"},{"title":"N+1 in REST APIs​","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#n1-in-rest-apis","content":" Imagine we need to fetch data from the jsonplaceholder.typicode.com, requiring both posts and their authors' details.  First, we request all posts:  ❯ curl https://jsonplaceholder.typicode.com/posts [ { &quot;userId&quot;: 1, &quot;id&quot;: 1, &quot;title&quot;: &quot;Creating Solutions for Challenges&quot;, &quot;body&quot;: &quot;We anticipate and understand challenges, creating solutions while considering exceptions and criticisms.&quot; }, { &quot;userId&quot;: 1, &quot;id&quot;: 2, &quot;title&quot;: &quot;Understanding Identity&quot;, &quot;body&quot;: &quot;Life's essence, measured through time, presents pains and joys. We find solace in the mundane, seeking meaning beyond the visible.&quot; } ]   This command retrieves posts from the API, with each post containing a userId field indicating its author.  Next, we fetch details for each post's author, such as:  ❯ curl https://jsonplaceholder.typicode.com/users/1 { &quot;id&quot;: 1, &quot;name&quot;: &quot;Leanne Graham&quot;, &quot;username&quot;: &quot;Bret&quot;, &quot;email&quot;: &quot;Sincere@april.biz&quot;, &quot;address&quot;: { &quot;street&quot;: &quot;Kulas Light&quot;, &quot;suite&quot;: &quot;Apt. 556&quot;, &quot;city&quot;: &quot;Gwenborough&quot;, &quot;zipcode&quot;: &quot;92998-3874&quot;, &quot;geo&quot;: { &quot;lat&quot;: &quot;-37.3159&quot;, &quot;lng&quot;: &quot;81.1496&quot; } }, &quot;phone&quot;: &quot;1-770-736-8031 x56442&quot;, &quot;website&quot;: &quot;hildegard.org&quot;, &quot;company&quot;: { &quot;name&quot;: &quot;Romaguera-Crona&quot;, &quot;catchPhrase&quot;: &quot;Multi-layered client-server neural-net&quot;, &quot;bs&quot;: &quot;harness real-time e-markets&quot; } }   For 100 posts, this results in 100 additional requests for author details, totaling 101 requests. This is the infamous N+1 problem:  1 request for /posts100 or N requests for /users/:id for each user  info This issue can escalate in real-world scenarios, leading to straining resources, increasing server costs, slowing response times, and potentially causing server downtime even at a moderate scale.  Hope this gives you a high-level overview of what the N+1 problem is in the API context. It's a common problem not specific to just APIs or GraphQL, you will see this problem very commonly in database queries also. However addressing the N+1 problem during application design and development is crucial and we will see how this is tackled in Tailcall.  ","version":"Next","tagName":"h2"},{"title":"N+1 in GraphQL using Tailcall​","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#n1-in-graphql-using-tailcall","content":" Before diving into solutions, let's observe the N+1 problem in the following GraphQL configuration:  tip If you are new here you might want to check out our Getting Started guide.  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) } type User { id: Int! name: String! username: String! email: String! }   This configuration sets up a GraphQL schema for a server utilizing jsonplaceholder.typicode.com as its data source. It allows direct querying of posts and, for each post, retrieves the associated author information. Similar to our curl requests above, when we query for posts and their authors using graphql query on client side given below we end up issuing multiple user calls upstream:  query { posts { id title user { id name email } } }   Let's examine the CLI output for this configuration with Tailcall's start command:  ❯ tailcall start ./examples/jsonplaceholder.graphql INFO File read: ./examples/jsonplaceholder.graphql ... ok INFO N+1 detected: 1 INFO 🚀 Tailcall launched at [0.0.0.0:8000] over HTTP/1.1 INFO 🌍 Playground: https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql INFO GET http://jsonplaceholder.typicode.com/posts HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/8 HTTP/1.1 ... INFO GET http://jsonplaceholder.typicode.com/users/8 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/10 HTTP/1.1   Tailcall logs a sequence of requests made to fetch posts and then their individual authors, highlighting the N+1 problem in real-time. Since there are 100 posts, so 100 requests are made to fetch the authors.  ","version":"Next","tagName":"h2"},{"title":"Deduplication using DataLoaders​","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#deduplication-using-dataloaders","content":" If you run the query, at first you will observe a lot of duplicate requests are being made for getting the same author details.    This happens because of the 100 posts, a lot them are authored by the same user and by default Tailcall will make a request for every user when requested. You can fix this by setting dedupe to true in server.  schema @server( dedupe: true port: 8000) @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query } type Query { # ... } type Post { # ... } type User { # ... }   When you enable dedupe, for each downstream request, Tailcall will automatically using a dataloader deduplicate all upstream requests and instead of making 100 it will only make 10 requests for unique users:  ❯ tailcall start ./examples/jsonplaceholder.graphql INFO File read: ./examples/jsonplaceholder.graphql ... ok INFO N+1 detected: 1 INFO 🚀 Tailcall launched at [0.0.0.0:8000] over HTTP/1.1 INFO 🌍 Playground: https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql INFO GET http://jsonplaceholder.typicode.com/posts HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/1 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/2 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/3 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/4 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/5 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/6 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/7 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/8 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/9 HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/10 HTTP/1.1   This is a massive 10x improvement over the previous implementation. However, it might not always be the case. For eg: If all the posts are created by different users you might still end up making 100 requests upstream.    tip Dedupe has a slight performance overhead so if your use case doesn't have any N+1 issues, it might be worth keeping this setting disabled.  ","version":"Next","tagName":"h2"},{"title":"Detect N+1 using Tailcall​","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#detect-n1-using-tailcall","content":" Before we get into the actual solution, if you observe closely the above logs Tailcall identified that there was one N+1 issue, even before the requests were made:  ❯ tailcall start ./examples/jsonplaceholder.graphql INFO File read: ./examples/jsonplaceholder.graphql ... ok INFO N+1 detected: 1 INFO 🚀 Tailcall launched at [0.0.0.0:8000] over HTTP/1.1 INFO 🌍 Playground: https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql INFO GET http://jsonplaceholder.typicode.com/posts HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users/8 HTTP/1.1 ... INFO GET http://jsonplaceholder.typicode.com/users/10 HTTP/1.1   To get a deeper understanding of what this N+1 issue is, we can use the --n-plus-one-queries parameter with the check command:  ❯ tailcall check ./jsonplaceholder.graphql --n-plus-one-queries INFO File read: ./examples/jsonplaceholder.graphql ... ok INFO Config ./examples/jsonplaceholder.graphql ... ok INFO N+1 detected: 1 query { posts { user } }   Incredible, isn't it? Tailcall has discovered that querying for posts followed by their users would result in N+1 upstream calls. This represents a significant productivity gain, as you can now identify all such N+1 issues upfront without resorting to complex profiling, tracing, or other runtime techniques. The check command also identifies the minimal query that could lead to these N+1 problems by performing semantic analysis of your configuration. With these powerful tools handy you can go about making extremely efficient GraphQL backends as we will see next:  ","version":"Next","tagName":"h2"},{"title":"Using Batch APIs​","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#using-batch-apis","content":"   An effective technique to mitigate the N+1 problem is deduplicating similar requests, significantly reducing the number of server calls. We achieved it previously using the dedupe setting. With Tailcall we can go one step further by giving hints about &quot;batch APIs&quot;.  Batch APIs: Are special APIs that allow us to query multiple things at once. In our case we can pass multiple user Ids as query params, to the /users API to resolve many users at once:  tip Try to hit /users?id=1&amp;id=2  Tailcall provides the capability to leverage Batch APIs. To utilize this feature, edit the @http directive on Post.user field in your GraphQL schema as follows:  type Post { id: Int! userId: Int! title: String! body: String! user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{.value.userId}}&quot;}] batchKey: [&quot;id&quot;] ) }   The described changes introduce two significant tweaks to the @http directive:  Addition of a query parameter: type Post { # ... user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{.value.userId}}&quot;}] batchKey: [&quot;id&quot;] ) } This configuration generates a URL with the userId from the Post in the query params. For a batch of users, the CLI compiles a single URL, such as /users?id=1&amp;id=2&amp;id=3...id=10, consolidating the 10 requests into one. Addition of a batchKey: type Post { # ... user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{.value.userId}}&quot;}] batchKey: [&quot;id&quot;] ) } This parameter instructs the system to use the user's id, in the User type, as the unique identifier. This helps in differentiating between users received from the batch API. important When batchKey is present, Tailcall considers the first query parameter to be the batch query key, so remember to adjust the order of the items accordingly. Whereas, the last item from batchKey is used to instruct which field is the ID of an object. In case that the returned result is a nested property batchKey can be used as a path to extract and group the items for the returned result.  Let's see what the server logs when you now start Tailcall with the updated configuration:  schema @server(port: 8000) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{.value.userId}}&quot;}] batchKey: [&quot;id&quot;] ) } type User { id: Int! name: String! username: String! email: String! }   Let's start the server as usual and focus on the detected N+1 issues:  ❯ tailcall start ./examples/jsonplaceholder.graphql INFO File read: ./examples/jsonplaceholder.graphql ... ok INFO N+1 detected: 0 INFO 🚀 Tailcall launched at [0.0.0.0:8000] over HTTP/1.1 INFO 🌍 Playground: https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql INFO GET http://jsonplaceholder.typicode.com/posts HTTP/1.1 INFO GET http://jsonplaceholder.typicode.com/users?id=1&amp;id=10&amp;id=2&amp;id=3&amp;id=4&amp;id=5&amp;id=6&amp;id=7&amp;id=8&amp;id=9 HTTP/1.1   As you can see there are ZERO N+1 detected this time! It basically means that irrespective of how large the list of posts is there is a finite number of requests that will be issued in this case that's always going to be TWO. And this is how Tailcall users tackle the N+1 problem in GraphQL.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Solving GraphQL N+1 Problem with Tailcall","url":"/docs/graphql-n-plus-one-problem-solved-tailcall/#conclusion","content":" To summarize, we learnt that N+1 is a general problem and not specific to GraphQL. It's a hard problem to identify, and developers often resort to runtime analysis to find such scenarios. N+1 can really strain your infrastructure, leading to serious downtime in certain cases.    We also learnt that in Tailcall, the CLI can introspect your configuration and identify all the potential N+1 issues upfront. Using dedupe, you can improve the N+1 problem significantly, however, it's not a complete solution. To completely eliminate the N+1 problem, you can configure Tailcall to leverage Batch APIs. Hopefully, this guide underscores the effectiveness of Tailcall in addressing the N+1 problem.   ","version":"Next","tagName":"h2"},{"title":"GraphQL Telemetry","type":0,"sectionRef":"#","url":"/docs/graphql-telemetry-guide/","content":"","keywords":"","version":"Next"},{"title":"What is Observability​","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#what-is-observability","content":" Observability is essential for maintaining the health and performance of your applications. It provides insights into your software's operation in real-time by analyzing telemetry data — logs, metrics, and traces. This data helps in troubleshooting, optimizing, and ensuring your application works as expected.  Logs offer a record of events that have happened within your application, useful for understanding actions taken or errors that have occurred.Metrics are numerical data that measure different aspects of your system's performance, such as request rates or memory usage.Traces show the journey of requests through your system, highlighting how different parts of your application interact and perform.  Tailcall provides observability support by integrating OpenTelemetry specification into it with help of provided SDKs and data formats.  OpenTelemetry is a toolkit for collecting telemetry data in a consistent manner across different languages and platforms. It frees you from being locked into a single observability platform, allowing you to send your data to different tools for analysis, such as New Relic or Honeycomb.  ","version":"Next","tagName":"h2"},{"title":"Comparison with Apollo Studio​","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#comparison-with-apollo-studio","content":" While Apollo studio telemetry also provides analytics tools for your schema but when choosing between it and OpenTelemetry integration consider next points:  OpenTelemetry is more generalized observability framework that could be used for cross-service analytics while Apollo Studio can provide insights related purely to graphQLOpenTelemetry is vendor-agnostic and therefore you could actually use different observability platforms depending on your needs and don't rely on single tool like Apollo StudioOpenTelemetry integration in Tailcall can provide more analytical data that is out of scope of graphQL analytics provided by Apollo Studio  ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#prerequisites","content":" Consider we have the following GraphQL configuration that connects with jsonplaceholder.com to fetch the data about user and posts  schema @server(port: 8000, hostname: &quot;0.0.0.0&quot;) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) @cache(maxAge: 3000) user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) }   We will update that config with telemetry integration in following sections.  ","version":"Next","tagName":"h2"},{"title":"GraphQL Configuration for Telemetry​","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#graphql-configuration-for-telemetry","content":" By default, telemetry data is not generated by Tailcall since it requires some setup to know where to send this data and also that affects performance of server that could be undesirable in some cases.  Telemetry configuration is provided by @telemetry directive to setup how and where the telemetry data is send.  To enable it we can update our config with something like config below:  schema @telemetry( export: { otlp: {url: &quot;http://your-otlp-compatible-backend.com&quot;} } ) { query: Query }   Here, export specifies the format of generated data and endpoint to which to send that data. Continue reading to know more about different options for it.  ","version":"Next","tagName":"h2"},{"title":"Export to OTLP​","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#export-to-otlp","content":" OTLP is a vendor agnostic protocol that is supported by growing number of observability backends.  OpenTelemetry Collector​  OpenTelemetry Collector is a vendor-agnostic way to receive, process and export telemetry data in OTLP format.  Although, tailcall can send the data directly to the backends that supports OTLP format using Otel Collector could be valuable choice since it's more robust solution well-suited for a high-scale, more flexible settings and ability to export in different formats other than OTLP.  In summary, if you're gonna to use OTLP compatible platform or prometheus and your load is not that massive you could send the data directly to platforms. From the other side, if you need to export to different formats (like Jaeger or Datadog) or your application involves high load consider using Otel Collector as an export target.  ","version":"Next","tagName":"h3"},{"title":"Export to prometheus​","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#export-to-prometheus","content":" Prometheus is a metric monitoring solution. Please note that prometheus works purely with metrics and other telemetry data like traces and logs won't be sent to it.  Prometheus integration works by adding a special route for the GraphQL server's router that outputs generated metrics in prometheus format consumable by prometheus scraper.  ","version":"Next","tagName":"h3"},{"title":"Data generated​","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#data-generated","content":" You can find a reference of type of info generated by Tailcall in the @telemetry reference or consult examples in the next section, in order to gain some understanding.  ","version":"Next","tagName":"h2"},{"title":"Relation with other services​","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#relation-with-other-services","content":" Tailcall fully supports Context Propagation functionality and therefore you can analyze distributed traces across all of your services that are provides telemetry data.  That may look like this:    Where Tailcall is a part of whole distributed trace  ","version":"Next","tagName":"h3"},{"title":"Customize generated data​","type":1,"pageTitle":"GraphQL Telemetry","url":"/docs/graphql-telemetry-guide/#customize-generated-data","content":" In some cases you may want to customize the data that were added to telemetry payload to have more control over analyzing process. Tailcall supports that customization for specific use cases described below. For eg. the metric http.server.request.count can be customized with the requestHeaders property to allow splitting the overall count by specific headers.  important The value of specified headers will be sent to telemetry backend as is, so use it with care to prevent of leaking any sensitive data to third-party services you don't have control over. ","version":"Next","tagName":"h3"},{"title":"Simplifying GraphQL Scalars","type":0,"sectionRef":"#","url":"/docs/graphql-scalars-guide/","content":"","keywords":"","version":"Next"},{"title":"Default Scalars​","type":1,"pageTitle":"Simplifying GraphQL Scalars","url":"/docs/graphql-scalars-guide/#default-scalars","content":" Here is a list of default scalars that are built into the GraphQL Spec:  Scalar\tDescription\tSpecificationInt\tA type representing non-fractional signed whole numbers. Values can range up to (2^31 - 1).\tGraphQL Specification for Int Float\tA type for signed double-precision floating-point numbers.\tGraphQL Specification for Float String\tA sequence of UTF-8 characters, representing textual data.\tGraphQL Specification for String Boolean\tA boolean type that represents true or false.\tGraphQL Specification for Boolean ID\tA unique identifier, typically used to refetch an object or as a cache key.\tGraphQL Specification for ID  ","version":"Next","tagName":"h2"},{"title":"GraphQL Scalars​","type":1,"pageTitle":"Simplifying GraphQL Scalars","url":"/docs/graphql-scalars-guide/#graphql-scalars","content":" These are the current set of custom scalars supported by Tailcall:  Scalar\tDescription\tSpecificationEmail\tA string that conforms to the email format as defined in the HTML specification, utilizing the Unicode character set.\tHTML Specification for Valid Email Addresses PhoneNumber\tA string format adhering to the E.164 international standard, which outlines the numbering plan for the worldwide public switched telephone network (PSTN) and certain data networks.\tE.164 International Numbering Plan Date\tA string that represents dates and times in the Internet protocols, following the ISO 8601 standard via the Gregorian calendar.\tRFC 3339 Date and Time Internet Formats Url\tA standardized format for Uniform Resource Identifiers (URI) that includes both the generic URI syntax and guidelines for resolving URI references, which may be in relative form.\tRFC 3986 Uniform Resource Identifier JSON\tA lightweight data interchange format based on the ECMAScript Programming Language Standard, designed for human-readable data representation.\tRFC 7159 The JavaScript Object Notation (JSON) Data Interchange Format Empty\tA type that represents no value or is used as a placeholder in contexts where no other data is expected or returned. It's equivalent to unit or void in other programming languages.\t  If none of the scalars make sense for your use case, consider opening an issue on the Tailcall github repository.  ","version":"Next","tagName":"h2"},{"title":"Custom Scalars​","type":1,"pageTitle":"Simplifying GraphQL Scalars","url":"/docs/graphql-scalars-guide/#custom-scalars","content":" Apart from the pre-defined list of scalars, you can define your own custom scalars in your GraphQL schema like in the example below.  scalar AnyScalar schema @server(port: 8000, hostname: &quot;localhost&quot;) { query: Query } type Query { any(value: AnyScalar!): AnyScalar! @expr(body: &quot;{{.args.value}}&quot;) }   important Be aware that custom scalars don't have any validation and can be mapped to any data structure when using it.  ","version":"Next","tagName":"h2"},{"title":"Example Usage​","type":1,"pageTitle":"Simplifying GraphQL Scalars","url":"/docs/graphql-scalars-guide/#example-usage","content":" Let's try using these custom scalars in our GraphQL schema.  schema @server(port: 8000, hostname: &quot;localhost&quot;) { query: Query } type Query { email(value: Email!): Email! @expr(body: &quot;{{.args.value}}&quot;) }   ","version":"Next","tagName":"h2"},{"title":"Valid Query Example​","type":1,"pageTitle":"Simplifying GraphQL Scalars","url":"/docs/graphql-scalars-guide/#valid-query-example","content":" Here is an example of a valid query that passes the custom scalar validations:  ","version":"Next","tagName":"h3"},{"title":"Invalid Query Example​","type":1,"pageTitle":"Simplifying GraphQL Scalars","url":"/docs/graphql-scalars-guide/#invalid-query-example","content":" And here is an example of an invalid query that fails the custom scalar validations as expected: ","version":"Next","tagName":"h3"},{"title":"Integrating Tailcall with Apollo Studio","type":0,"sectionRef":"#","url":"/docs/integrate-apollo-studio-graphql-tailcall/","content":"","keywords":"","version":"Next"},{"title":"Creating a monolith graph​","type":1,"pageTitle":"Integrating Tailcall with Apollo Studio","url":"/docs/integrate-apollo-studio-graphql-tailcall/#creating-a-monolith-graph","content":" Before you configure tailcall, you will need to create a Monolith graph on Apollo Studio. Go to your organization's home page and click on Create your first graph, if this is your first graph or Create New Graph if you have existing graphs. Change the Graph title, Graph ID and other fields as desired and make sure to change Graph Architecture to Monolith, assuming tailcall is booted in monolith mode. Once you are done, click on Next. You'll see the following screen. Copy the fields APOLLO_KEY and APOLLO_GRAPH_REF as they are required by tailcall to be able to send the usage metrics. Next we need to connect Apollo with our running instance of Tailcall. There are two ways to let Apollo know about your GraphQL schema: Navigate to Local Introspection. If you have a deployed instance of your GraphQL server you can put the URL pointing to that in Endpoint URL and click on Introspect and Upload. If not, start a local instance of tailcall and put the local url here, similar to how is shown in the image below. You can start a local instance of Tailcall by running tailcall start (click here to know more). Or, Navigate to Local Schema and insert your schema generated by tailcall and click Upload. You can get the schema by running tailcall check (click here to know more).  You have now created a Monolith graph in Apollo Studio. The next step is to configure tailcall to use the APOLLO_API_KEY and APOLLO_GRAPH_REF. Follow detailed instructions here.  ","version":"Next","tagName":"h2"},{"title":"Checking the metrics in Apollo Studio​","type":1,"pageTitle":"Integrating Tailcall with Apollo Studio","url":"/docs/integrate-apollo-studio-graphql-tailcall/#checking-the-metrics-in-apollo-studio","content":" To see the metrics for you queries follow these instructions:  Start tailcall with the appropriate configuration for Apollo (click here to know more). Below is an example of what a config may look like: schema @server(port: 8000) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) @telemetry( export: { apollo: { apiKey: &quot;&lt;APOLLO_API_KEY from Apollo Website&gt;&quot; graphRef: &quot;&lt;APOLLO_GRAPH_REF from Apollo Website&gt;&quot; } } ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! } Visit http://localhost:8000/graphql and create a query with an appropriate name (below is an example query named MyQuery) and run it multiple times to send the metrics to Apollo Studio. tip Naming the query is not required to be able to send the metrics, but it helps to organize the metrics with appropriate names when viewed in Apollo Studio. query MyQuery { posts { id title } } To see the metrics click on the VARIANT NAME of your graph. In the example below, the variant name is current. You will see the following page. From here click on insights icon as highlighted on the left side of the image. You will now be able to see all the information related to your queries here  important If you don't see the name of your query here, try running the query multiple times and waiting for some time. Since the metric isn't sent to Apollo Studio for each query, instead they are batched together and sent at once for efficiency reasons. ","version":"Next","tagName":"h2"},{"title":"GraphQL Server Watch Mode","type":0,"sectionRef":"#","url":"/docs/graphql-watch-mode-tailcall/","content":"","keywords":"","version":"Next"},{"title":"Use case​","type":1,"pageTitle":"GraphQL Server Watch Mode","url":"/docs/graphql-watch-mode-tailcall/#use-case","content":" Running a server in watch mode offers a lot of key benefits:  Real-time Feedback: Watch mode ensures that your server remains up-to-date with your code changes, instantly reflecting those changes and providing you with real-time feedback during development.Efficiency: Manually restarting the server each time you change code can be tedious and time-consuming. Watch mode automates this process, enhancing development efficiency.Debugging: It enables you to identify and resolve issues as they occur, reducing debugging time. With your server automatically restarting upon code changes, you detect errors earlier.  ","version":"Next","tagName":"h2"},{"title":"Using entr​","type":1,"pageTitle":"GraphQL Server Watch Mode","url":"/docs/graphql-watch-mode-tailcall/#using-entr","content":" It's a powerful file-watching utility that makes running a server in watch mode a breeze. Let's go through the steps for the installation process for different operating system :  ","version":"Next","tagName":"h2"},{"title":"Installation​","type":1,"pageTitle":"GraphQL Server Watch Mode","url":"/docs/graphql-watch-mode-tailcall/#installation","content":" Homebrew​  Open the Terminal, which you can find in the &quot;Utilities&quot; folder within the &quot;Applications&quot; folder. Install Homebrew if you haven't already. Run the following command in your Terminal: /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot; After installing Homebrew, proceed to install entr by executing the following command: brew install entr To verify the installation, run: entr --version   Upon successful installation, it will display the latest version of entr.  Windows Subsystem​  Install Windows Subsystem for Linux (WSL) on your Windows machine by following Microsoft's official documentation. After setting up WSL, open the Linux terminal by running: wsl -d &lt;DistributionName&gt; Replace &lt;DistributionName&gt; with the name of the Linux distribution that you have installed. Install entr within the Linux terminal using the package manager of your chosen Linux distribution. For example, on Ubuntu, you can use: sudo apt update sudo apt install entr Verify the installation by running: entr --version   A successful installation will display the latest version of entr.  apt-get​  On Linux, you can install entr using your distribution's package manager. For example, on Ubuntu, use: sudo apt update sudo apt install entr To verify the installation, run: entr --version   If you install it, it will show the latest version of the entr  ","version":"Next","tagName":"h3"},{"title":"Watch Mode​","type":1,"pageTitle":"GraphQL Server Watch Mode","url":"/docs/graphql-watch-mode-tailcall/#watch-mode","content":" To run your server in watch mode with entr, use the ls command to list the files you want to track. The general syntax is as follows:  ls *.graphql | entr -r tailcall start ./jsonplaceholder.graphql   This command uses entr to continuously track the jsonplaceholder.graphql file and when it changes, It runs the tailcall start command with the file as an argument  Detailing the above command as follows:  ls *.graphql : This part of the code lists the file or files you want to track for changes. In this case, it lists the file named &quot;jsonplaceholder.graphql&quot; within the &quot;examples&quot; directory. | : The pipe symbol ('|') takes the output of the preceding command (the file listing) and feeds it as input to the following command (entr). entr -r tc start ./jsonplaceholder.graphql : Whenever the file &quot;jsonplaceholder.graphql&quot; changes, this command executes.  entr is a command-line tool for running arbitrary commands whenever files change. It tracks the files specified in the previous command (ls ./jsonplaceholder.graphql) r : This flag instructs entr to persist in running the command through errors, ensuring continuous operation. tc start ./jsonplaceholder.graphql : This command runs upon detecting changes, executing tc start with the file path./jsonplaceholder.graphql as an argument  ","version":"Next","tagName":"h3"},{"title":"Some Best Practices​","type":1,"pageTitle":"GraphQL Server Watch Mode","url":"/docs/graphql-watch-mode-tailcall/#some-best-practices","content":" To make the most of running a server in watch mode with entr, consider the following best practices:  Selective File Watching: Be selective about which files you track with entr. Watching unnecessary files can lead to increased CPU and memory usage. Focus on the essential files related to your project. Organize Your Project: Maintain a well-organized project structure to make it easier to identify which files need tracking. Clear Output: Clear the terminal output before running entr to have a clean workspace. Version Control: Ensure that your project is under version control (e.g., Git) to track changes and revert if necessary. Update entr: Ensure entr is always updated to the latest version for bug fixes and enhancements.  By following these best practices and using entr effectively, you can greatly improve your development workflow. Experiment with entr, adapt it to your project's specific requirements, and enjoy a smoother and more efficient development process. Happy coding! ","version":"Next","tagName":"h2"},{"title":"LLM Integration","type":0,"sectionRef":"#","url":"/docs/llm-integration/","content":"","keywords":"","version":"Next"},{"title":"OpenAI​","type":1,"pageTitle":"LLM Integration","url":"/docs/llm-integration/#openai","content":" gpt-4ogpt-4o-minigpt-4-turbogpt-4gpt-3.5-turbo  ","version":"Next","tagName":"h2"},{"title":"Gemini​","type":1,"pageTitle":"LLM Integration","url":"/docs/llm-integration/#gemini","content":" gemini-1.5-progemini-1.5-flashgemini-1.0-progemini-1.5-flash-latest  ","version":"Next","tagName":"h2"},{"title":"Anthropic​","type":1,"pageTitle":"LLM Integration","url":"/docs/llm-integration/#anthropic","content":" claude-3-5-sonnet-20240620claude-3-opus-20240229claude-3-sonnet-20240229claude-3-haiku-20240307  ","version":"Next","tagName":"h2"},{"title":"Groq​","type":1,"pageTitle":"LLM Integration","url":"/docs/llm-integration/#groq","content":" llama-3.1-405b-reasoningllama-3.1-70b-versatilellama-3.1-8b-instantmixtral-8x7b-32768gemma-7b-itgemma2-9b-itllama3-groq-70b-8192-tool-use-previewllama3-groq-8b-8192-tool-use-previewllama3-8b-8192llama3-70b-8192  ","version":"Next","tagName":"h2"},{"title":"Cohere​","type":1,"pageTitle":"LLM Integration","url":"/docs/llm-integration/#cohere","content":" command-r-pluscommand-rcommandcommand-nightlycommand-lightcommand-light-nightly  If nothing is configured, Tailcall tries to connect to one of the Ollama models. ","version":"Next","tagName":"h2"},{"title":"Deploy Tailcall on AWS Lambda","type":0,"sectionRef":"#","url":"/docs/tailcall-on-aws/","content":"","keywords":"","version":"Next"},{"title":"Generate Access Keys for AWS​","type":1,"pageTitle":"Deploy Tailcall on AWS Lambda","url":"/docs/tailcall-on-aws/#generate-access-keys-for-aws","content":" Follow the steps below to generate the Access Keys:  Go to AWS Management Console and click the drop down menu in the top right corner and Click on Security credentials. Scroll down to the Access Keys section and click on Create access key. You will get the following warning since we are trying to create access keys for the root user. For this guide, we will continue with creating the access keys. If you do not want to continue with the root user, you can learn more about the AWS security credentials here and managing access keys here. Once you click on Create access key, you will get the Access key ID and Secret access key. Make sure to download the CSV file and store it securely.  ","version":"Next","tagName":"h2"},{"title":"Terraform setup​","type":1,"pageTitle":"Deploy Tailcall on AWS Lambda","url":"/docs/tailcall-on-aws/#terraform-setup","content":" Now that you have the AWS Access Key ID and Secret Access Key, you will need to generate API token for terraform and setup a terraform organization and workspace. If you don't have a Terraform Cloud account, you can create one here.  ","version":"Next","tagName":"h2"},{"title":"Terraform API Token​","type":1,"pageTitle":"Deploy Tailcall on AWS Lambda","url":"/docs/tailcall-on-aws/#terraform-api-token","content":" Follow these steps to generate the Terraform API token:  Go to the Tokens section in Settings and click on Create an API token. Give a description for the token and change the expiration if required. Click on Generate token. Copy the generated token and store it securely.  ","version":"Next","tagName":"h3"},{"title":"Terraform Organization and Workspace​","type":1,"pageTitle":"Deploy Tailcall on AWS Lambda","url":"/docs/tailcall-on-aws/#terraform-organization-and-workspace","content":" To create an organization, go to the Organizations section in Settings and click on Create organization. Fill in the organization name and email and click on Create organization. Now that you have created an organization, you will be presented with the following page for creating a workspace. Click on CLI-Driven Workflow, since the github action which we will be using for deployment, tailcallhq/gh-action, uses the terraform CLI. Fill in the workspace name. By default the project will be set to Default Project, if you have any project in terraform cloud, you can select that project, otherwise continue with the Default Project and click on Create.  You now have everything required for a successful deployment of your tailcall server on AWS Lambda.  ","version":"Next","tagName":"h3"},{"title":"Setting up the project repo​","type":1,"pageTitle":"Deploy Tailcall on AWS Lambda","url":"/docs/tailcall-on-aws/#setting-up-the-project-repo","content":" Now you need to create a new repository on Github and use the Github action tailcallhq/gh-action to deploy it. The easiest way to get started is to create a new repository using this template repo https://github.com/tailcallhq/deploy-tailcall.  Go to the repo and click on Use this template and create a new repository. Give your repository a name and click on Create repository. Now that you have created a repository, you will need to add the AWS access keys and Terraform API token to the repository secrets. To do that, click on Settings. Click on Secrets and variables in the left side bar to expand the section and click on Actions. Click on New repository secret to add a new secret. Add the secret name as AWS_ACCESS_KEY_ID or any name you prefer and paste the AWS access key ID that you generated earlier in the value field. Click on Add secret to save the secret. Similarly add the AWS secret access key and the Terraform API token as secrets to the repository.  You are now ready to deploy your tailcall server on AWS Lambda using terraform.  ","version":"Next","tagName":"h2"},{"title":"Deploy on AWS Lambda using terraform​","type":1,"pageTitle":"Deploy Tailcall on AWS Lambda","url":"/docs/tailcall-on-aws/#deploy-on-aws-lambda-using-terraform","content":" In this example, we will deploy a simple graphQL server using tailcall, on AWS Lambda using terraform, which will convert the JSONPlaceholder REST API to a GraphQL API.  Below is the config present in the template repo, that will be used for this deployment. You can learn more about this here.  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) }   To deploy the server, just update the provider to aws in the deploy-tailcall job in the .github/workflows/main.yml file, similar to the example below. Also, update the terraform-workspace and terraform-org as well as the other inputs based on your requirements.  on: [push] jobs: deploy_tailcall: runs-on: ubuntu-latest name: Deploy Tailcall steps: - name: Checkout repository uses: actions/checkout@v2 - name: Deploy Tailcall id: deploy-tailcall uses: tailcallhq/gh-action@v0.2 with: provider: &quot;aws&quot; aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} aws-region: &quot;us-east-1&quot; aws-iam-role: &quot;iam_for_tailcall&quot; terraform-api-token: ${{ secrets.TERRAFORM_API_TOKEN }} terraform-org: &quot;tailcall-demo&quot; terraform-workspace: &quot;tailcall&quot; tailcall-config: &quot;config.graphql&quot;   After updating the main.yml file, commit the changes and push them to the repository. This will trigger the deployment of the tailcall server on AWS Lambda. ","version":"Next","tagName":"h2"},{"title":"The Comprehensive Guide to GraphQL","type":0,"sectionRef":"#","url":"/graphql/","content":"","keywords":"","version":"Next"},{"title":"Introduction to GraphQL​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#introduction-to-graphql","content":" GraphQL, developed by Facebook in 2012 and open-sourced in 2015, is a query language for your API, and a server-side runtime for executing queries. It was originally developed to simplify endpoint management for REST-based APIs. Instead of maintaining multiple endpoints with small amounts of disjointed data, GraphQL provides a single endpoint that inputs complex queries and outputs only as much information as is needed for the query. This flexibility empowers developers to design more efficient and adaptable APIs, making GraphQL increasingly popular in modern web development.  At its core, GraphQL enables declarative data fetching, where clients specify the exact structure of the data they require, and the server responds with precisely that data. This contrasts with REST APIs, where endpoints are predefined, and clients receive fixed responses regardless of their specific data needs.  To know more in detail about GraphQL, you can refer What is GraphQL.  ","version":"Next","tagName":"h2"},{"title":"Fundamental Concepts of GraphQL Server​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#fundamental-concepts-of-graphql-server","content":" GraphQL is built upon several core concepts that form the foundation of its query language and API design. Understanding these concepts is essential for effectively utilizing GraphQL in your projects.  ","version":"Next","tagName":"h2"},{"title":"1. Schema​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#1-schema","content":" At the heart of every GraphQL API is the schema which is a set of types which completely describe the set of possible data you can query on that server. Then, when queries come in, they are validated and executed against that schema.  GraphQL schemas are typically defined using the GraphQL Schema Definition Language (SDL), a simple syntax for describing types. Each type in the schema represents a distinct object in the API. Types can have fields that correspond to the properties of the object, as well as relationships to other types.  Here's a code snippet illustrating how a GraphQL schema might be defined using the GraphQL Schema Definition Language (SDL):  schema { query: Query } type Post { id: ID! title: String! content: String! userId: ID! } type Query { post(id: ID!): Post }   In this schema:  We define an object type: Post.Each Post object has fields for id, title, content, and a userId.We also define a root Query type, which contains entry points for querying individual users and posts by their IDs. We will dig deep into this in Next Section  This schema serves as a contract between the client and the server, defining the structure of the data available through the API and specifying how clients can interact with it. It forms the foundation for building and querying data in a GraphQL API. You can learn more about GraphQL Schema in detail.  ","version":"Next","tagName":"h3"},{"title":"2. Query​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#2-query","content":" Most types in your schema will just be normal object types, but there are two types that are special within a schema Query and Mutation.  Every GraphQL server has a query type and may or may not have a mutation type. These types are the same as a regular object type, but they are special because they define the entry point of every GraphQL query. So if you see a query that looks like:  query { user(id: &quot;123&quot;) { name } }   That means that the GraphQL service needs to have a Query type with user field:  type Query { user(id: ID!): User }   ","version":"Next","tagName":"h3"},{"title":"3. Mutation​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#3-mutation","content":" Mutation work in a similar way as Query - you define fields on the Mutation type, and those are available as the root mutation fields you can call in your query.  It’s important to remember that other than the special status of being the “entry point” into the schema, the Query and Mutation types are the same as any other GraphQL object type, and their fields work exactly the same way. While queries are used for reading data from a GraphQL API, mutations are used for modifying or updating data. Mutations allow clients to perform actions such as creating, updating, or deleting objects in the API's data store.  Here's a code snippet illustrating how mutations might be defined in GraphQL:  type Mutation { createUser(input: CreateUserInput!): User! }   To query above mutation, you would use a query like this:  mutation { createUser( input: {name: &quot;Alice&quot;, email: &quot;dummy@gmail.com&quot;} ) { id name email } }   ","version":"Next","tagName":"h3"},{"title":"4. Subscriptions​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#4-subscriptions","content":" Subscriptions enable real-time communication between clients and servers in GraphQL APIs. Unlike queries and mutations, which are request-response interactions, subscriptions establish a persistent connection between the client and the server, allowing the server to push updates to the client as they occur.  Subscriptions are defined in the GraphQL schema alongside queries and mutations, specifying the events or data changes that clients can subscribe to. Clients initiate a subscription by sending a subscription query to the server, which then notifies the client whenever the subscribed event occurs.  Here's a code snippet illustrating how subscriptions might be defined in GraphQL:  type Subscription { newMessage: Message! } type Message { id: ID! content: String! createdAt: String! } input SendMessageInput { content: String! } type Mutation { sendMessage(input: SendMessageInput!): Message! }   In this schema:  We define a Subscription type, which contains an entry point newMessage representing the event that clients can subscribe to receive updates about new messages.The newMessage subscription returns a Message object whenever a new message is created.We define a Message type with fields for id, content, and createdAt, representing a message object.We also define an input object type SendMessageInput with a field for content, which represents the input data for creating a new message.Finally, we have a Mutation type with an operation sendMessage that takes an input object of type SendMessageInput and returns the created Message object.  Clients can subscribe to the newMessage event to receive real-time updates whenever a new message is created. When a new message is created, the server pushes the updated message data to all subscribed clients in real-time.  In summary, the fundamental concepts of GraphQL—schema, queries, mutations, and subscriptions—provide a powerful framework for building flexible and efficient APIs that meet the diverse needs of modern applications.  This GraphQL configuration is enough for starting a GraphQL server using Tailcall. You can start the server using the start command.  ","version":"Next","tagName":"h3"},{"title":"Advantages of Using GraphQL​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#advantages-of-using-graphql","content":" While REST (Representational State Transfer) has long been a dominant paradigm for building web APIs, GraphQL offers several key advantages that revolutionize API design and development:  ","version":"Next","tagName":"h2"},{"title":"1. Efficient Data Fetching​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#1-efficient-data-fetching","content":" One of the primary advantages of GraphQL is its ability to efficiently fetch data from the server. With GraphQL, clients can request only the specific fields they need, avoiding the problem of over-fetching data that often occurs with REST APIs. This minimizes the amount of data transferred over the network, leading to faster response times and improved performance for client applications.  Additionally, GraphQL enables clients to retrieve related pieces of data in a single request by specifying nested query structures. This eliminates the need for multiple round-trip requests to fetch data from different endpoints, further optimizing data fetching efficiency.  ","version":"Next","tagName":"h3"},{"title":"2. Strongly-Typed Schema​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#2-strongly-typed-schema","content":" GraphQL employs a strongly-typed schema to define the structure of the API and the types of data it supports. This schema serves as a contract between the client and the server, providing clear documentation of the available data and operations.  By defining a schema upfront, GraphQL enables type checking and validation of queries at compile-time, catching errors early in the development process. This helps prevent runtime errors and improves the reliability of client-server interactions.  Additionally, the schema serves as a central source of truth for the API, making it easier for frontend and backend developers to collaborate. Changes to the schema can be communicated effectively, and tools can be built around the schema to provide features like autocomplete and code generation.  ","version":"Next","tagName":"h3"},{"title":"3. Reduced Network Requests​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#3-reduced-network-requests","content":" GraphQL reduces the number of network requests required to fetch data by allowing clients to specify complex queries in a single request. Unlike REST APIs, which often require multiple requests to retrieve related data from different endpoints, GraphQL enables clients to fetch all the necessary data in a single round trip.  This reduction in network requests can have significant performance benefits, particularly for mobile and web applications operating over limited bandwidth or high-latency networks. By minimizing the overhead associated with network communication, GraphQL helps improve the responsiveness and efficiency of client applications.  In summary, GraphQL represents a paradigm shift in API design, offering developers greater flexibility, efficiency, and control over data fetching compared to traditional RESTful architectures. By leveraging the advantages of GraphQL—efficient data fetching, strongly-typed schema, and reduced network requests—developers can create more scalable, flexible, and performant systems that meet the needs of modern applications and users.  ","version":"Next","tagName":"h3"},{"title":"Getting Started with GraphQL​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#getting-started-with-graphql","content":" Before diving into GraphQL development, it's essential to understand the basic steps involved in setting up a GraphQL server, defining a schema, and creating resolvers.  ","version":"Next","tagName":"h2"},{"title":"1. Setting up a GraphQL Server​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#1-setting-up-a-graphql-server","content":" Setting up a GraphQL server involves configuring a server environment capable of processing GraphQL requests and responses. You can set up a GraphQL Server using Tailcall by following the steps below:  Install Tailcall's GraphQL CLI by running the following command:  npm install -g @tailcallhq/tailcall   Set up a new GraphQL project by running the following command on a new project directory:  tailcall init   Using Tailcall's GraphQL CLI, you can quickly set up a GraphQL server with minimal configuration. The CLI provides a streamlined development environment for building GraphQL APIs.  ","version":"Next","tagName":"h3"},{"title":"2. Defining a Schema​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#2-defining-a-schema","content":" The schema is a critical component of any GraphQL API, as it defines the types of data that clients can query and manipulate. GraphQL schemas are typically written using the GraphQL Schema Definition Language (SDL), a simple syntax for describing types, fields, and relationships.  To define a schema, you'll need to specify the types of data available in your API, including objects, along with their associated fields and relationships. You'll also define query, mutation, and subscription types to specify the operations that clients can perform. for example:  schema { query: Query } type Post { id: ID! title: String! content: String! } type Query { post(id: ID!): Post }   ","version":"Next","tagName":"h3"},{"title":"3. Attaching Resolvers​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#3-attaching-resolvers","content":" Resolvers are responsible for fetching the data requested by clients and returning it in the appropriate format. Each field in your schema corresponds to a resolver function, which retrieves the data from your data sources, such as databases, APIs, or in-memory caches.  When a client sends a GraphQL query, the server resolves each field in the query by executing the corresponding resolver function. Resolvers may perform database queries, call external APIs, or perform other tasks to retrieve the requested data. Once the data is fetched, the resolvers return it to the client in the format specified by the GraphQL schema.  By setting up a GraphQL server, defining a schema, and attaching resolvers, you can begin building powerful and flexible APIs that provide clients with the precise data they need. This foundational knowledge forms the basis for more advanced GraphQL development, including integrating GraphQL with existing APIs, handling complex data relationships, and optimizing API performance.  Lets attach resolvers to the schema we defined in the previous section using Tailcall's GraphQL Configuration: We will add the resolvers with @http directive:  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type Post { id: ID! title: String! content: String! } type Query { post(id: ID!): Post @http(path: &quot;/posts/{{.args.id}}&quot;) }   In this example: We have used the @http directive to attach resolvers to the post field in the Query. and @upstream directive to define the base URL for the upstream server.  This configuration is enough for starting a GraphQL server using Tailcall. You can start the server using the start command.  For starting the server, you can use the following command:  tailcall start path/to/your-graphql-configuration   ","version":"Next","tagName":"h3"},{"title":"4. Handling Data Relationships​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#4-handling-data-relationships","content":" One of the strengths of GraphQL is its ability to handle data relationships with ease. When designing your GraphQL schema, consider how different types of data relate to each other and how clients may want to query or manipulate these relationships.  Use GraphQL's powerful type system to define clear relationships between your data types, including one-to-one, one-to-many, and many-to-many relationships. This allows clients to fetch related data in a single query, reducing the need for multiple round-trip requests.  Here's a code snippet illustrating how to handle data relationships in GraphQL:  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query } type User { id: ID! name: String! email: String! } type Post { id: ID! title: String! content: String! userId: ID! author: User! @http(path: &quot;/users/{{.value.userId}}&quot;) } type Query { post(id: ID!): Post! @http(path: &quot;/posts/{{.args.id}}&quot;) }   In this example:  We define a User type representing a user object with fields for id, name, and email.We define a Post type representing a post object with fields for id, title, content, and userId.We establish a relationship between Post and User by adding an author field to the Post type. The author field fetches the user data corresponding to the userId of the post.We attach resolvers to the author field using the @http directive to fetch user data from the upstream server.  ","version":"Next","tagName":"h3"},{"title":"Tools and Libraries for GraphQL​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#tools-and-libraries-for-graphql","content":" Utilizing the right tools and libraries can significantly streamline the development, testing, and maintenance of your GraphQL API. Here are some essential tools and resources:  ","version":"Next","tagName":"h2"},{"title":"1. Popular GraphQL Clients​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#1-popular-graphql-clients","content":" Apollo Client: A comprehensive GraphQL client for JavaScript applications, offering features such as query caching, local state management, and error handling. Apollo Client supports various frontend frameworks, including React, Angular, and Vue.js.  Relay: Developed by Facebook, Relay is a powerful GraphQL client optimized for React applications. It provides features like declarative data fetching, pagination, and efficient updates through GraphQL mutations.  URQL (formerly known as &quot;Urql&quot;): A lightweight and flexible GraphQL client for React and other JavaScript frameworks. URQL focuses on simplicity, performance, and customization, offering hooks-based APIs for querying and caching GraphQL data.  ","version":"Next","tagName":"h3"},{"title":"2. Testing and Debugging Tools​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#2-testing-and-debugging-tools","content":" GraphQL Playground: An interactive GraphQL IDE that allows you to explore, test, and debug GraphQL APIs using a web-based interface. GraphQL Playground supports features like syntax highlighting, query autocompletion, and response visualization, making it invaluable for API development and testing.  GraphiQL: Similar to GraphQL Playground, GraphiQL is a web-based IDE for testing and debugging GraphQL APIs. It provides a user-friendly interface for composing and executing GraphQL queries, with built-in documentation and query history functionality.  Apollo Studio Explorer: Part of the Apollo Studio platform, Apollo Studio Explorer offers a visual GraphQL editor and testing environment for exploring GraphQL schemas, executing queries, and analyzing query performance. It integrates seamlessly with Apollo Client and provides insights into schema usage and query execution metrics.  Tailcall Playground: Tailcall Playground is a web-based IDE for testing and debugging GraphQL servers,and analyze the behavior of your GraphQL server.  ","version":"Next","tagName":"h3"},{"title":"3. Community Resources and Support​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#3-community-resources-and-support","content":" GraphQL Documentation: Comprehensive documentation resources are available for GraphQL, covering topics such as schema definition, query syntax, and best practices for API design. The official GraphQL website (graphql.org) provides detailed guides, tutorials, and reference documentation for learning and mastering GraphQL.  GitHub Repositories: Explore open-source GraphQL projects and libraries on GitHub to discover reusable components, utilities, and tools for building and extending GraphQL APIs. Many popular GraphQL clients, server frameworks, and development tools are hosted on GitHub, offering opportunities for collaboration and contribution.  Online Communities: Engage with the GraphQL community through online forums, discussion groups, and social media channels. Platforms like Reddit (r/graphql), Stack Overflow, and Discord host active communities of GraphQL enthusiasts and practitioners, where you can ask questions, share knowledge, and seek advice on GraphQL-related topics.  By leveraging these tools and resources, you can enhance your GraphQL development workflow, streamline API testing and debugging, and tap into the collective expertise of the GraphQL community for support and guidance.  ","version":"Next","tagName":"h3"},{"title":"Real-world Examples of GraphQL Implementation​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#real-world-examples-of-graphql-implementation","content":" Real-world examples of GraphQL implementation offer valuable insights into the practical applications, benefits, and challenges of adopting GraphQL in different industries and use cases. Here are some case studies and lessons learned from successful GraphQL adoption:  ","version":"Next","tagName":"h2"},{"title":"1. Case Studies of Successful GraphQL Adoption​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#1-case-studies-of-successful-graphql-adoption","content":" GitHub: GitHub adopted GraphQL to address the inefficiencies and complexities of its RESTful API, which led to over-fetching, under-fetching, and versioning challenges. By transitioning to GraphQL, GitHub improved data fetching efficiency, reduced network requests, and provided a more flexible and intuitive API for developers. GraphQL enabled GitHub to deliver personalized data, optimize performance, and streamline client-server communication.  Shopify: Shopify leveraged GraphQL to power its next-generation commerce platform, enabling merchants to build customized storefronts and applications. GraphQL empowered Shopify developers to fetch precisely the data they needed, avoiding over-fetching and reducing latency. Shopify's adoption of GraphQL resulted in improved developer productivity, faster feature development, and enhanced API performance for merchants and partners.  ","version":"Next","tagName":"h3"},{"title":"2. Lessons Learned from Industry Use Cases​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#2-lessons-learned-from-industry-use-cases","content":" Performance Optimization: Many companies, including Facebook, Twitter, and Airbnb, have shared insights into optimizing GraphQL performance at scale. Key strategies include batching requests, implementing caching mechanisms, optimizing resolver functions, and monitoring query execution times. By optimizing GraphQL performance, organizations can minimize latency, improve scalability, and enhance user experience.  Data Modeling and Schema Design: Successful GraphQL implementations emphasize the importance of thoughtful data modeling and schema design. Designing a clear and intuitive schema, defining relationships between types, and normalizing data structures are critical for building scalable and maintainable GraphQL APIs. Companies like PayPal and Coursera have documented their approaches to schema design, highlighting best practices for organizing and structuring data in GraphQL schemas.  Developer Experience: Prioritizing developer experience (DX) is essential for driving adoption and success with GraphQL. Providing comprehensive documentation, offering interactive tooling (e.g., GraphQL playgrounds), and fostering a supportive developer community are key factors in promoting GraphQL adoption. Companies like Apollo and Prisma have contributed to the GraphQL ecosystem by developing tools, libraries, and educational resources to empower developers and simplify GraphQL development workflows.  By studying real-world examples of GraphQL implementation and learning from industry use cases, organizations can gain valuable insights into the benefits, challenges, and best practices associated with adopting GraphQL. Whether optimizing performance, designing schemas, or enhancing developer experience, GraphQL offers compelling advantages for building modern, data-driven applications in various domains and industries.  ","version":"Next","tagName":"h3"},{"title":"Future Trends in GraphQL​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#future-trends-in-graphql","content":" As GraphQL continues to evolve and gain traction in the developer community, several emerging trends and advancements are shaping the future of GraphQL adoption and implementation. Here are some key areas to watch:  ","version":"Next","tagName":"h2"},{"title":"1. GraphQL in the Context of Microservices​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#1-graphql-in-the-context-of-microservices","content":" Service Mesh Integration: With the increasing adoption of microservices architectures, GraphQL is poised to play a significant role in service mesh environments. Integrating GraphQL with service mesh technologies such as Istio and Linkerd enables developers to build distributed, resilient, and scalable applications with enhanced API management, observability, and security capabilities.  GraphQL Federation: GraphQL federation, an architectural pattern for composing distributed GraphQL schemas, is gaining momentum as a preferred approach for building scalable and modular microservices architectures. By federating multiple GraphQL APIs into a unified graph, organizations can achieve greater agility, autonomy, and composability across their microservices ecosystem.  ","version":"Next","tagName":"h3"},{"title":"2. Integration with Emerging Technologies​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#2-integration-with-emerging-technologies","content":" Serverless Computing: The integration of GraphQL with serverless computing platforms such as AWS Lambda, Azure Functions, and Google Cloud Functions enables developers to build event-driven, scalable APIs with minimal operational overhead. Serverless GraphQL functions provide dynamic data resolution, auto-scaling, and cost-efficient execution, making them ideal for modern, cloud-native applications.  Edge Computing: GraphQL is increasingly being adopted in edge computing scenarios, where low-latency data access and distributed processing are critical requirements. By deploying GraphQL at the edge using technologies like Cloudflare Workers and AWS CloudFront, organizations can deliver performant, responsive APIs to edge locations worldwide, improving user experience and application performance.  ","version":"Next","tagName":"h3"},{"title":"3. Potential Advancements in the GraphQL Ecosystem​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#3-potential-advancements-in-the-graphql-ecosystem","content":" GraphQL Standardization: As GraphQL adoption continues to grow, efforts to standardize GraphQL specifications, tooling, and best practices are gaining momentum. Organizations such as the GraphQL Foundation and the GraphQL Working Group are leading initiatives to define and maintain GraphQL standards, promote interoperability, and drive innovation in the GraphQL ecosystem.  Schema Stitching and Composition: Advanced schema stitching and composition techniques are emerging to address the challenges of building and managing complex GraphQL schemas. Tools and libraries for schema stitching, such as Apollo Federation and GraphQL Mesh, enable developers to compose distributed schemas, federate data sources, and implement cross-cutting concerns like authentication, authorization, and caching.  Advanced Query Optimization: Ongoing research and development efforts are focused on advancing query optimization techniques for GraphQL APIs. Innovations in query planning, execution, and caching are enhancing the performance, scalability, and efficiency of GraphQL queries, enabling organizations to deliver real-time, data-intensive applications with low latency and high throughput.  As GraphQL continues to mature and expand its capabilities, organizations can expect to see further integration with microservices, emerging technologies, and advancements in the GraphQL ecosystem. By staying informed about these future trends and embracing GraphQL as a strategic technology, organizations can unlock new opportunities for innovation, agility, and growth in the rapidly evolving landscape of modern software development.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#conclusion","content":" In conclusion, GraphQL has emerged as a powerful query language and runtime for building efficient, flexible, and scalable APIs. Throughout this guide, we've explored the fundamental concepts, advantages, implementation strategies, optimization techniques, and future trends of GraphQL. Here's a summary of the key takeaways:  ","version":"Next","tagName":"h2"},{"title":"Key Takeaways​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#key-takeaways","content":" GraphQL offers several advantages over traditional REST APIs, including efficient data fetching, a strongly-typed schema, and reduced network requests. By enabling clients to request precisely the data they need, GraphQL optimizes data transfer and improves application performance.Understanding the fundamental concepts of GraphQL, such as schema, queries, mutations, and subscriptions, is essential for effectively designing, implementing, and consuming GraphQL APIs. With a clear understanding of these concepts, developers can leverage the full potential of GraphQL to build sophisticated and intuitive APIs.Implementing GraphQL in your API involves setting up a GraphQL server, defining a schema, and attaching resolvers to fetch and manipulate data. By structuring queries and mutations, developers can design APIs that are easy to understand, maintain, and evolve over time.  ","version":"Next","tagName":"h3"},{"title":"Recap of Fundamental Concepts​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#recap-of-fundamental-concepts","content":" Schema: Defines the types of data available in the API and the relationships between them.Queries: Retrieve data from the API.Mutations: Modify data in the API.Subscriptions: Listen for real-time updates from the API.  By embracing GraphQL and leveraging its capabilities to build modern, data-driven APIs, developers can unlock new opportunities for innovation, collaboration, and growth. Whether you're a beginner exploring the basics of GraphQL or an experienced developer optimizing complex APIs, the comprehensive guide to GraphQL provides valuable insights and guidance to support your journey in mastering this powerful technology.  Thank you for joining us on this exploration of GraphQL. We hope this guide has equipped you with the knowledge and tools needed to build successful GraphQL APIs and navigate the evolving landscape of modern software development.  ","version":"Next","tagName":"h3"},{"title":"Next Steps​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#next-steps","content":" Congratulations on completing this comprehensive guide to GraphQL! As you continue your journey to mastering GraphQL and building powerful APIs, here are some recommended next steps to further enhance your skills and stay updated on GraphQL developments:  ","version":"Next","tagName":"h2"},{"title":"Further Resources for Mastering GraphQL​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#further-resources-for-mastering-graphql","content":" Explore in-depth tutorials, documentation, and guides provided by GraphQL's official website (https://graphql.org/). The website offers a wealth of resources, including tutorials, specifications, and best practices for implementing GraphQL APIs.Dive deeper into GraphQL concepts and techniques with online courses and tutorials available on platforms like Udemy, Coursera, and Pluralsight. These courses cover a wide range of topics, from GraphQL fundamentals to advanced topics like schema stitching and federation.Check out books and ebooks on GraphQL, such as &quot;Learning GraphQL: Declarative Data Fetching for Modern Web Apps&quot; by Eve Porcello and &quot;The GraphQL Guide&quot; by John Resig and Loren Sands-Ramshaw. These resources provide comprehensive coverage of GraphQL concepts, best practices, and real-world examples.  ","version":"Next","tagName":"h2"},{"title":"Community Forums and Events for Staying Updated on GraphQL Developments​","type":1,"pageTitle":"The Comprehensive Guide to GraphQL","url":"/graphql/#community-forums-and-events-for-staying-updated-on-graphql-developments","content":" Join the GraphQL community on platforms like GitHub, Reddit, and Stack Overflow to connect with other developers, ask questions, and share insights and experiences. These forums are valuable resources for staying updated on the latest trends, tools, and techniques in the GraphQL ecosystem.Attend GraphQL meetups, conferences, and workshops to network with industry experts, learn from experienced developers, and gain hands-on experience with GraphQL. Events like GraphQL Summit, GraphQL Europe, and GraphQL Asia offer opportunities to connect with the broader GraphQL community and stay informed about emerging trends and best practices. ","version":"Next","tagName":"h2"},{"title":"GraphQL Configuration Formats","type":0,"sectionRef":"#","url":"/docs/tailcall-graphql-configuration-format-conversion/","content":"","keywords":"","version":"Next"},{"title":"Converting Formats​","type":1,"pageTitle":"GraphQL Configuration Formats","url":"/docs/tailcall-graphql-configuration-format-conversion/#converting-formats","content":" To convert files between different formats, use the following command:  tailcall check format_type &lt; input_files &gt; --format   Let's try to convert a Tailcall graphql file to json and then back to graphql  To convert graphql to json  tailcall check examples/jsonplaceholder.graphql --format json &gt; &quot;examples/jsonplaceholder.json&quot;   Now to convert back to graphql  tailcall check examples/jsonplaceholder.json --format graphql &gt; &quot;examples/jsonplaceholder2.graphql&quot;   To learn more about writing configuration to leverage the full power of Tailcall, explore the Directives documentation.  ","version":"Next","tagName":"h2"},{"title":"Format Conversions​","type":1,"pageTitle":"GraphQL Configuration Formats","url":"/docs/tailcall-graphql-configuration-format-conversion/#format-conversions","content":" graphqlymljson schema @server(port: 8000, hostname: &quot;0.0.0.0&quot;) @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;, httpCache: 42, batch: {delay: 100}) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) users: [User] @http(path: &quot;/users&quot;) user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @call(query: &quot;user&quot;, args: {id: &quot;{{.value.userId}}&quot;}) }   ","version":"Next","tagName":"h2"},{"title":"Editor Support​","type":1,"pageTitle":"GraphQL Configuration Formats","url":"/docs/tailcall-graphql-configuration-format-conversion/#editor-support","content":" To leverage autocomplete and validation for GraphQL configurations, the init command can be used to automatically create .tailcallrc.graphql for GraphQL configurations and .tailcallrc.schema.json for JSON and YAML configurations. These files enhance editor support by providing schema definitions, facilitating faster and error-free configuration.  ","version":"Next","tagName":"h2"},{"title":"GraphQL​","type":1,"pageTitle":"GraphQL Configuration Formats","url":"/docs/tailcall-graphql-configuration-format-conversion/#graphql","content":" When you run tailcall init, it creates a .tailcallrc.graphql file containing your GraphQL schema definitions and a .graphqlrc.yml file configured to use this schema. The .graphqlrc.yml file is set up as follows:  schema: - &quot;./.tailcallrc.graphql&quot; - &quot;./app.graphql&quot;   This file contains the path to the .tailcallrc.graphql file and the path to the main GraphQL configuration file which is app.graphql. This setup allows GraphQL IDE plugins and Language Server Protocols (LSP) to automatically pick up the schema for autocomplete and validation, enhancing your development experience with real-time feedback and suggestions.  ","version":"Next","tagName":"h3"},{"title":"JSON & YAML​","type":1,"pageTitle":"GraphQL Configuration Formats","url":"/docs/tailcall-graphql-configuration-format-conversion/#json--yaml","content":" For JSON or YAML configurations, tailcall init also creates a .tailcallrc.schema.json file. To enable validation and autocomplete in your JSON files, reference the .tailcallrc.schema.json in the $schema attribute at the beginning of your JSON file:  { &quot;$schema&quot;: &quot;./.tailcallrc.schema.json&quot; }   This reference enables your IDE to validate and autocomplete using the JSON schema, offering a streamlined configuration process with instant error and typo detection. ","version":"Next","tagName":"h3"},{"title":"Command Line Reference","type":0,"sectionRef":"#","url":"/docs/tailcall-graphql-cli/","content":"","keywords":"","version":"Next"},{"title":"check​","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#check","content":" The check command validates a composition spec. Notably, this command can detect potential N+1 issues. To use the check command, follow this format:  tailcall check [OPTIONS] &lt;FILE_PATHS&gt;...   The check command offers options that control settings such as the display of the generated schema, n + 1 issues etc.  ","version":"Next","tagName":"h2"},{"title":"--n-plus-one-queries​","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#--n-plus-one-queries","content":" This flag triggers the detection of N+1 issues.  Type: BooleanDefault: false  tailcall check --n-plus-one-queries &lt;FILE_PATHS&gt; ...   ","version":"Next","tagName":"h3"},{"title":"--schema​","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#--schema","content":" This option enables the display of the schema of the composition spec.  Type: BooleanDefault: false  tailcall check --schema &lt;file1&gt; &lt;file2&gt; ... &lt;fileN&gt;   The check command allows for files. Specify each file path, separated by a space, after the options.  Example:  tailcall check --schema ./path/to/file1.graphql ./path/to/file2.graphql   ","version":"Next","tagName":"h3"},{"title":"--format​","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#--format","content":" This is an optional command which allows changing the format of the input file. It accepts gql or graphql,yml or yaml, json .  tailcall check ./path/to/file1.graphql ./path/to/file2.graphql --format json   ","version":"Next","tagName":"h3"},{"title":"start​","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#start","content":" The start command launches the GraphQL Server for the specific configuration.  To start the server, use the following command:  tailcall start &lt;file1&gt; &lt;file2&gt; ... &lt;fileN&gt; &lt;http_path1&gt; &lt;http_path2&gt; .. &lt;http_pathN&gt;   The start command allows for files and supports loading configurations over HTTP. You can mix file system paths with HTTP paths. Specify each path, separated by a space, after the options.  Example:  tailcall start ./path/to/file1.graphql ./path/to/file2.graphql http://example.com/file2.graphql   ","version":"Next","tagName":"h2"},{"title":"init​","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#init","content":" The init command bootstraps a new Tailcall project. It creates the necessary GraphQL schema files in the provided file path.  tailcall init &lt;file_path&gt;   This command prompts for file creation and configuration, creating the following files:  File Name\tDescription.tailcallrc.schema.json\tProvides autocomplete in your editor when the configuration is written in json or yml format. .graphqlrc.yml\tAn IDE configuration that references your GraphQL configuration (if it's in .graphql format) and the following .tailcallrc.graphql. .tailcallrc.graphql\tContains Tailcall specific auto-completions for .graphql format.  ","version":"Next","tagName":"h2"},{"title":"gen​","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#gen","content":" The gen command in the Tailcall CLI is designed to generate GraphQL configurations from various sources, such as protobuf files and REST endpoints.  usage:  tailcall gen path_to_configuration_file.json   To generate a Tailcall GraphQL configuration, provide a configuration file to the gen command like done above. This configuration file should be in JSON or YAML format, as illustrated in the example below:  JSONYML { &quot;llm&quot;: { &quot;model&quot;: &quot;gemini-1.5-flash-latest&quot;, &quot;secret&quot;: &quot;API_KEY&quot; }, &quot;inputs&quot;: [ { &quot;curl&quot;: { &quot;src&quot;: &quot;https://jsonplaceholder.typicode.com/posts/1&quot;, &quot;fieldName&quot;: &quot;post&quot;, &quot;headers&quot;: { &quot;Content-Type&quot;: &quot;application/json&quot;, &quot;Accept&quot;: &quot;application/json&quot;, &quot;Authorization&quot;: &quot;Bearer {{.env.AUTH_TOKEN}}&quot; } } }, { &quot;curl&quot;: { &quot;src&quot;: &quot;https://jsonplaceholder.typicode.com/posts&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;body&quot;: { &quot;title&quot;: &quot;Tailcall - Modern GraphQL Runtime&quot;, &quot;body&quot;: &quot;Tailcall - Modern GraphQL Runtime&quot;, &quot;userId&quot;: 1 }, &quot;headers&quot;: { &quot;Content-Type&quot;: &quot;application/json&quot;, &quot;Accept&quot;: &quot;application/json&quot; }, &quot;isMutation&quot;: true, &quot;fieldName&quot;: &quot;createPost&quot; } }, { &quot;proto&quot;: { &quot;src&quot;: &quot;./news.proto&quot; } } ], &quot;output&quot;: { &quot;path&quot;: &quot;./output.graphql&quot;, &quot;format&quot;: &quot;graphQL&quot; }, &quot;schema&quot;: { &quot;query&quot;: &quot;Query&quot;, &quot;mutation&quot;: &quot;Mutation&quot; }, &quot;preset&quot;: { &quot;mergeType&quot;: 1, &quot;consolidateURL&quot;: 0.5, &quot;treeShake&quot;: true, &quot;unwrapSingleFieldTypes&quot;: true, &quot;inferTypeNames&quot;: true } }   ","version":"Next","tagName":"h2"},{"title":"Inputs​","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#inputs","content":" The inputs section specifies the sources from which the GraphQL configuration should be generated. Each source can be either a REST endpoint or a protobuf file.  REST: When defining REST endpoints, the configuration should include the following properties. src (Required): The URL of the REST endpoint. In this example, it points to a specific post on jsonplaceholder.typicode.com. fieldName (Required): A unique name that should be used as the field name, which is then used in the operation type. In the example below, it's set to post. important Ensure that each field name is unique across the entire configuration to prevent overwriting previous definitions. headers (Optional): Users can specify the required headers to make the HTTP request in the headers section. info Ensure that secrets are not stored directly in the configuration file. Instead, use templates to securely reference secrets from environment variables. For example, see the following configuration where AUTH_TOKEN is referenced from the environment like {{.env.AUTH_TOKEN}}. body (Optional): This property allows you to specify the request body for methods like POST or PUT. If the endpoint requires a payload, include it here. method (Optional): Specify the HTTP method for the request (e.g. GET, POST, PUT, DEL). If not provided, the default method is GET. isMutation (Optional): This flag indicates whether the request should be treated as a GraphQL Mutation. Set isMutation to true to configure the request as a Mutation. If not specified or set to false, the request will be treated as a Query by default. Query Operation: To define a GraphQL Query, either omit the isMutation property or set it to false. By default, if isMutation is not provided, the request will be configured as a Query. JSONYML sample input example for generating Query type sample input example for generating Query type { &quot;curl&quot;: { &quot;src&quot;: &quot;https://jsonplaceholder.typicode.com/posts/1&quot;, &quot;fieldName&quot;: &quot;post&quot;, &quot;headers&quot;: { &quot;Authorization&quot;: &quot;Bearer {{.env.AUTH_TOKEN}}&quot; } } } For the above input configuration, the following field will be generated in the operation type: Generated Configuration Generated Configuration type Query { # field name is taken from the above JSON config post(p1: Int!): Post @http(path: &quot;/posts/{{arg.p1}}&quot;) } Mutation Operation: To define a GraphQL Mutation, set isMutation to true and provide the necessary request body, method, isMutation and headers. JSONYML sample input example for generating Mutation type sample input example for generating Mutation type { &quot;curl&quot;: { &quot;src&quot;: &quot;https://jsonplaceholder.typicode.com/posts&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;body&quot;: { &quot;title&quot;: &quot;Tailcall - Modern GraphQL Runtime&quot;, &quot;body&quot;: &quot;Tailcall - Modern GraphQL Runtime&quot;, &quot;userId&quot;: 1 }, &quot;headers&quot;: { &quot;Content-Type&quot;: &quot;application/json&quot;, &quot;Accept&quot;: &quot;application/json&quot; }, &quot;isMutation&quot;: true, &quot;fieldName&quot;: &quot;createPost&quot; } } For the above input configuration, the following field will be generated in the operation type: Generated Configuration Generated Configuration input PostInput { title: String body: String userId: ID } type Mutation { # field name is taken from the above JSON config createPost(createPostInput: PostInput!): Post @http(path: &quot;/posts/{{arg.p1}}&quot;, method: &quot;POST&quot;) } Proto: For protobuf files, specify the path to the proto file (src). JSONYML { &quot;proto&quot;: { &quot;src&quot;: &quot;./path/to/file.proto&quot; } }   ","version":"Next","tagName":"h3"},{"title":"Output​","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#output","content":" The output section specifies the path and format for the generated GraphQL configuration.  path: The file path where the output will be saved.format: The format of the output file. Supported formats are json, yml, and graphQL.  tip You can also change the format of the configuration later using the check command.  ","version":"Next","tagName":"h3"},{"title":"Preset​","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#preset","content":" The config generator provides a set of tuning parameters that can make the generated configurations more readable by reducing duplication. This can be configured using the preset section.  JSONYML Presets with default values Presets with default values { &quot;preset&quot;: { &quot;mergeType&quot;: 1, &quot;consolidateURL&quot;: 0.5, &quot;treeShake&quot;: true, &quot;unwrapSingleFieldTypes&quot;: true, &quot;inferTypeNames&quot;: true } }   mergeType: This setting merges types in the configuration that satisfy the threshold criteria. It takes a threshold value between 0.0 and 1.0 to determine if two types should be merged or not. The default is 1.0. For example, the following types T1 and T2 are exactly similar, and with a threshold value of 1.0, they can be merged into a single type called M1: Merging type T1 and T2 into M1 Merging type T1 and T2 into M1 # BEFORE type T1 { id: ID firstName: String lastName: String } type T2 { id: ID firstName: String lastName: String } # AFTER: T1 and T2 are merged into M1. type M1 { id: ID firstName: String lastName: String } consolidateURL: The setting identifies the most common base URL among multiple REST endpoints and uses this URL in the upstream directive. It takes a threshold value between 0.0 and 1.0 to determine the most common endpoint. The default is 0.5. For example, if the Query type has three base URLs, using the consolidateURL setting with a 0.5 threshold will pick the base URL that is used in more than 50% of the http directives, http://jsonplaceholder.typicode.com, and add it to the upstream, cleaning the base URLs from the Query type. schema @server(hostname: &quot;0.0.0.0&quot;, port: 8000) @upstream(httpCache: 42) { query: Query } type Query { post(id: Int!): Post @http( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; path: &quot;/posts/{{.args.id}}&quot; ) posts: [Post] @http( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; path: &quot;/posts&quot; ) user(id: Int!): User @http( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; path: &quot;/users/{{.args.id}}&quot; ) users: [User] @http( baseURL: &quot;http://jsonplaceholder-1.typicode.com&quot; path: &quot;/users&quot; ) } After enabling the consolidateURL setting: schema @server(hostname: &quot;0.0.0.0&quot;, port: 8000) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; httpCache: 42 ) { query: Query } type Query { post(id: Int!): Post @http(path: &quot;/posts/{{.args.id}}&quot;) posts: [Post] @http(path: &quot;/posts&quot;) user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) users: [User] @http( baseURL: &quot;http://jsonplaceholder-1.typicode.com&quot; path: &quot;/users&quot; ) } treeShake: This setting removes unused types from the configuration. When enabled, any type that is defined in the configuration but not referenced anywhere else (e.g., as a field type, union member, or interface implementation) will be removed. This helps to keep the configuration clean and free from unnecessary definitions. Before applying treeShake, the configuration might look like this. Before applying treeShake, the configuration might look like this. type Query { foo: Foo } type Foo { bar: Bar } # Type not used anywhere else type UnusedType { baz: String } type Bar { a: Int } After enabling treeShake, the UnusedType will be removed. After enabling treeShake, the UnusedType will be removed. type Query { foo: Foo } type Foo { bar: Bar } type Bar { a: Int } unwrapSingleFieldTypes: This setting instructs Tailcall to flatten out types with single field. Before applying the setting Before applying the setting type Query { foo: Foo } # Type with only one field type Foo { bar: Bar } # Type with only one field type Bar { a: Int } After applying setting After applying setting type Query { foo: Int } This helps in flattening out types into single field. inferTypeNames: This setting enables the automatic inference of type names based on their schema and it's usage. For it to work reliably it depends on an external secure AI agent. Before enabling inferTypeNames setting Before enabling inferTypeNames setting type T1 { id: ID name: String email: String post: [T2] } type T2 { id: ID title: String body: String } type Query { users: [T1] @http(path: &quot;/users&quot;) } Type T1: T1 is used as the output type for the user field in the Query type. We recognize that T1 is associated with users in the users field of Query. Therefore, it infers that T1 should be named User to indicate that it represents user data. Type T2: T2 is used as the output type for the post field within T1. We recognize that T2 is associated with posts in the post field of User. Therefore, it infers that T2 should be named Post to indicate that it represents post data. After enabling inferTypeNames setting After enabling inferTypeNames setting type User { id: ID name: String email: String post: [Post] } type Post { id: ID title: String body: String } type Query { user: User @http(path: &quot;/users&quot;) } By leveraging field names to derive type names, the schema becomes more intuitive and aligned with the data it represents, enhancing overall readability and understanding.  ","version":"Next","tagName":"h3"},{"title":"LLM​","type":1,"pageTitle":"Command Line Reference","url":"/docs/tailcall-graphql-cli/#llm","content":" Tailcall leverages LLM to improve the quality of configuration files by suggesting better names for types, fields, and more. The llm section in the configuration allows you to specify the LLM model and secret (API key) that will be used for generating the configuration.  Example:  Using Gemini. Set TAILCALL_LLM_API_KEY to your Gemini API key. &quot;llm&quot;: { &quot;model&quot;: &quot;gemini-1.5-flash-latest&quot;, &quot;secret&quot;: &quot;{{.env.TAILCALL_LLM_API_KEY}}&quot; } Using Ollama. Don't need secret. &quot;llm&quot;: { &quot;model&quot;: &quot;gemma2&quot;, }   important Ensure that secrets are not stored directly in the configuration file. Instead, use templates to securely reference secrets from environment variables. For example, you can write secret as {{.env.TAILCALL_SECRET}}, where TAILCALL_SECRET is referenced from the running environment. ","version":"Next","tagName":"h3"},{"title":"CTOs Guide to GraphQL","type":0,"sectionRef":"#","url":"/graphql/cto-guide/","content":"CTOs Guide to GraphQL Good APIs craft a broad spectrum of functionalities. Yet, the broader their scope, the more they diverge from being the perfect fit for any specific use case. This fundamental discrepancy — the impedance mismatch between the general capabilities of an API and the precise needs of a particular scenario — amplifies the necessity for an orchestration layer. Such a layer adeptly bridges this gap, tailor-fitting generic APIs to meet exact requirements with finesse. Tailcall stands at the forefront of this innovation, seamlessly transforming the way APIs are integrated and interacted with. Tailcall introduces a set of primitives, enabling developers to express and fine-tune how APIs are orchestrated without writing any code. This approach facilitates specifying different caching and batching strategies to enhance the overall system's efficiency. It also enables precise governance and access control mechanisms on actual domain entities and their relationships. Tailcall serves as a central hub for team collaboration, offering a unified point for managing all APIs, documentation, and more. Once configured, it positions itself between the clients and microservices, adeptly managing all requests and orchestrating them as needed. Manually crafting BFF (Backend for Frontend) layers has become outdated. With Tailcall, API orchestration evolves into a streamlined and highly optimized process. It functions as an essential intermediary, intelligently directing requests and assembling responses from each microservice. This approach diminishes the development burden associated with traditional BFF layers but also bolsters performance, reliability, and scalability throughout the application infrastructure.","keywords":"","version":"Next"},{"title":"Frequently Asked Questions","type":0,"sectionRef":"#","url":"/graphql/faq/","content":"","keywords":"","version":"Next"},{"title":"Performance​","type":1,"pageTitle":"Frequently Asked Questions","url":"/graphql/faq/#performance","content":" What sort of throughput and latency can we expect?  Check out our benchmarks page for detailed information.  What is the maximum capacity that Tailcall can manage effectively?  Tailcall is designed to scale horizontally and can handle billions of requests per second.  ","version":"Next","tagName":"h2"},{"title":"Features​","type":1,"pageTitle":"Frequently Asked Questions","url":"/graphql/faq/#features","content":" I use REST APIs. How can I use Tailcall if I don’t currently use GraphQL?  You can use Tailcall in two ways:  You can use Tailcall to build a GraphQL server atop your existing REST APIs and Tailcall's @http directive. And you can replace your REST APIs with GraphQL over time.In case you don't want to use GraphQL, Tailcall has a directive called @rest that lets you use the composition capabilities of GraphQL without needing you to adopt GraphQL for your endpoints. This directive makes Tailcall GraphQL queries and mutations available as REST endpoints.  Can Tailcall generate GraphQL from gRPC APIs?  Absolutely! Tailcall automatically generates GraphQL configurations from REST, gRPC, and existing GraphQL configuration files. We even support a hybrid integration of REST and gRPC. You can learn more about generating GraphQL configuration from gRPC APIs here.  Is authentication built-in with Tailcall? If yes, how?  Yes, Tailcall offers a simple way to add entity-level authentication to your GraphQL schema. You can read more about it here.  Does Tailcall work with HTTP/2?  Yes, Tailcall supports HTTP/2 for both server (ingress) and client (egress) operations, enabling the protocol for incoming and outgoing server requests. For egress, no special settings are needed Tailcall will automatically upgrade the connection to HTTP/2 whenever possible.  Do you follow the Federation specification?  Yes, our subgraph is fully compatible with the Federation specification.  Are you going to have a control plan like Apollo or Cosmo that has a self-hosted solution?  Yes, it’s in the works! Please contact us to get more details.  ","version":"Next","tagName":"h2"},{"title":"Installation​","type":1,"pageTitle":"Frequently Asked Questions","url":"/graphql/faq/#installation","content":" What observability integrations do you support?  Tailcall integrates with Apollo Studio, Data Dog, New Relic, and Honeycomb for telemetry.  Where can I deploy Tailcall apps?  Tailcall is built using Rust and when you compile Rust, it gets compiled to an executable. You can then run the binary from anywhere - including your own self-hosted server! You can also run them as serverless functions through supported platforms like AWS Lambda. Each of these deployment methods have their own tradeoffs. You can also deploy Tailcall apps on Kubernetes, Docker, or any other container orchestration platform. Tailcall can also be compiled to WebAssembly and run in the browser/js based server .  ","version":"Next","tagName":"h2"},{"title":"Trivia​","type":1,"pageTitle":"Frequently Asked Questions","url":"/graphql/faq/#trivia","content":" Why did you start Tailcall?  Tailcall was inspired by our experiences at Dream11, a fast-growing fantasy sports platform with over 200 million users. As the platform grew rapidly, we needed to make frequent UI changes and maintain type safety on the backend. We adopted GraphQL on the frontend’s recommendation, which reduced our workload, but as the platform expanded, infrastructure costs skyrocketed. Handwriting GraphQL servers also became cumbersome and error-prone.  We developed a Domain Specific Language (DSL) to address GraphQL’s performance issues and other concerns, which helped us cut infrastructure costs by 90%. Our key takeaway was that APIs should be independently built and operated, and GraphQL should be used as a client-side abstraction closer to the client, not the server. This knowledge shaped the way we architected Tailcall today! You can read more about our GraphQL journey at Dream11 here.  What specific problem does Tailcall solve and for whom? Who is your ideal customer?  Tailcall is perfect for growing companies that need efficient API management and are currently using REST APIs. Imagine you have a REST API and run an e-commerce store. The UI must make three separate requests:  One to get the list of products.Another to get the seller details for each product.A third to get the reviews for each product and calculate the average rating.  Manual Composition: The UI is responsible for combining product data with seller names and calculating the average rating.  Over-fetching: REST endpoints may return unnecessary fields, leading to over-fetching of data that the UI does not need.  With GraphQL, a single query can be crafted to fetch exactly what the UI needs in one request. The GraphQL schema defines the relationships, simplifying data retrieval. However, setting this up usually involves writing backend code.  Tailcall takes it a step further, enabling you to build an efficient GraphQL server using only a configuration file—no code required. This significantly speeds up the development process.  Is GraphQL dead? Why do you use GraphQL when so many in the industry think it’s dead?  Handwriting GraphQL can solve certain problems but also introduces new challenges. While manual GraphQL might fade away, combining GraphQL with a powerful runtime like Tailcall has a bright future!  We already have a GraphQL API ready and don't have a reason to change. Why should we use Tailcall?  While GraphQL is great for querying, manually writing backend code introduces complexity and potential errors. Tailcall simplifies this by letting you build a fast GraphQL server with just a configuration file, greatly speeding up your development. We encourage you to try it out, and if you have questions, we’re here to help!  What does the name Tailcall mean?  Our name was inspired by &quot;tail call optimization&quot; (TCO), a concept in programming that perfectly reflects our mission to optimize performance and turbocharge developers' productivity!  I am ready for Tailcall. What next?  Awesome! Check out our Getting Started page to begin your journey. For any questions or to chat with us, join us on Discord. ","version":"Next","tagName":"h2"},{"title":"Unlocking the Power of GraphQL Directives: A Comprehensive Guide","type":0,"sectionRef":"#","url":"/graphql/graphql-directives/","content":"","keywords":"","version":"Next"},{"title":"Introduction to GraphQL Directives​","type":1,"pageTitle":"Unlocking the Power of GraphQL Directives: A Comprehensive Guide","url":"/graphql/graphql-directives/#introduction-to-graphql-directives","content":" GraphQL directives are a vital component of the GraphQL specification. These powerful tools may be less familiar due to their limited mandatory usage in API compliance. However, their ability to extend the functionality of a GraphQL API and server is crucial, especially in advanced tools like Tailcall Graph Server.  This article will explore the nature of GraphQL directives, their applications, and provide examples of their usage.  ","version":"Next","tagName":"h2"},{"title":"What Are GraphQL Directives?​","type":1,"pageTitle":"Unlocking the Power of GraphQL Directives: A Comprehensive Guide","url":"/graphql/graphql-directives/#what-are-graphql-directives","content":" GraphQL directives serve as annotations within a GraphQL schema, indicating that the annotated element requires special evaluation. They enable modifications in runtime execution and type validation within a GraphQL document.  Directives allow the alteration of GraphQL execution behavior by providing options beyond those available through field arguments. For example, directives can conditionally include or exclude fields.  Both built-in and custom directives can be utilized when building or consuming a GraphQL API. Built-in directives are defined by the GraphQL specification, while custom directives are created by the GraphQL service or tool being used.  ","version":"Next","tagName":"h2"},{"title":"Built-in GraphQL Directives​","type":1,"pageTitle":"Unlocking the Power of GraphQL Directives: A Comprehensive Guide","url":"/graphql/graphql-directives/#built-in-graphql-directives","content":" The GraphQL specification includes several built-in directives with specific names and argument values of any input type. These directives can be applied to types, fields, fragments, and operations. Here are the built-in directives:  @skip: Conditionally excludes fields from a query operation.@include: Conditionally includes fields in a query operation, opposite of @skip.@deprecated: Marks a field or enum value as deprecated and provides a reason for deprecation.  As GraphQL evolves, new directives like @defer and @stream may be introduced by the GraphQL Working Group. Additionally, GraphQL services and tools can provide custom directives.  ","version":"Next","tagName":"h3"},{"title":"Custom GraphQL Directives​","type":1,"pageTitle":"Unlocking the Power of GraphQL Directives: A Comprehensive Guide","url":"/graphql/graphql-directives/#custom-graphql-directives","content":" Custom directives enhance GraphQL's functionality, allowing the addition of bespoke behaviors to a GraphQL API. Various GraphQL server and client implementations use custom directives to extend functionality.  For instance, Tailcall uses custom directives like @http, @grpc and, @graphql to connect with data sources. These directives enable interfacing with REST APIs, gRPC APIs, and other GraphQL APIs. Directives like @call help combine data from multiple sources into a single type.  ","version":"Next","tagName":"h3"},{"title":"Directive Locations in GraphQL​","type":1,"pageTitle":"Unlocking the Power of GraphQL Directives: A Comprehensive Guide","url":"/graphql/graphql-directives/#directive-locations-in-graphql","content":" Directives can be applied to different locations within GraphQL. The GraphQL specification differentiates between type system directive locations and executable directive locations. The location determines how a GraphQL implementation handles them.  For example, @include and @skip can be used in queries passed to the GraphQL server, affecting query processing based on an argument. Conversely, @deprecated is only added to a schema definition.  ","version":"Next","tagName":"h3"},{"title":"Type System Directives​","type":1,"pageTitle":"Unlocking the Power of GraphQL Directives: A Comprehensive Guide","url":"/graphql/graphql-directives/#type-system-directives","content":" Type system directives annotate a schema, object type, or field definition in GraphQL SDL (Schema Definition Language) when building a GraphQL server. Both built-in and custom directives can be used in type system directive locations, allowing GraphQL server implementations to take additional actions.  Type system directive locations, also known as &quot;schema directives,&quot; include:  SCHEMASCALAROBJECTFIELD_DEFINITIONARGUMENT_DEFINITIONINTERFACEUNIONENUM &amp; ENUM_VALUEINPUT_OBJECT &amp; INPUT_FIELD_DEFINITION  For example, the @deprecated directive marks a field as deprecated:  type User { id: ID! name: String! @deprecated( reason: &quot;Use the firstName and lastName fields instead&quot; ) firstName: String! lastName: String! email: String! }   The @deprecated directive provides a reason for deprecation, which is available to services that introspect the schema. Clients can then warn users about the deprecated field.  ","version":"Next","tagName":"h3"},{"title":"Example of @http Directive​","type":1,"pageTitle":"Unlocking the Power of GraphQL Directives: A Comprehensive Guide","url":"/graphql/graphql-directives/#example-of-http-directive","content":" The @http directive, a custom directive in Tailcall Graph Server, fetches data for the User type from a REST API:  type User { id: ID! name: String! email: String! } type Query { user(id: ID!): User @http( baseURL: &quot;https://jsonplaceholder.typicode.com&quot; path: &quot;/users/{{.args.id)}&quot; ) }   When executing an operation that includes the user field, the Tailcall GraphQL API fetches data from the REST API and returns it to the client. The @http directive, applied to a type system location, annotates the user field and defines how data should be fetched.  ","version":"Next","tagName":"h3"},{"title":"Execution Directives​","type":1,"pageTitle":"Unlocking the Power of GraphQL Directives: A Comprehensive Guide","url":"/graphql/graphql-directives/#execution-directives","content":" Execution directives modify the behavior of an operation, field, or fragment during runtime execution. They can include or exclude fields or perform additional data processing before returning a response.  Executable directive locations in GraphQL include:  QUERYMUTATIONSUBSCRIPTIONFIELDFRAGMENT_DEFINITION &amp; FRAGMENT_SPREADINLINE_FRAGMENTVARIABLE_DEFINITION  Both built-in and custom directives can be applied to executable locations. Most built-in directives are executable, such as @skip and @include, used to conditionally include or exclude fields in an operation.  ","version":"Next","tagName":"h3"},{"title":"Example of @include Directive​","type":1,"pageTitle":"Unlocking the Power of GraphQL Directives: A Comprehensive Guide","url":"/graphql/graphql-directives/#example-of-include-directive","content":" The @include directive conditionally includes fields in a query operation:  query me($showName: Boolean!) { me { id firstName @include(if: $showName) lastName @include(if: $showName) email } }   The @include directive conditionally includes the firstName and lastName fields in the response. The if argument specifies a boolean value determining whether to include the field. The if argument is set to the variable $showName, allowing for conditional inclusion based on its value.  ","version":"Next","tagName":"h3"},{"title":"Conclusion and Next Steps​","type":1,"pageTitle":"Unlocking the Power of GraphQL Directives: A Comprehensive Guide","url":"/graphql/graphql-directives/#conclusion-and-next-steps","content":" GraphQL directives, though initially complex, are a powerful tool within the GraphQL ecosystem. This article explained built-in and custom directives and their application across type system and executable locations in GraphQL. Type system directives apply to GraphQL SDL, while executable directives modify GraphQL responses during runtime execution.  Understanding directives is crucial when working with GraphQL APIs, whether using tools like Tailcall GraphQL server or manually implementing. ","version":"Next","tagName":"h2"},{"title":"Comprehensive Guide to GraphQL Fragments","type":0,"sectionRef":"#","url":"/graphql/graphql-fragments/","content":"","keywords":"","version":"Next"},{"title":"Introduction to GraphQL Fragments​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#introduction-to-graphql-fragments","content":" GraphQL fragments are reusable units that allow developers to define a piece of a query once and use it in multiple places. This capability not only reduces redundancy but also improves the maintainability of your GraphQL code. By using fragments, you can streamline your queries and mutations, ensuring a more efficient and organized approach to handling data.  ","version":"Next","tagName":"h2"},{"title":"Why Use GraphQL Fragments?​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#why-use-graphql-fragments","content":" ","version":"Next","tagName":"h2"},{"title":"Code Reusability and Maintainability​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#code-reusability-and-maintainability","content":" GraphQL fragments enable the reuse of common fields across different queries and mutations. This reduces the need for writing the same field selections repeatedly, making your code more DRY (Don't Repeat Yourself). Consequently, maintaining and updating your codebase becomes more manageable.  ","version":"Next","tagName":"h3"},{"title":"Improved Query Performance​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#improved-query-performance","content":" Using fragments can lead to optimized queries by minimizing the amount of bytes sent in the query. This can result in faster query responses and a more efficient use of network resources.  ","version":"Next","tagName":"h3"},{"title":"Consistent Data Fetching​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#consistent-data-fetching","content":" With fragments, you ensure that your application fetches consistent sets of fields across various parts of your UI. This consistency can reduce bugs and discrepancies in your data representation, leading to a more stable and reliable application.  ","version":"Next","tagName":"h3"},{"title":"How to Define and Use GraphQL Fragments​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#how-to-define-and-use-graphql-fragments","content":" ","version":"Next","tagName":"h2"},{"title":"Defining a Fragment​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#defining-a-fragment","content":" To define a fragment, use the fragment keyword followed by the fragment name and the type it belongs to. Here’s an example:  fragment UserDetails on User { id name email }   ","version":"Next","tagName":"h3"},{"title":"Using a Fragment in Queries​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#using-a-fragment-in-queries","content":" Once defined, you can include the fragment in any query that requires the same set of fields. This is done using the ...FragmentName syntax. Here’s how you can use the UserDetails fragment in a query:  query GetUser { user(id: &quot;1&quot;) { ...UserDetails } }   ","version":"Next","tagName":"h3"},{"title":"Combining Multiple Fragments​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#combining-multiple-fragments","content":" You can also combine multiple fragments in a single query to fetch different sets of fields. Here’s an example:  fragment PostDetails on Post { id title content } query GetUserWithPosts { user(id: &quot;1&quot;) { ...UserDetails posts { ...PostDetails } } }   ","version":"Next","tagName":"h3"},{"title":"Best Practices for Using GraphQL Fragments​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#best-practices-for-using-graphql-fragments","content":" ","version":"Next","tagName":"h2"},{"title":"Keep Fragments Small and Specific​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#keep-fragments-small-and-specific","content":" Avoid creating overly large fragments that include too many fields. Instead, create small, focused fragments that serve a specific purpose. This makes your fragments more reusable and easier to manage.  ","version":"Next","tagName":"h3"},{"title":"Use Descriptive Names​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#use-descriptive-names","content":" Name your fragments descriptively to indicate their purpose and the type of data they fetch. This enhances the readability of your code and makes it easier for other developers to understand the intent of each fragment.  ","version":"Next","tagName":"h3"},{"title":"Organize Fragments Logically​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#organize-fragments-logically","content":" Group related fragments together in your codebase to keep things organized. For instance, you might have a folder dedicated to user-related fragments and another for post-related fragments. This logical organization aids in the maintainability of your project.  ","version":"Next","tagName":"h3"},{"title":"Advanced Fragment Usage​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#advanced-fragment-usage","content":" ","version":"Next","tagName":"h2"},{"title":"Nested Fragments​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#nested-fragments","content":" Fragments can be nested within other fragments to build more complex data structures. Here’s an example:  fragment CommentDetails on Comment { id text author { ...UserDetails } } fragment PostWithComments on Post { id title content comments { ...CommentDetails } }   ","version":"Next","tagName":"h3"},{"title":"Fragments on Interfaces and Unions​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#fragments-on-interfaces-and-unions","content":" You can also define fragments on interfaces and unions to handle various data types. This is particularly useful when working with polymorphic data structures. Here’s an example:  fragment MediaFields on Media { ... on Photo { url height width } ... on Video { url duration } } query GetMedia { media { ...MediaFields } }   ","version":"Next","tagName":"h3"},{"title":"Example Diagram​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#example-diagram","content":" Below is an example diagram to illustrate the relationship between different fragments and their usage in queries:    ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Fragments","url":"/graphql/graphql-fragments/#conclusion","content":" GraphQL fragments are a powerful feature that enhances the reusability, maintainability, and performance of your GraphQL queries. By defining and using fragments effectively, you can create a more efficient and organized codebase, ensuring that your application fetches data consistently and optimally. Follow best practices such as keeping fragments small, using descriptive names, and organizing them logically to make the most out of this feature. ","version":"Next","tagName":"h2"},{"title":"🚀 GraphQL Conf Hackathon 2024","type":0,"sectionRef":"#","url":"/graphql/graphql-conf-hackathon-2024/","content":"","keywords":"","version":"Next"},{"title":"Getting Started​","type":1,"pageTitle":"🚀 GraphQL Conf Hackathon 2024","url":"/graphql/graphql-conf-hackathon-2024/#getting-started","content":" Support the following GraphQL schema:  schema { query: Query } type Query { posts: [Post] post(id: Int!): Post users: [User] user(id: Int!): User } type Post { id: Int userId: Int! title: String body: String user: User } type User { id: Int name: String username: String email: String address: Address phone: String website: String } type Address { zipcode: String geo: Geo } type Geo { lat: Float lng: Float }   ","version":"Next","tagName":"h2"},{"title":"Technical Requirements​","type":1,"pageTitle":"🚀 GraphQL Conf Hackathon 2024","url":"/graphql/graphql-conf-hackathon-2024/#technical-requirements","content":" Repository should be forked from Tailcall's GraphQL Conf Hackathon 2024All CI tests should pass.Your implementation should be under the /projects directory.Should support any query that is supported by the schema.  ","version":"Next","tagName":"h2"},{"title":"And Some More...​","type":1,"pageTitle":"🚀 GraphQL Conf Hackathon 2024","url":"/graphql/graphql-conf-hackathon-2024/#and-some-more","content":" We might add new tests and modify the existing ones to ensure there is no hardcoding and it's a level playing field for all.If you have questions or doubts about the hackathon, connect with us on Discord or X or the only two people in that bright yellow T-shirt they'd be glad to say 👋.  ","version":"Next","tagName":"h2"},{"title":"Scoring​","type":1,"pageTitle":"🚀 GraphQL Conf Hackathon 2024","url":"/graphql/graphql-conf-hackathon-2024/#scoring","content":" Test Execution: For every commit, a set of predefined tests and benchmarks are executed. These tests are located in the ./tests directory. Throughput Normalization: Your performance is measured in terms of requests per second (RPS) for each query. This performance is then compared to Tailcall's RPS for the same query. The comparison is done by dividing your RPS by Tailcall's RPS. This gives a normalized score for each query. Example: For the posts-title query: If your RPS is 100 and Tailcall's RPS is 50, the normalized score for this query would be 100/50 = 2.0. Final Score Calculation: The normalized scores for all queries are averaged. The final score is this average multiplied by 1000. Example: Given the following scores: Query\tYour RPS\tTailcall RPS\tNormalizedposts-nested\t100\t50\t2.0 posts-title\t200\t350\t0.8 posts-with-user\t300\t250\t1.2 The average normalized score is (2.0 + 0.8 + 1.2) / 3 = 1.33. The final score would be 1.33 * 1000 = 1,333.33.  ","version":"Next","tagName":"h2"},{"title":"FAQs​","type":1,"pageTitle":"🚀 GraphQL Conf Hackathon 2024","url":"/graphql/graphql-conf-hackathon-2024/#faqs","content":" How do I submit my solution?Submit your solution as a pull request (PR) from your forked repo to the main repo.  What should my PR include?Your PR should only include file additions inside /projects/${participant_name}. Don't change any other files or code belonging to other participants.  Can I use any language or tools?Yes, you can use any language, framework, or tools as long as they're within the scope of the licenses. However, the tailcall tool is not allowed.  What should be included in the solution?Your solution should include all the source code and setup instructions necessary to understand how you achieved the solution and how to run it.  Can I work with others on the solution?Yes, you can collaborate, but only the person who submits the PR will be eligible to win the prize.  What if there are multiple solutions with identical code?Any kind of plagiarism will result in a ban, Check our guidelines below on plagiarism for more.  What if two solutions have the same score?When multiple solutions achieve identical scores, the tiebreaker will be determined by the timestamp of their most recent commit. The solution with the earlier last commit will be declared the winner in such cases.  Contribution Guidelines Data Source (Upstream REST API)​ On the CI your GraphQL server will need to fetch data from the upstream REST API at: Base URL: http://localhost:3000 Endpoints​ GET /postsReturns a list of posts. GET /posts/:idReturns a post by ID. GET /usersReturns a list of users. GET /users/:idReturns a user by ID. GET /users?id=1&amp;id=2&amp;id=3Returns multiple users with IDs specified in query parameters. The structure of the REST API responses will match the GraphQL schema fields. GraphQL server​ Your GraphQL server should start on url http://localhost:8000/graphql and serve POST Graphql requests on it. Getting Started​ Fork this repositoryClone the repository locally or run the codespace of your choiceAdd new folder to ./projects folder with your username. Copy the /template folder content from the repository root to your folder to populate required files.Add the code of the implementation inside the folder you could use any language or tool by your choice that allows you to create the required GraphQL server. Just make sure the solution could be replicated in Github Actions environment.use the schema.graphql file from the root of the repo. Feel free to copy the file to your folder and change it the way you needed to work properly, but don't change the structure of types Add run.sh file that installs required tools and runs the server the script is running on Github Hosted runner. List of available tools and packages could be found herefirst add installation and build steps for required tools and code. E.g. npm i or cargo build --releaseadd steps to start the server. E.g. npm start or cargo run --releasemake sure the script is marked as executable chmod +x run.sh Make sure your code is working and handles GraphQL requestsCommit and push changes to your forkCreate a pull request from your fork into original repository Run mock server locally​ To run the mock server locally you need a Rust toolchain installed. To run the mock server in the root of the repo run: cargo run -p mock-api The server will start on http://localhost:3000 and will serve the endpoints mentioned in data source Run test suite locally​ To run the whole test suite locally you need a Rust toolchain installed. For the first time you need to build the mock server code (one-time run): cargo build -p mock-api After finishing the command you can use following command to run test suite: cargo run If you need to run only specific project, specify this project as option with name of the directory of the project: cargo run -- --project tailcall How implementation is checked​ Build everything that is required to run test environment and custom implementationStart the test environment to validate response: mock server and reference server that is used to test implementation correctnessRun correctness testsRun the benchmarkRun correctness tests again Testing correctness​ For testing the correctness repeat next process multiple times: Regenerate mocks on mock-api serverFor every request in /tests directory execute the request to user implementationExecute the same request for reference implementationCompare the results and in case they are mismatch throw an error Benchmarking the performance​ Ran many requests in parallel to the server with tools like wrk or k6 to collect info about provided RPS and latency  Terms and Conditions Final Decision: Tailcall reserves the exclusive right to determine the winner of the GraphQL Conf Hackathon 2024. The decision made by Tailcall is final and binding. No disputes, appeals, or challenges to the outcome will be entertained, either during the event or after its conclusion. Right to Disqualify: Tailcall retains the right to disqualify any participant or team at any stage of the hackathon for reasons including, but not limited to, violations of the rules, inappropriate conduct, attempts to manipulate or cheat the scoring system, or any activity deemed unethical or unfair. Such disqualification decisions are at the sole discretion of Tailcall and will not be subject to review or reversal. Intellectual Property: By submitting your solution, you agree that all work is your own or properly licensed. Any form of plagiarism, submission of duplicate solutions, or unauthorized use of third-party intellectual property will result in immediate disqualification. Participants are responsible for ensuring that their work complies with all applicable intellectual property laws and licenses. No Legal Recourse: Participants acknowledge that they are participating in the hackathon at their own risk and discretion. Tailcall’s decision regarding winners, disqualifications, or any aspect of the competition will not be subject to any form of legal recourse, challenge, or litigation. Participants waive any rights to seek compensation, damages, or legal action against Tailcall or its affiliates. Tiebreaker and Scoring: In the event of a tie, Tailcall will decide the winner based on a tiebreaker determined by the timestamp of the last valid commit. Tailcall also reserves the right to alter or adjust scoring criteria to ensure fairness and integrity. These changes will be communicated, but participants agree that such changes will not be a basis for challenge. Modification of Rules: Tailcall reserves the right to modify or amend the rules, guidelines, or requirements of the hackathon at any time to ensure a fair and transparent competition. Any changes will be announced promptly, and participants are expected to comply with updated rules. Failure to adhere to the modified rules may result in disqualification. Collaboration and Multiple Entries: While collaboration is allowed, only one individual from a team may submit the final entry. Tailcall will not accept any disputes arising from team collaborations. Any identical or highly similar solutions submitted by different participants will be investigated, and Tailcall reserves the right to disqualify participants if plagiarism or collusion is suspected. Use of Submissions: By submitting your entry, you grant Tailcall the right to use, display, and promote your submission for purposes related to the hackathon or future events, including marketing or showcasing your work. However, all intellectual property rights to the original code remain with the participants, unless explicitly stated otherwise. ","version":"Next","tagName":"h2"},{"title":"Comprehensive Guide to GraphQL Introspection","type":0,"sectionRef":"#","url":"/graphql/graphql-introspection/","content":"","keywords":"","version":"Next"},{"title":"Introduction to GraphQL Introspection​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#introduction-to-graphql-introspection","content":" GraphQL introspection is a powerful feature that allows developers to query details about the GraphQL schema itself. This capability is essential for understanding the structure and capabilities of an API, enabling dynamic querying, generating documentation, and creating development tools. In this article, we delve deeply into the mechanics and benefits of GraphQL introspection, providing you with a thorough understanding of its uses and implementations.  ","version":"Next","tagName":"h2"},{"title":"Understanding GraphQL Introspection Queries​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#understanding-graphql-introspection-queries","content":" ","version":"Next","tagName":"h2"},{"title":"What Are Introspection Queries?​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#what-are-introspection-queries","content":" Introspection queries in GraphQL are specialized queries that allow clients to retrieve information about the schema, types, fields, and operations available in a GraphQL API. These queries can be used to dynamically understand what a server can do, which is particularly useful for tools like GraphiQL and Apollo Client.  ","version":"Next","tagName":"h3"},{"title":"Basic Introspection Query Example​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#basic-introspection-query-example","content":" Here is an example of a simple introspection query that retrieves the schema's types:  { __schema { types { name kind description } } }   ","version":"Next","tagName":"h3"},{"title":"Advanced Introspection Queries​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#advanced-introspection-queries","content":" For more detailed insights, advanced introspection queries can be used to fetch information about specific types, fields, and their arguments. An example is querying the fields of a particular type:  { __type(name: &quot;Query&quot;) { name fields { name description args { name type { name kind } defaultValue } type { name kind } } } }   ","version":"Next","tagName":"h3"},{"title":"Benefits of GraphQL Introspection​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#benefits-of-graphql-introspection","content":" ","version":"Next","tagName":"h2"},{"title":"Enhancing Developer Experience​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#enhancing-developer-experience","content":" GraphQL introspection greatly enhances the developer experience by providing a clear and comprehensive view of the API capabilities. This transparency reduces the learning curve and allows for more efficient development and debugging processes.  ","version":"Next","tagName":"h3"},{"title":"Dynamic Documentation Generation​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#dynamic-documentation-generation","content":" With introspection, tools can automatically generate up-to-date documentation. This dynamic documentation ensures that developers always have access to the latest API information without manual updates.  ","version":"Next","tagName":"h3"},{"title":"Enabling Smart Clients​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#enabling-smart-clients","content":" Introspection allows the creation of smart clients that can adapt to schema changes. This adaptability ensures that clients can continue to function correctly even when the server's schema evolves.  ","version":"Next","tagName":"h3"},{"title":"Implementing Introspection in GraphQL​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#implementing-introspection-in-graphql","content":" ","version":"Next","tagName":"h2"},{"title":"Enabling Introspection in Your GraphQL Server​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#enabling-introspection-in-your-graphql-server","content":" Most GraphQL servers have introspection enabled by default. However, it is crucial to ensure that this feature is properly configured and secured, especially in production environments. Here is an example of enabling introspection in Tailcall GraphQL server configuration:  schema @server(introspection: true) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"Security Considerations​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#security-considerations","content":" While introspection is incredibly useful, it can also expose potentially sensitive information about your schema. It is advisable to disable introspection in production environments or to secure it through proper authentication and authorization mechanisms.  ","version":"Next","tagName":"h3"},{"title":"GraphQL Introspection and Tooling​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#graphql-introspection-and-tooling","content":" ","version":"Next","tagName":"h2"},{"title":"GraphiQL and Introspection​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#graphiql-and-introspection","content":" GraphiQL, an in-browser IDE for exploring GraphQL, heavily relies on introspection queries to provide a rich interface for querying and visualizing data. By utilizing introspection, GraphiQL can offer autocompletion, error highlighting, and real-time query feedback.  ","version":"Next","tagName":"h3"},{"title":"Apollo Client and Schema Awareness​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#apollo-client-and-schema-awareness","content":" Apollo Client leverages introspection to manage local state and remote data seamlessly. By understanding the schema, Apollo Client can perform efficient queries and handle schema changes gracefully.  ","version":"Next","tagName":"h3"},{"title":"GraphQL Introspection Workflow​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#graphql-introspection-workflow","content":"   ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Comprehensive Guide to GraphQL Introspection","url":"/graphql/graphql-introspection/#conclusion","content":" GraphQL introspection is a cornerstone feature that significantly improves the development lifecycle by providing real-time insights into API schemas. It empowers developers with dynamic documentation, enhances development tools, and enables adaptive client applications. By leveraging introspection effectively, you can ensure a robust and flexible GraphQL implementation. ","version":"Next","tagName":"h2"},{"title":"GraphQL Mutations: Techniques and Best Practices","type":0,"sectionRef":"#","url":"/graphql/graphql-mutations/","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#introduction","content":" GraphQL has revolutionized the way we interact with APIs by offering a flexible and efficient approach to querying and manipulating data. Among its powerful features, mutations stand out as the key mechanism for creating, updating, and deleting data. In this article, we delve into the intricacies of GraphQL mutations, providing a detailed guide to mastering this essential component.  ","version":"Next","tagName":"h2"},{"title":"Understanding GraphQL Mutations​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#understanding-graphql-mutations","content":" ","version":"Next","tagName":"h2"},{"title":"What are GraphQL Mutations?​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#what-are-graphql-mutations","content":" GraphQL mutations are the counterpart to queries, designed specifically for writing data rather than reading it. While queries fetch data, mutations allow you to modify server-side data. Think of queries as a way to ask questions and get answers, while mutations are more like giving commands to change things.  ","version":"Next","tagName":"h3"},{"title":"Why Use Mutations?​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#why-use-mutations","content":" Mutations are essential because they enable dynamic interactions with your data. Instead of just looking at information, you can add new entries, update existing ones, or even remove data that's no longer needed. This ability to change data makes your application more interactive and responsive.  ","version":"Next","tagName":"h3"},{"title":"Mutation Structure​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#mutation-structure","content":" ","version":"Next","tagName":"h2"},{"title":"Mutation Type​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#mutation-type","content":" A GraphQL mutation typically involves several key components. First, you have the Mutation Type, which defines the action to be performed, such as creating, updating, or deleting data.  ","version":"Next","tagName":"h3"},{"title":"Input Arguments​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#input-arguments","content":" Next, you have Input Arguments, which specify the data required for the mutation. These are like the ingredients you need to perform the mutation.  ","version":"Next","tagName":"h3"},{"title":"Return Fields​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#return-fields","content":" Finally, you have Return Fields, which indicate the data returned after the mutation is executed. This is what you get back after the mutation has done its job.  Here’s a basic example of a mutation to create a new user:  mutation { createUser( input: {name: &quot;John Doe&quot;, email: &quot;john.doe@example.com&quot;} ) { id name email } }   ","version":"Next","tagName":"h3"},{"title":"Defining Mutations in the Schema​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#defining-mutations-in-the-schema","content":" To implement mutations, you must define them in your GraphQL schema. This involves specifying the mutation type and the fields it supports. Here’s an example schema definition:  type Mutation { createUser(input: CreateUserInput!): User updateUser(id: ID!, input: UpdateUserInput!): User deleteUser(id: ID!): User } input CreateUserInput { name: String! email: String! } input UpdateUserInput { name: String email: String }   ","version":"Next","tagName":"h2"},{"title":"Executing Mutations​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#executing-mutations","content":" Executing mutations in GraphQL involves sending a mutation request with the necessary input data. The response typically includes the newly modified data, confirming the mutation's success.  ","version":"Next","tagName":"h2"},{"title":"Example: Creating a User​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#example-creating-a-user","content":" Here's how you can create a new user named Jane Doe:  mutation { createUser( input: {name: &quot;Jane Doe&quot;, email: &quot;jane.doe@example.com&quot;} ) { id name email } }   The response might look like this:  { &quot;data&quot;: { &quot;createUser&quot;: { &quot;id&quot;: &quot;1&quot;, &quot;name&quot;: &quot;Jane Doe&quot;, &quot;email&quot;: &quot;jane.doe@example.com&quot; } } }   ","version":"Next","tagName":"h3"},{"title":"Handling Errors in Mutations​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#handling-errors-in-mutations","content":" Error handling is crucial for robust GraphQL APIs. Mutations should provide meaningful error messages and handle various scenarios gracefully.  ","version":"Next","tagName":"h2"},{"title":"Example: Handling Validation Errors​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#example-handling-validation-errors","content":" If you try to create a user without a name or with an invalid email, you'll get a validation error:  mutation { createUser(input: {name: &quot;&quot;, email: &quot;invalid-email&quot;}) { id name email } }   The response will be:  { &quot;errors&quot;: [ { &quot;message&quot;: &quot;Validation error: Name is required, Email is invalid&quot;, &quot;locations&quot;: [ { &quot;line&quot;: 2, &quot;column&quot;: 3 } ], &quot;path&quot;: [&quot;createUser&quot;] } ], &quot;data&quot;: { &quot;createUser&quot;: null } }   ","version":"Next","tagName":"h3"},{"title":"Advanced Mutation Techniques​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#advanced-mutation-techniques","content":" ","version":"Next","tagName":"h2"},{"title":"Nested Mutations​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#nested-mutations","content":" Nested mutations allow you to perform multiple related operations in a single mutation. This can be particularly useful for complex data relationships. For example, you can create a user and their associated posts in one go:  mutation { createUser( input: { name: &quot;Alice&quot; email: &quot;alice@example.com&quot; posts: [{title: &quot;First Post&quot;}, {title: &quot;Second Post&quot;}] } ) { id name email posts { id title } } }   caution Performing Nested Mutations is possible but caution is advised as by default, GraphQL mutations are not transactional. This means that if one part of the mutation fails, the other parts will still be executed. You may need to implement custom logic to handle this.  ","version":"Next","tagName":"h3"},{"title":"Optimizing Mutations for Performance​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#optimizing-mutations-for-performance","content":" Efficiently designed mutations are essential for maintaining performance and scalability in your GraphQL API. Consider the following techniques:  ","version":"Next","tagName":"h2"},{"title":"Optimistic UI Updates​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#optimistic-ui-updates","content":" Enhance user experience by updating the UI optimistically before the mutation response is received. This makes the app feel faster and more responsive.  ","version":"Next","tagName":"h3"},{"title":"Input Validation​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#input-validation","content":" Perform thorough validation on the client-side to minimize server-side processing. This helps ensure that only valid data reaches your server, reducing the risk of errors and improving performance.  ","version":"Next","tagName":"h3"},{"title":"Example Diagram: Mutation Lifecycle​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#example-diagram-mutation-lifecycle","content":" Here’s a simple diagram to illustrate the lifecycle of a mutation:    ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#conclusion","content":" Mastering GraphQL mutations is fundamental for any developer working with GraphQL APIs. By understanding their structure, implementing them effectively, and optimizing for performance, you can leverage the full potential of GraphQL for dynamic and efficient data manipulation.    ","version":"Next","tagName":"h2"},{"title":"FAQs​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#faqs","content":" ","version":"Next","tagName":"h2"},{"title":"What is a GraphQL mutation?​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#what-is-a-graphql-mutation","content":" A GraphQL mutation is an operation that allows clients to modify server-side data, including creating, updating, and deleting records.  ","version":"Next","tagName":"h3"},{"title":"How do I handle errors in GraphQL mutations?​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#how-do-i-handle-errors-in-graphql-mutations","content":" GraphQL responses include both data and errors. Clients can handle partial successes by checking the presence of errors in the response and taking appropriate actions.  ","version":"Next","tagName":"h3"},{"title":"What is the difference between queries and mutations in GraphQL?​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#what-is-the-difference-between-queries-and-mutations-in-graphql","content":" Queries are used to fetch data, while mutations are used to modify data. Queries are typically idempotent, while mutations change the state of the server.  ","version":"Next","tagName":"h3"},{"title":"How do I secure GraphQL mutations?​","type":1,"pageTitle":"GraphQL Mutations: Techniques and Best Practices","url":"/graphql/graphql-mutations/#how-do-i-secure-graphql-mutations","content":" Secure GraphQL mutations by implementing authentication to verify user identity and authorization to ensure users have the correct permissions to perform the mutation. ","version":"Next","tagName":"h3"},{"title":"Mastering GraphQL Queries: Comprehensive Guide","type":0,"sectionRef":"#","url":"/graphql/graphql-queries/","content":"","keywords":"","version":"Next"},{"title":"Introduction to GraphQL Queries​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#introduction-to-graphql-queries","content":" In GraphQL, queries are the primary method to fetch data from a server. A GraphQL query allows you to specify exactly what data you need, making data retrieval both precise and efficient.  ","version":"Next","tagName":"h2"},{"title":"What is a GraphQL Query?​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#what-is-a-graphql-query","content":" A GraphQL query is a read operation that allows clients to specify precisely which data they need from the server. Unlike traditional REST APIs, where endpoints define the structure of responses, GraphQL queries let clients dictate the shape and size of the response. This flexibility reduces over-fetching and under-fetching of data, optimizing both server and client performance.  ","version":"Next","tagName":"h2"},{"title":"Basic Structure of a GraphQL Query​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#basic-structure-of-a-graphql-query","content":" GraphQL queries are written in a declarative syntax, resembling the structure of the requested data. Here is an example of a simple query to fetch user information:  { user(id: &quot;1&quot;) { id name email } }   ","version":"Next","tagName":"h2"},{"title":"Components of a Query​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#components-of-a-query","content":" Field: The basic unit of a query. In the example, id, name, and email are fields.Arguments: Parameters passed to fields to specify or filter data. id: &quot;1&quot; is an argument to the user field.Aliases: Alternative names for fields to avoid conflicts and improve readability.  ","version":"Next","tagName":"h3"},{"title":"Advanced Query Features​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#advanced-query-features","content":" ","version":"Next","tagName":"h2"},{"title":"Nested Queries​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#nested-queries","content":" GraphQL queries support nesting, allowing clients to request related data in a single query. This feature is particularly useful for fetching hierarchical data structures.  { user(id: &quot;1&quot;) { id name posts { title content } } }   ","version":"Next","tagName":"h3"},{"title":"Fragments​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#fragments","content":" Fragments allow the reuse of common field selections across multiple queries, mutations, or subscriptions. They help in maintaining a DRY (Don't Repeat Yourself) approach in GraphQL queries. We will cover fragments in detail in the GraphQL Fragments section.  fragment userFields on User { id name email } { user(id: &quot;1&quot;) { ...userFields } }   ","version":"Next","tagName":"h3"},{"title":"Variables​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#variables","content":" Variables enable dynamic queries, where the arguments can be passed externally, making the queries more flexible and reusable.  query getUser($userId: ID!) { user(id: $userId) { id name email } }   { &quot;userId&quot;: &quot;1&quot; }   ","version":"Next","tagName":"h3"},{"title":"Directives​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#directives","content":" Directives are used to modify the behavior of queries at runtime. Common directives include @include and @skip for conditional field inclusion.  { user(id: &quot;1&quot;) { id name email @include(if: $includeEmail) } }   ","version":"Next","tagName":"h3"},{"title":"Error Handling in Queries​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#error-handling-in-queries","content":" GraphQL provides a standardized way to handle errors. The response includes both data and errors, allowing clients to handle partial success scenarios gracefully.  { &quot;data&quot;: { &quot;user&quot;: null }, &quot;errors&quot;: [ { &quot;message&quot;: &quot;User not found&quot;, &quot;locations&quot;: [ { &quot;line&quot;: 2, &quot;column&quot;: 3 } ], &quot;path&quot;: [&quot;user&quot;] } ] }   ","version":"Next","tagName":"h2"},{"title":"Best Practices for Writing GraphQL Queries​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#best-practices-for-writing-graphql-queries","content":" Fetch Only Necessary Data: Always request the minimum required fields to reduce the payload and improve performance.Use Aliases and Fragments: To avoid naming conflicts and promote reuse of common field selections.Implement Pagination: For queries that return large lists, use pagination techniques like first, last, before, and after.Handle Errors Gracefully: Ensure your client can handle partial successes and provide useful feedback to users.  ","version":"Next","tagName":"h2"},{"title":"Example Diagram: GraphQL Query Structure​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#example-diagram-graphql-query-structure","content":"   ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#conclusion","content":" You now have the skills to write simple and nested GraphQL queries, pass arguments, use variables for dynamic queries, paginate results, and filter queries. Mastering these concepts will enable you to fetch data efficiently and effectively using GraphQL.    ","version":"Next","tagName":"h2"},{"title":"Frequently Asked Questions (FAQs)​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#frequently-asked-questions-faqs","content":" ","version":"Next","tagName":"h2"},{"title":"How do I handle errors in GraphQL queries?​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#how-do-i-handle-errors-in-graphql-queries","content":" GraphQL responses include both data and errors. Clients can handle partial successes by checking the presence of errors in the response and taking appropriate actions.  ","version":"Next","tagName":"h3"},{"title":"What are GraphQL fragments?​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#what-are-graphql-fragments","content":" Fragments are reusable units of query logic that help maintain a DRY approach in your GraphQL queries. They allow you to define common field selections and use them across multiple queries, mutations, or subscriptions.  ","version":"Next","tagName":"h3"},{"title":"Can I use GraphQL with existing REST APIs?​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#can-i-use-graphql-with-existing-rest-apis","content":" Yes, you can use GraphQL as a layer on top of existing REST APIs to provide a more flexible and efficient way to query your data. For quickly creating a GraphQL server that converts REST APIs to GraphQL, check out Getting Started with Tailcall.  ","version":"Next","tagName":"h3"},{"title":"What are GraphQL directives?​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#what-are-graphql-directives","content":" Directives are used to modify the behavior of queries at runtime. Common directives like @include and @skip allow you to conditionally include or exclude fields from the query based on dynamic conditions.  ","version":"Next","tagName":"h3"},{"title":"How does GraphQL handle nested queries?​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#how-does-graphql-handle-nested-queries","content":" GraphQL allows you to fetch related data in a single request using nested queries. This is particularly useful for hierarchical data structures where you need to retrieve parent and child data together.  ","version":"Next","tagName":"h3"},{"title":"What is GraphiQL?​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#what-is-graphiql","content":" GraphiQL is an open-source in-browser IDE for exploring GraphQL APIs. You can use GraphiQL to interact with GraphQL servers and visualize query results.  ","version":"Next","tagName":"h3"},{"title":"What is the benefit of using aliases in GraphQL?​","type":1,"pageTitle":"Mastering GraphQL Queries: Comprehensive Guide","url":"/graphql/graphql-queries/#what-is-the-benefit-of-using-aliases-in-graphql","content":" Aliases allow you to rename fields in the response, avoiding conflicts and improving readability. This is useful when querying the same field multiple times with different arguments. ","version":"Next","tagName":"h3"},{"title":"Using GraphQL Variables for Type-Safe Queries","type":0,"sectionRef":"#","url":"/graphql/graphql-variables/","content":"","keywords":"","version":"Next"},{"title":"What Are GraphQL Variables?​","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#what-are-graphql-variables","content":" GraphQL variables are similar to variables in any other programming language. They store values that you can access using their names. These variables are used to pass data from your application to your GraphQL queries and mutations. For instance, take a look at this example where a GraphQL query uses a variable to fetch data:  query GetUserByName($name: String!) { user(name: $name) { name email age } }   In this query, the $name variable in the query helps find a user by its name. You can easily spot GraphQL variables because they always start with a dollar sign ($). Here’s how a response might look:  { &quot;data&quot;: { &quot;user&quot;: { &quot;name&quot;: &quot;John&quot;, &quot;email&quot;: &quot;john@example.com&quot;, &quot;age&quot;: 10 } } }   ","version":"Next","tagName":"h2"},{"title":"Defining and Using Variables in GraphQL Queries​","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#defining-and-using-variables-in-graphql-queries","content":" GraphQL variables are defined separately from the query string itself. When you run the query, these variables are inserted into it, and the API responds with matching results. Here’s how you define a query and its variables in a JSON object for HTTP requests:  { &quot;query&quot;: &quot;query GetUserByName($name: String!) { user(name: $name) { name email age } }&quot;, &quot;variables&quot;: { &quot;name&quot;: &quot;John&quot; } }   Separating the query from the variables makes it easy to write reusable queries. When making requests, you send the query and variables as separate objects.  ","version":"Next","tagName":"h2"},{"title":"Default Values for GraphQL Variables​","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#default-values-for-graphql-variables","content":" You can set default values for variables, which allows queries to run even without input. Here’s how you do it:  query GetUserByName($name: String = &quot;Jack&quot;) { user(name: $name) { name email age } }   In this example, if no value is provided for $name, the query uses &quot;Jack&quot; as the default.  ","version":"Next","tagName":"h2"},{"title":"Using Variables in GraphQL Mutations​","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#using-variables-in-graphql-mutations","content":" GraphQL mutations can create, update, or delete data on the server. Variables work the same way in mutations as they do in queries.  ","version":"Next","tagName":"h2"},{"title":"Example:​","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#example","content":" mutation UpdateUserName($id: ID!, $new_name: String!) { updateUserName(id: $id, name: $new_name) { id name email age } }   ","version":"Next","tagName":"h3"},{"title":"Passing Variables:​","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#passing-variables","content":" { &quot;id&quot;: &quot;1&quot;, &quot;new_name&quot;: &quot;Johnny&quot; }   ","version":"Next","tagName":"h3"},{"title":"Using JavaScript to Make a GraphQL Request:​","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#using-javascript-to-make-a-graphql-request","content":" const query = ` query GetUserByName($name: String!) { user(name: $name) { name email age } } ` const variables = {name: &quot;John&quot;} fetch(&quot;https://YOUR_GRAPHQL_SERVER_URL&quot;, { method: &quot;POST&quot;, headers: { &quot;Content-Type&quot;: &quot;application/json&quot;, }, body: JSON.stringify({query, variables}), }) .then((response) =&gt; response.json()) .then((data) =&gt; console.log(data))   Replace YOUR_GRAPHQL_SERVER_URL with your GraphQL Server url.  ","version":"Next","tagName":"h3"},{"title":"GraphQL Variable Types and Type Safety​","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#graphql-variable-types-and-type-safety","content":" GraphQL variables come with types to ensure type safety. For example, String! indicates that the variable must be a string GraphQL type and is required. If you pass a different type, an error occurs, and the query won’t run. This type safety prevents unexpected inputs and results, ensuring your application runs smoothly.  GraphQL has several built-in types: String, Int, Float, Boolean, and ID. These types form the foundation for input object types. You can also define custom input types to model your data.  ","version":"Next","tagName":"h2"},{"title":"Building Apps with GraphQL​","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#building-apps-with-graphql","content":" Tailcall’s CLI tool can generate GraphQL configurations from various sources, such as protobuf files and REST endpoints. This tool simplifies the process of creating GraphQL configurations, enabling you to build powerful applications with ease. To know more about the gen command in the Tailcall CLI, check out the documentation.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Using GraphQL Variables for Type-Safe Queries","url":"/graphql/graphql-variables/#conclusion","content":" GraphQL variables and type safety ensure consistent data across your applications. By leveraging these features, you can build flexible, reliable, and scalable applications. Tailcall’s CLI tool simplifies the process of generating GraphQL configurations, enabling you to create powerful applications with ease. To learn more about building apps with GraphQL, explore the TailCall documentation. ","version":"Next","tagName":"h2"},{"title":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","type":0,"sectionRef":"#","url":"/graphql/graphql-vs-rest-api-comparison/","content":"","keywords":"","version":"Next"},{"title":"What is REST?​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#what-is-rest","content":" REST (Representational State Transfer) is an architectural style for designing networked applications. It uses HTTP requests to perform CRUD (Create, Read, Update, Delete) operations. Each resource in a RESTful system is identified by a unique URI and can be manipulated using standard HTTP methods: GET, POST, PUT, DELETE. It is designed to utilize the stateless operations of the HTTP protocol for web communications. REST has been widely adopted due to its simplicity and effectiveness in designing scalable web services. Detailed Example: Consider a typical social media platform:  GET /users // Retrieves a list of users POST /users // Creates a new user GET /users/123 // Retrieves details about user 123 GET /users/123/posts // Retrieves posts by user 123 GET /users/123/followers // Retrieves followers of user 123 GET /posts // Retrieves posts POST /posts // Creates a post GET /posts/123/comments // Retrieves comments for post 123   REST API Design  Each endpoint is designed to handle a specific type of resource and HTTP method (GET, POST, PUT, DELETE). This design allows clients to interact with the server in a predictable manner.  ","version":"Next","tagName":"h2"},{"title":"Key Characteristics of REST:​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#key-characteristics-of-rest","content":" Stateless Operations: Each API request from a client to server must contain all the information needed to understand and process the request. The server side should not store any client context between requests, which is beneficial for scalability and reliability.Cacheable: Responses must explicitly define themselves as cacheable or non cacheable. If a response is defined as cacheable, the client can reuse the response for similar requests in future. Server also defines when to invalidate the cached response for a particular request to prevent clients from reusing stale or inappropriate data. A good caching practice can significantly reduce the number of requests to the server.Layered System: A client cannot ordinarily tell whether it is connected directly to the end server or an intermediary along the way. A REST API can consist of multiple layers of servers, each with its own specific functionality. For example, an E-Commerce application might have a server for authentication, another for product information, and a third for payment processing. A client can interact with a layer without knowing the details of other layers.  ","version":"Next","tagName":"h3"},{"title":"Advantages of REST​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#advantages-of-rest","content":" Simplicity and Maturity: REST has been widely used and is supported by most platforms and programming languages (Frontend and Backend), making it a mature choice for building APIs. Its principles are well-understood, and there is a wealth of documentation and tooling available.Scalability: Due to its stateless nature and ability to handle requests independently, REST can scale effectively. Each request is treated as an independent transaction, allowing for easy distribution across multiple servers.Caching: REST can efficiently leverage web infrastructure for caching requests, reducing the load on the backend and improving performance. HTTP caching mechanisms, such as ETags and cache-control headers, can be used to cache responses and minimize redundant data transfers.  ","version":"Next","tagName":"h3"},{"title":"What is GraphQL?​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#what-is-graphql","content":" GraphQL is a query language for APIs and a runtime for executing those queries. It allows clients to request exactly the data they need, avoiding over-fetching and under-fetching issues common with REST. Developed by Facebook in 2012 and open-sourced in 2015, GraphQL provides a more flexible and efficient approach to API design.  ","version":"Next","tagName":"h2"},{"title":"Key Characteristics of GraphQL:​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#key-characteristics-of-graphql","content":" Strongly Typed: GraphQL APIs are defined by a schema using the GraphQL Schema Definition Language (SDL).Single Endpoint: GraphQL APIs have a single endpoint, making it simpler to manage than multiple REST endpoints. This single endpoint can handle a wide variety of queries and mutations, streamlining the client-server interaction.Declarative Data Fetching: Clients can specify exactly what data they need, even to the level of specifying individual fields in a single query. This allows for highly efficient data fetching and reduces the likelihood of over-fetching or under-fetching. Example Query:  { user(id: &quot;1&quot;) { name email posts { title comments { content author { name } } } } }   In this example, the client requests specific fields (name, email, posts, comments) in a single query, avoiding unnecessary data transfers.  GraphQL Efficiency: This image shows how clients specify data needs, ensuring the server response matches the query structure precisely.  ","version":"Next","tagName":"h3"},{"title":"Advantages of GraphQL​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#advantages-of-graphql","content":" Efficient Data Loading: Reduces over-fetching and under-fetching, leading to more efficient data transfers. Clients can request exactly the data they need, minimizing network traffic and improving performance.Strongly Typed: Every GraphQL service defines a set of types which completely describe the set of possible data you can query on that service. This strong typing helps prevent errors and improves the development experience.Rapid Development: GraphQL's declarative nature and strong type system make it easier to develop and maintain APIs. The self-documenting nature of GraphQL schemas also aids in understanding the API structure.  ","version":"Next","tagName":"h2"},{"title":"Limitations of GraphQL​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#limitations-of-graphql","content":" Complexity in Client: The flexibility of GraphQL requires clients to handle more complexity in data handling and state management. Clients must be capable of constructing complex queries and managing the resulting data structures.Caching: Unlike REST, which can leverage HTTP caching mechanisms, caching a GraphQL API can be more involved because each query can be unique. This requires more sophisticated caching strategies, such as field-level caching or custom cache management solutions.  ","version":"Next","tagName":"h2"},{"title":"Similarities Between GraphQL and REST​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#similarities-between-graphql-and-rest","content":" Both GraphQL and REST facilitate data exchange between client and server in a client-server model, using HTTP as the underlying communication protocol. Here are some similarities:  Resource-Based Design: Both treat data as resources with unique identifiers. In REST, these are represented by URIs, while in GraphQL, they are defined in the schema and identified by the entities.Stateless: Both are stateless architectures, where each request is independent.Support for JSON: Both can use JSON for data format, although REST can also support XML and other formats.  ","version":"Next","tagName":"h2"},{"title":"Key Differences Between GraphQL and REST​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#key-differences-between-graphql-and-rest","content":" ","version":"Next","tagName":"h2"},{"title":"Data Fetching​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#data-fetching","content":" REST: Multiple endpoints can lead to inefficiencies when fetching related data across several resources. For example, fetching a user and their posts might require multiple requests. GraphQL: A single query can retrieve all related data, significantly reducing the need for multiple network requests. This leads to more efficient data fetching and improved performance.  Example: In REST, to fetch a user and their posts, you might need:  GET /users/123 GET /users/123/posts   In GraphQL, you can fetch the same data with a single query:  { user(id: &quot;123&quot;) { name email posts { title } } }   ","version":"Next","tagName":"h3"},{"title":"Performance and Flexibility​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#performance-and-flexibility","content":" REST: While REST APIs are generally easy to cache and scale, they can suffer from latency issues in complex systems due to multiple round trips. Each endpoint is designed to serve a specific resource, which can lead to inefficient data fetching.GraphQL: By reducing the number of requests and allowing for precise data retrieval, GraphQL can offer performance benefits, especially in systems with complex data relationships. It enables clients to specify their exact data needs, reducing the likelihood of redundant data transfers. Code Snippet Example (GraphQL):  { user(id: &quot;1&quot;) { name email posts { title comments { content author { name } } } } }   ","version":"Next","tagName":"h3"},{"title":"Error Handling​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#error-handling","content":" REST: Error handling needs to be implemented by developers. Responses typically include http status codes and error messages, but the structure can vary across different APIs.GraphQL: Inbuilt error handling and detailed error messages due to its strong type system. Errors are returned alongside the data, making it easier for clients to understand and handle exceptions.  ","version":"Next","tagName":"h3"},{"title":"Versioning​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#versioning","content":" REST: Often uses versioned endpoints to handle changes, which can be cumbersome.GraphQL: No need for versioning; deprecated fields are marked and can be handled gracefully.  ","version":"Next","tagName":"h3"},{"title":"When to Use GraphQL vs. REST​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#when-to-use-graphql-vs-rest","content":" ","version":"Next","tagName":"h2"},{"title":"Use GraphQL if:​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#use-graphql-if","content":" You need to reduce the number of API calls without creating new REST APIs for different data compositions.You have various frontend clients with different data requirements.Your application has a rich user interface that changes frequently.You want to expose your API to third-party developers for building external applications.  ","version":"Next","tagName":"h3"},{"title":"Use REST if:​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#use-rest-if","content":" You are building simple APIs with well-defined endpoints.Your application has low complexity and data interrelations.You prefer the simplicity and familiarity of REST.  ","version":"Next","tagName":"h3"},{"title":"Summary of Differences: REST vs GraphQL​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#summary-of-differences-rest-vs-graphql","content":" Aspect\tREST\tGraphQLEndpoint Structure\tMultiple endpoints for different resources\tSingle endpoint for all operations Data Fetching\tFixed data structure, may lead to overfetching or underfetching\tClients specify exact data needed, avoiding overfetching Performance\tPotentially slower for complex queries due to multiple requests\tMore efficient for complex queries, reduces multiple requests Flexibility\tLess flexible, relies on predefined endpoints\tHigh flexibility in querying data Data Types\tWeakly typed, depends on documentation for consistency\tStrongly typed schema, ensures consistency Real-Time Data\tRequires additional mechanisms for real-time updates\tSupports subscriptions for real-time updates Caching\tLeverages HTTP caching mechanisms (e.g., ETags, cache-control headers)\tMore complex, requires custom caching strategies Versioning\tOften requires versioned endpoints to manage changes\tNo versioning needed, handles changes through schema updates Error Handling\tRequires custom error handling in the API implementation\tBuilt-in error handling with detailed messages Development Speed\tSlower for complex queries, requires managing multiple endpoints\tFaster development for complex queries and rapid iterations Learning Curve\tEasier to learn and implement, well-documented and supported\tSteeper learning curve due to its flexibility and complexity Tooling and Ecosystem\tMature ecosystem with extensive tooling and documentation\tGrowing ecosystem with strong community support Use Cases\tBest for simple, well-defined data structures and public APIs\tIdeal for complex, interrelated data, and real-time applications Scalability\tInherently scalable due to statelessness and simplicity\tRequires careful management of queries and resolvers  ","version":"Next","tagName":"h2"},{"title":"GraphQL complements REST​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#graphql-complements-rest","content":" While GraphQL offers an excellent developer experience for frontend developers, it should primarily be used for composing data from multiple sources. REST/RPC APIs remain the best choice for implementing your business logic. Additionally, you should not hand-write your GraphQL layer. Instead, you can use Tailcall to automatically convert your REST APIs to GraphQL.  If you want to know why we think this way, you can read more about it in the article Writing a GraphQL Backend by Hand is Long Gone.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Is GraphQL Better Than REST? GraphQL vs REST Comparison","url":"/graphql/graphql-vs-rest-api-comparison/#conclusion","content":" REST is ideal for simple data sources with well-defined resources, using multiple endpoints in the form of URLs. GraphQL excels in handling large, complex, and interrelated data sources with a single URL endpoint, providing flexibility and efficiency.  Choosing between GraphQL and REST depends on the specific needs of your application. While REST offers simplicity and scalability, GraphQL provides unparalleled flexibility and efficiency for complex and dynamic data needs. For many applications, using a hybrid approach that leverages the strengths of both technologies might be the most effective strategy.  Understanding the differences between GraphQL and REST, along with their appropriate use cases, allows you to make informed decisions that optimize both the development process and the end-user experience. By considering the structure of your data, the nature of your client applications, and the specific requirements of your use cases, you can select the API design that best fits your needs.  Explore both GraphQL and REST by implementing them in small projects or integrating them into different parts of a larger system. Experience firsthand how each handles real-world data scenarios to better understand their operational benefits and limitations. This hands-on approach will provide deeper insights into their practical applications and help you make more informed decisions about which technology to adopt for various aspects of your projects.  For quickly creating a GraphQL server that converts REST APIs to GraphQL, check out Getting Started with Tailcall.  By immersing yourself in both the theory and practice of GraphQL and REST, you can develop a robust understanding of how to effectively design and implement APIs that meet the evolving demands of modern applications. ","version":"Next","tagName":"h2"},{"title":"Problem Statement","type":0,"sectionRef":"#","url":"/graphql/problem-statement/","content":"","keywords":"","version":"Next"},{"title":"Problem Space​","type":1,"pageTitle":"Problem Statement","url":"/graphql/problem-statement/#problem-space","content":" Two of the major paradigm shifts happening in the technology industry over the past few years are:  Complex User Interfaces: Responsive websites that worked on desktop and mobile are dead. To build a successful B2C business, you need to build for all three platforms viz. Android, iOS, and Web (Desktop/PWA). The applications need to look slick, rich in information, and have snappy response times.Microservice Proliferation: Many companies these days bootstrap themselves on microservices instead of monoliths. This is because the tooling has gotten a lot better, and reusable components are available either in open-source or as a fully managed SAAS solution. This allows developers to focus on their core business logic and move fast.  ","version":"Next","tagName":"h2"},{"title":"Microservice Architecture​","type":1,"pageTitle":"Problem Statement","url":"/graphql/problem-statement/#microservice-architecture","content":" This is what a typical microservices architecture looks like today:  The clients (Mobile/Web) make requests to the microservices through an API gateway. An API gateway is a server that acts as a single point of entry for any type of request, responsible for routing requests to the appropriate backend service and forwarding the response to the client. An API gateway can also perform common tasks such as authentication, rate limiting, and caching, making it a useful component in a microservices architecture: each service exposes an API to the gateway, and the gateway acts as the &quot;front desk&quot; for clients to access the services.  ","version":"Next","tagName":"h2"},{"title":"API Orchestration​","type":1,"pageTitle":"Problem Statement","url":"/graphql/problem-statement/#api-orchestration","content":" API orchestration refers to the process of combining one or more APIs to create a new API. This can be done by creating a new API that either acts as a facade for the underlying APIs, or splits up incoming requests, delegates to the underlying APIs, and combines the results back together. Consider a scenario where a social media client application wants to display a timeline of posts with the author's profile information next to each one. In this case, the client can send two separate requests to two different APIs and combine them as follows: First to /posts to retrieve recent posts, with the following response:  type Post { id: ID! title: String! body: String! userId: ID! # Reference to the user by its id. }   Second, with the userId from the above post response, make a request to /users to retrieve the user's profile information, with the following response:  type User { id: ID! name: String! email: String! }   The client can then combine the results from these two APIs to create a single response that contains all the required information. This new response can be considered as the output of the composed API.  type Post { id: ID! title: String! body: String! user: User # Reference to the complete user object }   Orchestration is not limited to stitching APIs, here are some other use cases where having an API Orchestrator is of significant value:  Access Control: Instead of building an “admin” API and a “customer” API, you could create a set of basic CRUD endpoints and build access control on top of the orchestrator. Localization: Adding support for language translations can be moved to an orchestration layer instead of embedding into the application layer. Batching: An orchestrator can intelligently leverage batch APIs automatically without the consumer making any change, thus drastically reducing load. Obfuscation: An orchestrator can precisely control which field needs to be obfuscated, how, and when. Protocol Translation: An orchestrator can very efficiently convert between protocols. Validations: An orchestrator could filter out invalid requests up front, reducing unnecessary work on the underlying services. Type Safe SDK: Orchestration engines can generate type safe client SDKs to consume APIs. Discoverability: Orchestrators can provide detailed &amp; up-to-date documentation of the APIs that are exposed. Collaboration: Allows consumers and producers of APIs to move at different speeds via &quot;mocking&quot;. Optimize APIs based on usage patterns. Breaking Changes: Identify breaking changes, performance degradations and other potential issues even before deployment. Business Logic: Logic controlling the flow of requests based on business conditions is best suited to execution within the gateway or orchestration layer. Distributed Management: Instead of giving control of all APIs to one team, each team can manage their part of the API and seamlessly compose with the existing API network.  important API Orchestration is distinct from Microservice Orchestration, the latter relates to managing multiple micro-services working together to perform a larger task or workflow.  ","version":"Next","tagName":"h2"},{"title":"Composition on Clients​","type":1,"pageTitle":"Problem Statement","url":"/graphql/problem-statement/#composition-on-clients","content":" Composition on the client side remains unstandardized. Common problems include over-fetching and under-fetching. Over-fetching is where the server responds to a client request with more data than is required to render the screen. Under fetching is where the client needs to make multiple, often chained, API requests to get relevant data for a particular screen because the server couldn't provide all the required data in a single request. These two problems in conjunction with modest hardware and an unreliable network connection can make the overall solution unreliable, slow, and frustrating.  tip When composing on the client side, modest hardware and unfavorable network conditions often result in poor user-experience.  Increased Complexity:To build a rich user interface, API composition is necessary. One of the main challenges with API composition on the client side is that it can lead to increased complexity in the client application: the client needs to handle sending requests to multiple APIs and combining the results, adding to the overall size and complexity of the client code. Reduced Performance:Another challenge with API composition on the client side is that it can result in reduced performance and increased latency:the client often needs to make multiple requests to different APIs, taking more time and resulting in a slower response from the composed API. Increased Risk:In addition, API composition on the client side can also lead to increased security risks:the client needs to handle sensitive information such as API keys and authentication credentials for multiple APIs. These critical security tokens can be vulnerable to attacks if not properly secured, and many clients lack access to powerful CPUs and reliable network connections.  ","version":"Next","tagName":"h2"},{"title":"Backend For Frontend (BFF)​","type":1,"pageTitle":"Problem Statement","url":"/graphql/problem-statement/#backend-for-frontend-bff","content":" A BFF layer can help to solve the challenges of API composition mentioned above by providing a separate backend service that is optimized for each specific frontend client. This can enable the BFF to perform API composition on behalf of the client, which can help to improve the performance and reliability of the composed API. The BFF layer typically sits as a separate component in the overall architecture, between the frontend client and the microservices. It can communicate with both the frontend client and the microservices using well-defined interfaces and protocols, such as REST or gRPC.  tip BFFs can dramatically improve the reliability and performance of the system, thereby having a direct positive impact on user-experience.  The BFF can take advantage of a powerful CPU and access to a fast network to improve the performance and reliability of the composed API. It can also provide added flexibility and control over the composition process. This can make it a useful tool for developers who want to create new APIs by combining the functionality of multiple underlying APIs. However, there are a few challenges with a BFF layer:  Highly Specialized:BFF layers are highly specialized solutions that require a significant amount of hand-written code. Unlike an API gateway, there is no standard BFF solution that can be deployed out-of-the-box, and each BFF implementation must be custom-tailored to the specific requirements of the frontend client. This lack of standardization and reusability can make the BFF solution more complex and difficult to maintain. Fragile:Fragile and susceptible to failure, the BFF solution is dependent on the developers to follow best practices and handle all error scenarios. If these steps are not taken, the solution can be prone to bugs and performance issues. Additionally, the BFF solution must be thoroughly tested, including performance testing, unit testing, and integration testing, to ensure that it is reliable and performs well in production. This can require significant effort and expertise, and if these steps are not properly followed, the resulting BFF solution will likely be fragile and prone to failure. Since the BFF layer is the client's sole entry point to your backend, it becoming unavailable translates into a complete service outage for the user - it is therefore essential this layer be robust and resilient to exceptions. Speculative Performance:Because BFF layers are typically custom-written for each use case, it can be difficult to predict the performance impact of a small code change. Issues such as unoptimized algorithms, inefficient caching, and unnecessary downstream requests can go unnoticed and only be discovered very late in the development cycle. Typically this means companies must perform thorough benchmarking and load testing before anything goes to production, resulting in a high time to market even for minor changes. Monolithic:This layer frequently becomes quite comprehensive, intertwining with numerous backend services. It's not unusual for it to include a significant amount of complex, manually written code that can be challenging to manage. These issues can make it more difficult for new engineers to get up to speed, and can increase the time and cost associated with updating libraries or making architectural enhancements. Even small changes might necessitate large scale deployments across your infrastructure. Canary Support (Lack thereof):Every change that happens in the backend requires the deployment of the BFF layer. Any feature that is built on the client also requires changes on the BFF layer. Such frequent changes can not be exposed to 100% of users because the reliability and performance of this system are unknown. A common way to solve this problem is to use Blue-Green deployments. This requires additional infrastructure and complex routing mechanisms. First-class support to do canary releases is very important and should be part of a modern BFF layer, however, most companies rely on DevOps for its support. Coupled Releases:Since the BFF layer acts as a bridge between clients and services it serves as the middle link in the dependency chain: the client depends on the BFF, which in turn depends on the services. When it's time to deploy new features, first you must deploy the new services (which must support the existing and new BFF), then the new BFF layer is deployed (which must support existing and new clients), and finally the client can be deployed. If, due to a bug in a microservice, you need to revert the services, then you'd also need to replace the BFF layer with one that supports the new client calls even though the services have (temporarily) lost support for these calls. This coupling makes for expensive operational management. Composability:Traditional APIs, such as REST, work well when interacting directly with a single data source. REST benefits from a mature infrastructure that handles various cross-cutting concerns, such as routing, load balancing, caching, rate limiting, authentication, and authorization. However, the semantics of these capabilities start to break down when we consider API composition. For example, imagine an API composed of two other APIs, where one is highly cacheable and the other is not well defined. The same issues arise with authorization, authentication, and rate limiting. This inherent lack of composability makes REST challenging to use in scenarios requiring API composition.  note Presentation Layer, Facade, Middleware, Frontend Layer, Orchestration Layer, API Adapter — these are all terms that are sometimes used to refer to the BFF layer ","version":"Next","tagName":"h2"},{"title":"What is GraphQL?: A Simple Introduction","type":0,"sectionRef":"#","url":"/graphql/what-is-graphql/","content":"","keywords":"","version":"Next"},{"title":"GraphQL over HTTP​","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#graphql-over-http","content":" ","version":"Next","tagName":"h2"},{"title":"Client Side​","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#client-side","content":" GraphQL is a query language for your APIs. It gives clients the capability to ask for exactly what they need without worrying about where to get it from.  Instead of making traditional GET, POST, PUT, and DELETE requests to different endpoints, GraphQL needs only one endpoint to interact, typically using the POST method. The client sends queries in the body of the POST request. The request will look something like this:The query is sent as a string inside a JSON object.  ","version":"Next","tagName":"h3"},{"title":"Server Side​","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#server-side","content":" On the server side, It is a runtime that understands these &quot;queries,&quot; fetches data from various data sources, bundles it in the shape that the client requested, and sends it back in an HTTP response.The response object is inside the data key of the JSON object.  The GraphQL server is responsible for exposing the schema, which is a strongly typed contract between the client and the server. It defines what queries clients can make, what types of data can be fetched, and what mutations can be performed.  For GraphQL, the origin of the data is irrelevant—it could come from a database, a microservice, or even a RESTful API. In essence, GraphQL is not concerned with the source of the data.  Check out the diagram below to get a better understanding of how GraphQL is used in your stack.  ","version":"Next","tagName":"h3"},{"title":"Client-Server Interaction:​","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#client-server-interaction","content":" The client sends a query to the server. Note that the query is not in JSON format, but it looks like the shape of the JSON data the client needs. So when the POST request is made, the query is sent as a string inside a JSON object.The server receives the JSON object, extracts the query string from it, parses the query to check for proper syntax, and validates it against the Schema (the contract between the client and the server).Based on the query, the server fetches the data from the data sources and bundles it in the JSON object in the shape that the client requested.  ","version":"Next","tagName":"h3"},{"title":"GraphQL Adoption​","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#graphql-adoption","content":" Due to this flexibility, the adoption of GraphQL has been increasing rapidly. There are many implementations available in various languages like JavaScript, Python, Ruby, Java, Rust, and more.  Starting off as a &quot;hobbyist&quot; stack, It has now been adopted by many big companies like Netflix, GitHub, Twitter, Pinterest, Shopify, and more.  ","version":"Next","tagName":"h2"},{"title":"Frequently Asked Questions​","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#frequently-asked-questions","content":" ","version":"Next","tagName":"h2"},{"title":"Is GraphQL frontend or backend?​","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#is-graphql-frontend-or-backend","content":" GraphQL has two parts: the client-side and the server-side. On the client side, It is a query language that allows you to ask for the data you need. On the server side, It is a runtime for executing those queries using a type system you define for your data.  ","version":"Next","tagName":"h3"},{"title":"Is GraphQL an API Gateway?​","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#is-graphql-an-api-gateway","content":" GraphQL is not an API Gateway. However, it can be used as a layer between your client and your existing APIs to provide a more flexible and efficient way to interact with your data.  ","version":"Next","tagName":"h3"},{"title":"Is GraphQL a Database?​","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#is-graphql-a-database","content":" GraphQL is not a database. It is a query language for your API and a server-side runtime for executing queries using a type system you define for your data. It can be used to query data from databases, REST/gRPC APIs, and other data sources.  ","version":"Next","tagName":"h3"},{"title":"Is GraphQL better than REST?​","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#is-graphql-better-than-rest","content":" It depends on your use case. Since there is more efficiency associated with working with GraphQL, development is much faster with it than with REST.  ","version":"Next","tagName":"h3"},{"title":"How can I convert my REST APIs to GraphQL?​","type":1,"pageTitle":"What is GraphQL?: A Simple Introduction","url":"/graphql/what-is-graphql/#how-can-i-convert-my-rest-apis-to-graphql","content":" You can use tools like Tailcall, which is the simplest way to convert your REST APIs to GraphQL APIs. You can find more details here. ","version":"Next","tagName":"h3"},{"title":"Understanding GraphQL Schemas and Types","type":0,"sectionRef":"#","url":"/graphql/schemas-and-types/","content":"","keywords":"","version":"Next"},{"title":"What is GraphQL Schema?​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#what-is-graphql-schema","content":" In GraphQL, schemas act as a bridge between the client and the owner of the data, i.e., the Data Source. A schema defines a contract between the client and the server, providing a clear understanding of the data that can be queried. Upon receiving a query, the server validates the query against the GraphQL schema, then executes it and sends back the response in the requested shape.  In simple terms, a schema is a comprehensive description of the data that clients can query. It outlines the types of objects, the relationships between them, and the operations available for querying and mutating data. It is defined using the GraphQL Schema Definition Language (SDL), a human-readable syntax that describes the capabilities of the API.  ","version":"Next","tagName":"h2"},{"title":"The Importance of Schemas in GraphQL​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#the-importance-of-schemas-in-graphql","content":" Schemas in GraphQL are vital because they:  Specify the available data types.Define relationships between different data entities.Enforce data validation rules.Provide a clear contract between the server and the client.  ","version":"Next","tagName":"h2"},{"title":"GraphQL Type System​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#graphql-type-system","content":" As discussed above, GraphQL defines various types that we can utilize to build our schema. Here are the different available types.  Scalar TypeObject TypeInput TypesEnum TypeInterface and Union TypesLists and Non-Null  ","version":"Next","tagName":"h2"},{"title":"Defining Types in GraphQL​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#defining-types-in-graphql","content":" ","version":"Next","tagName":"h2"},{"title":"Scalar Types​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#scalar-types","content":" Scalar types are primitive data types that resolve to a single value. Common scalar types in GraphQL include Int, Float, String, Boolean, and ID.  type Post { id: ID! title: String! content: String! }   ","version":"Next","tagName":"h3"},{"title":"Object Types​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#object-types","content":" Object types represent a collection of fields, each with a specific type. For example, a User object type might have fields like id, name, and email and their corresponding types.  type User { id: ID! name: String! email: String! }   ","version":"Next","tagName":"h3"},{"title":"Input Types​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#input-types","content":" Input types are used for complex mutations, allowing clients to pass structured objects as arguments.  input PostInput { title: String! content: String! authorId: ID! }   ","version":"Next","tagName":"h3"},{"title":"Enum Types​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#enum-types","content":" Enumeration types restrict a field to a set of predefined values, enhancing type safety and validation.  enum Role { ADMIN EDITOR USER }   ","version":"Next","tagName":"h3"},{"title":"Interface and Union Types​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#interface-and-union-types","content":" Interfaces and unions enable polymorphic queries by allowing fields to return different types under a common interface or union.  interface Node { id: ID! } type User implements Node { id: ID! name: String! } type Post implements Node { id: ID! title: String! }   ","version":"Next","tagName":"h3"},{"title":"Lists and Non-Null Types​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#lists-and-non-null-types","content":" In defining your schema, you will utilize object, scalar, input, and enum types. GraphQL also offers modifiers that enable quick validations within type definitions and arguments of queries and mutations. The available modifiers include:  Exclamation Mark (!) for Non-NullSquare Brackets ([]) for List  ","version":"Next","tagName":"h3"},{"title":"Relationships Between Types​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#relationships-between-types","content":" GraphQL schema can represent relationships between types using references. For instance, a User can have multiple posts, and each Post can reference its author.  type User { id: ID! name: String! posts: [Post!]! } type Post { id: ID! title: String! content: String! author: User! }   ","version":"Next","tagName":"h2"},{"title":"Schema, Query and Mutation Types​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#schema-query-and-mutation-types","content":" ","version":"Next","tagName":"h2"},{"title":"Schema Type​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#schema-type","content":" Schema type is a special Object type which is the entry point for all GraphQL operations. It defines the queries, mutations, and subscriptions available in the schema.  schema { query: Query mutation: Mutation subscription: Subscription }   ","version":"Next","tagName":"h3"},{"title":"Query Type​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#query-type","content":" The query type defines the entry point for read operations in a GraphQL schema. It specifies what data clients can fetch.  type Query { users: [User!]! user(id: ID!): User posts: [Post!]! post(id: ID!): Post }   ","version":"Next","tagName":"h3"},{"title":"Mutation Type​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#mutation-type","content":" The mutation type defines the entry point for write operations, allowing clients to modify data.  type Mutation { createUser(name: String!, email: String!): User! createPost(input: PostInput!): Post! }   ","version":"Next","tagName":"h3"},{"title":"Subscriptions in GraphQL​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#subscriptions-in-graphql","content":" Subscriptions allow clients to receive real-time updates when data changes. They are defined similarly to queries and mutations.  type Subscription { postAdded: Post! }   ","version":"Next","tagName":"h2"},{"title":"Best Practices for Designing GraphQL Schemas​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#best-practices-for-designing-graphql-schemas","content":" Use Descriptive Naming Conventions: Ensure that type and field names are intuitive and descriptive.Leverage Scalar and Enum Types: Use scalar and enum types to enforce data validation.Design for Performance: Minimize nested queries and optimize resolver functions.Modularize Schemas: Break down large schemas into smaller, reusable modules.Documentation: Annotate schemas with comments for better maintainability and clarity.  ","version":"Next","tagName":"h2"},{"title":"Example Diagram: GraphQL Schema Structure​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#example-diagram-graphql-schema-structure","content":"   ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Understanding GraphQL Schemas and Types","url":"/graphql/schemas-and-types/#conclusion","content":" A robust and well-defined GraphQL schema is essential for building scalable and efficient APIs. By understanding the core concepts and best practices for defining schemas and types, developers can create powerful and flexible GraphQL servers that meet the needs of their clients. ","version":"Next","tagName":"h2"},{"title":"GraphQL in React: 5 Best Approaches for Data Fetching.","type":0,"sectionRef":"#","url":"/graphql/graphql-react-client/","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#introduction","content":" React developers often need to fetch data from GraphQL APIs. This comprehensive guide explores five effective methods for querying GraphQL data in React applications, using the SpaceX GraphQL API to demonstrate fetching and displaying data about recent space missions. We'll cover full-featured client libraries to lightweight solutions, providing a detailed comparison table and specific use cases for each method.  ","version":"Next","tagName":"h2"},{"title":"1. Apollo Client: The Comprehensive Solution​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#1-apollo-client-the-comprehensive-solution","content":" Apollo Client is the most feature-rich GraphQL library for React, widely adopted for its robust data fetching, built-in caching, and integrated state management.  Getting started with Apollo Client​  Install dependencies: npm install @apollo/client graphql Set up the Apollo Provider and client: import { ApolloProvider, ApolloClient, InMemoryCache, } from &quot;@apollo/client&quot; const client = new ApolloClient({ uri: &quot;https://api.spacex.land/graphql/&quot;, cache: new InMemoryCache(), }) ReactDOM.render( &lt;ApolloProvider client={client}&gt; &lt;App /&gt; &lt;/ApolloProvider&gt;, rootElement, ) Use the useQuery hook to fetch data: import {useQuery, gql} from &quot;@apollo/client&quot; const LAUNCHES_QUERY = gql` { launchesPast(limit: 10) { id mission_name } } ` function SpaceXLaunches() { const {data, loading, error} = useQuery(LAUNCHES_QUERY) if (loading) return &quot;Loading...&quot; if (error) return &lt;pre&gt;{error.message}&lt;/pre&gt; return ( &lt;ul&gt; {data.launchesPast.map((launch) =&gt; ( &lt;li key={launch.id}&gt;{launch.mission_name}&lt;/li&gt; ))} &lt;/ul&gt; ) }   ","version":"Next","tagName":"h3"},{"title":"2. Urql: The Lightweight Contender​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#2-urql-the-lightweight-contender","content":" Urql provides a streamlined alternative to Apollo, with a smaller bundle size, simpler setup process, and optional caching.  To use Urql​  Install dependencies: npm install urql graphql Set up the Urql Provider and client: import {createClient, Provider} from &quot;urql&quot; const client = createClient({ url: &quot;https://api.spacex.land/graphql/&quot;, }) ReactDOM.render( &lt;Provider value={client}&gt; &lt;App /&gt; &lt;/Provider&gt;, rootElement, ) Implement data fetching with the useQuery hook: import {useQuery} from &quot;urql&quot; const LAUNCHES_QUERY = ` { launchesPast(limit: 10) { id mission_name } } ` function SpaceXLaunches() { const [result] = useQuery({query: LAUNCHES_QUERY}) const {data, fetching, error} = result if (fetching) return &quot;Loading...&quot; if (error) return &lt;pre&gt;{error.message}&lt;/pre&gt; return ( &lt;ul&gt; {data.launchesPast.map((launch) =&gt; ( &lt;li key={launch.id}&gt;{launch.mission_name}&lt;/li&gt; ))} &lt;/ul&gt; ) }   ","version":"Next","tagName":"h3"},{"title":"3. React Query + GraphQL Request: The Flexible Duo​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#3-react-query--graphql-request-the-flexible-duo","content":" This combination pairs a lightweight GraphQL client with a powerful data-fetching library.  Install dependencies: npm install react-query graphql-request Set up React Query's QueryClientProvider: import { QueryClient, QueryClientProvider, } from &quot;react-query&quot; const queryClient = new QueryClient() ReactDOM.render( &lt;QueryClientProvider client={queryClient}&gt; &lt;App /&gt; &lt;/QueryClientProvider&gt;, rootElement, ) Implement data fetching: import {request, gql} from &quot;graphql-request&quot; import {useQuery} from &quot;react-query&quot; const endpoint = &quot;https://api.spacex.land/graphql/&quot; const LAUNCHES_QUERY = gql` { launchesPast(limit: 10) { id mission_name } } ` function SpaceXLaunches() { const {data, isLoading, error} = useQuery( &quot;launches&quot;, () =&gt; request(endpoint, LAUNCHES_QUERY), ) if (isLoading) return &quot;Loading...&quot; if (error) return &lt;pre&gt;{error.message}&lt;/pre&gt; return ( &lt;ul&gt; {data.launchesPast.map((launch) =&gt; ( &lt;li key={launch.id}&gt;{launch.mission_name}&lt;/li&gt; ))} &lt;/ul&gt; ) }   ","version":"Next","tagName":"h3"},{"title":"4. React Query + Axios: Leveraging a Popular HTTP Client​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#4-react-query--axios-leveraging-a-popular-http-client","content":" Combines React Query with Axios for familiar HTTP handling.  Install dependencies: npm install react-query axios Implement data fetching: import axios from &quot;axios&quot; import {useQuery} from &quot;react-query&quot; const endpoint = &quot;https://api.spacex.land/graphql/&quot; const LAUNCHES_QUERY = ` { launchesPast(limit: 10) { id mission_name } } ` function SpaceXLaunches() { const {data, isLoading, error} = useQuery( &quot;launches&quot;, () =&gt; axios .post(endpoint, {query: LAUNCHES_QUERY}) .then((response) =&gt; response.data.data), ) if (isLoading) return &quot;Loading...&quot; if (error) return &lt;pre&gt;{error.message}&lt;/pre&gt; return ( &lt;ul&gt; {data.launchesPast.map((launch) =&gt; ( &lt;li key={launch.id}&gt;{launch.mission_name}&lt;/li&gt; ))} &lt;/ul&gt; ) }   ","version":"Next","tagName":"h3"},{"title":"5. React Query + Fetch API: The Minimalist Approach​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#5-react-query--fetch-api-the-minimalist-approach","content":" Utilizes the browser's Fetch API with React Query for a minimalistic approach.  Install React Query: npm install react-query Implement data fetching: import { useQuery } from &quot;react-query&quot;; const endpoint = &quot;https://api.spacex.land/graphql/&quot;; const LAUNCHES_QUERY = ` { launchesPast(limit: 10) { id mission_name } } `; function SpaceXLaunches() { the { data, isLoading, error } = useQuery(&quot;launches&quot;, () =&gt; fetch(endpoint, { method: &quot;POST&quot;, headers: { &quot;Content-Type&quot;: &quot;application/json&quot; }, body: JSON.stringify({ query: LAUNCHES_QUERY }) }) .then(response =&gt; { if (!response.ok) throw new Error(&quot;Network response was not ok&quot;); return response.json(); }) .then(result =&gt; result.data) ); if (isLoading) return &quot;Loading...&quot;; if (error) return &lt;pre&gt;{error.message}&lt;/pre&gt;; return ( &lt;ul&gt; {data.launchesPast.map((launch) =&gt; ( &lt;li key={launch.id}&gt;{launch.mission_name}&lt;/li&gt; ))} &lt;/ul&gt; ); }   ","version":"Next","tagName":"h3"},{"title":"Detailed Comparison Table​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#detailed-comparison-table","content":" Here’s a comparison table to help choose the right method based on specific needs:  Method\tBundle Size (minified + gzip)*\tLearning Curve\tCaching Capabilities\tCommunity Support\tAdditional FeaturesApollo Client\t~47.04 KB\tModerate\tExtensive (InMemoryCache, customizable)\tHigh\tState management, optimistic UI updates Urql\t~2.18 KB\tLow\tModerate (Document caching)\tModerate\tExtensible architecture React Query + GraphQL Request\t~13 KB + ~185.8 KB\tLow\tBasic (Managed by React Query)\tGrowing\tMinimal overhead React Query + Axios\t~13 KB + ~13.2 KB\tLow\tBasic (Managed by React Query)\tHigh\tFamiliar HTTP handling React Query + Fetch API\t~13 KB + ~152.4 KB\tLow\tBasic (Managed by React Query)\tModerate\tBrowser-native, minimal setup  (*) culled from *bundlephobia.com*  ","version":"Next","tagName":"h2"},{"title":"Caching Capabilities​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#caching-capabilities","content":" Apollo Client: Normalized caching (stores entities by ID)Automatic cache updatesManual cache manipulationPersistence and rehydrationOptimistic updates Urql: Document caching (stores full query responses)Customizable caching with exchangersPersistence support React Query (applies to all React Query combinations): Time-based cachingStale-while-revalidate strategyManual cache manipulationPersistence and rehydration  ","version":"Next","tagName":"h3"},{"title":"Error Handling​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#error-handling","content":" Proper error handling is crucial for creating robust GraphQL applications. This section provides a detailed discussion on error handling for each client, including code examples for different types of errors and guidance on displaying user-friendly error messages.  ","version":"Next","tagName":"h2"},{"title":"1. Apollo Client​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#1-apollo-client","content":" Apollo Client provides detailed error information through the error property returned by the useQuery hook. It distinguishes between GraphQL errors and network errors.  import {useQuery, gql} from &quot;@apollo/client&quot; const LAUNCHES_QUERY = gql` { launchesPast(limit: 10) { id mission_name } } ` function SpaceXLaunches() { const {data, loading, error} = useQuery(LAUNCHES_QUERY) if (loading) return &quot;Loading...&quot; if (error) { return &lt;ErrorDisplay error={error} /&gt; } // Render data... } function ErrorDisplay({error}) { // Function to generate a user-friendly error message const getUserFriendlyErrorMessage = (error) =&gt; { if (error.networkError) { return &quot;Unable to reach the server. Please check your internet connection and try again.&quot; } if (error.graphQLErrors.length &gt; 0) { // You might want to customize this based on specific error codes or messages return &quot;There was an issue processing your request. Please try again later.&quot; } return &quot;An unexpected error occurred. Please try again.&quot; } return ( &lt;div className=&quot;error-container&quot;&gt; &lt;h2&gt;Oops! Something went wrong&lt;/h2&gt; &lt;p&gt;{getUserFriendlyErrorMessage(error)}&lt;/p&gt; {process.env.NODE_ENV !== &quot;production&quot; &amp;&amp; ( &lt;details&gt; &lt;summary&gt;Technical Details&lt;/summary&gt; {error.graphQLErrors.map( ({message, locations, path}, index) =&gt; ( &lt;div key={index}&gt; &lt;p&gt;GraphQL error: {message}&lt;/p&gt; &lt;p&gt;Location: {JSON.stringify(locations)}&lt;/p&gt; &lt;p&gt;Path: {JSON.stringify(path)}&lt;/p&gt; &lt;/div&gt; ), )} {error.networkError &amp;&amp; ( &lt;p&gt; Network error: {error.networkError.message} &lt;/p&gt; )} &lt;/details&gt; )} &lt;/div&gt; ) }   This example demonstrates how to:  Display a user-friendly error message based on the type of errorShow technical details only in non-production environmentsHandle both GraphQL and network errors  ","version":"Next","tagName":"h3"},{"title":"2. Urql​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#2-urql","content":" Urql provides error information through the error property in the result object.  import {useQuery} from &quot;urql&quot; const LAUNCHES_QUERY = ` { launchesPast(limit: 10) { id mission_name } } ` function SpaceXLaunches() { const [result] = useQuery({query: LAUNCHES_QUERY}) const {data, fetching, error} = result if (fetching) return &quot;Loading...&quot; if (error) { return &lt;ErrorDisplay error={error} /&gt; } // Render data... } function ErrorDisplay({error}) { const getUserFriendlyErrorMessage = (error) =&gt; { if (error.networkError) { return &quot;Unable to reach the server. Please check your internet connection and try again.&quot; } if (error.graphQLErrors.length &gt; 0) { // Customize based on specific error types if needed return &quot;There was an issue processing your request. Please try again later.&quot; } return &quot;An unexpected error occurred. Please try again.&quot; } return ( &lt;div className=&quot;error-container&quot;&gt; &lt;h2&gt;Oops! Something went wrong&lt;/h2&gt; &lt;p&gt;{getUserFriendlyErrorMessage(error)}&lt;/p&gt; {process.env.NODE_ENV !== &quot;production&quot; &amp;&amp; ( &lt;details&gt; &lt;summary&gt;Technical Details&lt;/summary&gt; {error.graphQLErrors.map( (graphQLError, index) =&gt; ( &lt;div key={index}&gt; &lt;p&gt;GraphQL error: {graphQLError.message}&lt;/p&gt; {graphQLError.locations &amp;&amp; ( &lt;p&gt; Location:{&quot; &quot;} {JSON.stringify(graphQLError.locations)} &lt;/p&gt; )} {graphQLError.path &amp;&amp; ( &lt;p&gt; Path:{&quot; &quot;} {JSON.stringify(graphQLError.path)} &lt;/p&gt; )} &lt;/div&gt; ), )} {error.networkError &amp;&amp; ( &lt;p&gt; Network error: {error.networkError.message} &lt;/p&gt; )} &lt;/details&gt; )} &lt;/div&gt; ) }   ","version":"Next","tagName":"h3"},{"title":"React Query (applies to all React Query examples)​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#react-query-applies-to-all-react-query-examples","content":" React Query provides error information through the error property returned by the useQuery hook.  When using React Query with GraphQL Request, you need to handle errors from both libraries. This approach requires more manual error handling but offers fine-grained control.  import {useQuery} from &quot;react-query&quot; import {request, gql} from &quot;graphql-request&quot; const endpoint = &quot;https://api.spacex.land/graphql/&quot; const LAUNCHES_QUERY = gql` { launchesPast(limit: 10) { id mission_name } } ` function SpaceXLaunches() { const {data, isLoading, error} = useQuery( &quot;launches&quot;, async () =&gt; { try { return await request(endpoint, LAUNCHES_QUERY) } catch (error) { // GraphQL Request wraps GraphQL errors in a ClientError if (error.response) { throw new Error( JSON.stringify(error.response.errors), ) } else { // Network error throw new Error(`Network error: ${error.message}`) } } }, ) if (isLoading) return &quot;Loading...&quot; if (error) { return &lt;ErrorDisplay error={error} /&gt; } // Render data... } function ErrorDisplay({error}) { const getUserFriendlyErrorMessage = (error) =&gt; { try { const parsedError = JSON.parse(error.message) if (Array.isArray(parsedError)) { // GraphQL errors return &quot;There was an issue processing your request. Please try again later.&quot; } } catch { // Network error or other non-GraphQL error return &quot;Unable to reach the server. Please check your internet connection and try again.&quot; } return &quot;An unexpected error occurred. Please try again.&quot; } return ( &lt;div className=&quot;error-container&quot;&gt; &lt;h2&gt;Oops! Something went wrong&lt;/h2&gt; &lt;p&gt;{getUserFriendlyErrorMessage(error)}&lt;/p&gt; {process.env.NODE_ENV !== &quot;production&quot; &amp;&amp; ( &lt;details&gt; &lt;summary&gt;Technical Details&lt;/summary&gt; &lt;pre&gt;{error.message}&lt;/pre&gt; &lt;/details&gt; )} &lt;/div&gt; ) }   ","version":"Next","tagName":"h3"},{"title":"Common Issues and Resolutions​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#common-issues-and-resolutions","content":" ","version":"Next","tagName":"h2"},{"title":"1. Apollo Client​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#1-apollo-client-1","content":" Issue: Cache inconsistencies Resolution: Use refetchQueries option when mutating data or implement cache update functions.Issue: Overfeching data Resolution: Utilize fragment colocation and implement proper query splitting.  ","version":"Next","tagName":"h3"},{"title":"2. Urql​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#2-urql-1","content":" Issue: Stale data after mutations Resolution: Use the cache-and-network fetch policy or implement manual cache updates.Issue: SSR hydration mismatches Resolution: Ensure consistent query variables between server and client, or use the ssrExchange.  ","version":"Next","tagName":"h3"},{"title":"3. React Query (all combinations)​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#3-react-query-all-combinations","content":" Issue: Stale data displayed briefly before refetch Resolution: Adjust staleTime and cacheTime options to fine-tune caching behavior.Issue: Unnecessary refetches on component remount Resolution: Implement proper query keys and adjust refetchOnMount option.  ","version":"Next","tagName":"h3"},{"title":"Use Cases for Each Method​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#use-cases-for-each-method","content":" Apollo Client: Best for large-scale applications needing complex state management and data synchronization.Urql: Suitable for medium-sized projects where simplicity and performance are prioritized.React Query + GraphQL Request: Ideal for projects requiring high flexibility with minimal GraphQL-specific setup.React Query + Axios: Preferred when developers are already familiar with Axios and need robust HTTP capabilities.React Query + Fetch API: Optimal for projects that require a minimalistic approach with no additional dependencies.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"GraphQL in React: 5 Best Approaches for Data Fetching.","url":"/graphql/graphql-react-client/#conclusion","content":" By understanding the distinct features and use cases of each method, developers can select the most appropriate GraphQL fetching technique for their React projects. This guide aims to equip developers with the knowledge to efficiently integrate GraphQL data fetching into their applications, regardless of scale or complexity. ","version":"Next","tagName":"h2"},{"title":"GraphQL Configuration","type":0,"sectionRef":"#","url":"/docs/tailcall-dsl-graphql-custom-directives/","content":"","keywords":"","version":"Next"},{"title":"@addField Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#addfield-directive","content":" The @addField directive simplifies data structures and queries by adding a field that inline or flattens a nested field or node within your schema. It modifies the schema and the data transformation process, making nested data more accessible and straightforward to present.  For instance, consider a schema:  schema { query: Query } type User @addField(name: &quot;street&quot;, path: [&quot;address&quot;, &quot;street&quot;]) { id: Int! name: String! username: String! email: String! phone: String website: String address: Address @modify(omit: true) } type Address { street: String! city: String! state: String! } type Query { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) }   Suppose we focus on the street field in Address.  In this case, applying the @addField directive to the User type creates a street field within the User type. It uses a path argument to specify the sequence of fields from a declared field (address), leading to the Address field to add. We also can apply @modify(omit: true) to remove the address field from the schema, as the street field from Address is now directly accessible on the User type.  Post application, the schema becomes:  schema { query: Query } type User { id: Int! name: String! username: String! email: String! phone: String website: String street: String } type Query { user(id: Int): Post! }   In the above example, since we added a @modify(omit: true) on the address field, the schema no longer includes the Address type.  The @addField directive also take cares of nullablity of the fields. If any of the fields in the path is nullable, the resulting type will be nullable.  @addField also supports indexing, allowing for the specification of an array index for inline inclusion. For instance, if a field posts is of type [Post], and the goal is to access the title of the first post, specify the path as [&quot;posts&quot;,&quot;0&quot;,&quot;title&quot;].  type User @addField( name: &quot;firstPostTitle&quot; path: [&quot;posts&quot;, &quot;0&quot;, &quot;title&quot;] ) { id: Int! name: String! username: String! email: String! phone: String website: String posts: Post @http(path: &quot;/users/{{.value.id}}/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! }   In conclusion, the @addField directive helps tidy up your schema and streamline data fetching by reducing query depth, promoting better performance and simplicity.  ","version":"Next","tagName":"h2"},{"title":"@cache Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#cache-directive","content":" The @cache directive provides a protocol agnostic mechanism for caching the results of fields within a GraphQL schema. Like any other cache implementation, this feature is useful for optimizing performance by reducing the need to fetch data that doesn't change frequently.  ","version":"Next","tagName":"h2"},{"title":"maxAge​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#maxage","content":" @cache(maxAge: Int)   This parameter is a non-zero unsigned integer specifying the duration, in milliseconds, that retains the cached value.  ","version":"Next","tagName":"h3"},{"title":"Usage​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#usage","content":" Consider the following GraphQL schema example:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int title: String userId: Int @cache(maxAge: 100) user: User @http(path: &quot;/user/{{.value.userId}}&quot;) @cache(maxAge: 200) } type User { id: Int name: String email: String }   In this configuration, the system caches the result of the user field due to its association with an HTTP resolver. But it does not cache the values of userId and title because they lack individual resolvers; the resolver for the posts field retrieves their values, employing the @http(path: &quot;/posts&quot;) directive.  Applying the @cache directive at the type level affects all fields within that type. For example:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post @cache(maxAge: 100) { id: Int title: String userId: Int user: User @http(path: &quot;/user/{{.value.userId}}&quot;) } type User { id: Int name: String email: String }   You can simplify this configuration to show that applying the @cache directive to a type means every field within that type inherits it:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int @cache(maxAge: 100) title: String @cache(maxAge: 100) userId: Int @cache(maxAge: 100) user: User @http(path: &quot;/user/{{.value.userId}}&quot;) @cache(maxAge: 100) } type User { id: Int name: String email: String }   Since the @cache directive does not affect fields without resolvers, the effective configuration can be further reduced as follows:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int title: String userId: Int user: User @http(path: &quot;/user/{{.value.userId}}&quot;) @cache(maxAge: 100) } type User { id: Int name: String email: String }   When applying the @cache directive both at the type level and on individual fields within that type, the field-level directive takes precedence:  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post @cache(maxAge: 200) { id: Int title: String userId: Int user: User @http(path: &quot;/user/{{.value.userId}}&quot;) @cache(maxAge: 100) } type User { id: Int name: String email: String }   Thus, in the configuration above, while all fields inherit the @cache(maxAge: 200) directive at the type level, the user field's explicit @cache(maxAge: 100) directive takes precedence.  ","version":"Next","tagName":"h3"},{"title":"Cache Key​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#cache-key","content":" The caching mechanism generates a hash based on information related to the applied query to serve as the cache key for the corresponding value.  For instance, the system caches the user field in the following configuration, using the hash of the interpolated string &quot;/user/{{.value.userId}}&quot; as the cache key. For example, if Post.userId equals 1, the system generates the cache key by hashing the string &quot;/users/1&quot;.  ","version":"Next","tagName":"h3"},{"title":"@call Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#call-directive","content":" The @call directive in GraphQL signifies a shift towards more efficient configuration management by introducing a methodology akin to function invocations in conventional programming. This directive is pivotal for developers navigating the intricacies of elaborate GraphQL schemas, where minimizing redundancy and adhering to the DRY (Don't Repeat Yourself) principle are paramount. Consider the following schema example:  schema @upstream( baseURL: &quot;https://jsonplaceholder.typicode.com&quot; ) { query: Query } type Query { user(id: Int!): User @http(path: &quot;/users/{{.args.id}}&quot;) posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{.value.userId}}&quot;) } type User { id: Int! name: String! email: String! }   In this schema, at lines 9 and 18, a pattern of configuration duplication emerges when fetching user's data by its id, demonstrating a prime use case for the @call directive. Through refactoring the Post type to incorporate the @call directive, we can eliminate this redundancy.  type Post { id: Int! userId: Int! title: String! body: String! user: User @call( steps: [ {query: &quot;user&quot;, args: {id: &quot;{{.value.userId}}&quot;}} ] ) }   Here, the @call directive invokes the user query from the Query type, leveraging the data-fetching process that's already defined in the root query. The query parameter specifies the target field, while the args parameter delineates the arguments to be passed.  ","version":"Next","tagName":"h2"},{"title":"steps​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#steps","content":" @call directive can compose together other resolvers, allowing to create a chain of resolvers that can be executed in sequence. This is done by using the steps parameter, which is an array of objects that define the operations to be executed.  ","version":"Next","tagName":"h3"},{"title":"query​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#query","content":" Specify the root query field to invoke, alongside the requisite arguments, using the @call directive for a concise and efficient query structure.  type Post { userId: Int! user: User @call( steps: [ {query: &quot;user&quot;, args: {id: &quot;{{.value.userId}}&quot;}} ] ) }   ","version":"Next","tagName":"h3"},{"title":"mutation​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#mutation","content":" Similarly, the @call directive can facilitate calling a mutation from another mutation field, employing the mutation parameter for field specification and the args parameter for argument delineation.  type Mutation { insertPost(input: PostInput, overwrite: Boolean): Post @http( body: &quot;{{.args.input}}&quot; method: &quot;POST&quot; path: &quot;/posts&quot; query: {overwrite: &quot;{{.args.overwrite}}&quot;} ) upsertPost(input: PostInput): Post @call( steps: [ { mutation: &quot;insertPost&quot; args: {input: &quot;{{.args.input}}&quot;, overwrite: true} } ] ) }   ","version":"Next","tagName":"h3"},{"title":"args​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#args","content":" The args parameter in the @call directive facilitates passing arguments to the targeted query or mutation, represented as a key-value mapping where each key corresponds to an argument name and its associated value.  type Post { userId: Int! user: User @call( steps: [ {query: &quot;user&quot;, args: {id: &quot;{{.value.userId}}&quot;}} ] ) }   tip The @call directive is predominantly advantageous in complex, large-scale configurations. For those new to GraphQL or Tailcall, it may be beneficial to explore this directive after familiarizing yourself with the foundational aspects of GraphQL.  ","version":"Next","tagName":"h3"},{"title":"Composition​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#composition","content":" @call directive provides the ability to express a sequence of steps that one might need to compose. These steps are executed such that the result of each step is passed as an argument to the next step. The query and mutation parameters are used to specify the target field, while the args parameter is used to pass arguments to the target field.  Let's explain this with an example:  schema @server { query: Query } type Query { a(input: JSON): JSON @expr(body: {value: &quot;{{.args.input.a}}&quot;}) b(input: JSON): JSON @expr(body: {value: &quot;{{.args.input.b}}&quot;}) c(input: JSON): JSON @expr(body: {value: &quot;{{.args.input.c}}&quot;}) }   Here we have defined there operations viz. a, b &amp; c each of them pluck their respective keys from the given input value. Let's run this query with some test input:  { a(input: {a: 100}) b(input: {b: 200}) c(input: {c: 300}) }   Here is how the response would look like:  { &quot;data&quot;: { &quot;a&quot;: { &quot;value&quot;: 100 }, &quot;b&quot;: { &quot;value&quot;: 200 }, &quot;c&quot;: { &quot;value&quot;: 300 } } }   As you can see the @expr directive plucks the inner value and returns the result. How about we implement an abc operation that could leverage the existing operations and unwrap the following input value:  {&quot;a&quot;: {&quot;b&quot;: {&quot;c&quot;: {&quot;d&quot;: 1000}}}}   Given the above input if we wish to extract the last inner number 1000 then we could define a new operation as follows  schema @server { query: Query } type Query { a(input: JSON): JSON @expr(body: {value: &quot;{{.args.input.a}}&quot;}) b(input: JSON): JSON @expr(body: {value: &quot;{{.args.input.b}}&quot;}) c(input: JSON): JSON @expr(body: {value: &quot;{{.args.input.c}}&quot;}) abc(input: JSON): JSON @call( steps: [ {query: &quot;a&quot;, args: {input: &quot;{{.args.input}}&quot;}} {query: &quot;b&quot;, args: {input: &quot;{{.args.value}}&quot;}} {query: &quot;c&quot;, args: {input: &quot;{{.args.value}}&quot;}} ] ) }   We use the @call directive to compose the operations together. The args specify how we would like to pass the arguments to the operation and the result of that operation is passed to the next step. We can test the new abc operation with the following query:  query { abc(input: {a: {b: {c: 1000}}}) }   The server returns the response that we expected:  { &quot;data&quot;: { &quot;abc&quot;: { &quot;value&quot;: 100 } } }   This way you can compose combine multiple operations can compose them together using the @call directive.  note We use JSON scalar here because we don't care about the type safety of this option. In a real world example you might want to use proper input and output types.  ","version":"Next","tagName":"h3"},{"title":"@expr Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#expr-directive","content":" The @expr directive in GraphQL is a powerful tool for embedding data directly into your schema, offering two primary functionalities:  ","version":"Next","tagName":"h2"},{"title":"Static​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#static","content":" This feature allows for the inclusion of a constant response within the schema definition itself. It is useful for scenarios where the response is unchanging. e.g:  schema { query: Query } type Query { user: User @expr(body: {name: &quot;John&quot;, age: 12}) } type User { name: String age: Int }   The @expr directive also checks the provided value at compile time to ensure it matches the field's schema. If not, the console displays a descriptive error message.  ","version":"Next","tagName":"h3"},{"title":"Dynamic​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#dynamic","content":" Beyond static data embedding, the @expr directive extends its utility to support dynamic data injection through Mustache template syntax. This feature enables the use of placeholders within the constant data, which are then dynamically replaced with actual values at runtime. It supports both scalar values and complex objects, including lists and nested objects, offering flexibility in tailoring responses to specific needs. e.g:  schema { query: Query } type Query { user: User @expr( body: { name: &quot;John&quot; workEmail: &quot;john@xyz.com&quot; personalEmail: &quot;john@xyz.com&quot; } ) } type User { name: String age: Int personalEmail: String workEmail: String emails: Emails @expr( body: { emails: { workEmail: &quot;{{.value.workEmail}}&quot; personalEmail: &quot;{{.value.personalEmail}}&quot; } } ) } type Emails { workEmail: String personalEmail: String }   In this example, the @expr directive dynamically generate an Emails object based on the provided template data. The placeholders within the template ({{.value.workEmail}} and {{.value.personalEmail}}) gets replaced with the actual values specified in the User type, allowing for dynamic content generation while still adhering to the schema's structure.  ","version":"Next","tagName":"h3"},{"title":"@graphQL Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#graphql-directive","content":" The @graphQL directive allows to specify GraphQL API server request to fetch data from.  type Query { users: [User] @graphQL(name: &quot;userList&quot;) }   The @graphQL directive facilitates fetching a list of users from the GraphQL API upstream. The name argument specifies the root field's name on the upstream server. The upcoming request to the GraphQL server determines the User type's inner fields for the request. Depending on the operation type within which one finds the @graphQL directive, the GraphQL configuration determines the query's operation type.  For the next request with the config above:  query { users { id name } }   Tailcall will request the next query for the upstream:  query { userList { id name } }   ","version":"Next","tagName":"h2"},{"title":"baseURL​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#baseurl","content":" This refers to the base URL of the API. If not specified, the default base URL is the one specified in the @upstream directive.  type Query { users: [User] @graphQL( name: &quot;users&quot; baseURL: &quot;https://graphqlzero.almansi.me/api&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"name​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#name","content":" The root field's name on the upstream to request data from. For example:  type Query { users: [User] @graphQL(name: &quot;userList&quot;) }   When Tailcall receives a query for the users field, it will request a query for userList from the upstream.  ","version":"Next","tagName":"h3"},{"title":"args​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#args-1","content":" Named arguments for the requested field. For example:  type Query { user: User @graphQL( name: &quot;user&quot; args: [{key: &quot;id&quot;, value: &quot;{{.value.userId}}&quot;}] ) }   Will request the next query from the upstream for the first user's name:  query { user(id: 1) { name } }   ","version":"Next","tagName":"h3"},{"title":"headers​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#headers","content":" The headers parameter allows customizing the headers of the GraphQL request made by the @graphQL directive. Specifying a key-value map of header names and their values achieves this.  For instance:  type Mutation { users: User @graphQL( name: &quot;users&quot; headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}] ) }   In this example, a request to /users will include the HTTP header X-Server with the value Tailcall.  ","version":"Next","tagName":"h3"},{"title":"batch​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#batch","content":" In case the upstream GraphQL server supports request batching, we can specify the batch argument to batch requests to a single upstream into a single batch request. For example:  schema @upstream( batch: { maxSize: 1000 delay: 10 headers: [&quot;X-Server&quot;, &quot;Authorization&quot;] } ) { query: Query mutation: Mutation } type Query { users: [User] @graphQL(name: &quot;users&quot;, batch: true) posts: [Post] @graphQL(name: &quot;posts&quot;, batch: true) }   Make sure you have also specified batch settings to the @upstream and to the @graphQL directive.  ","version":"Next","tagName":"h3"},{"title":"@grpc Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#grpc-directive","content":" The @grpc directive enables the resolution of GraphQL fields via gRPC services. Below is an illustrative example of how to apply this directive within a GraphQL schema:  schema @link(src: &quot;./users.proto&quot;, type: Protobuf) { query: Query } type Query { users: [User] @grpc(method: &quot;users.UserService.ListUsers&quot;) }   This schema snippet demonstrates the directive's application, where a query for users triggers a gRPC request to the UserService's ListUsers method, thereby fetching the user data.  The .proto file delineates the structure and methods of the gRPC service. A simplified example of such a file is as follows:  syntax = &quot;proto3&quot;; package users; service UserService { rpc ListUsers (UserListRequest) returns (UserListReply) {} rpc GetUser (UserGetRequest) returns (UserGetReply) {} } message UserListRequest { // Definitions of request parameters } message UserListReply { // Structure of the reply } message UserGetRequest { // Definitions of request parameters } message UserGetReply { // Structure of the reply }   important It is mandatory to have a package name in a protobuf file.  Linking this file within a GraphQL schema is facilitated by the @link directive, as shown below:  schema @link(src: &quot;./users.proto&quot;, type: Protobuf) { query: Query }   Tailcall automatically resolves the protobuf file for any methods referenced in the @grpc directive.  ","version":"Next","tagName":"h2"},{"title":"method​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#method","content":" This parameter specifies the gRPC service and method to be invoked, formatted as &lt;package&gt;.&lt;service&gt;.&lt;method&gt;:  type Query { users: [User] @grpc(method: &quot;proto.users.UserService.ListUsers&quot;) }   ","version":"Next","tagName":"h3"},{"title":"baseURL​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#baseurl-1","content":" Defines the base URL for the gRPC API. If not specified, the URL set in the @upstream directive is used by default:  type Query { users: [User] @grpc( baseURL: &quot;https://grpc-server.example.com&quot; method: &quot;proto.users.UserService.ListUsers&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"body​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#body","content":" This parameter outlines the arguments for the gRPC call, allowing for both static and dynamic inputs:  type UserInput { id: ID } type Query { user(id: UserInput!): User @grpc( body: &quot;{{.args.id}}&quot; method: &quot;proto.users.UserService.GetUser&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"headers​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#headers-1","content":" Custom headers for the gRPC request can be defined, facilitating the transmission of authentication tokens or other contextual data:  type Query { users: [User] @grpc( headers: [ {key: &quot;X-CUSTOM-HEADER&quot;, value: &quot;custom-value&quot;} ] method: &quot;proto.users.UserService.ListUsers&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"batchKey​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#batchkey","content":" This argument is employed to optimize batch requests by grouping them based on specified response keys, enhancing performance in scenarios requiring multiple, similar requests:  type Query { users(id: UserInput!): [User] @grpc( batchKey: [&quot;id&quot;] method: &quot;proto.users.UserService.ListUsers&quot; baseURL: &quot;https://grpc-server.example.com&quot; ) }   info Read about n + 1 to learn how to use the batchKey setting.  ","version":"Next","tagName":"h3"},{"title":"@http Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#http-directive","content":" The @http directive indicates a field or node relies on a REST API. For example:  type Query { users: [User] @http(path: &quot;/users&quot;) }   In this example, adding the @http directive to the users field of the Query type indicates reliance on a REST API for the users field. The path argument specifies the REST API's path, which is /users in this scenario.Querying the users field prompts the GraphQL server to issue a GET request to https://jsonplaceholder.typicode.com/users.  ","version":"Next","tagName":"h2"},{"title":"baseURL​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#baseurl-2","content":" Specifies the API's base URL. If unspecified, it defaults to the URL in the @upstream directive.  type Query { users: [User] @http( path: &quot;/users&quot; baseURL: &quot;https://jsonplaceholder.typicode.com&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"path​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#path","content":" Refers to the API endpoint, for example, https://jsonplaceholder.typicode.com/users.  type Query { users: [User] @http(path: &quot;/users&quot;) }   If your API endpoint contains dynamic segments, you can substitute variables using Mustache templates. For example, to fetch a specific user, you can write the path as /users/{{.args.id}}.  type Query { user(id: ID!): User @http(path: &quot;/users/{{.args.id}}&quot;) }   ","version":"Next","tagName":"h3"},{"title":"method​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#method-1","content":" Specifies the HTTP method for the API call. The default method is GET if not specified.  type Mutation { createUser(input: UserInput!): User @http(method: &quot;POST&quot;, path: &quot;/users&quot;) }   ","version":"Next","tagName":"h3"},{"title":"query​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#query-1","content":" Represents the API call's query parameters, either as a static object or with dynamic parameters using Mustache templates. These parameters append to the URL.  type Query { userPosts(id: ID!): [Post] @http( path: &quot;/posts&quot; query: [ { key: &quot;userId&quot; value: &quot;{{.args.id}}&quot; skipEmpty: false } ] ) }   The query field and be further configured using the following fields:  key : Represents the name of the query parameter.value : A string literal or a mustache template representing the value of query parameter.skipEmpty : When set to true the query parameter is skipped if the value of the parameter is null, defaults to false.  important When batchKey is present, Tailcall considers the first query parameter to be the batch query key, so remember to adjust the order of the items accordingly.  ","version":"Next","tagName":"h3"},{"title":"body​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#body-1","content":" Defines the API call's body, necessary for methods like POST or PUT. Pass it as a static object or use Mustache templates for variable substitution from the GraphQL variables.  type Mutation { createUser(input: UserInput!): User @http( method: &quot;POST&quot; path: &quot;/users&quot; body: &quot;{{.args.input}}&quot; ) }   In the example above, the createUser mutation sends a POST request to /users, with the input object converted to JSON and included in the request body.  ","version":"Next","tagName":"h3"},{"title":"headers​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#headers-2","content":" Customizes the HTTP request headers made by the @http directive. Specify a key-value map of header names and values.  For instance:  type Mutation { createUser(input: UserInput!): User @http( path: &quot;/users&quot; headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}] ) }   In this example, a request to /users will include a HTTP header X-Server with the value Tailcall.  You can make use of mustache templates to provide dynamic values for headers, derived from the arguments or context provided in the request. For example:  type Mutation { users(name: String): User @http( path: &quot;/users&quot; headers: [ {key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;} {key: &quot;User-Name&quot;, value: &quot;{{.args.name}}&quot;} ] ) }   In this scenario, the User-Name header's value will dynamically adjust according to the name argument passed in the request.  ","version":"Next","tagName":"h3"},{"title":"batchKey​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#batchkey-1","content":" Groups data requests into a single call, enhancing efficiency. Refer to our n + 1 guide for more details.  important When batchKey is present, Tailcall considers the first query parameter to be the batch query key, so remember to adjust the order of the items accordingly. Whereas, the last item from batchKey is used to instruct which field is the ID of an object. In case that the returned result is a nested property batchKey can be used as a path to extract and group the items for the returned result.  type Post { id: Int! name: String! user: User @http( path: &quot;/users&quot; query: [{key: &quot;user_id&quot;, value: &quot;{{.value.userId}}&quot;}] batchKey: [&quot;users&quot;, &quot;id&quot;] ) }   query: {key: &quot;user_id&quot;, value: &quot;{{.value.userId}}&quot;}]: Instructs Tailcall CLI to generate a URL aligning the user id with userId from the parent Post, compiling a single URL for a batch of posts, such as /users?user_id=1&amp;user_id=2&amp;user_id=3...user_id=10, consolidating requests into one.  ","version":"Next","tagName":"h3"},{"title":"onRequest​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#onrequest","content":" The onRequest property accepts a string value representing the remote function to be called every time an HTTP request is initiated. Typically the remote function is defined in a linked JavaScript worker file.  note For defining a request middleware globally for all requests, refer to the upstream directive documentation.  type Query { userPosts(id: ID!): [Post] @http( path: &quot;/posts&quot; query: [{key: &quot;userId&quot;, value: &quot;{{.args.id}}&quot;}] onRequest: &quot;someFunctionName&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"@js Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#js-directive","content":" The @js directive allows you to use JavaScript functions to resolve fields in your GraphQL schema. This can be useful for custom data transformations or complex field resolutions.  ","version":"Next","tagName":"h2"},{"title":"Usage​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#usage-1","content":" The @js directive is used to specify a JavaScript function that will resolve the value of a field. The directive takes a single argument, name, which is the name of the JavaScript function to be used.  ","version":"Next","tagName":"h3"},{"title":"Syntax​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#syntax","content":" fieldName: FieldType @js(name: &quot;functionName&quot;)   ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#example","content":" Let's consider a foo.js file which contains a resolve function:  function resolve(val) { let json = JSON.parse(val) return JSON.stringify(json.id) }   Here is an example of how the @js directive is used within a GraphQL schema:  schema @link(type: Script, src: &quot;./scripts/foo.js&quot;) @server(port: 8000) @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; httpCache: true ) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! idx: Int! @js(name: &quot;resolve&quot;) userId: Int! title: String! body: String! }   ","version":"Next","tagName":"h3"},{"title":"Error Handling​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#error-handling","content":" When using the @js directive, it is important to handle errors within your JavaScript functions. For example, you can use try-catch blocks to catch and handle any errors that occur during the resolution process.  function resolve(val) { try { let json = JSON.parse(val) return JSON.stringify(json.id) } catch (error) { console.error(&quot;Error resolving value:&quot;, error) throw new Error(&quot;Failed to resolve value&quot;) } }   ","version":"Next","tagName":"h3"},{"title":"Performance Considerations​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#performance-considerations","content":" When using the @js directive, keep in mind that JavaScript functions can introduce performance overhead, especially if they perform complex operations or are called frequently. To minimize performance impact, ensure that your functions are optimized and avoid unnecessary computations.  ","version":"Next","tagName":"h3"},{"title":"@link Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#link-directive","content":" The @link directive is used for bringing external resources into your GraphQL schema. It makes it easier to include configurations, .proto files for gRPC services, and other files into your schema. With this directive, external resources are either merged with or used effectively in the importing configuration.  ","version":"Next","tagName":"h2"},{"title":"How it Works​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#how-it-works","content":" The @link directive requires specifying a source src, the resource's type type, and an optional identifier id.  src: The source of the link is defined here. It can be either a URL or a file path. When a file path is given, it's relative to the file's location that is importing the link. type: This specifies the link's type, which determines how the imported resource is integrated into the schema. For a list of supported types, see the Supported Types section. id: This is an optional field that assigns a unique identifier to the link. It's helpful for referring to the link within the schema.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#example-1","content":" The following example illustrates how to utilize the @link directive to incorporate a Protocol Buffers (.proto) file for a gRPC service into your GraphQL schema.  schema @server(port: 8000) @upstream( baseURL: &quot;http://news.local&quot; httpCache: 42 batch: {delay: 10} ) @link( id: &quot;news&quot; src: &quot;./src/grpc/news.proto&quot; type: Protobuf ) { query: Query } type Query { news: NewsData! @grpc(method: &quot;news.NewsService.GetAllNews&quot;) } type News { id: Int title: String body: String postImage: String } type NewsData { news: [News]! }   ","version":"Next","tagName":"h3"},{"title":"Supported Types​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#supported-types","content":" The @link directive enriches your configuration by supporting the integration of external resources. Each link type is designed to serve a specific purpose, enhancing the functionality and flexibility of your schema. Below is a detailed overview of each supported link type:  ","version":"Next","tagName":"h3"},{"title":"Config​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#config","content":" The Config link type is essential for importing other configuration files. This feature enables a modular approach to schema management by allowing configurations from the imported file to override overlapping settings in the main schema. This functionality is useful in large projects, where maintaining a single monolithic schema file becomes impractical. By using Config, developers can split their schema configurations into manageable pieces, thus promoting better organization and scalability.  Example use case:  Modularizing schema configurations for different environments (development, staging, production).Reusing common configurations across multiple schema files.  ","version":"Next","tagName":"h3"},{"title":"Protobuf​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#protobuf","content":" The Protobuf link type integrates Protocol Buffers definitions by importing .proto files. This integration is crucial for Tailcall to communicate with gRPC services. By including .proto definitions, the GraphQL server can directly interact with gRPC services, allowing for efficient and type-safe communication.  For detailed integration steps and best practices, refer to the gRPC Integration Guide.  ","version":"Next","tagName":"h3"},{"title":"Script​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#script","content":" The Script link type allows the config to link to an external JavaScript file. This file can contain custom logic that is executed in response to HTTP request-response events. This feature enables developers to implement custom behaviors, such as adding headers to responses or filtering requests based on specific criteria.  Example script for adding a custom header to all outgoing requests:  function onRequest({request}) { // Add a custom header for all outgoing requests request.headers[&quot;X-Custom-Header&quot;] = &quot;Processed&quot; // Return the updated request return {request} }   ","version":"Next","tagName":"h3"},{"title":"Cert​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#cert","content":" The Cert link type is designed for importing SSL/TLS certificates, a crucial component for enabling HTTPS in your GraphQL server. This link type ensures that the server can expose connections over HTTPS.  tip When using the Cert link type, specify the path to the certificate file. Ensure the certificate is up-to-date and issued by a trusted certificate authority (CA) to avoid security warnings or connection issues.  Example use case:  Securing communication between the GraphQL server and clients.Enhancing privacy and security by encrypting data in transit.  ","version":"Next","tagName":"h3"},{"title":"Key​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#key","content":" The Key link type imports the private key associated with your SSL/TLS certificate, enabling HTTPS for your GraphQL server. The private key is a critical security element that decrypts information encrypted by the corresponding public key in the SSL/TLS certificate.  When configuring the Key link type, provide the path to your private key file. Ensure the private key matches the imported certificate specified by the Cert link above, and is protected by appropriate file permissions to maintain security.  ","version":"Next","tagName":"h3"},{"title":"Operation​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#operation","content":" The Operation link type connects your schema to a set of predefined, GraphQL spec-compliant queries and mutations. This functionality allows for the validation and optimization of these operations by the GraphQL server.  Each type serves a specific purpose, enabling the flexible integration of external resources into your GraphQL schema.  ","version":"Next","tagName":"h3"},{"title":"Htpasswd​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#htpasswd","content":" The Htpasswd link type allows the importation of an htpasswd file. This file is utilized to set up Basic authentication.  ","version":"Next","tagName":"h3"},{"title":"Jwks​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#jwks","content":" The Jwks link type enables the importation of a JWKS file. This file facilitates the provision of detailed access control through JWT authentication.  ","version":"Next","tagName":"h3"},{"title":"@modify Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#modify-directive","content":" The @modify directive in GraphQL provides the flexibility to alter the attributes of a field or a node within your GraphQL schema. Here's how you can use this directive:  ","version":"Next","tagName":"h2"},{"title":"name​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#name-1","content":" You can rename a field or a node in your GraphQL schema using the name argument in the @modify directive. This can be helpful when the field name in your underlying data source doesn't match the desired field name in your schema. For instance:  type User { id: Int! @modify(name: &quot;userId&quot;) }   @modify(name: &quot;userId&quot;) informs GraphQL to present the field known as id in the underlying data source as userId in your schema.  ","version":"Next","tagName":"h3"},{"title":"omit​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#omit","content":" You can exclude a field or a node from your GraphQL schema using the omit argument in the @modify directive. This can be useful if you want to keep certain data hidden from the client. For instance:  type User { id: Int! @modify(omit: true) }   @modify(omit: true) instructs GraphQL to exclude the id field from the schema, making it inaccessible to the client.  tip @omit is a standalone directive and is an alias/shorthand for modify(omit: true) checkout documentation  ","version":"Next","tagName":"h3"},{"title":"@omit Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#omit-directive","content":" Within a GraphQL schema, the @omit directive excludes fields or nodes from the generated schema, making them inaccessible through the GraphQL API. This directive is useful for hiding sensitive information or simplifying your API by removing unnecessary fields.  ","version":"Next","tagName":"h2"},{"title":"How it works​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#how-it-works-1","content":" When applied to a field or node, the @omit directive instructs the Tailcall not to include that field or node in the schema. This means that clients cannot query or mutate data in those fields.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#example-2","content":" Consider a scenario where you have a User type with an embedded Address type. If you want to exclude the Address type from the schema to simplify the API, you can use the @omit directive:  type Address { city: String street: String } type User { name: String address: Address @omit }   In this example, the address field will not be accessible or visible through the GraphQL API.  ","version":"Next","tagName":"h3"},{"title":"Comparison with modify​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#comparison-with-modify","content":" The @omit directive and @modify(omit: true) essentially serve the same purpose in excluding fields from the schema, but they differ in syntax and flexibility. In fact, one can consider @omit as a shorthand or alias for the more verbose @modify(omit: true).  @omit offers a concise way to directly exclude a field or node without additional arguments. @modify(omit: true), as part of the broader @modify directive, provides more options, such as field renaming through the name argument. This makes it a more flexible choice when you need more than field exclusion.  ","version":"Next","tagName":"h3"},{"title":"@protected Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#protected-directive","content":" The @protected annotation designates a type or field as protected, meaning that a user must be authenticated to access that data.  type Query { protected: String! @protected protectedType: ProtectedType } type ProtectedType @protected { name: String! nested: String! }   important To utilize the @protected directive, you must link at least one authentication provider in the configuration using the @link directive (Htpasswd or Jwks).  ","version":"Next","tagName":"h2"},{"title":"How It Works​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#how-it-works-2","content":" When a field is annotated with @protected, an authentication check is performed upon receiving the request. Depending on the authentication result, either the requested data is provided in the response, or an authentication error is returned.If a type is annotated with @protected, all fields within that type inherit the protection, requiring user authentication for any field that's queried.  ","version":"Next","tagName":"h3"},{"title":"@rest Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#rest-directive","content":" API orchestration is essential, yet not all can adopt GraphQL despite its benefits. The Tailcall DSL feature leverages GraphQL at compile time to generate REST endpoints, aligning with traditional API infrastructure like CDNs and Gateways.  ","version":"Next","tagName":"h2"},{"title":"Usage​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#usage-2","content":" method: Specifies the HTTP method (GET, POST, etc.).path: Sets the endpoint URL, with support for dynamic values from query arguments.query: Defines the query parameters as key-value pairs.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#example-3","content":" Define GraphQL types and queries, using the @rest directive to map fields to REST API endpoints.  schema.graphql  schema @upstream(baseURL: &quot;https://jsonplaceholder.typicode.com&quot;) @link(type: Operation, src: &quot;user-operation.graphql&quot;) { query: Query } type Query { user(id: Int!): User @rest(method: &quot;GET&quot;, path: &quot;/users/{{.args.id}}&quot;) } type User { id: Int! name: String! email: String! }   user-operation.graphql  query ($id: Int!) @rest(method: GET, path: &quot;/user/$id&quot;) { user(id: $id) { id name } }     This example demonstrates how to define a simple query to fetch user data from a REST endpoint using the @rest directive. By leveraging @rest, GraphQL can serve as a layer over RESTful services, combining REST's simplicity with GraphQL's flexibility.  ","version":"Next","tagName":"h3"},{"title":"@server Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#server-directive","content":" The @server directive, applied at the schema level, provides a comprehensive set of server configurations. It dictates server behavior and helps tune Tailcall for a range of use-cases.  schema @server(...[ServerSettings]...){ query: Query mutation: Mutation }   In this templated structure, replace ...[ServerSettings]... with specific configurations tailored to your project's needs. Adjust and expand these settings as necessary.  The ServerSettings options and their details appear below.  ","version":"Next","tagName":"h2"},{"title":"workers​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#workers","content":" Setting workers to 32 means that the GraphQL server will use 32 worker threads.  schema @server(workers: 32) { query: Query mutation: Mutation }   This example sets the workers to 32, meaning the GraphQL server will use 32 worker threads.  ","version":"Next","tagName":"h3"},{"title":"port​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#port","content":" Setting the port to 8090 means that Tailcall will be accessible at http://localhost:8000.  schema @server(port: 8090) { query: Query mutation: Mutation }   This example sets the port to 8090, making Tailcall accessible at http://localhost:8090.  tip Always choose non-standard ports, avoiding typical ones like 80 or 8080. Make sure your chosen port is free.  ","version":"Next","tagName":"h3"},{"title":"headers​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#headers-3","content":" Allows intelligent configuration of the final response headers that's produced by Tailcall.  ","version":"Next","tagName":"h3"},{"title":"cacheControl​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#cachecontrol","content":" Activating the cacheControl configuration directs Tailcall to send Cache-Control headers in its responses. The max-age value in the header matches the lowest of the values in the responses that Tailcall receives from its upstream. By default, this is false, which means Tailcall does not set any header.  schema @server(headers: {cacheControl: true}) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"custom​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#custom","content":" The custom is an array of key-value pairs. These headers get added to the response of every request made to the server. This can be useful for adding headers like Access-Control-Allow-Origin to allow cross-origin requests, or some headers like X-Allowed-Roles for use by downstream services.  schema @server( headers: { custom: [ {key: &quot;X-Allowed-Roles&quot;, value: &quot;admin,user&quot;} ] } ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"experimental​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#experimental","content":" When the experimental configuration is enabled, Tailcall can include headers starting with X- in its responses, which are sourced from its upstream. By default, this feature is disabled ([]), meaning Tailcall does not forward any such headers unless explicitly configured to do so.  schema @server( headers: {experimental: [&quot;X-Experimental-Header&quot;]} ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"setCookies​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#setcookies","content":" Enabling the setCookies option instructs Tailcall to include set-cookie headers in its responses, which are obtained from the headers of upstream responses.  schema @server(headers: {setCookies: true}) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"cors​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#cors","content":" The cors configuration allows you to enable CORS on Tailcall. This is useful when you want to access Tailcall in the browser. Here is a simple configuration to get started with cors:  schema @server( headers: { cors: {allowHeaders: [&quot;*&quot;], allowOrigins: [&quot;*&quot;]} } ) { query: Query }   The above setting will enable CORS on the server for all headers, origins &amp; methods. You can further configure the cors settings to make it more secure with the following fields:  allowCredentials: Indicates whether the server allows credentials (e.g., cookies, authorization headers) to be sent in cross-origin requests.allowHeaders: A list of allowed headers in cross-origin requests. This can be used to specify custom headers that are allowed to be included in cross-origin requests.allowMethods: A list of allowed HTTP methods in cross-origin requests. These methods specify the actions that are permitted in cross-origin requests.allowOrigins: A list of origins that are allowed to access the server's resources in cross-origin requests. An origin can be a domain, a subdomain, or even 'null' for local file schemes.allowPrivateNetwork: Indicates whether requests from private network addresses are allowed in cross-origin requests. Private network addresses typically include IP addresses reserved for internal networks.exposeHeaders: A list of headers that the server exposes to the browser in cross-origin responses. Exposing certain headers allows client-side code to access them in the response.maxAge: The maximum time (in seconds) that the client should cache preflight OPTIONS requests to avoid sending excessive requests to the server.vary: A list of header names that indicate the values of which might cause the server's response to vary, potentially affecting caching.  schema @server( port: 8000 hostname: &quot;0.0.0.0&quot; headers: { cors: { allowCredentials: false allowHeaders: [&quot;Authorization&quot;] allowMethods: [POST, GET, OPTIONS] allowOrigins: [&quot;abc.xyz&quot;] allowPrivateNetwork: true exposeHeaders: [&quot;Content-Type&quot;] maxAge: 360 vary: [&quot;Origin&quot;] } } ) { query: Query }   ","version":"Next","tagName":"h3"},{"title":"vars​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#vars","content":" This configuration allows defining local variables for use during the server's operations. These variables are handy for storing constant configurations, secrets, or other shared information that operations might need.  schema @server( vars: {key: &quot;apiKey&quot;, value: &quot;YOUR_API_KEY_HERE&quot;} ) { query: Query mutation: Mutation } type Query { externalData: Data @http( path: &quot;/external-api/data&quot; headers: [ { key: &quot;Authorization&quot; value: &quot;Bearer {{.vars.apiKey}}&quot; } ] ) }   In the provided example, setting a variable named apiKey with a placeholder value of &quot;YOUR_API_KEY_HERE&quot; implies that whenever Tailcall fetches data from the externalData endpoint, it includes the apiKey in the Authorization header of the HTTP request.  tip Local variables, like apiKey, are instrumental in securing access to external services or providing a unified place for configurations. Ensure that sensitive information stored this way is well protected and not exposed unintentionally, if your GraphQL configuration is publicly accessible.  ","version":"Next","tagName":"h3"},{"title":"introspection​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#introspection","content":" This setting controls the server's allowance of introspection queries. Introspection, a core feature of GraphQL, allows clients to directly fetch schema information. This capability proves crucial for tools and client applications in comprehending the available types, fields, and operations. By default, the server enables this setting (true).  schema @server(introspection: false) { query: Query mutation: Mutation }   tip Although introspection is beneficial during development and debugging stages, consider disabling it in production environments. Turning off introspection in live deployments can enhance security by preventing potential attackers from discerning the schema and any associated business logic or data structures.  ","version":"Next","tagName":"h3"},{"title":"queryValidation​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#queryvalidation","content":" The queryValidation configuration determines if the server checks incoming GraphQL queries against the defined schema. Each query check ensures it matches the schema, preventing errors from incorrect or malformed queries. In some situations, you might want to disable it, notably to enhance server performance at the cost of these checks. This defaults to false if not specified.  schema @server(queryValidation: true) { query: Query mutation: Mutation }   The example above sets queryValidation to true, enabling the validation phase for incoming queries.  tip Enable this in the development environment to ensure the queries sent are correct and validated. In the production environment, consider disabling it for improved performance.  ","version":"Next","tagName":"h3"},{"title":"responseValidation​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#responsevalidation","content":" Tailcall can automatically infer the schema of the HTTP endpoints for you. This information can check responses received from the upstream services. Enabling this setting allows you to do that. If not specified, the default setting for responseValidation is false.  schema @server(responseValidation: true) { query: Query mutation: Mutation }   tip Disabling this setting will offer major performance improvements, but at the potential expense of data integrity.  ","version":"Next","tagName":"h3"},{"title":"globalResponseTimeout​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#globalresponsetimeout","content":" The globalResponseTimeout configuration sets the max duration a query can run before the server terminates it. Essentially, it acts as a safeguard against long-running queries that could strain resources or pose security concerns.  If not explicitly defined, there might be a system-specific or default value that applies.  schema @server(globalResponseTimeout: 5000) { query: Query mutation: Mutation }   In this given example, setting the globalResponseTimeout to 5000 milliseconds, or 5 seconds, means any query execution taking longer than this duration will be automatically terminated by  tip Setting an appropriate response timeout in production environments is crucial. This optimizes resource use and serves as a security measure against potential denial-of-service attacks, where adversaries might run complex queries to exhaust server resources.  ","version":"Next","tagName":"h3"},{"title":"version​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#version","content":" The server uses the HTTP version. If not specified, the default value is HTTP1. The available options are HTTP1 and HTTP2.  schema @server(version: HTTP2) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"cert​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#cert-1","content":" The path to certificate(s) for running the server over HTTP2 (HTTPS). If not specified, the default value is null.  schema @server(cert: &quot;./cert.pem&quot;) { query: Query mutation: Mutation }   tip The certificate can be of any extension, but it's highly recommended to use standards (pem, crt, key).  ","version":"Next","tagName":"h3"},{"title":"key​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#key-1","content":" The path to the key for running the server over HTTP2 (HTTPS). If not specified, the default value is null.  schema @server(key: &quot;./key.pem&quot;) { query: Query mutation: Mutation }   tip The key can be of any extension, but it's highly recommended to use standards (pem, crt, key).  ","version":"Next","tagName":"h3"},{"title":"showcase​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#showcase","content":" The @server directive's showcase option allows for hands-on experimentation with server configurations in a controlled environment. This feature simplifies the process of exploring and testing different settings.  schema @server(showcase: true) { query: Query }   ","version":"Next","tagName":"h3"},{"title":"batchRequests​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#batchrequests","content":" Batching in GraphQL combines requests into one, reducing server round trips.  schema @server( port: 8000 batchRequests: true )   tip Batching can improve performance but may introduce latency if one request in the batch takes longer. It also makes network traffic debugging harder.  ","version":"Next","tagName":"h3"},{"title":"dedupe​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#dedupe","content":" A boolean flag, if set to true, will enable deduplication of IO operations to enhance performance. This flag prevents duplicate IO requests from being executed concurrently, reducing resource load. If not specified, this feature defaults to false.  schema @server( port: 8000 dedupe: true )   ","version":"Next","tagName":"h3"},{"title":"@telemetry Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#telemetry-directive","content":" The @telemetry directive facilitates seamless integration with OpenTelemetry, enhancing the observability of your GraphQL services powered by Tailcall. By leveraging this directive, developers gain access to valuable insights into the performance and behavior of their applications.  ","version":"Next","tagName":"h2"},{"title":"Traces​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#traces","content":" Here are the traces that are captured by the @telemetry directive:  Trace Name\tDescriptionrequest\tCaptures the span for processing the HTTP request on the server side, providing foundational observability. graphQL\tOnly for GraphQL ingress. Span for processing GraphQL call REST &lt;http_method&gt; &lt;http_route&gt;\tOnly for REST ingress. Span for processing REST API call &lt;field_name&gt;\tDenotes spans for fields with defined resolvers, offering insights into field names and execution times for resolver logic. &lt;expr_name&gt;\tNested within the &lt;field_name&gt; spans, these granulated spans detail the execution of expressions in resolving a field, highlighting the hierarchical execution pattern of nested expressions. upstream_request\tRequest that were made from tailcall service to upstream  ","version":"Next","tagName":"h3"},{"title":"Metrics​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#metrics","content":" The @telemetry directive also captures the following metrics:  Metric\tDescriptioncache.hit_rate\tReflects the cache hit rate for the cache powered by the @cache directive http.server.request.count\tCounts the number of incoming requests made to specific route. Optionally enriched with selected headers by requestHeaders http.client.request.count\tCounts the number of outgoing requests to specific upstream  ","version":"Next","tagName":"h3"},{"title":"export​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#export","content":" The export field defines how the open-telemetry data should be exported and in which format. The following are the supported formats:  ","version":"Next","tagName":"h3"},{"title":"otlp​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#otlp","content":" Utilizes the OTLP format to export telemetry data to backend systems, supported by most modern tracing and analytics platforms. Here is an example using [honeycomb.io]:  schema @telemetry( export: { otlp: { url: &quot;https://api.honeycomb.io:443&quot; headers: [ { key: &quot;x-honeycomb-team&quot; value: &quot;{{.env.HONEYCOMB_API_KEY}}&quot; } {key: &quot;x-honeycomb-dataset&quot;, value: &quot;tailcall&quot;} ] } } ) { query: Query }   You can configure the OTLP exporter with the following options:  Field\tDescriptionurl\tDefines the URL for the OTLP Collector. headers\tSets additional headers for requests to the OTLP Collector.  ","version":"Next","tagName":"h3"},{"title":"prometheus​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#prometheus","content":" Facilitates metrics export in a Prometheus compatible format, providing a dedicated endpoint for metrics.  schema @telemetry(export: {prometheus: {path: &quot;/metrics&quot;}}) { query: Query }   You can configure the Prometheus exporter with the following options:  Field\tDescriptionpath\tDesignates the endpoint path for Prometheus metrics, defaulting to /metrics. format\tControls the format viz. text or protobuf, for sending data to Prometheus.  ","version":"Next","tagName":"h3"},{"title":"stdout​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#stdout","content":" Outputs all telemetry data to stdout, ideal for testing or local development environments.  schema @telemetry(export: {stdout: {pretty: true}}) { query: Query }   You can configure the stdout exporter with the following options:  Field\tDescriptionpretty\tEnables formatted output of telemetry data for enhanced readability.  ","version":"Next","tagName":"h3"},{"title":"requestHeaders​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#requestheaders","content":" Specifies list of headers of ingress request the value of which will be sent to the telemetry as attributes.  schema @telemetry(requestHeaders: [&quot;X-User-Id&quot;]) { query: Query }   ","version":"Next","tagName":"h3"},{"title":"apollo​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#apollo","content":" Facilitates seamless integration with Apollo Studio, enhancing the observability of GraphQL services. By leveraging this field, developers gain access to valuable insights into the performance and behavior of their GraphQL APIs.  schema @telemetry( export: { otlp: { api_key: &quot;{{.env.APOLLO_API_KEY}}&quot; graph_ref: &quot;graph-id@current&quot; platform: &quot;website.com&quot; version: &quot;1.0.0&quot; } } ) { query: Query }   You can configure the apollo exporter with the following options:  Field\tDescriptionapi_key\tThe API Key generated from Apollo Studio. graph_ref\tThe Graph Ref, which is the graph_id and the variant concatenated using @(i.e. &lt;graph_id&gt;@&lt;variant&gt;) platform\tAn arbitrary value which can contain the name of your website or some other value to identify your deployment uniqely, in case you have multiple deployments. version\tVersion of Apollo which is being used.  By integrating the @telemetry directive into your GraphQL schema, you empower your development teams with critical insights into application performance, enabling proactive optimization and maintenance.  ","version":"Next","tagName":"h3"},{"title":"@upstream Directive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#upstream-directive","content":" The upstream directive enables control over specific aspects of the upstream server connection, including settings such as connection timeouts, keep-alive intervals, and more. The system applies default values if you do not specify them.  schema @upstream(...[UpstreamSetting]...){ query: Query mutation: Mutation }   The document below details the options for UpstreamSetting.  ","version":"Next","tagName":"h2"},{"title":"poolIdleTimeout​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#poolidletimeout","content":" The connection pool waits for this duration in seconds before closing idle connections.  schema @upstream( poolIdleTimeout: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"poolMaxIdlePerHost​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#poolmaxidleperhost","content":" The max number of idle connections each host will maintain.  schema @upstream( poolMaxIdlePerHost: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"keepAliveInterval​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#keepaliveinterval","content":" The time in seconds between each keep-alive message sent to maintain the connection.  schema @upstream( keepAliveInterval: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"keepAliveTimeout​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#keepalivetimeout","content":" The time in seconds that the connection will wait for a keep-alive message before closing.  schema @upstream( keepAliveTimeout: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"keepAliveWhileIdle​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#keepalivewhileidle","content":" A boolean value that determines whether to send keep-alive messages while the connection is idle.  schema @upstream( keepAliveWhileIdle: false baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"proxy​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#proxy","content":" The proxy setting defines an intermediary server that routes upstream requests before they reach their intended endpoint. By specifying a proxy URL, you introduce a layer, enabling custom routing and security policies.  schema @upstream( proxy: {url: &quot;http://localhost:3000&quot;} baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   In the provided example, we've set the proxy's url to &quot;http://localhost:3000&quot;. This configuration ensures that all requests aimed at the designated baseURL first go through this proxy. To illustrate, if the baseURL is &quot;http://jsonplaceholder.typicode.com&quot;, any request targeting it initially goes to &quot;http://localhost:3000&quot; before the proxy redirects it to its final destination.  ","version":"Next","tagName":"h3"},{"title":"connectTimeout​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#connecttimeout","content":" The time in seconds that the connection will wait for a response before timing out.  schema @upstream( connectTimeout: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"timeout​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#timeout","content":" The max time in seconds that the connection will wait for a response.  schema @upstream( timeout: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"tcpKeepAlive​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#tcpkeepalive","content":" The time in seconds between each TCP keep-alive message sent to maintain the connection.  schema @upstream( tcpKeepAlive: 60 baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"userAgent​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#useragent","content":" The User-Agent header value for HTTP requests.  schema @upstream( userAgent: &quot;Tailcall/1.0&quot; baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"allowedHeaders​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#allowedheaders","content":" The allowedHeaders configuration defines a set of whitelisted HTTP headers that can be forwarded to upstream services during requests. Without specifying allowedHeaders, the system will not forward any incoming headers to upstream services, offering an extra security layer but potentially limiting necessary data flow. Tailcall compares the provided whitelisted headers in a case-insensitive format.  schema @upstream( allowedHeaders: [&quot;Authorization&quot;, &quot;X-Api-Key&quot;] ) { query: Query mutation: Mutation }   In the example above, the configuration for allowedHeaders permits Authorization and X-Api-Key headers. Thus, requests with these headers will forward them to upstream services; the system ignores all others. This configuration ensures communication of the expected headers to dependent services, emphasizing security and consistency.  ","version":"Next","tagName":"h3"},{"title":"baseURL​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#baseurl-3","content":" This refers to the default base URL for your APIs. If it's not explicitly mentioned in the @upstream directive, then each @http directive must specify its own baseURL. If neither @upstream nor @http provides a baseURL, it results in a compilation error.  schema @upstream( baseURL: &quot;http://jsonplaceholder.typicode.com&quot; ) { query: Query mutation: Mutation }   In this representation, http://jsonplaceholder.typicode.com serves as the baseURL. Thus, all API calls made by @http prepend this URL to their respective paths.  tip Ensure that your base URL remains free from specific path segments. GOOD: @upstream(baseURL: http://jsonplaceholder.typicode.com)BAD: @upstream(baseURL: http://jsonplaceholder.typicode.com/api)  ","version":"Next","tagName":"h3"},{"title":"httpCache​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#httpcache","content":" When httpCache passed with value greater than 0 it directs Tailcall to use HTTP caching mechanisms, following the HTTP Caching RFC to enhance performance by minimizing unnecessary data fetches. If left unspecified, this feature defaults to 0 disabling the caching mechanism.  schema @upstream(httpCache: 42) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"Tips​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#tips","content":" Use batching when other optimization techniques fail to resolve performance issues.Apply batching and thoroughly assess its impact.Understand that batching may make debugging more challenging.  ","version":"Next","tagName":"h3"},{"title":"batch​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#batch-1","content":" An object that specifies the batch settings, including maxSize (the max size of the batch), delay (the delay in milliseconds between each batch), and headers (an array of HTTP headers that the batch will include).  schema @upstream( batch: { maxSize: 1000 delay: 10 headers: [&quot;X-Server&quot;, &quot;Authorization&quot;] } ) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h3"},{"title":"onRequest​","type":1,"pageTitle":"GraphQL Configuration","url":"/docs/tailcall-dsl-graphql-custom-directives/#onrequest-1","content":" Similar to the @http property, this accepts a string value representing a middleware function defined in a JavaScript file. It intercepts all outgoing HTTP requests from the server. This interceptor, written in JavaScript, can be used to modify outgoing requests and also generate artificial responses to customize the behavior of the GraphQL server.  schema @upstream(onRequest: 'someFunctionName') @link(type: Script, src: &quot;path_to/worker.js&quot;) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h3"}],"options":{"highlightResult":true,"id":"default"}}